{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFjrWwbwmm--"
   },
   "source": [
    "# __Demo: Generating Fake Images with Generative Adversarial Networks (GANs)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zAosTOTB-qP"
   },
   "source": [
    "# __Steps to Perform__\n",
    "\n",
    "Step 1: Import the Necessary Libraries\n",
    "\n",
    "Step 2: Load and Preprocess the Data\n",
    "\n",
    "Step 3: Build the Generator and Discriminator\n",
    "\n",
    "Step 4: Compile the Models\n",
    "\n",
    "Step 5: Train the Models\n",
    "\n",
    "Step 6: Execute the Training\n",
    "\n",
    "Step 7: Generate New Images and Evaluate the Model's Performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWSHe4DSf-eN"
   },
   "source": [
    "# __Step 1: Import the Necessary Libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MJUz4u4rdcOQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 10:59:10.370423: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-05 10:59:10.434305: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-05 10:59:13.671238: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-05 10:59:13.721312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-05 10:59:13.722517: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOC-NOTICE: GPU memory for this assignment is capped at 2048MiB\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NlLSckbgHt0"
   },
   "source": [
    "# __Step 2: Load and Preprocess the Data__\n",
    "\n",
    "- Load the MNIST dataset and preprocess it.\n",
    "- Preprocessing involves normalizing the data that can improve models' performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gTjuO07Mdoe5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST data\n",
    "(X_train, _), (_, _) = mnist.load_data()\n",
    "# Normalize to between -1 and 1\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train.shape #(n, h, w, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDoEhcHcgRmZ"
   },
   "source": [
    "# __Step 3: Build the Generator and Discriminator__\n",
    "\n",
    "- Define the generator and discriminator models.\n",
    "- Generator takes a random noise vector as input and outputs an image.\n",
    "- Discriminator takes an image as input and outputs the probability of the image being real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "l0d5rZYeeUmP"
   },
   "outputs": [],
   "source": [
    "# Generator\n",
    "def create_generator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=100, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(784, activation='tanh'))\n",
    "    model.add(Reshape((28, 28, 1)))\n",
    "    return model\n",
    "\n",
    "# Discriminator\n",
    "def create_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28, 1)))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPpH5pVQgYic"
   },
   "source": [
    "# __Step 4: Compile the Models__\n",
    "\n",
    "- Compile the models, which involves defining the loss function and the optimizer.\n",
    "- The loss function evaluates the model's performance, while the optimizer aims to minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KY1zu283eg0C"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 11:13:25.035513: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-05 11:13:25.036968: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-05 11:13:25.038103: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-05 11:13:25.293803: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-05 11:13:25.294761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-05 11:13:25.295596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-05 11:13:25.296398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2048 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "# Create and compile the discriminator\n",
    "discriminator = create_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# Create and compile the generator\n",
    "generator = create_generator()\n",
    "generator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# Create and compile the combined model\n",
    "discriminator.trainable = False\n",
    "gan_input = Input(shape=(100,))\n",
    "x = generator(gan_input)\n",
    "gan_output = discriminator(x)\n",
    "gan = Model(inputs=gan_input, outputs=gan_output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HY3QwDoXgcPs"
   },
   "source": [
    "# __Step 5: Train the Models__\n",
    "\n",
    "- Train the model, which involves feeding data into the models and adjusting the weights of the models based on the output.\n",
    "- The primary aim is for the generator to create images indistinguishable from real images by the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((128,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468.75"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97908145],\n",
       "       [0.9054383 ],\n",
       "       [0.96819051],\n",
       "       [0.90727162],\n",
       "       [0.94130004],\n",
       "       [0.92255733],\n",
       "       [0.92762035],\n",
       "       [0.91829691],\n",
       "       [0.91733863],\n",
       "       [0.9067541 ],\n",
       "       [0.99832862],\n",
       "       [0.94277998],\n",
       "       [0.92865629],\n",
       "       [0.90298298],\n",
       "       [0.92226276],\n",
       "       [0.96773936],\n",
       "       [0.99842188],\n",
       "       [0.99511606],\n",
       "       [0.92209528],\n",
       "       [0.91628959],\n",
       "       [0.9595913 ],\n",
       "       [0.93701116],\n",
       "       [0.97958151],\n",
       "       [0.93912341],\n",
       "       [0.944679  ],\n",
       "       [0.96030781],\n",
       "       [0.93376325],\n",
       "       [0.94980444],\n",
       "       [0.90851337],\n",
       "       [0.98244251],\n",
       "       [0.94793277],\n",
       "       [0.99954843],\n",
       "       [0.94184019],\n",
       "       [0.9105173 ],\n",
       "       [0.9666736 ],\n",
       "       [0.98096565],\n",
       "       [0.96755687],\n",
       "       [0.94133624],\n",
       "       [0.98883313],\n",
       "       [0.96394181],\n",
       "       [0.97574945],\n",
       "       [0.94181928],\n",
       "       [0.9521338 ],\n",
       "       [0.90330797],\n",
       "       [0.9526561 ],\n",
       "       [0.93721689],\n",
       "       [0.98663206],\n",
       "       [0.90022673],\n",
       "       [0.93649119],\n",
       "       [0.99112001],\n",
       "       [0.9722415 ],\n",
       "       [0.91902795],\n",
       "       [0.9037308 ],\n",
       "       [0.95061807],\n",
       "       [0.9369563 ],\n",
       "       [0.91253864],\n",
       "       [0.90399301],\n",
       "       [0.96301355],\n",
       "       [0.90485136],\n",
       "       [0.95690585],\n",
       "       [0.96201911],\n",
       "       [0.98372024],\n",
       "       [0.9208014 ],\n",
       "       [0.94980279],\n",
       "       [0.99895582],\n",
       "       [0.96736683],\n",
       "       [0.96100615],\n",
       "       [0.90024258],\n",
       "       [0.95439603],\n",
       "       [0.97065843],\n",
       "       [0.93224192],\n",
       "       [0.94805818],\n",
       "       [0.99319768],\n",
       "       [0.99764938],\n",
       "       [0.96126307],\n",
       "       [0.9498293 ],\n",
       "       [0.90652817],\n",
       "       [0.96431105],\n",
       "       [0.90810137],\n",
       "       [0.99974419],\n",
       "       [0.92183935],\n",
       "       [0.91841404],\n",
       "       [0.96274815],\n",
       "       [0.94089408],\n",
       "       [0.95531307],\n",
       "       [0.90466835],\n",
       "       [0.91259724],\n",
       "       [0.99976606],\n",
       "       [0.93020773],\n",
       "       [0.97522317],\n",
       "       [0.97025381],\n",
       "       [0.95223358],\n",
       "       [0.93649229],\n",
       "       [0.96999106],\n",
       "       [0.99702503],\n",
       "       [0.98923354],\n",
       "       [0.95355407],\n",
       "       [0.99557091],\n",
       "       [0.90692566],\n",
       "       [0.94388184],\n",
       "       [0.94450596],\n",
       "       [0.99542369],\n",
       "       [0.9319235 ],\n",
       "       [0.94582775],\n",
       "       [0.93981702],\n",
       "       [0.92638178],\n",
       "       [0.91010592],\n",
       "       [0.95061991],\n",
       "       [0.93868598],\n",
       "       [0.90438939],\n",
       "       [0.98931051],\n",
       "       [0.94238392],\n",
       "       [0.94941006],\n",
       "       [0.99389037],\n",
       "       [0.98214596],\n",
       "       [0.95283718],\n",
       "       [0.99457425],\n",
       "       [0.91208294],\n",
       "       [0.95421593],\n",
       "       [0.97403905],\n",
       "       [0.96676693],\n",
       "       [0.92874466],\n",
       "       [0.91041707],\n",
       "       [0.92460294],\n",
       "       [0.90533557],\n",
       "       [0.94695018],\n",
       "       [0.92310374],\n",
       "       [0.99696761]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-np.random.rand(128,1)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "IE9tbYPdenYp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epochs=3, batch_size=128):\n",
    "    # Load the data\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    # Labels for the batch size and the test size\n",
    "    y_train_ones = np.ones((batch_size, 1))\n",
    "    y_train_zeros = np.zeros((batch_size, 1))\n",
    "    y_test_ones = np.ones((100, 1))\n",
    "\n",
    "    # Start training\n",
    "    for e in range(epochs):\n",
    "        for i in range(X_train.shape[0] // batch_size):\n",
    "            # Train Discriminator weights\n",
    "            discriminator.trainable = True\n",
    "\n",
    "            # Real samples\n",
    "            X_batch = X_train[i*batch_size:(i+1)*batch_size]#[0:128:1*128\n",
    "            d_loss_real = discriminator.train_on_batch(x=X_batch, y=y_train_ones * (1 - 0.1 * np.random.rand(batch_size, 1)))\n",
    "\n",
    "            # Fake Samples\n",
    "            z_noise = np.random.normal(loc=0, scale=1, size=(batch_size, 100))\n",
    "            X_fake = generator.predict_on_batch(z_noise)\n",
    "            d_loss_fake = discriminator.train_on_batch(x=X_fake, y=y_train_zeros)\n",
    "\n",
    "            # Discriminator loss\n",
    "            d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "\n",
    "            # Train Generator weights\n",
    "            discriminator.trainable = False\n",
    "            g_loss = gan.train_on_batch(x=z_noise, y=y_train_ones)\n",
    "\n",
    "            print(f'Epoch: {e+1}, Batch: {i}, D Loss: {d_loss}, G Loss: {g_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFwC_WhRgo8q"
   },
   "source": [
    "# __Step 6: Execute the Training__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74Qf18jCes5z",
    "outputId": "7182133e-b227-4f5e-b03d-ad8289a1d0df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 11:25:12.782428: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f42f9f9a200 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-05 11:25:12.782469: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2025-10-05 11:25:12.788240: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-05 11:25:12.828183: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2025-10-05 11:25:13.002910: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 0, D Loss: 0.9065954089164734, G Loss: 0.5996946096420288\n",
      "Epoch: 1, Batch: 1, D Loss: 1.5319864749908447, G Loss: 0.3770087659358978\n",
      "Epoch: 1, Batch: 2, D Loss: 1.0204374939203262, G Loss: 0.8713287115097046\n",
      "Epoch: 1, Batch: 3, D Loss: 0.6988593935966492, G Loss: 0.9626674652099609\n",
      "Epoch: 1, Batch: 4, D Loss: 0.5637899339199066, G Loss: 1.0906956195831299\n",
      "Epoch: 1, Batch: 5, D Loss: 0.42138390243053436, G Loss: 1.5647811889648438\n",
      "Epoch: 1, Batch: 6, D Loss: 0.35409702360630035, G Loss: 1.9898808002471924\n",
      "Epoch: 1, Batch: 7, D Loss: 0.32306383550167084, G Loss: 2.1749675273895264\n",
      "Epoch: 1, Batch: 8, D Loss: 0.2502126917243004, G Loss: 2.5491161346435547\n",
      "Epoch: 1, Batch: 9, D Loss: 0.19657878577709198, G Loss: 2.993393898010254\n",
      "Epoch: 1, Batch: 10, D Loss: 0.17502281069755554, G Loss: 3.1871519088745117\n",
      "Epoch: 1, Batch: 11, D Loss: 0.15764883905649185, G Loss: 3.114168167114258\n",
      "Epoch: 1, Batch: 12, D Loss: 0.1599176563322544, G Loss: 3.032334327697754\n",
      "Epoch: 1, Batch: 13, D Loss: 0.1847844049334526, G Loss: 2.8699512481689453\n",
      "Epoch: 1, Batch: 14, D Loss: 0.1910882666707039, G Loss: 2.483487129211426\n",
      "Epoch: 1, Batch: 15, D Loss: 0.2080075740814209, G Loss: 2.4446029663085938\n",
      "Epoch: 1, Batch: 16, D Loss: 0.23390351235866547, G Loss: 2.1537699699401855\n",
      "Epoch: 1, Batch: 17, D Loss: 0.25021717697381973, G Loss: 2.0492658615112305\n",
      "Epoch: 1, Batch: 18, D Loss: 0.2310977503657341, G Loss: 2.019139289855957\n",
      "Epoch: 1, Batch: 19, D Loss: 0.3366745710372925, G Loss: 1.6848509311676025\n",
      "Epoch: 1, Batch: 20, D Loss: 0.4299202263355255, G Loss: 1.5175070762634277\n",
      "Epoch: 1, Batch: 21, D Loss: 0.502104178071022, G Loss: 1.4446213245391846\n",
      "Epoch: 1, Batch: 22, D Loss: 0.5609160363674164, G Loss: 1.3898727893829346\n",
      "Epoch: 1, Batch: 23, D Loss: 0.49079304933547974, G Loss: 1.3532664775848389\n",
      "Epoch: 1, Batch: 24, D Loss: 0.43487250804901123, G Loss: 1.3212932348251343\n",
      "Epoch: 1, Batch: 25, D Loss: 0.30654899775981903, G Loss: 1.3537964820861816\n",
      "Epoch: 1, Batch: 26, D Loss: 1.7075442224740982, G Loss: 0.9830014109611511\n",
      "Epoch: 1, Batch: 27, D Loss: 0.4615401029586792, G Loss: 0.8482818007469177\n",
      "Epoch: 1, Batch: 28, D Loss: 0.5895051062107086, G Loss: 0.8535921573638916\n",
      "Epoch: 1, Batch: 29, D Loss: 0.5764086544513702, G Loss: 1.0768463611602783\n",
      "Epoch: 1, Batch: 30, D Loss: 0.46346406638622284, G Loss: 1.6792556047439575\n",
      "Epoch: 1, Batch: 31, D Loss: 0.23638293147087097, G Loss: 2.7302818298339844\n",
      "Epoch: 1, Batch: 32, D Loss: 2.0810359716415405, G Loss: 1.4751008749008179\n",
      "Epoch: 1, Batch: 33, D Loss: 0.5430511832237244, G Loss: 0.6818649768829346\n",
      "Epoch: 1, Batch: 34, D Loss: 0.8872165679931641, G Loss: 0.4773007333278656\n",
      "Epoch: 1, Batch: 35, D Loss: 0.9872708022594452, G Loss: 0.49168282747268677\n",
      "Epoch: 1, Batch: 36, D Loss: 0.9631316661834717, G Loss: 0.6653797626495361\n",
      "Epoch: 1, Batch: 37, D Loss: 0.7319395244121552, G Loss: 1.1961737871170044\n",
      "Epoch: 1, Batch: 38, D Loss: 0.4231926202774048, G Loss: 2.2988927364349365\n",
      "Epoch: 1, Batch: 39, D Loss: 0.1757761687040329, G Loss: 3.1592235565185547\n",
      "Epoch: 1, Batch: 40, D Loss: 2.503074422478676, G Loss: 0.8968528509140015\n",
      "Epoch: 1, Batch: 41, D Loss: 0.7011726945638657, G Loss: 0.3743112087249756\n",
      "Epoch: 1, Batch: 42, D Loss: 0.9503026008605957, G Loss: 0.31129246950149536\n",
      "Epoch: 1, Batch: 43, D Loss: 0.9897676706314087, G Loss: 0.39611220359802246\n",
      "Epoch: 1, Batch: 44, D Loss: 0.7131165564060211, G Loss: 0.84993976354599\n",
      "Epoch: 1, Batch: 45, D Loss: 0.3613650053739548, G Loss: 2.579498767852783\n",
      "Epoch: 1, Batch: 46, D Loss: 0.13817030936479568, G Loss: 4.337940216064453\n",
      "Epoch: 1, Batch: 47, D Loss: 0.6974742747843266, G Loss: 3.479297161102295\n",
      "Epoch: 1, Batch: 48, D Loss: 0.18588221073150635, G Loss: 2.591031074523926\n",
      "Epoch: 1, Batch: 49, D Loss: 0.3173641413450241, G Loss: 1.973254680633545\n",
      "Epoch: 1, Batch: 50, D Loss: 0.3433980494737625, G Loss: 2.0576508045196533\n",
      "Epoch: 1, Batch: 51, D Loss: 0.27483999729156494, G Loss: 2.444990873336792\n",
      "Epoch: 1, Batch: 52, D Loss: 0.881909966468811, G Loss: 0.7209867238998413\n",
      "Epoch: 1, Batch: 53, D Loss: 0.5913102626800537, G Loss: 0.5740728378295898\n",
      "Epoch: 1, Batch: 54, D Loss: 0.6832533627748489, G Loss: 0.5867367386817932\n",
      "Epoch: 1, Batch: 55, D Loss: 0.6861416697502136, G Loss: 0.6674923896789551\n",
      "Epoch: 1, Batch: 56, D Loss: 0.653860867023468, G Loss: 0.8001565933227539\n",
      "Epoch: 1, Batch: 57, D Loss: 0.4958365857601166, G Loss: 1.1195811033248901\n",
      "Epoch: 1, Batch: 58, D Loss: 0.3226322531700134, G Loss: 1.6541259288787842\n",
      "Epoch: 1, Batch: 59, D Loss: 0.17689798027276993, G Loss: 2.4199411869049072\n",
      "Epoch: 1, Batch: 60, D Loss: 0.5001547187566757, G Loss: 2.466029644012451\n",
      "Epoch: 1, Batch: 61, D Loss: 0.15455802157521248, G Loss: 2.5763161182403564\n",
      "Epoch: 1, Batch: 62, D Loss: 0.1923142485320568, G Loss: 2.7319421768188477\n",
      "Epoch: 1, Batch: 63, D Loss: 0.2195473238825798, G Loss: 2.9017105102539062\n",
      "Epoch: 1, Batch: 64, D Loss: 0.21999720111489296, G Loss: 3.0371124744415283\n",
      "Epoch: 1, Batch: 65, D Loss: 0.1841505914926529, G Loss: 3.297903537750244\n",
      "Epoch: 1, Batch: 66, D Loss: 0.1442459188401699, G Loss: 3.4209203720092773\n",
      "Epoch: 1, Batch: 67, D Loss: 0.42540648579597473, G Loss: 1.8676955699920654\n",
      "Epoch: 1, Batch: 68, D Loss: 0.3693421930074692, G Loss: 1.036862850189209\n",
      "Epoch: 1, Batch: 69, D Loss: 0.5720251053571701, G Loss: 0.7766638994216919\n",
      "Epoch: 1, Batch: 70, D Loss: 0.6142572313547134, G Loss: 0.7527059316635132\n",
      "Epoch: 1, Batch: 71, D Loss: 0.5240564942359924, G Loss: 0.8788902163505554\n",
      "Epoch: 1, Batch: 72, D Loss: 0.44700418412685394, G Loss: 1.2767083644866943\n",
      "Epoch: 1, Batch: 73, D Loss: 0.2923431992530823, G Loss: 1.8933699131011963\n",
      "Epoch: 1, Batch: 74, D Loss: 1.0252007097005844, G Loss: 0.7600065469741821\n",
      "Epoch: 1, Batch: 75, D Loss: 0.605800598859787, G Loss: 0.5327178239822388\n",
      "Epoch: 1, Batch: 76, D Loss: 0.7647345662117004, G Loss: 0.48990780115127563\n",
      "Epoch: 1, Batch: 77, D Loss: 0.8258481323719025, G Loss: 0.5263424515724182\n",
      "Epoch: 1, Batch: 78, D Loss: 0.7559948861598969, G Loss: 0.6539990305900574\n",
      "Epoch: 1, Batch: 79, D Loss: 0.5872502326965332, G Loss: 0.9591243267059326\n",
      "Epoch: 1, Batch: 80, D Loss: 0.38868245482444763, G Loss: 1.7745156288146973\n",
      "Epoch: 1, Batch: 81, D Loss: 0.21953042596578598, G Loss: 3.1909446716308594\n",
      "Epoch: 1, Batch: 82, D Loss: 0.1265604691579938, G Loss: 4.77082633972168\n",
      "Epoch: 1, Batch: 83, D Loss: 0.2210823567584157, G Loss: 5.218914985656738\n",
      "Epoch: 1, Batch: 84, D Loss: 0.15520120225846767, G Loss: 5.049942970275879\n",
      "Epoch: 1, Batch: 85, D Loss: 0.10848910920321941, G Loss: 4.713385581970215\n",
      "Epoch: 1, Batch: 86, D Loss: 0.12733275443315506, G Loss: 4.3612775802612305\n",
      "Epoch: 1, Batch: 87, D Loss: 0.13822343200445175, G Loss: 4.051931858062744\n",
      "Epoch: 1, Batch: 88, D Loss: 0.15464778430759907, G Loss: 3.8925857543945312\n",
      "Epoch: 1, Batch: 89, D Loss: 0.1422123685479164, G Loss: 3.9094738960266113\n",
      "Epoch: 1, Batch: 90, D Loss: 0.12877168506383896, G Loss: 3.824239492416382\n",
      "Epoch: 1, Batch: 91, D Loss: 0.15141187235713005, G Loss: 3.2282602787017822\n",
      "Epoch: 1, Batch: 92, D Loss: 0.15256903320550919, G Loss: 2.871572971343994\n",
      "Epoch: 1, Batch: 93, D Loss: 0.1620815023779869, G Loss: 2.9682860374450684\n",
      "Epoch: 1, Batch: 94, D Loss: 0.17485813423991203, G Loss: 3.1044769287109375\n",
      "Epoch: 1, Batch: 95, D Loss: 0.37002164125442505, G Loss: 1.4253809452056885\n",
      "Epoch: 1, Batch: 96, D Loss: 0.39774133265018463, G Loss: 1.5392130613327026\n",
      "Epoch: 1, Batch: 97, D Loss: 0.24388659000396729, G Loss: 2.9967031478881836\n",
      "Epoch: 1, Batch: 98, D Loss: 0.14583164267241955, G Loss: 4.3576130867004395\n",
      "Epoch: 1, Batch: 99, D Loss: 0.8125381320714951, G Loss: 0.6267070770263672\n",
      "Epoch: 1, Batch: 100, D Loss: 0.6705026924610138, G Loss: 0.4350397288799286\n",
      "Epoch: 1, Batch: 101, D Loss: 0.8173601031303406, G Loss: 0.40484774112701416\n",
      "Epoch: 1, Batch: 102, D Loss: 0.8178979456424713, G Loss: 0.4666125774383545\n",
      "Epoch: 1, Batch: 103, D Loss: 0.6982965022325516, G Loss: 0.6155255436897278\n",
      "Epoch: 1, Batch: 104, D Loss: 0.5418973416090012, G Loss: 0.9045395255088806\n",
      "Epoch: 1, Batch: 105, D Loss: 0.3306504487991333, G Loss: 1.3590970039367676\n",
      "Epoch: 1, Batch: 106, D Loss: 0.23639096319675446, G Loss: 1.9287464618682861\n",
      "Epoch: 1, Batch: 107, D Loss: 0.552469328045845, G Loss: 1.7921130657196045\n",
      "Epoch: 1, Batch: 108, D Loss: 0.22201286256313324, G Loss: 1.6813793182373047\n",
      "Epoch: 1, Batch: 109, D Loss: 0.26583269983530045, G Loss: 1.6393473148345947\n",
      "Epoch: 1, Batch: 110, D Loss: 0.2961120381951332, G Loss: 1.8655471801757812\n",
      "Epoch: 1, Batch: 111, D Loss: 0.28344154357910156, G Loss: 2.1654672622680664\n",
      "Epoch: 1, Batch: 112, D Loss: 0.23964856564998627, G Loss: 2.3782799243927\n",
      "Epoch: 1, Batch: 113, D Loss: 0.5136617720127106, G Loss: 1.3625602722167969\n",
      "Epoch: 1, Batch: 114, D Loss: 0.9044903516769409, G Loss: 0.5458204746246338\n",
      "Epoch: 1, Batch: 115, D Loss: 0.9233729392290115, G Loss: 0.4671698808670044\n",
      "Epoch: 1, Batch: 116, D Loss: 0.6687128692865372, G Loss: 0.9986110925674438\n",
      "Epoch: 1, Batch: 117, D Loss: 0.3963732123374939, G Loss: 2.449507474899292\n",
      "Epoch: 1, Batch: 118, D Loss: 0.22422591596841812, G Loss: 3.894029140472412\n",
      "Epoch: 1, Batch: 119, D Loss: 0.17082922160625458, G Loss: 3.9060864448547363\n",
      "Epoch: 1, Batch: 120, D Loss: 0.1653822846710682, G Loss: 3.75463604927063\n",
      "Epoch: 1, Batch: 121, D Loss: 0.2291901484131813, G Loss: 3.4549970626831055\n",
      "Epoch: 1, Batch: 122, D Loss: 0.8557532131671906, G Loss: 1.4758707284927368\n",
      "Epoch: 1, Batch: 123, D Loss: 1.129719078540802, G Loss: 1.3729385137557983\n",
      "Epoch: 1, Batch: 124, D Loss: 1.7927474975585938, G Loss: 0.489767849445343\n",
      "Epoch: 1, Batch: 125, D Loss: 1.0213249623775482, G Loss: 0.97601318359375\n",
      "Epoch: 1, Batch: 126, D Loss: 0.464748814702034, G Loss: 2.189436912536621\n",
      "Epoch: 1, Batch: 127, D Loss: 0.5607409626245499, G Loss: 2.2434959411621094\n",
      "Epoch: 1, Batch: 128, D Loss: 0.17234625667333603, G Loss: 3.1216042041778564\n",
      "Epoch: 1, Batch: 129, D Loss: 0.12480226811021566, G Loss: 5.0695648193359375\n",
      "Epoch: 1, Batch: 130, D Loss: 0.10890906397253275, G Loss: 6.776630878448486\n",
      "Epoch: 1, Batch: 131, D Loss: 0.11605080857407302, G Loss: 7.196026802062988\n",
      "Epoch: 1, Batch: 132, D Loss: 0.11697792098857462, G Loss: 6.298527717590332\n",
      "Epoch: 1, Batch: 133, D Loss: 0.14530013501644135, G Loss: 4.485533714294434\n",
      "Epoch: 1, Batch: 134, D Loss: 0.18900355696678162, G Loss: 4.177524089813232\n",
      "Epoch: 1, Batch: 135, D Loss: 0.2347048670053482, G Loss: 4.726032733917236\n",
      "Epoch: 1, Batch: 136, D Loss: 0.6259780526161194, G Loss: 3.288240909576416\n",
      "Epoch: 1, Batch: 137, D Loss: 0.9056331515312195, G Loss: 3.5998616218566895\n",
      "Epoch: 1, Batch: 138, D Loss: 1.065349817276001, G Loss: 2.4093477725982666\n",
      "Epoch: 1, Batch: 139, D Loss: 0.9175819754600525, G Loss: 2.5351366996765137\n",
      "Epoch: 1, Batch: 140, D Loss: 0.5715506970882416, G Loss: 2.9353508949279785\n",
      "Epoch: 1, Batch: 141, D Loss: 0.8244032859802246, G Loss: 2.1015913486480713\n",
      "Epoch: 1, Batch: 142, D Loss: 0.5353195518255234, G Loss: 2.7229702472686768\n",
      "Epoch: 1, Batch: 143, D Loss: 0.34756775945425034, G Loss: 3.3228769302368164\n",
      "Epoch: 1, Batch: 144, D Loss: 0.3373628258705139, G Loss: 2.9341049194335938\n",
      "Epoch: 1, Batch: 145, D Loss: 0.31054793298244476, G Loss: 2.8938755989074707\n",
      "Epoch: 1, Batch: 146, D Loss: 0.19383380562067032, G Loss: 3.7780001163482666\n",
      "Epoch: 1, Batch: 147, D Loss: 0.16965178400278091, G Loss: 4.549264907836914\n",
      "Epoch: 1, Batch: 148, D Loss: 0.1669224388897419, G Loss: 5.0457892417907715\n",
      "Epoch: 1, Batch: 149, D Loss: 0.1603926457464695, G Loss: 5.2198967933654785\n",
      "Epoch: 1, Batch: 150, D Loss: 0.1647503338754177, G Loss: 4.8527092933654785\n",
      "Epoch: 1, Batch: 151, D Loss: 0.20804493129253387, G Loss: 4.233697414398193\n",
      "Epoch: 1, Batch: 152, D Loss: 0.23108576238155365, G Loss: 3.9369444847106934\n",
      "Epoch: 1, Batch: 153, D Loss: 0.25346724689006805, G Loss: 3.6921658515930176\n",
      "Epoch: 1, Batch: 154, D Loss: 0.292561873793602, G Loss: 2.853245496749878\n",
      "Epoch: 1, Batch: 155, D Loss: 0.27909426391124725, G Loss: 2.369762420654297\n",
      "Epoch: 1, Batch: 156, D Loss: 0.20969760417938232, G Loss: 2.6387953758239746\n",
      "Epoch: 1, Batch: 157, D Loss: 0.17404110729694366, G Loss: 3.1497325897216797\n",
      "Epoch: 1, Batch: 158, D Loss: 0.1541837602853775, G Loss: 3.4381918907165527\n",
      "Epoch: 1, Batch: 159, D Loss: 0.13906381651759148, G Loss: 3.6532862186431885\n",
      "Epoch: 1, Batch: 160, D Loss: 0.15145941823720932, G Loss: 3.4982481002807617\n",
      "Epoch: 1, Batch: 161, D Loss: 0.14955637976527214, G Loss: 3.6434693336486816\n",
      "Epoch: 1, Batch: 162, D Loss: 0.1856260746717453, G Loss: 3.0602428913116455\n",
      "Epoch: 1, Batch: 163, D Loss: 0.19048701226711273, G Loss: 3.1622533798217773\n",
      "Epoch: 1, Batch: 164, D Loss: 0.29668015241622925, G Loss: 2.6073975563049316\n",
      "Epoch: 1, Batch: 165, D Loss: 0.5246692001819611, G Loss: 1.6324036121368408\n",
      "Epoch: 1, Batch: 166, D Loss: 0.5456734597682953, G Loss: 1.778778314590454\n",
      "Epoch: 1, Batch: 167, D Loss: 1.1190025806427002, G Loss: 0.5318722724914551\n",
      "Epoch: 1, Batch: 168, D Loss: 0.710412859916687, G Loss: 1.101343035697937\n",
      "Epoch: 1, Batch: 169, D Loss: 0.3062075972557068, G Loss: 2.4168763160705566\n",
      "Epoch: 1, Batch: 170, D Loss: 0.8492215499281883, G Loss: 1.5241520404815674\n",
      "Epoch: 1, Batch: 171, D Loss: 0.378079354763031, G Loss: 1.4363824129104614\n",
      "Epoch: 1, Batch: 172, D Loss: 0.23613376915454865, G Loss: 2.6202192306518555\n",
      "Epoch: 1, Batch: 173, D Loss: 0.13304691016674042, G Loss: 4.251136302947998\n",
      "Epoch: 1, Batch: 174, D Loss: 0.17316731996834278, G Loss: 4.517544746398926\n",
      "Epoch: 1, Batch: 175, D Loss: 0.1812196522951126, G Loss: 3.2737035751342773\n",
      "Epoch: 1, Batch: 176, D Loss: 0.25557102262973785, G Loss: 3.054232120513916\n",
      "Epoch: 1, Batch: 177, D Loss: 0.20415906608104706, G Loss: 4.5698652267456055\n",
      "Epoch: 1, Batch: 178, D Loss: 0.43703311681747437, G Loss: 3.369837522506714\n",
      "Epoch: 1, Batch: 179, D Loss: 0.6791886240243912, G Loss: 4.293839931488037\n",
      "Epoch: 1, Batch: 180, D Loss: 0.777848869562149, G Loss: 3.5123672485351562\n",
      "Epoch: 1, Batch: 181, D Loss: 0.3236475884914398, G Loss: 4.224058151245117\n",
      "Epoch: 1, Batch: 182, D Loss: 0.18751153908669949, G Loss: 5.3841681480407715\n",
      "Epoch: 1, Batch: 183, D Loss: 0.14146954100579023, G Loss: 6.1641316413879395\n",
      "Epoch: 1, Batch: 184, D Loss: 0.12917498499155045, G Loss: 6.3749308586120605\n",
      "Epoch: 1, Batch: 185, D Loss: 0.13293079938739538, G Loss: 6.42494535446167\n",
      "Epoch: 1, Batch: 186, D Loss: 0.13255352806299925, G Loss: 6.596048355102539\n",
      "Epoch: 1, Batch: 187, D Loss: 0.12435313104651868, G Loss: 6.84205436706543\n",
      "Epoch: 1, Batch: 188, D Loss: 0.13092672359198332, G Loss: 5.643711566925049\n",
      "Epoch: 1, Batch: 189, D Loss: 0.1827300675213337, G Loss: 5.948112964630127\n",
      "Epoch: 1, Batch: 190, D Loss: 0.12219228316098452, G Loss: 8.758965492248535\n",
      "Epoch: 1, Batch: 191, D Loss: 0.11657873180229217, G Loss: 9.984819412231445\n",
      "Epoch: 1, Batch: 192, D Loss: 0.13813093985663727, G Loss: 8.002384185791016\n",
      "Epoch: 1, Batch: 193, D Loss: 0.13180710468441248, G Loss: 6.475998401641846\n",
      "Epoch: 1, Batch: 194, D Loss: 0.12821093201637268, G Loss: 7.300521373748779\n",
      "Epoch: 1, Batch: 195, D Loss: 0.12354336422868073, G Loss: 8.825754165649414\n",
      "Epoch: 1, Batch: 196, D Loss: 0.23353339917957783, G Loss: 5.684720039367676\n",
      "Epoch: 1, Batch: 197, D Loss: 0.17446424439549446, G Loss: 10.079751014709473\n",
      "Epoch: 1, Batch: 198, D Loss: 0.11863995998646715, G Loss: 17.15943717956543\n",
      "Epoch: 1, Batch: 199, D Loss: 0.21927449045915637, G Loss: 12.307928085327148\n",
      "Epoch: 1, Batch: 200, D Loss: 0.14170160476351157, G Loss: 8.341178894042969\n",
      "Epoch: 1, Batch: 201, D Loss: 0.1788488794118166, G Loss: 6.326412200927734\n",
      "Epoch: 1, Batch: 202, D Loss: 0.19599668867886066, G Loss: 7.6627349853515625\n",
      "Epoch: 1, Batch: 203, D Loss: 0.15147175476886332, G Loss: 9.932991027832031\n",
      "Epoch: 1, Batch: 204, D Loss: 0.13279060076456517, G Loss: 9.581047058105469\n",
      "Epoch: 1, Batch: 205, D Loss: 0.24969256669282913, G Loss: 5.914708614349365\n",
      "Epoch: 1, Batch: 206, D Loss: 0.32603631913661957, G Loss: 10.708208084106445\n",
      "Epoch: 1, Batch: 207, D Loss: 0.688943749293685, G Loss: 3.6322453022003174\n",
      "Epoch: 1, Batch: 208, D Loss: 0.5746443569660187, G Loss: 10.483528137207031\n",
      "Epoch: 1, Batch: 209, D Loss: 0.12390718485844232, G Loss: 28.875652313232422\n",
      "Epoch: 1, Batch: 210, D Loss: 2.33077812463216, G Loss: 16.84055519104004\n",
      "Epoch: 1, Batch: 211, D Loss: 0.13538166265607288, G Loss: 9.142815589904785\n",
      "Epoch: 1, Batch: 212, D Loss: 0.14207742555299774, G Loss: 5.449429035186768\n",
      "Epoch: 1, Batch: 213, D Loss: 0.19024075753986835, G Loss: 3.907867193222046\n",
      "Epoch: 1, Batch: 214, D Loss: 0.19929546676576138, G Loss: 3.8984718322753906\n",
      "Epoch: 1, Batch: 215, D Loss: 0.19363028928637505, G Loss: 4.924063205718994\n",
      "Epoch: 1, Batch: 216, D Loss: 0.18677546177059412, G Loss: 6.151814937591553\n",
      "Epoch: 1, Batch: 217, D Loss: 0.16481695300899446, G Loss: 7.069680690765381\n",
      "Epoch: 1, Batch: 218, D Loss: 0.16461155895376578, G Loss: 7.772359371185303\n",
      "Epoch: 1, Batch: 219, D Loss: 0.14009919951786287, G Loss: 8.31745719909668\n",
      "Epoch: 1, Batch: 220, D Loss: 0.11837044497951865, G Loss: 8.551301956176758\n",
      "Epoch: 1, Batch: 221, D Loss: 0.10564657536451705, G Loss: 8.670730590820312\n",
      "Epoch: 1, Batch: 222, D Loss: 0.10185224219458178, G Loss: 8.47421646118164\n",
      "Epoch: 1, Batch: 223, D Loss: 0.10473672125954181, G Loss: 7.251947402954102\n",
      "Epoch: 1, Batch: 224, D Loss: 0.1134514226578176, G Loss: 5.870275497436523\n",
      "Epoch: 1, Batch: 225, D Loss: 0.11354305036365986, G Loss: 4.354985237121582\n",
      "Epoch: 1, Batch: 226, D Loss: 0.13096223026514053, G Loss: 3.7760391235351562\n",
      "Epoch: 1, Batch: 227, D Loss: 0.13135365024209023, G Loss: 4.042215347290039\n",
      "Epoch: 1, Batch: 228, D Loss: 0.12317366153001785, G Loss: 4.784975051879883\n",
      "Epoch: 1, Batch: 229, D Loss: 0.11821052432060242, G Loss: 5.225094318389893\n",
      "Epoch: 1, Batch: 230, D Loss: 0.12058755988255143, G Loss: 5.375056266784668\n",
      "Epoch: 1, Batch: 231, D Loss: 0.1257843878120184, G Loss: 5.048041343688965\n",
      "Epoch: 1, Batch: 232, D Loss: 0.13802162185311317, G Loss: 4.422239303588867\n",
      "Epoch: 1, Batch: 233, D Loss: 0.18915417045354843, G Loss: 4.878396034240723\n",
      "Epoch: 1, Batch: 234, D Loss: 0.16368889436125755, G Loss: 5.682305335998535\n",
      "Epoch: 1, Batch: 235, D Loss: 0.3709690719842911, G Loss: 5.8603386878967285\n",
      "Epoch: 1, Batch: 236, D Loss: 0.3356222752481699, G Loss: 5.191989421844482\n",
      "Epoch: 1, Batch: 237, D Loss: 0.17602556385099888, G Loss: 5.06757116317749\n",
      "Epoch: 1, Batch: 238, D Loss: 0.11251942813396454, G Loss: 5.764134407043457\n",
      "Epoch: 1, Batch: 239, D Loss: 0.1313068149611354, G Loss: 5.689009666442871\n",
      "Epoch: 1, Batch: 240, D Loss: 0.13246813416481018, G Loss: 5.949793815612793\n",
      "Epoch: 1, Batch: 241, D Loss: 0.12263507302850485, G Loss: 6.863509178161621\n",
      "Epoch: 1, Batch: 242, D Loss: 0.13200166076421738, G Loss: 7.26751184463501\n",
      "Epoch: 1, Batch: 243, D Loss: 0.15107238572090864, G Loss: 5.482741832733154\n",
      "Epoch: 1, Batch: 244, D Loss: 0.14073514938354492, G Loss: 4.089776992797852\n",
      "Epoch: 1, Batch: 245, D Loss: 0.14205852150917053, G Loss: 5.326665878295898\n",
      "Epoch: 1, Batch: 246, D Loss: 0.11624430422671139, G Loss: 7.73388671875\n",
      "Epoch: 1, Batch: 247, D Loss: 0.10626588818558957, G Loss: 9.42930793762207\n",
      "Epoch: 1, Batch: 248, D Loss: 0.11966874665085925, G Loss: 10.007635116577148\n",
      "Epoch: 1, Batch: 249, D Loss: 0.11949340702267364, G Loss: 9.554420471191406\n",
      "Epoch: 1, Batch: 250, D Loss: 0.10996058859745972, G Loss: 9.036920547485352\n",
      "Epoch: 1, Batch: 251, D Loss: 0.11608013285149354, G Loss: 8.938789367675781\n",
      "Epoch: 1, Batch: 252, D Loss: 0.12868662345863413, G Loss: 9.093286514282227\n",
      "Epoch: 1, Batch: 253, D Loss: 0.10703256750275614, G Loss: 9.256308555603027\n",
      "Epoch: 1, Batch: 254, D Loss: 0.10360252458485775, G Loss: 9.191995620727539\n",
      "Epoch: 1, Batch: 255, D Loss: 0.10261981392977759, G Loss: 8.747435569763184\n",
      "Epoch: 1, Batch: 256, D Loss: 0.10177881619893014, G Loss: 8.178894996643066\n",
      "Epoch: 1, Batch: 257, D Loss: 0.10545533747063018, G Loss: 7.413257598876953\n",
      "Epoch: 1, Batch: 258, D Loss: 0.10651602642610669, G Loss: 5.999783515930176\n",
      "Epoch: 1, Batch: 259, D Loss: 0.11991530004888773, G Loss: 5.06459903717041\n",
      "Epoch: 1, Batch: 260, D Loss: 0.1132911890745163, G Loss: 5.014034271240234\n",
      "Epoch: 1, Batch: 261, D Loss: 0.10912501066923141, G Loss: 5.711423397064209\n",
      "Epoch: 1, Batch: 262, D Loss: 0.09976744826417416, G Loss: 6.687366485595703\n",
      "Epoch: 1, Batch: 263, D Loss: 0.10390518448548391, G Loss: 7.48884391784668\n",
      "Epoch: 1, Batch: 264, D Loss: 0.10994324722560123, G Loss: 8.00527572631836\n",
      "Epoch: 1, Batch: 265, D Loss: 0.10726025181065779, G Loss: 8.14394760131836\n",
      "Epoch: 1, Batch: 266, D Loss: 0.10836322151590139, G Loss: 7.734516143798828\n",
      "Epoch: 1, Batch: 267, D Loss: 0.09994115083827637, G Loss: 7.581732749938965\n",
      "Epoch: 1, Batch: 268, D Loss: 0.10952118563000113, G Loss: 7.6391377449035645\n",
      "Epoch: 1, Batch: 269, D Loss: 0.09764982623164542, G Loss: 7.671366214752197\n",
      "Epoch: 1, Batch: 270, D Loss: 0.10546472325222567, G Loss: 7.668905735015869\n",
      "Epoch: 1, Batch: 271, D Loss: 0.10025416949065402, G Loss: 7.61208438873291\n",
      "Epoch: 1, Batch: 272, D Loss: 0.10368611724697985, G Loss: 7.475579261779785\n",
      "Epoch: 1, Batch: 273, D Loss: 0.10313894436694682, G Loss: 7.2365570068359375\n",
      "Epoch: 1, Batch: 274, D Loss: 0.09903661499265581, G Loss: 6.64529275894165\n",
      "Epoch: 1, Batch: 275, D Loss: 0.1021215432556346, G Loss: 5.775553226470947\n",
      "Epoch: 1, Batch: 276, D Loss: 0.10687618143856525, G Loss: 5.491868019104004\n",
      "Epoch: 1, Batch: 277, D Loss: 0.10091722011566162, G Loss: 5.872760772705078\n",
      "Epoch: 1, Batch: 278, D Loss: 0.11168201314285398, G Loss: 6.5832109451293945\n",
      "Epoch: 1, Batch: 279, D Loss: 0.10431348311249167, G Loss: 7.302577972412109\n",
      "Epoch: 1, Batch: 280, D Loss: 0.10684800386661664, G Loss: 7.387580871582031\n",
      "Epoch: 1, Batch: 281, D Loss: 0.10325033782282844, G Loss: 7.035052299499512\n",
      "Epoch: 1, Batch: 282, D Loss: 0.09898036730010062, G Loss: 6.695555210113525\n",
      "Epoch: 1, Batch: 283, D Loss: 0.10454386624041945, G Loss: 6.661730766296387\n",
      "Epoch: 1, Batch: 284, D Loss: 0.1072758206864819, G Loss: 6.742048740386963\n",
      "Epoch: 1, Batch: 285, D Loss: 0.0988341134507209, G Loss: 7.089483737945557\n",
      "Epoch: 1, Batch: 286, D Loss: 0.10804684169124812, G Loss: 7.595389366149902\n",
      "Epoch: 1, Batch: 287, D Loss: 0.10101477458374575, G Loss: 7.86973762512207\n",
      "Epoch: 1, Batch: 288, D Loss: 0.09834477247204632, G Loss: 7.660548686981201\n",
      "Epoch: 1, Batch: 289, D Loss: 0.09758494247216731, G Loss: 7.071093559265137\n",
      "Epoch: 1, Batch: 290, D Loss: 0.10764436988392845, G Loss: 6.6481170654296875\n",
      "Epoch: 1, Batch: 291, D Loss: 0.10196851985529065, G Loss: 6.245635032653809\n",
      "Epoch: 1, Batch: 292, D Loss: 0.10440530418418348, G Loss: 6.363237380981445\n",
      "Epoch: 1, Batch: 293, D Loss: 0.10668707126751542, G Loss: 6.707693099975586\n",
      "Epoch: 1, Batch: 294, D Loss: 0.10152327129617333, G Loss: 6.80971097946167\n",
      "Epoch: 1, Batch: 295, D Loss: 0.1153588299639523, G Loss: 6.377758502960205\n",
      "Epoch: 1, Batch: 296, D Loss: 0.12446554936468601, G Loss: 6.316425323486328\n",
      "Epoch: 1, Batch: 297, D Loss: 0.11766857746988535, G Loss: 6.638800621032715\n",
      "Epoch: 1, Batch: 298, D Loss: 0.12045324128121138, G Loss: 6.638715744018555\n",
      "Epoch: 1, Batch: 299, D Loss: 0.10554825887084007, G Loss: 6.563680648803711\n",
      "Epoch: 1, Batch: 300, D Loss: 0.1130331908352673, G Loss: 6.785892486572266\n",
      "Epoch: 1, Batch: 301, D Loss: 0.10833689942955971, G Loss: 7.331477165222168\n",
      "Epoch: 1, Batch: 302, D Loss: 0.10388499079272151, G Loss: 7.784494876861572\n",
      "Epoch: 1, Batch: 303, D Loss: 0.10403523145942017, G Loss: 7.4968953132629395\n",
      "Epoch: 1, Batch: 304, D Loss: 0.10422309418208897, G Loss: 6.9615960121154785\n",
      "Epoch: 1, Batch: 305, D Loss: 0.1056644634809345, G Loss: 5.927478790283203\n",
      "Epoch: 1, Batch: 306, D Loss: 0.10320005565881729, G Loss: 6.443521499633789\n",
      "Epoch: 1, Batch: 307, D Loss: 0.10127563891001046, G Loss: 7.479502201080322\n",
      "Epoch: 1, Batch: 308, D Loss: 0.10743312130216509, G Loss: 7.870250225067139\n",
      "Epoch: 1, Batch: 309, D Loss: 0.10104305681306869, G Loss: 7.5150628089904785\n",
      "Epoch: 1, Batch: 310, D Loss: 0.10607995529426262, G Loss: 7.0645599365234375\n",
      "Epoch: 1, Batch: 311, D Loss: 0.09890142129734159, G Loss: 7.127973556518555\n",
      "Epoch: 1, Batch: 312, D Loss: 0.10555506823584437, G Loss: 7.718961715698242\n",
      "Epoch: 1, Batch: 313, D Loss: 0.10637252358719707, G Loss: 8.3422269821167\n",
      "Epoch: 1, Batch: 314, D Loss: 0.09974898627842776, G Loss: 8.477018356323242\n",
      "Epoch: 1, Batch: 315, D Loss: 0.09646289746160619, G Loss: 7.849129676818848\n",
      "Epoch: 1, Batch: 316, D Loss: 0.10242850461509079, G Loss: 7.036693572998047\n",
      "Epoch: 1, Batch: 317, D Loss: 0.10122229147236794, G Loss: 6.88938045501709\n",
      "Epoch: 1, Batch: 318, D Loss: 0.10129279573448002, G Loss: 7.308467388153076\n",
      "Epoch: 1, Batch: 319, D Loss: 0.10429351462516934, G Loss: 7.75039005279541\n",
      "Epoch: 1, Batch: 320, D Loss: 0.1052637251559645, G Loss: 8.23849105834961\n",
      "Epoch: 1, Batch: 321, D Loss: 0.09529772188398056, G Loss: 8.190641403198242\n",
      "Epoch: 1, Batch: 322, D Loss: 0.09660751989576966, G Loss: 7.630583763122559\n",
      "Epoch: 1, Batch: 323, D Loss: 0.10318112396635115, G Loss: 7.093862533569336\n",
      "Epoch: 1, Batch: 324, D Loss: 0.10871543409302831, G Loss: 7.5226149559021\n",
      "Epoch: 1, Batch: 325, D Loss: 0.10519682709127665, G Loss: 8.359611511230469\n",
      "Epoch: 1, Batch: 326, D Loss: 0.1200253926217556, G Loss: 8.0574951171875\n",
      "Epoch: 1, Batch: 327, D Loss: 0.13322709687054157, G Loss: 9.389251708984375\n",
      "Epoch: 1, Batch: 328, D Loss: 0.1085921567864716, G Loss: 10.130010604858398\n",
      "Epoch: 1, Batch: 329, D Loss: 0.2239772081375122, G Loss: 9.701264381408691\n",
      "Epoch: 1, Batch: 330, D Loss: 0.12876874605717603, G Loss: 12.512882232666016\n",
      "Epoch: 1, Batch: 331, D Loss: 0.202009260392515, G Loss: 8.109832763671875\n",
      "Epoch: 1, Batch: 332, D Loss: 0.1174188363365829, G Loss: 6.889038562774658\n",
      "Epoch: 1, Batch: 333, D Loss: 0.15103837102651596, G Loss: 5.627856731414795\n",
      "Epoch: 1, Batch: 334, D Loss: 0.16625715047121048, G Loss: 6.037365913391113\n",
      "Epoch: 1, Batch: 335, D Loss: 0.13641169713810086, G Loss: 8.292753219604492\n",
      "Epoch: 1, Batch: 336, D Loss: 0.14532316318218363, G Loss: 10.396187782287598\n",
      "Epoch: 1, Batch: 337, D Loss: 0.11005423045389762, G Loss: 12.136566162109375\n",
      "Epoch: 1, Batch: 338, D Loss: 0.11428142365707572, G Loss: 13.627151489257812\n",
      "Epoch: 1, Batch: 339, D Loss: 0.10087838586190401, G Loss: 14.59444808959961\n",
      "Epoch: 1, Batch: 340, D Loss: 0.11455661094703373, G Loss: 14.032267570495605\n",
      "Epoch: 1, Batch: 341, D Loss: 0.11032353234952552, G Loss: 13.03799057006836\n",
      "Epoch: 1, Batch: 342, D Loss: 0.10867182679612597, G Loss: 11.571439743041992\n",
      "Epoch: 1, Batch: 343, D Loss: 0.09935512897209264, G Loss: 10.124476432800293\n",
      "Epoch: 1, Batch: 344, D Loss: 0.09933883548364975, G Loss: 9.071762084960938\n",
      "Epoch: 1, Batch: 345, D Loss: 0.09369754973158706, G Loss: 8.26956558227539\n",
      "Epoch: 1, Batch: 346, D Loss: 0.10100899689132348, G Loss: 7.586178779602051\n",
      "Epoch: 1, Batch: 347, D Loss: 0.10665501683251932, G Loss: 7.271994590759277\n",
      "Epoch: 1, Batch: 348, D Loss: 0.10078870033612475, G Loss: 7.139453887939453\n",
      "Epoch: 1, Batch: 349, D Loss: 0.10713177407160401, G Loss: 7.037937164306641\n",
      "Epoch: 1, Batch: 350, D Loss: 0.10251751018222421, G Loss: 7.285902976989746\n",
      "Epoch: 1, Batch: 351, D Loss: 0.09740195781341754, G Loss: 7.774843215942383\n",
      "Epoch: 1, Batch: 352, D Loss: 0.09995925649127457, G Loss: 8.136265754699707\n",
      "Epoch: 1, Batch: 353, D Loss: 0.0949796066415729, G Loss: 8.038548469543457\n",
      "Epoch: 1, Batch: 354, D Loss: 0.09612554404884577, G Loss: 7.6504716873168945\n",
      "Epoch: 1, Batch: 355, D Loss: 0.10017456038622186, G Loss: 7.657550811767578\n",
      "Epoch: 1, Batch: 356, D Loss: 0.10468383494298905, G Loss: 7.955122947692871\n",
      "Epoch: 1, Batch: 357, D Loss: 0.10182648655609228, G Loss: 8.303403854370117\n",
      "Epoch: 1, Batch: 358, D Loss: 0.09879941973485984, G Loss: 8.481005668640137\n",
      "Epoch: 1, Batch: 359, D Loss: 0.09098363583325408, G Loss: 8.48440170288086\n",
      "Epoch: 1, Batch: 360, D Loss: 0.10408978271880187, G Loss: 8.63967227935791\n",
      "Epoch: 1, Batch: 361, D Loss: 0.10483532230136916, G Loss: 8.730391502380371\n",
      "Epoch: 1, Batch: 362, D Loss: 0.09409760397102218, G Loss: 8.578819274902344\n",
      "Epoch: 1, Batch: 363, D Loss: 0.09309955468779663, G Loss: 8.492218017578125\n",
      "Epoch: 1, Batch: 364, D Loss: 0.10328541992930695, G Loss: 8.217201232910156\n",
      "Epoch: 1, Batch: 365, D Loss: 0.10485439578769729, G Loss: 7.670042037963867\n",
      "Epoch: 1, Batch: 366, D Loss: 0.10086687933653593, G Loss: 7.553474426269531\n",
      "Epoch: 1, Batch: 367, D Loss: 0.10019253171049058, G Loss: 7.236223220825195\n",
      "Epoch: 1, Batch: 368, D Loss: 0.10407922801095992, G Loss: 7.12502384185791\n",
      "Epoch: 1, Batch: 369, D Loss: 0.09646232367958874, G Loss: 7.204893112182617\n",
      "Epoch: 1, Batch: 370, D Loss: 0.10496599157340825, G Loss: 7.103879928588867\n",
      "Epoch: 1, Batch: 371, D Loss: 0.10150269977748394, G Loss: 6.979669094085693\n",
      "Epoch: 1, Batch: 372, D Loss: 0.09928255598060787, G Loss: 7.14664363861084\n",
      "Epoch: 1, Batch: 373, D Loss: 0.10767746157944202, G Loss: 7.374175071716309\n",
      "Epoch: 1, Batch: 374, D Loss: 0.10509827389614657, G Loss: 8.140401840209961\n",
      "Epoch: 1, Batch: 375, D Loss: 0.1030713907093741, G Loss: 8.518080711364746\n",
      "Epoch: 1, Batch: 376, D Loss: 0.10265346989035606, G Loss: 7.907434940338135\n",
      "Epoch: 1, Batch: 377, D Loss: 0.10260854242369533, G Loss: 7.327230453491211\n",
      "Epoch: 1, Batch: 378, D Loss: 0.09565689513692632, G Loss: 8.080389976501465\n",
      "Epoch: 1, Batch: 379, D Loss: 0.10715233367227484, G Loss: 8.770590782165527\n",
      "Epoch: 1, Batch: 380, D Loss: 0.10292382320039906, G Loss: 9.347611427307129\n",
      "Epoch: 1, Batch: 381, D Loss: 0.0977517763421929, G Loss: 9.333531379699707\n",
      "Epoch: 1, Batch: 382, D Loss: 0.09031916384992655, G Loss: 8.339521408081055\n",
      "Epoch: 1, Batch: 383, D Loss: 0.09765710355713964, G Loss: 7.299452304840088\n",
      "Epoch: 1, Batch: 384, D Loss: 0.10620709578506649, G Loss: 6.58514404296875\n",
      "Epoch: 1, Batch: 385, D Loss: 0.09825550485402346, G Loss: 7.292143821716309\n",
      "Epoch: 1, Batch: 386, D Loss: 0.10061758512165397, G Loss: 8.966375350952148\n",
      "Epoch: 1, Batch: 387, D Loss: 0.09810072460095398, G Loss: 10.477394104003906\n",
      "Epoch: 1, Batch: 388, D Loss: 0.09725695314773475, G Loss: 10.435752868652344\n",
      "Epoch: 1, Batch: 389, D Loss: 0.10270179626968456, G Loss: 8.952523231506348\n",
      "Epoch: 1, Batch: 390, D Loss: 0.09775640742736869, G Loss: 8.216349601745605\n",
      "Epoch: 1, Batch: 391, D Loss: 0.09627104245009832, G Loss: 7.664317607879639\n",
      "Epoch: 1, Batch: 392, D Loss: 0.09636495797894895, G Loss: 7.106850624084473\n",
      "Epoch: 1, Batch: 393, D Loss: 0.10811469936743379, G Loss: 6.932724475860596\n",
      "Epoch: 1, Batch: 394, D Loss: 0.09885944577399641, G Loss: 8.229095458984375\n",
      "Epoch: 1, Batch: 395, D Loss: 0.1023249980644323, G Loss: 9.674830436706543\n",
      "Epoch: 1, Batch: 396, D Loss: 0.10185129036472063, G Loss: 10.00529670715332\n",
      "Epoch: 1, Batch: 397, D Loss: 0.10312183664063923, G Loss: 9.030574798583984\n",
      "Epoch: 1, Batch: 398, D Loss: 0.10639969242038205, G Loss: 7.674790382385254\n",
      "Epoch: 1, Batch: 399, D Loss: 0.10123812849633396, G Loss: 7.335572242736816\n",
      "Epoch: 1, Batch: 400, D Loss: 0.10714201501104981, G Loss: 7.212391376495361\n",
      "Epoch: 1, Batch: 401, D Loss: 0.09891642426373437, G Loss: 7.428035259246826\n",
      "Epoch: 1, Batch: 402, D Loss: 0.09911399945849553, G Loss: 8.348161697387695\n",
      "Epoch: 1, Batch: 403, D Loss: 0.10014392895391211, G Loss: 9.179132461547852\n",
      "Epoch: 1, Batch: 404, D Loss: 0.10178837991406908, G Loss: 9.550861358642578\n",
      "Epoch: 1, Batch: 405, D Loss: 0.09688426080538193, G Loss: 9.615705490112305\n",
      "Epoch: 1, Batch: 406, D Loss: 0.09737805857730564, G Loss: 9.251165390014648\n",
      "Epoch: 1, Batch: 407, D Loss: 0.10564503630303079, G Loss: 9.395000457763672\n",
      "Epoch: 1, Batch: 408, D Loss: 0.10221069399995031, G Loss: 9.588411331176758\n",
      "Epoch: 1, Batch: 409, D Loss: 0.10555794359970605, G Loss: 9.491243362426758\n",
      "Epoch: 1, Batch: 410, D Loss: 0.09641427677706815, G Loss: 9.002561569213867\n",
      "Epoch: 1, Batch: 411, D Loss: 0.10120923061913345, G Loss: 8.8619384765625\n",
      "Epoch: 1, Batch: 412, D Loss: 0.10380656862980686, G Loss: 8.027512550354004\n",
      "Epoch: 1, Batch: 413, D Loss: 0.09699371014721692, G Loss: 7.168537139892578\n",
      "Epoch: 1, Batch: 414, D Loss: 0.10952099997666664, G Loss: 7.72415018081665\n",
      "Epoch: 1, Batch: 415, D Loss: 0.09613589511718601, G Loss: 8.619611740112305\n",
      "Epoch: 1, Batch: 416, D Loss: 0.09776220343337627, G Loss: 9.133414268493652\n",
      "Epoch: 1, Batch: 417, D Loss: 0.10756086793116992, G Loss: 9.61098861694336\n",
      "Epoch: 1, Batch: 418, D Loss: 0.09990699521586066, G Loss: 9.23157787322998\n",
      "Epoch: 1, Batch: 419, D Loss: 0.10019251453923061, G Loss: 7.461696624755859\n",
      "Epoch: 1, Batch: 420, D Loss: 0.09571548260282725, G Loss: 6.7909369468688965\n",
      "Epoch: 1, Batch: 421, D Loss: 0.10047827300149947, G Loss: 7.720105171203613\n",
      "Epoch: 1, Batch: 422, D Loss: 0.1008127590175718, G Loss: 8.986214637756348\n",
      "Epoch: 1, Batch: 423, D Loss: 0.10026347235543653, G Loss: 9.120314598083496\n",
      "Epoch: 1, Batch: 424, D Loss: 0.09758907504874514, G Loss: 9.404193878173828\n",
      "Epoch: 1, Batch: 425, D Loss: 0.09946265526377829, G Loss: 9.188020706176758\n",
      "Epoch: 1, Batch: 426, D Loss: 0.0978242889395915, G Loss: 8.469005584716797\n",
      "Epoch: 1, Batch: 427, D Loss: 0.10130774386925623, G Loss: 7.365180969238281\n",
      "Epoch: 1, Batch: 428, D Loss: 0.09642405202612281, G Loss: 7.222720623016357\n",
      "Epoch: 1, Batch: 429, D Loss: 0.10072451131418347, G Loss: 7.669919013977051\n",
      "Epoch: 1, Batch: 430, D Loss: 0.10197618321399204, G Loss: 8.119819641113281\n",
      "Epoch: 1, Batch: 431, D Loss: 0.10695389937609434, G Loss: 7.405599594116211\n",
      "Epoch: 1, Batch: 432, D Loss: 0.11447788053192198, G Loss: 5.331429481506348\n",
      "Epoch: 1, Batch: 433, D Loss: 0.10996581357903779, G Loss: 6.695734024047852\n",
      "Epoch: 1, Batch: 434, D Loss: 0.10353671186021529, G Loss: 9.581720352172852\n",
      "Epoch: 1, Batch: 435, D Loss: 0.10576453867906821, G Loss: 11.814173698425293\n",
      "Epoch: 1, Batch: 436, D Loss: 0.10602093770467036, G Loss: 12.291128158569336\n",
      "Epoch: 1, Batch: 437, D Loss: 0.10110378985200441, G Loss: 12.414395332336426\n",
      "Epoch: 1, Batch: 438, D Loss: 0.09640989083072782, G Loss: 10.625787734985352\n",
      "Epoch: 1, Batch: 439, D Loss: 0.10429507650405867, G Loss: 9.330254554748535\n",
      "Epoch: 1, Batch: 440, D Loss: 0.0927709224561113, G Loss: 8.340071678161621\n",
      "Epoch: 1, Batch: 441, D Loss: 0.09691222285619006, G Loss: 7.097516059875488\n",
      "Epoch: 1, Batch: 442, D Loss: 0.09517827007221058, G Loss: 6.999391555786133\n",
      "Epoch: 1, Batch: 443, D Loss: 0.10718005412491038, G Loss: 7.577724933624268\n",
      "Epoch: 1, Batch: 444, D Loss: 0.10625483395415358, G Loss: 8.527920722961426\n",
      "Epoch: 1, Batch: 445, D Loss: 0.09910004488483537, G Loss: 9.402795791625977\n",
      "Epoch: 1, Batch: 446, D Loss: 0.09537595303845592, G Loss: 10.213762283325195\n",
      "Epoch: 1, Batch: 447, D Loss: 0.1012241561902556, G Loss: 10.791868209838867\n",
      "Epoch: 1, Batch: 448, D Loss: 0.0975883787859857, G Loss: 11.074527740478516\n",
      "Epoch: 1, Batch: 449, D Loss: 0.09713834532158216, G Loss: 11.255461692810059\n",
      "Epoch: 1, Batch: 450, D Loss: 0.10708207499010314, G Loss: 11.529132843017578\n",
      "Epoch: 1, Batch: 451, D Loss: 0.10261956911836023, G Loss: 11.744791030883789\n",
      "Epoch: 1, Batch: 452, D Loss: 0.10010736482763605, G Loss: 11.15317153930664\n",
      "Epoch: 1, Batch: 453, D Loss: 0.10517794561928895, G Loss: 11.229772567749023\n",
      "Epoch: 1, Batch: 454, D Loss: 0.09856683838552271, G Loss: 11.49606704711914\n",
      "Epoch: 1, Batch: 455, D Loss: 0.0999954275730488, G Loss: 11.344792366027832\n",
      "Epoch: 1, Batch: 456, D Loss: 0.10371773787483107, G Loss: 10.541481971740723\n",
      "Epoch: 1, Batch: 457, D Loss: 0.09901478212486836, G Loss: 10.274967193603516\n",
      "Epoch: 1, Batch: 458, D Loss: 0.10201983242950519, G Loss: 9.86233901977539\n",
      "Epoch: 1, Batch: 459, D Loss: 0.09658954889891902, G Loss: 9.622631072998047\n",
      "Epoch: 1, Batch: 460, D Loss: 0.09498544351299643, G Loss: 9.010623931884766\n",
      "Epoch: 1, Batch: 461, D Loss: 0.10174653268768452, G Loss: 8.188794136047363\n",
      "Epoch: 1, Batch: 462, D Loss: 0.10031081388297025, G Loss: 8.118012428283691\n",
      "Epoch: 1, Batch: 463, D Loss: 0.0995367543073371, G Loss: 7.876594066619873\n",
      "Epoch: 1, Batch: 464, D Loss: 0.1025135115487501, G Loss: 7.533137321472168\n",
      "Epoch: 1, Batch: 465, D Loss: 0.09903492040757556, G Loss: 8.182206153869629\n",
      "Epoch: 1, Batch: 466, D Loss: 0.1027266506862361, G Loss: 7.971053600311279\n",
      "Epoch: 1, Batch: 467, D Loss: 0.09647060147835873, G Loss: 7.893860816955566\n",
      "Epoch: 2, Batch: 0, D Loss: 0.10413037618855014, G Loss: 7.614114761352539\n",
      "Epoch: 2, Batch: 1, D Loss: 0.09779846665333025, G Loss: 8.435270309448242\n",
      "Epoch: 2, Batch: 2, D Loss: 0.09635800699470565, G Loss: 9.260497093200684\n",
      "Epoch: 2, Batch: 3, D Loss: 0.10123159692375339, G Loss: 9.77489185333252\n",
      "Epoch: 2, Batch: 4, D Loss: 0.0942483858380001, G Loss: 9.58736801147461\n",
      "Epoch: 2, Batch: 5, D Loss: 0.10129209407023154, G Loss: 8.4866304397583\n",
      "Epoch: 2, Batch: 6, D Loss: 0.0995046286698198, G Loss: 7.579963684082031\n",
      "Epoch: 2, Batch: 7, D Loss: 0.10636019648518413, G Loss: 7.425046443939209\n",
      "Epoch: 2, Batch: 8, D Loss: 0.09554683981696144, G Loss: 7.755774021148682\n",
      "Epoch: 2, Batch: 9, D Loss: 0.10778316541109234, G Loss: 8.075508117675781\n",
      "Epoch: 2, Batch: 10, D Loss: 0.09760447923326865, G Loss: 8.511467933654785\n",
      "Epoch: 2, Batch: 11, D Loss: 0.09831814760400448, G Loss: 9.127243995666504\n",
      "Epoch: 2, Batch: 12, D Loss: 0.09126028898026561, G Loss: 9.401748657226562\n",
      "Epoch: 2, Batch: 13, D Loss: 0.09317197918062448, G Loss: 9.302793502807617\n",
      "Epoch: 2, Batch: 14, D Loss: 0.09457367012510076, G Loss: 8.279178619384766\n",
      "Epoch: 2, Batch: 15, D Loss: 0.0969497274782043, G Loss: 8.209939956665039\n",
      "Epoch: 2, Batch: 16, D Loss: 0.1022414775507059, G Loss: 8.751801490783691\n",
      "Epoch: 2, Batch: 17, D Loss: 0.09793444146635011, G Loss: 9.453903198242188\n",
      "Epoch: 2, Batch: 18, D Loss: 0.09725367090868531, G Loss: 9.972646713256836\n",
      "Epoch: 2, Batch: 19, D Loss: 0.10089608030830277, G Loss: 10.209599494934082\n",
      "Epoch: 2, Batch: 20, D Loss: 0.10409574945515487, G Loss: 10.534887313842773\n",
      "Epoch: 2, Batch: 21, D Loss: 0.0990711004997138, G Loss: 10.652242660522461\n",
      "Epoch: 2, Batch: 22, D Loss: 0.1026130514092074, G Loss: 10.783699989318848\n",
      "Epoch: 2, Batch: 23, D Loss: 0.09265512068850512, G Loss: 10.779844284057617\n",
      "Epoch: 2, Batch: 24, D Loss: 0.10470624833669717, G Loss: 10.851386070251465\n",
      "Epoch: 2, Batch: 25, D Loss: 0.09053097339347005, G Loss: 9.700900077819824\n",
      "Epoch: 2, Batch: 26, D Loss: 0.1011513097473653, G Loss: 8.639142036437988\n",
      "Epoch: 2, Batch: 27, D Loss: 0.0984276556991972, G Loss: 8.29229736328125\n",
      "Epoch: 2, Batch: 28, D Loss: 0.10165962963947095, G Loss: 8.252235412597656\n",
      "Epoch: 2, Batch: 29, D Loss: 0.09767750598257408, G Loss: 8.225668907165527\n",
      "Epoch: 2, Batch: 30, D Loss: 0.10275944950990379, G Loss: 7.782756805419922\n",
      "Epoch: 2, Batch: 31, D Loss: 0.09783301030984148, G Loss: 8.150793075561523\n",
      "Epoch: 2, Batch: 32, D Loss: 0.10216824913368328, G Loss: 8.786484718322754\n",
      "Epoch: 2, Batch: 33, D Loss: 0.1046799447722151, G Loss: 9.41105842590332\n",
      "Epoch: 2, Batch: 34, D Loss: 0.09762345364651992, G Loss: 9.8447847366333\n",
      "Epoch: 2, Batch: 35, D Loss: 0.09709335653678863, G Loss: 10.10727310180664\n",
      "Epoch: 2, Batch: 36, D Loss: 0.09903161122747406, G Loss: 10.131294250488281\n",
      "Epoch: 2, Batch: 37, D Loss: 0.10652494515852595, G Loss: 10.013166427612305\n",
      "Epoch: 2, Batch: 38, D Loss: 0.10397419899709348, G Loss: 9.902963638305664\n",
      "Epoch: 2, Batch: 39, D Loss: 0.10014284470707935, G Loss: 10.169795989990234\n",
      "Epoch: 2, Batch: 40, D Loss: 0.10184752517125162, G Loss: 10.39944839477539\n",
      "Epoch: 2, Batch: 41, D Loss: 0.09512049501245201, G Loss: 10.127336502075195\n",
      "Epoch: 2, Batch: 42, D Loss: 0.10215386209711141, G Loss: 10.193314552307129\n",
      "Epoch: 2, Batch: 43, D Loss: 0.09624203725616098, G Loss: 10.311108589172363\n",
      "Epoch: 2, Batch: 44, D Loss: 0.10295918085830635, G Loss: 10.356865882873535\n",
      "Epoch: 2, Batch: 45, D Loss: 0.0960325674386695, G Loss: 9.534404754638672\n",
      "Epoch: 2, Batch: 46, D Loss: 0.10150600318593206, G Loss: 9.51230525970459\n",
      "Epoch: 2, Batch: 47, D Loss: 0.0993246982106939, G Loss: 9.49537467956543\n",
      "Epoch: 2, Batch: 48, D Loss: 0.1040509501399356, G Loss: 9.540045738220215\n",
      "Epoch: 2, Batch: 49, D Loss: 0.10003547985252226, G Loss: 9.674392700195312\n",
      "Epoch: 2, Batch: 50, D Loss: 0.10082183507984155, G Loss: 9.789827346801758\n",
      "Epoch: 2, Batch: 51, D Loss: 0.10081313223054167, G Loss: 9.944024085998535\n",
      "Epoch: 2, Batch: 52, D Loss: 0.09311751163477311, G Loss: 10.017354965209961\n",
      "Epoch: 2, Batch: 53, D Loss: 0.10306846591265639, G Loss: 10.017536163330078\n",
      "Epoch: 2, Batch: 54, D Loss: 0.10195831364762853, G Loss: 10.059022903442383\n",
      "Epoch: 2, Batch: 55, D Loss: 0.10092813624214614, G Loss: 9.88719367980957\n",
      "Epoch: 2, Batch: 56, D Loss: 0.10069966664013918, G Loss: 9.70440673828125\n",
      "Epoch: 2, Batch: 57, D Loss: 0.10472313388891052, G Loss: 9.834680557250977\n",
      "Epoch: 2, Batch: 58, D Loss: 0.09553388099448057, G Loss: 9.901483535766602\n",
      "Epoch: 2, Batch: 59, D Loss: 0.10275800091221754, G Loss: 9.978775024414062\n",
      "Epoch: 2, Batch: 60, D Loss: 0.1048349357333791, G Loss: 10.103398323059082\n",
      "Epoch: 2, Batch: 61, D Loss: 0.0890275617930456, G Loss: 10.085695266723633\n",
      "Epoch: 2, Batch: 62, D Loss: 0.09913227170727623, G Loss: 10.11098861694336\n",
      "Epoch: 2, Batch: 63, D Loss: 0.09380564303683059, G Loss: 10.010643005371094\n",
      "Epoch: 2, Batch: 64, D Loss: 0.09111720826513192, G Loss: 9.934280395507812\n",
      "Epoch: 2, Batch: 65, D Loss: 0.09655844757071463, G Loss: 10.012670516967773\n",
      "Epoch: 2, Batch: 66, D Loss: 0.10125701849756297, G Loss: 10.298861503601074\n",
      "Epoch: 2, Batch: 67, D Loss: 0.1105281441614352, G Loss: 10.689607620239258\n",
      "Epoch: 2, Batch: 68, D Loss: 0.10229067213003873, G Loss: 10.487997055053711\n",
      "Epoch: 2, Batch: 69, D Loss: 0.0938986312612542, G Loss: 10.292926788330078\n",
      "Epoch: 2, Batch: 70, D Loss: 0.10466012449978734, G Loss: 9.772659301757812\n",
      "Epoch: 2, Batch: 71, D Loss: 0.09979244098212803, G Loss: 9.008336067199707\n",
      "Epoch: 2, Batch: 72, D Loss: 0.0925979764724616, G Loss: 8.181595802307129\n",
      "Epoch: 2, Batch: 73, D Loss: 0.09907908926834352, G Loss: 8.00323486328125\n",
      "Epoch: 2, Batch: 74, D Loss: 0.09834138047881424, G Loss: 8.218240737915039\n",
      "Epoch: 2, Batch: 75, D Loss: 0.10286199700203724, G Loss: 8.213171005249023\n",
      "Epoch: 2, Batch: 76, D Loss: 0.09802072148886509, G Loss: 8.527270317077637\n",
      "Epoch: 2, Batch: 77, D Loss: 0.10168704739044188, G Loss: 9.279850006103516\n",
      "Epoch: 2, Batch: 78, D Loss: 0.1021615296122036, G Loss: 9.993942260742188\n",
      "Epoch: 2, Batch: 79, D Loss: 0.10027530985462363, G Loss: 10.545513153076172\n",
      "Epoch: 2, Batch: 80, D Loss: 0.1014518364227115, G Loss: 10.881685256958008\n",
      "Epoch: 2, Batch: 81, D Loss: 0.09715019880786713, G Loss: 11.002765655517578\n",
      "Epoch: 2, Batch: 82, D Loss: 0.09882543456478743, G Loss: 11.068849563598633\n",
      "Epoch: 2, Batch: 83, D Loss: 0.09950423693680932, G Loss: 11.063531875610352\n",
      "Epoch: 2, Batch: 84, D Loss: 0.1007182712028225, G Loss: 11.1392822265625\n",
      "Epoch: 2, Batch: 85, D Loss: 0.09834200477325794, G Loss: 11.246255874633789\n",
      "Epoch: 2, Batch: 86, D Loss: 0.09734925786688109, G Loss: 11.300856590270996\n",
      "Epoch: 2, Batch: 87, D Loss: 0.0965400463160222, G Loss: 11.213861465454102\n",
      "Epoch: 2, Batch: 88, D Loss: 0.09506427931682992, G Loss: 11.04824447631836\n",
      "Epoch: 2, Batch: 89, D Loss: 0.09943632410795544, G Loss: 10.180912971496582\n",
      "Epoch: 2, Batch: 90, D Loss: 0.10568961468197813, G Loss: 10.029496192932129\n",
      "Epoch: 2, Batch: 91, D Loss: 0.09712909177324036, G Loss: 9.471100807189941\n",
      "Epoch: 2, Batch: 92, D Loss: 0.09539016027702019, G Loss: 8.457847595214844\n",
      "Epoch: 2, Batch: 93, D Loss: 0.10061260931252036, G Loss: 8.407551765441895\n",
      "Epoch: 2, Batch: 94, D Loss: 0.0985984043290955, G Loss: 8.51272201538086\n",
      "Epoch: 2, Batch: 95, D Loss: 0.1042544617812382, G Loss: 8.723915100097656\n",
      "Epoch: 2, Batch: 96, D Loss: 0.09712431790831033, G Loss: 8.803838729858398\n",
      "Epoch: 2, Batch: 97, D Loss: 0.1037592454085825, G Loss: 8.716814994812012\n",
      "Epoch: 2, Batch: 98, D Loss: 0.09726743925421033, G Loss: 9.043900489807129\n",
      "Epoch: 2, Batch: 99, D Loss: 0.10300556677975692, G Loss: 9.508661270141602\n",
      "Epoch: 2, Batch: 100, D Loss: 0.0949061274077394, G Loss: 9.425163269042969\n",
      "Epoch: 2, Batch: 101, D Loss: 0.09865756606450304, G Loss: 8.814278602600098\n",
      "Epoch: 2, Batch: 102, D Loss: 0.10412428529525641, G Loss: 9.273334503173828\n",
      "Epoch: 2, Batch: 103, D Loss: 0.1034744229145872, G Loss: 9.492843627929688\n",
      "Epoch: 2, Batch: 104, D Loss: 0.09915920639468823, G Loss: 8.51623249053955\n",
      "Epoch: 2, Batch: 105, D Loss: 0.102878676407272, G Loss: 8.908434867858887\n",
      "Epoch: 2, Batch: 106, D Loss: 0.10346889034190099, G Loss: 9.299214363098145\n",
      "Epoch: 2, Batch: 107, D Loss: 0.09731646400541649, G Loss: 9.517596244812012\n",
      "Epoch: 2, Batch: 108, D Loss: 0.09976848205042188, G Loss: 9.232038497924805\n",
      "Epoch: 2, Batch: 109, D Loss: 0.09181654377607629, G Loss: 8.083562850952148\n",
      "Epoch: 2, Batch: 110, D Loss: 0.09976878398447298, G Loss: 7.993151664733887\n",
      "Epoch: 2, Batch: 111, D Loss: 0.10382854379713535, G Loss: 7.965313911437988\n",
      "Epoch: 2, Batch: 112, D Loss: 0.09981999342562631, G Loss: 8.151283264160156\n",
      "Epoch: 2, Batch: 113, D Loss: 0.10076051090436522, G Loss: 8.222549438476562\n",
      "Epoch: 2, Batch: 114, D Loss: 0.09913901871186681, G Loss: 8.709888458251953\n",
      "Epoch: 2, Batch: 115, D Loss: 0.1021438631505589, G Loss: 9.004302978515625\n",
      "Epoch: 2, Batch: 116, D Loss: 0.0988444164977409, G Loss: 8.519878387451172\n",
      "Epoch: 2, Batch: 117, D Loss: 0.0989052478398662, G Loss: 8.235405921936035\n",
      "Epoch: 2, Batch: 118, D Loss: 0.10049996556335827, G Loss: 8.74981689453125\n",
      "Epoch: 2, Batch: 119, D Loss: 0.102197332023934, G Loss: 9.286396026611328\n",
      "Epoch: 2, Batch: 120, D Loss: 0.09340911660547135, G Loss: 9.697678565979004\n",
      "Epoch: 2, Batch: 121, D Loss: 0.09647951132137678, G Loss: 9.68032455444336\n",
      "Epoch: 2, Batch: 122, D Loss: 0.09723142157599796, G Loss: 9.327664375305176\n",
      "Epoch: 2, Batch: 123, D Loss: 0.0994185797899263, G Loss: 9.632278442382812\n",
      "Epoch: 2, Batch: 124, D Loss: 0.1035604770804639, G Loss: 9.309240341186523\n",
      "Epoch: 2, Batch: 125, D Loss: 0.10356962429432315, G Loss: 9.566259384155273\n",
      "Epoch: 2, Batch: 126, D Loss: 0.09645291329798056, G Loss: 9.854503631591797\n",
      "Epoch: 2, Batch: 127, D Loss: 0.0993664186244132, G Loss: 9.943222999572754\n",
      "Epoch: 2, Batch: 128, D Loss: 0.09740712215534586, G Loss: 10.01571273803711\n",
      "Epoch: 2, Batch: 129, D Loss: 0.09399787022812234, G Loss: 9.795814514160156\n",
      "Epoch: 2, Batch: 130, D Loss: 0.10031206426720018, G Loss: 9.670801162719727\n",
      "Epoch: 2, Batch: 131, D Loss: 0.10243770822125953, G Loss: 9.362504005432129\n",
      "Epoch: 2, Batch: 132, D Loss: 0.1022744851798052, G Loss: 9.106903076171875\n",
      "Epoch: 2, Batch: 133, D Loss: 0.09944747462577652, G Loss: 8.269564628601074\n",
      "Epoch: 2, Batch: 134, D Loss: 0.09165526785363909, G Loss: 8.406726837158203\n",
      "Epoch: 2, Batch: 135, D Loss: 0.0968623607623158, G Loss: 8.661543846130371\n",
      "Epoch: 2, Batch: 136, D Loss: 0.10094442213448929, G Loss: 9.15257453918457\n",
      "Epoch: 2, Batch: 137, D Loss: 0.1008809277554974, G Loss: 8.902642250061035\n",
      "Epoch: 2, Batch: 138, D Loss: 0.09785304179240484, G Loss: 8.767108917236328\n",
      "Epoch: 2, Batch: 139, D Loss: 0.10290640449966304, G Loss: 8.895851135253906\n",
      "Epoch: 2, Batch: 140, D Loss: 0.09838279409450479, G Loss: 8.401725769042969\n",
      "Epoch: 2, Batch: 141, D Loss: 0.09627249313052744, G Loss: 7.871718883514404\n",
      "Epoch: 2, Batch: 142, D Loss: 0.09470187788247131, G Loss: 8.542083740234375\n",
      "Epoch: 2, Batch: 143, D Loss: 0.10323412619618466, G Loss: 9.327400207519531\n",
      "Epoch: 2, Batch: 144, D Loss: 0.10606276173712104, G Loss: 10.088438034057617\n",
      "Epoch: 2, Batch: 145, D Loss: 0.09648021714565402, G Loss: 10.679033279418945\n",
      "Epoch: 2, Batch: 146, D Loss: 0.09569484928397287, G Loss: 10.964412689208984\n",
      "Epoch: 2, Batch: 147, D Loss: 0.09707590611469641, G Loss: 11.15676498413086\n",
      "Epoch: 2, Batch: 148, D Loss: 0.0970322336515892, G Loss: 11.359441757202148\n",
      "Epoch: 2, Batch: 149, D Loss: 0.09875746472789615, G Loss: 11.615863800048828\n",
      "Epoch: 2, Batch: 150, D Loss: 0.1004057697459757, G Loss: 11.913111686706543\n",
      "Epoch: 2, Batch: 151, D Loss: 0.09048025971787865, G Loss: 12.085692405700684\n",
      "Epoch: 2, Batch: 152, D Loss: 0.09789229535545019, G Loss: 12.048709869384766\n",
      "Epoch: 2, Batch: 153, D Loss: 0.1035274637092698, G Loss: 12.154045104980469\n",
      "Epoch: 2, Batch: 154, D Loss: 0.09904619255576108, G Loss: 11.837324142456055\n",
      "Epoch: 2, Batch: 155, D Loss: 0.10489773660492574, G Loss: 11.18294906616211\n",
      "Epoch: 2, Batch: 156, D Loss: 0.10053150188241489, G Loss: 11.16990852355957\n",
      "Epoch: 2, Batch: 157, D Loss: 0.10286622398507461, G Loss: 10.892149925231934\n",
      "Epoch: 2, Batch: 158, D Loss: 0.10062986418870423, G Loss: 10.56110668182373\n",
      "Epoch: 2, Batch: 159, D Loss: 0.09463692959252512, G Loss: 9.414904594421387\n",
      "Epoch: 2, Batch: 160, D Loss: 0.10290309223273653, G Loss: 9.038839340209961\n",
      "Epoch: 2, Batch: 161, D Loss: 0.10349470489018131, G Loss: 9.084301948547363\n",
      "Epoch: 2, Batch: 162, D Loss: 0.10222004971001297, G Loss: 9.176397323608398\n",
      "Epoch: 2, Batch: 163, D Loss: 0.10321115823535365, G Loss: 9.40404987335205\n",
      "Epoch: 2, Batch: 164, D Loss: 0.09977296840952476, G Loss: 9.615402221679688\n",
      "Epoch: 2, Batch: 165, D Loss: 0.10594175126971095, G Loss: 9.850481033325195\n",
      "Epoch: 2, Batch: 166, D Loss: 0.10243721061851829, G Loss: 10.092643737792969\n",
      "Epoch: 2, Batch: 167, D Loss: 0.09395716759536299, G Loss: 10.176657676696777\n",
      "Epoch: 2, Batch: 168, D Loss: 0.09923276970584993, G Loss: 10.246882438659668\n",
      "Epoch: 2, Batch: 169, D Loss: 0.10254912287200568, G Loss: 10.4293212890625\n",
      "Epoch: 2, Batch: 170, D Loss: 0.09851504043581372, G Loss: 10.59078598022461\n",
      "Epoch: 2, Batch: 171, D Loss: 0.10773682484068559, G Loss: 10.379035949707031\n",
      "Epoch: 2, Batch: 172, D Loss: 0.10344184593122918, G Loss: 8.561760902404785\n",
      "Epoch: 2, Batch: 173, D Loss: 0.1009514264005702, G Loss: 8.39558219909668\n",
      "Epoch: 2, Batch: 174, D Loss: 0.09948006887861993, G Loss: 8.47793197631836\n",
      "Epoch: 2, Batch: 175, D Loss: 0.10506084897497203, G Loss: 8.70169734954834\n",
      "Epoch: 2, Batch: 176, D Loss: 0.09696365994750522, G Loss: 8.900436401367188\n",
      "Epoch: 2, Batch: 177, D Loss: 0.10086290208710125, G Loss: 8.670489311218262\n",
      "Epoch: 2, Batch: 178, D Loss: 0.09705641292384826, G Loss: 8.792401313781738\n",
      "Epoch: 2, Batch: 179, D Loss: 0.10236910793173593, G Loss: 8.489323616027832\n",
      "Epoch: 2, Batch: 180, D Loss: 0.0956978701724438, G Loss: 8.894866943359375\n",
      "Epoch: 2, Batch: 181, D Loss: 0.10125460281778942, G Loss: 9.508694648742676\n",
      "Epoch: 2, Batch: 182, D Loss: 0.10290541881840909, G Loss: 10.110189437866211\n",
      "Epoch: 2, Batch: 183, D Loss: 0.09883669020200614, G Loss: 10.555746078491211\n",
      "Epoch: 2, Batch: 184, D Loss: 0.10811762934918079, G Loss: 10.686689376831055\n",
      "Epoch: 2, Batch: 185, D Loss: 0.1017463652715378, G Loss: 10.850773811340332\n",
      "Epoch: 2, Batch: 186, D Loss: 0.09761262146457739, G Loss: 10.962752342224121\n",
      "Epoch: 2, Batch: 187, D Loss: 0.09922645907317929, G Loss: 10.972631454467773\n",
      "Epoch: 2, Batch: 188, D Loss: 0.10199310165444331, G Loss: 10.992400169372559\n",
      "Epoch: 2, Batch: 189, D Loss: 0.10069144369299465, G Loss: 11.06216049194336\n",
      "Epoch: 2, Batch: 190, D Loss: 0.10229799149647079, G Loss: 11.202164649963379\n",
      "Epoch: 2, Batch: 191, D Loss: 0.10451990851379378, G Loss: 11.351190567016602\n",
      "Epoch: 2, Batch: 192, D Loss: 0.09893764154094242, G Loss: 11.364770889282227\n",
      "Epoch: 2, Batch: 193, D Loss: 0.1070814602653627, G Loss: 11.268402099609375\n",
      "Epoch: 2, Batch: 194, D Loss: 0.1028123361611506, G Loss: 9.092849731445312\n",
      "Epoch: 2, Batch: 195, D Loss: 0.09570445495774038, G Loss: 8.821732521057129\n",
      "Epoch: 2, Batch: 196, D Loss: 0.09859697405045154, G Loss: 8.875576972961426\n",
      "Epoch: 2, Batch: 197, D Loss: 0.09595556929707527, G Loss: 8.882915496826172\n",
      "Epoch: 2, Batch: 198, D Loss: 0.10222820808849065, G Loss: 9.234373092651367\n",
      "Epoch: 2, Batch: 199, D Loss: 0.09470283312475658, G Loss: 9.329865455627441\n",
      "Epoch: 2, Batch: 200, D Loss: 0.10133582999333157, G Loss: 9.743816375732422\n",
      "Epoch: 2, Batch: 201, D Loss: 0.09626997734812903, G Loss: 9.901281356811523\n",
      "Epoch: 2, Batch: 202, D Loss: 0.10109383911185432, G Loss: 9.568510055541992\n",
      "Epoch: 2, Batch: 203, D Loss: 0.09954789961921051, G Loss: 9.557574272155762\n",
      "Epoch: 2, Batch: 204, D Loss: 0.10000316915829899, G Loss: 9.674888610839844\n",
      "Epoch: 2, Batch: 205, D Loss: 0.10528392273045029, G Loss: 9.921253204345703\n",
      "Epoch: 2, Batch: 206, D Loss: 0.09575002164274338, G Loss: 10.022754669189453\n",
      "Epoch: 2, Batch: 207, D Loss: 0.10230464731284883, G Loss: 9.986793518066406\n",
      "Epoch: 2, Batch: 208, D Loss: 0.10374644260082277, G Loss: 10.067391395568848\n",
      "Epoch: 2, Batch: 209, D Loss: 0.10401267723500496, G Loss: 10.27920913696289\n",
      "Epoch: 2, Batch: 210, D Loss: 0.10140757887529617, G Loss: 10.302814483642578\n",
      "Epoch: 2, Batch: 211, D Loss: 0.10081225717658526, G Loss: 10.147628784179688\n",
      "Epoch: 2, Batch: 212, D Loss: 0.10867761209010496, G Loss: 10.307106018066406\n",
      "Epoch: 2, Batch: 213, D Loss: 0.102112701313672, G Loss: 10.460372924804688\n",
      "Epoch: 2, Batch: 214, D Loss: 0.09843706517494866, G Loss: 9.995750427246094\n",
      "Epoch: 2, Batch: 215, D Loss: 0.10001520017976873, G Loss: 9.499336242675781\n",
      "Epoch: 2, Batch: 216, D Loss: 0.0972563599316345, G Loss: 9.16470718383789\n",
      "Epoch: 2, Batch: 217, D Loss: 0.0944922685448546, G Loss: 8.581308364868164\n",
      "Epoch: 2, Batch: 218, D Loss: 0.0983031720679719, G Loss: 8.835336685180664\n",
      "Epoch: 2, Batch: 219, D Loss: 0.10459179719327949, G Loss: 9.351795196533203\n",
      "Epoch: 2, Batch: 220, D Loss: 0.10493153881543549, G Loss: 9.87356185913086\n",
      "Epoch: 2, Batch: 221, D Loss: 0.09694627550561563, G Loss: 10.247243881225586\n",
      "Epoch: 2, Batch: 222, D Loss: 0.10344500648716348, G Loss: 10.530252456665039\n",
      "Epoch: 2, Batch: 223, D Loss: 0.09767272310455155, G Loss: 10.583480834960938\n",
      "Epoch: 2, Batch: 224, D Loss: 0.10007073852830217, G Loss: 10.588737487792969\n",
      "Epoch: 2, Batch: 225, D Loss: 0.09720009827378817, G Loss: 10.541298866271973\n",
      "Epoch: 2, Batch: 226, D Loss: 0.09616241612729937, G Loss: 10.471670150756836\n",
      "Epoch: 2, Batch: 227, D Loss: 0.09305897901685967, G Loss: 10.375869750976562\n",
      "Epoch: 2, Batch: 228, D Loss: 0.10254618844373908, G Loss: 10.411746978759766\n",
      "Epoch: 2, Batch: 229, D Loss: 0.10117782159068156, G Loss: 9.73853874206543\n",
      "Epoch: 2, Batch: 230, D Loss: 0.09973858447847306, G Loss: 9.931741714477539\n",
      "Epoch: 2, Batch: 231, D Loss: 0.10044338933221297, G Loss: 9.797643661499023\n",
      "Epoch: 2, Batch: 232, D Loss: 0.0994103179909871, G Loss: 9.067026138305664\n",
      "Epoch: 2, Batch: 233, D Loss: 0.09764357907988597, G Loss: 8.167281150817871\n",
      "Epoch: 2, Batch: 234, D Loss: 0.09473664095276035, G Loss: 8.23404312133789\n",
      "Epoch: 2, Batch: 235, D Loss: 0.09701067008427344, G Loss: 8.641988754272461\n",
      "Epoch: 2, Batch: 236, D Loss: 0.1051984903824632, G Loss: 9.309823036193848\n",
      "Epoch: 2, Batch: 237, D Loss: 0.10045051213819534, G Loss: 9.906229019165039\n",
      "Epoch: 2, Batch: 238, D Loss: 0.09411119335891271, G Loss: 10.326351165771484\n",
      "Epoch: 2, Batch: 239, D Loss: 0.0998624957355787, G Loss: 10.521133422851562\n",
      "Epoch: 2, Batch: 240, D Loss: 0.1039611962478375, G Loss: 10.399198532104492\n",
      "Epoch: 2, Batch: 241, D Loss: 0.09533555500820512, G Loss: 8.857325553894043\n",
      "Epoch: 2, Batch: 242, D Loss: 0.10044220637064427, G Loss: 7.922724723815918\n",
      "Epoch: 2, Batch: 243, D Loss: 0.09765193681232631, G Loss: 7.181227207183838\n",
      "Epoch: 2, Batch: 244, D Loss: 0.09757221938343719, G Loss: 7.980169773101807\n",
      "Epoch: 2, Batch: 245, D Loss: 0.09097592771286145, G Loss: 8.160735130310059\n",
      "Epoch: 2, Batch: 246, D Loss: 0.10554428011528216, G Loss: 8.622069358825684\n",
      "Epoch: 2, Batch: 247, D Loss: 0.09089759372000117, G Loss: 8.540376663208008\n",
      "Epoch: 2, Batch: 248, D Loss: 0.10045294335577637, G Loss: 8.586060523986816\n",
      "Epoch: 2, Batch: 249, D Loss: 0.09829517250182107, G Loss: 9.457925796508789\n",
      "Epoch: 2, Batch: 250, D Loss: 0.09768530036672018, G Loss: 10.107599258422852\n",
      "Epoch: 2, Batch: 251, D Loss: 0.09644026551359275, G Loss: 10.378568649291992\n",
      "Epoch: 2, Batch: 252, D Loss: 0.09790631486612256, G Loss: 10.1596097946167\n",
      "Epoch: 2, Batch: 253, D Loss: 0.1002802460006933, G Loss: 10.173927307128906\n",
      "Epoch: 2, Batch: 254, D Loss: 0.10310427546937717, G Loss: 8.53892707824707\n",
      "Epoch: 2, Batch: 255, D Loss: 0.09476054323022254, G Loss: 7.567373275756836\n",
      "Epoch: 2, Batch: 256, D Loss: 0.09688466810621321, G Loss: 7.363213062286377\n",
      "Epoch: 2, Batch: 257, D Loss: 0.0966879475308815, G Loss: 8.758743286132812\n",
      "Epoch: 2, Batch: 258, D Loss: 0.09950283884609235, G Loss: 10.259269714355469\n",
      "Epoch: 2, Batch: 259, D Loss: 0.09861513690339052, G Loss: 11.167093276977539\n",
      "Epoch: 2, Batch: 260, D Loss: 0.09884485327938819, G Loss: 11.521188735961914\n",
      "Epoch: 2, Batch: 261, D Loss: 0.09374189533627941, G Loss: 10.097192764282227\n",
      "Epoch: 2, Batch: 262, D Loss: 0.09768099338543834, G Loss: 9.361985206604004\n",
      "Epoch: 2, Batch: 263, D Loss: 0.10600751559832133, G Loss: 9.03872299194336\n",
      "Epoch: 2, Batch: 264, D Loss: 0.103381597524276, G Loss: 8.891702651977539\n",
      "Epoch: 2, Batch: 265, D Loss: 0.10016050677950261, G Loss: 9.48640251159668\n",
      "Epoch: 2, Batch: 266, D Loss: 0.1015828767867788, G Loss: 10.388483047485352\n",
      "Epoch: 2, Batch: 267, D Loss: 0.09225840744147717, G Loss: 10.119002342224121\n",
      "Epoch: 2, Batch: 268, D Loss: 0.09964882630993088, G Loss: 10.086453437805176\n",
      "Epoch: 2, Batch: 269, D Loss: 0.10220834813480906, G Loss: 10.076854705810547\n",
      "Epoch: 2, Batch: 270, D Loss: 0.09694824820144277, G Loss: 10.180522918701172\n",
      "Epoch: 2, Batch: 271, D Loss: 0.10542721322599391, G Loss: 10.19831657409668\n",
      "Epoch: 2, Batch: 272, D Loss: 0.09986945577111328, G Loss: 10.316192626953125\n",
      "Epoch: 2, Batch: 273, D Loss: 0.10455505243771768, G Loss: 10.225367546081543\n",
      "Epoch: 2, Batch: 274, D Loss: 0.09577421296853572, G Loss: 9.305929183959961\n",
      "Epoch: 2, Batch: 275, D Loss: 0.10332195099908859, G Loss: 9.139636993408203\n",
      "Epoch: 2, Batch: 276, D Loss: 0.09349137548997533, G Loss: 9.017280578613281\n",
      "Epoch: 2, Batch: 277, D Loss: 0.10143980677094078, G Loss: 9.306581497192383\n",
      "Epoch: 2, Batch: 278, D Loss: 0.10158167606277857, G Loss: 9.68170166015625\n",
      "Epoch: 2, Batch: 279, D Loss: 0.09944053206709214, G Loss: 9.694581985473633\n",
      "Epoch: 2, Batch: 280, D Loss: 0.10128723503294168, G Loss: 9.607624053955078\n",
      "Epoch: 2, Batch: 281, D Loss: 0.10089555084050517, G Loss: 10.085277557373047\n",
      "Epoch: 2, Batch: 282, D Loss: 0.09811096823250409, G Loss: 9.864526748657227\n",
      "Epoch: 2, Batch: 283, D Loss: 0.09856720930110896, G Loss: 9.601033210754395\n",
      "Epoch: 2, Batch: 284, D Loss: 0.09389101700071478, G Loss: 8.908214569091797\n",
      "Epoch: 2, Batch: 285, D Loss: 0.09830979147227481, G Loss: 8.922039031982422\n",
      "Epoch: 2, Batch: 286, D Loss: 0.10509103207732551, G Loss: 9.755781173706055\n",
      "Epoch: 2, Batch: 287, D Loss: 0.09927968636839068, G Loss: 10.471776962280273\n",
      "Epoch: 2, Batch: 288, D Loss: 0.10418677356938133, G Loss: 10.360414505004883\n",
      "Epoch: 2, Batch: 289, D Loss: 0.09604256512830034, G Loss: 9.361968994140625\n",
      "Epoch: 2, Batch: 290, D Loss: 0.10052822981378995, G Loss: 8.314706802368164\n",
      "Epoch: 2, Batch: 291, D Loss: 0.09733068681089208, G Loss: 8.22900390625\n",
      "Epoch: 2, Batch: 292, D Loss: 0.1023779601600836, G Loss: 8.841537475585938\n",
      "Epoch: 2, Batch: 293, D Loss: 0.0940962912136456, G Loss: 8.661263465881348\n",
      "Epoch: 2, Batch: 294, D Loss: 0.10383093473501503, G Loss: 9.608927726745605\n",
      "Epoch: 2, Batch: 295, D Loss: 0.09934176465321798, G Loss: 8.743545532226562\n",
      "Epoch: 2, Batch: 296, D Loss: 0.09614418071578257, G Loss: 8.000737190246582\n",
      "Epoch: 2, Batch: 297, D Loss: 0.1060839549463708, G Loss: 8.896553039550781\n",
      "Epoch: 2, Batch: 298, D Loss: 0.10322213996187202, G Loss: 9.704792022705078\n",
      "Epoch: 2, Batch: 299, D Loss: 0.09880724592949264, G Loss: 9.667637825012207\n",
      "Epoch: 2, Batch: 300, D Loss: 0.10160861336044036, G Loss: 9.48745346069336\n",
      "Epoch: 2, Batch: 301, D Loss: 0.09974293644336285, G Loss: 9.40839958190918\n",
      "Epoch: 2, Batch: 302, D Loss: 0.1057729087624466, G Loss: 8.54482650756836\n",
      "Epoch: 2, Batch: 303, D Loss: 0.0966289372445317, G Loss: 8.984975814819336\n",
      "Epoch: 2, Batch: 304, D Loss: 0.09509271803108277, G Loss: 8.672445297241211\n",
      "Epoch: 2, Batch: 305, D Loss: 0.09593006630893797, G Loss: 8.117518424987793\n",
      "Epoch: 2, Batch: 306, D Loss: 0.09290266296011396, G Loss: 8.421897888183594\n",
      "Epoch: 2, Batch: 307, D Loss: 0.09874231524008792, G Loss: 8.625463485717773\n",
      "Epoch: 2, Batch: 308, D Loss: 0.103777227071987, G Loss: 9.357405662536621\n",
      "Epoch: 2, Batch: 309, D Loss: 0.10919927357463166, G Loss: 8.851461410522461\n",
      "Epoch: 2, Batch: 310, D Loss: 0.10292918460618239, G Loss: 9.133075714111328\n",
      "Epoch: 2, Batch: 311, D Loss: 0.09600121375115123, G Loss: 8.269142150878906\n",
      "Epoch: 2, Batch: 312, D Loss: 0.09788617509184405, G Loss: 8.565265655517578\n",
      "Epoch: 2, Batch: 313, D Loss: 0.0954157164087519, G Loss: 7.890233993530273\n",
      "Epoch: 2, Batch: 314, D Loss: 0.09769690071698278, G Loss: 7.8113555908203125\n",
      "Epoch: 2, Batch: 315, D Loss: 0.10533998297614744, G Loss: 9.8299560546875\n",
      "Epoch: 2, Batch: 316, D Loss: 0.09754337735103036, G Loss: 10.968976974487305\n",
      "Epoch: 2, Batch: 317, D Loss: 0.0998977186573029, G Loss: 9.791157722473145\n",
      "Epoch: 2, Batch: 318, D Loss: 0.09825488716887776, G Loss: 8.862260818481445\n",
      "Epoch: 2, Batch: 319, D Loss: 0.09241428156383336, G Loss: 7.223495006561279\n",
      "Epoch: 2, Batch: 320, D Loss: 0.1069148862734437, G Loss: 8.757530212402344\n",
      "Epoch: 2, Batch: 321, D Loss: 0.09951156416536833, G Loss: 12.370587348937988\n",
      "Epoch: 2, Batch: 322, D Loss: 0.12156409250383149, G Loss: 6.750597953796387\n",
      "Epoch: 2, Batch: 323, D Loss: 0.10555971460416913, G Loss: 7.089226722717285\n",
      "Epoch: 2, Batch: 324, D Loss: 0.1004851760881138, G Loss: 11.726814270019531\n",
      "Epoch: 2, Batch: 325, D Loss: 0.0984798285544457, G Loss: 14.510472297668457\n",
      "Epoch: 2, Batch: 326, D Loss: 0.10071359120398427, G Loss: 16.965803146362305\n",
      "Epoch: 2, Batch: 327, D Loss: 0.10424441830815256, G Loss: 19.083383560180664\n",
      "Epoch: 2, Batch: 328, D Loss: 0.09302834546038885, G Loss: 20.4704647064209\n",
      "Epoch: 2, Batch: 329, D Loss: 0.09802570243494746, G Loss: 21.027029037475586\n",
      "Epoch: 2, Batch: 330, D Loss: 0.10507291586157155, G Loss: 21.404956817626953\n",
      "Epoch: 2, Batch: 331, D Loss: 0.1040286500680819, G Loss: 21.065906524658203\n",
      "Epoch: 2, Batch: 332, D Loss: 0.09871932897283336, G Loss: 21.29224395751953\n",
      "Epoch: 2, Batch: 333, D Loss: 0.10154378437054379, G Loss: 21.69991683959961\n",
      "Epoch: 2, Batch: 334, D Loss: 0.09809675828672644, G Loss: 22.015153884887695\n",
      "Epoch: 2, Batch: 335, D Loss: 0.10192199810857636, G Loss: 21.92406463623047\n",
      "Epoch: 2, Batch: 336, D Loss: 0.10352169748229409, G Loss: 20.90410614013672\n",
      "Epoch: 2, Batch: 337, D Loss: 0.10210602053920992, G Loss: 19.976646423339844\n",
      "Epoch: 2, Batch: 338, D Loss: 0.1003184706939142, G Loss: 19.247419357299805\n",
      "Epoch: 2, Batch: 339, D Loss: 0.0963239500853792, G Loss: 17.23072624206543\n",
      "Epoch: 2, Batch: 340, D Loss: 0.09672480363675007, G Loss: 16.586944580078125\n",
      "Epoch: 2, Batch: 341, D Loss: 0.10338065652662465, G Loss: 16.318622589111328\n",
      "Epoch: 2, Batch: 342, D Loss: 0.09494607019294676, G Loss: 15.909985542297363\n",
      "Epoch: 2, Batch: 343, D Loss: 0.10565943448683868, G Loss: 15.698278427124023\n",
      "Epoch: 2, Batch: 344, D Loss: 0.10188988812105038, G Loss: 15.509160995483398\n",
      "Epoch: 2, Batch: 345, D Loss: 0.10201741645946072, G Loss: 15.294819831848145\n",
      "Epoch: 2, Batch: 346, D Loss: 0.09854375107543945, G Loss: 14.747903823852539\n",
      "Epoch: 2, Batch: 347, D Loss: 0.0964116920969218, G Loss: 12.901187896728516\n",
      "Epoch: 2, Batch: 348, D Loss: 0.10188581356669602, G Loss: 12.513750076293945\n",
      "Epoch: 2, Batch: 349, D Loss: 0.09631882093526656, G Loss: 9.115550994873047\n",
      "Epoch: 2, Batch: 350, D Loss: 0.09808830857218709, G Loss: 8.874923706054688\n",
      "Epoch: 2, Batch: 351, D Loss: 0.10900815994682489, G Loss: 9.15597915649414\n",
      "Epoch: 2, Batch: 352, D Loss: 0.10322503306815634, G Loss: 9.500324249267578\n",
      "Epoch: 2, Batch: 353, D Loss: 0.10182737286959309, G Loss: 8.244714736938477\n",
      "Epoch: 2, Batch: 354, D Loss: 0.10012642532819882, G Loss: 7.343576908111572\n",
      "Epoch: 2, Batch: 355, D Loss: 0.09836400533095002, G Loss: 8.073495864868164\n",
      "Epoch: 2, Batch: 356, D Loss: 0.09706811215437483, G Loss: 9.258177757263184\n",
      "Epoch: 2, Batch: 357, D Loss: 0.0979224200345925, G Loss: 9.338924407958984\n",
      "Epoch: 2, Batch: 358, D Loss: 0.09603052082456998, G Loss: 9.918834686279297\n",
      "Epoch: 2, Batch: 359, D Loss: 0.09935479526757263, G Loss: 8.716623306274414\n",
      "Epoch: 2, Batch: 360, D Loss: 0.09678669652930694, G Loss: 9.128403663635254\n",
      "Epoch: 2, Batch: 361, D Loss: 0.09124709782190621, G Loss: 8.847868919372559\n",
      "Epoch: 2, Batch: 362, D Loss: 0.09804940005415119, G Loss: 9.345880508422852\n",
      "Epoch: 2, Batch: 363, D Loss: 0.10122204107028665, G Loss: 9.848690032958984\n",
      "Epoch: 2, Batch: 364, D Loss: 0.10211816896844539, G Loss: 10.086566925048828\n",
      "Epoch: 2, Batch: 365, D Loss: 0.10395034441899043, G Loss: 10.70872688293457\n",
      "Epoch: 2, Batch: 366, D Loss: 0.09787386530115327, G Loss: 10.966361045837402\n",
      "Epoch: 2, Batch: 367, D Loss: 0.10560120354421088, G Loss: 10.237593650817871\n",
      "Epoch: 2, Batch: 368, D Loss: 0.10340913214895409, G Loss: 8.379233360290527\n",
      "Epoch: 2, Batch: 369, D Loss: 0.09933334804372862, G Loss: 7.4515485763549805\n",
      "Epoch: 2, Batch: 370, D Loss: 0.09942946571391076, G Loss: 8.266551971435547\n",
      "Epoch: 2, Batch: 371, D Loss: 0.09893065302458126, G Loss: 8.448934555053711\n",
      "Epoch: 2, Batch: 372, D Loss: 0.09987212356645614, G Loss: 8.80302619934082\n",
      "Epoch: 2, Batch: 373, D Loss: 0.09559691837057471, G Loss: 8.898903846740723\n",
      "Epoch: 2, Batch: 374, D Loss: 0.09583804114663508, G Loss: 9.421795845031738\n",
      "Epoch: 2, Batch: 375, D Loss: 0.09702834366180468, G Loss: 9.788691520690918\n",
      "Epoch: 2, Batch: 376, D Loss: 0.10340660558722448, G Loss: 10.025106430053711\n",
      "Epoch: 2, Batch: 377, D Loss: 0.0975296017677465, G Loss: 10.418485641479492\n",
      "Epoch: 2, Batch: 378, D Loss: 0.0998851192634902, G Loss: 9.00330924987793\n",
      "Epoch: 2, Batch: 379, D Loss: 0.09724839002592489, G Loss: 7.810787200927734\n",
      "Epoch: 2, Batch: 380, D Loss: 0.098450118501205, G Loss: 7.711535930633545\n",
      "Epoch: 2, Batch: 381, D Loss: 0.09770928128273226, G Loss: 8.388161659240723\n",
      "Epoch: 2, Batch: 382, D Loss: 0.1073186165158404, G Loss: 9.39712905883789\n",
      "Epoch: 2, Batch: 383, D Loss: 0.1057931950672355, G Loss: 10.130695343017578\n",
      "Epoch: 2, Batch: 384, D Loss: 0.10464831013632647, G Loss: 10.323232650756836\n",
      "Epoch: 2, Batch: 385, D Loss: 0.10513857829209883, G Loss: 9.287395477294922\n",
      "Epoch: 2, Batch: 386, D Loss: 0.10052127816015854, G Loss: 8.672979354858398\n",
      "Epoch: 2, Batch: 387, D Loss: 0.10093065073306207, G Loss: 8.488495826721191\n",
      "Epoch: 2, Batch: 388, D Loss: 0.09844657633948373, G Loss: 8.624483108520508\n",
      "Epoch: 2, Batch: 389, D Loss: 0.10261174981133081, G Loss: 9.251639366149902\n",
      "Epoch: 2, Batch: 390, D Loss: 0.10423618511049426, G Loss: 9.986286163330078\n",
      "Epoch: 2, Batch: 391, D Loss: 0.09850355374874198, G Loss: 10.614971160888672\n",
      "Epoch: 2, Batch: 392, D Loss: 0.09994124136483151, G Loss: 11.040668487548828\n",
      "Epoch: 2, Batch: 393, D Loss: 0.08852476813171961, G Loss: 11.104801177978516\n",
      "Epoch: 2, Batch: 394, D Loss: 0.09763642900725245, G Loss: 11.04334831237793\n",
      "Epoch: 2, Batch: 395, D Loss: 0.0980426016740239, G Loss: 10.833614349365234\n",
      "Epoch: 2, Batch: 396, D Loss: 0.10466571268443658, G Loss: 10.99390983581543\n",
      "Epoch: 2, Batch: 397, D Loss: 0.09924527061593835, G Loss: 11.2555513381958\n",
      "Epoch: 2, Batch: 398, D Loss: 0.09934916299425822, G Loss: 11.520415306091309\n",
      "Epoch: 2, Batch: 399, D Loss: 0.09932581398879847, G Loss: 11.690889358520508\n",
      "Epoch: 2, Batch: 400, D Loss: 0.09619000829479774, G Loss: 11.635388374328613\n",
      "Epoch: 2, Batch: 401, D Loss: 0.10329301432102511, G Loss: 11.591718673706055\n",
      "Epoch: 2, Batch: 402, D Loss: 0.09850349845783057, G Loss: 11.536625862121582\n",
      "Epoch: 2, Batch: 403, D Loss: 0.095582159105561, G Loss: 11.478325843811035\n",
      "Epoch: 2, Batch: 404, D Loss: 0.101417826116176, G Loss: 11.467592239379883\n",
      "Epoch: 2, Batch: 405, D Loss: 0.10222147538752324, G Loss: 11.543828010559082\n",
      "Epoch: 2, Batch: 406, D Loss: 0.10889784834307648, G Loss: 11.755739212036133\n",
      "Epoch: 2, Batch: 407, D Loss: 0.10102239671323332, G Loss: 11.36435317993164\n",
      "Epoch: 2, Batch: 408, D Loss: 0.09428895637938695, G Loss: 11.167887687683105\n",
      "Epoch: 2, Batch: 409, D Loss: 0.10391829833406518, G Loss: 11.041135787963867\n",
      "Epoch: 2, Batch: 410, D Loss: 0.09029124879725714, G Loss: 10.783061981201172\n",
      "Epoch: 2, Batch: 411, D Loss: 0.0940611612804787, G Loss: 10.140878677368164\n",
      "Epoch: 2, Batch: 412, D Loss: 0.1026663156790164, G Loss: 9.970979690551758\n",
      "Epoch: 2, Batch: 413, D Loss: 0.09554597541864496, G Loss: 9.785202026367188\n",
      "Epoch: 2, Batch: 414, D Loss: 0.10240432632963348, G Loss: 9.964656829833984\n",
      "Epoch: 2, Batch: 415, D Loss: 0.1009995845706726, G Loss: 10.24736213684082\n",
      "Epoch: 2, Batch: 416, D Loss: 0.10237333708391816, G Loss: 10.20026969909668\n",
      "Epoch: 2, Batch: 417, D Loss: 0.09848006100219209, G Loss: 10.318751335144043\n",
      "Epoch: 2, Batch: 418, D Loss: 0.103328075592799, G Loss: 10.383563995361328\n",
      "Epoch: 2, Batch: 419, D Loss: 0.09637933705016621, G Loss: 9.824811935424805\n",
      "Epoch: 2, Batch: 420, D Loss: 0.1007995182153536, G Loss: 9.629419326782227\n",
      "Epoch: 2, Batch: 421, D Loss: 0.10156811986962566, G Loss: 9.682257652282715\n",
      "Epoch: 2, Batch: 422, D Loss: 0.10169069998664781, G Loss: 9.765710830688477\n",
      "Epoch: 2, Batch: 423, D Loss: 0.09292944907792844, G Loss: 9.547361373901367\n",
      "Epoch: 2, Batch: 424, D Loss: 0.09506873684586026, G Loss: 9.367490768432617\n",
      "Epoch: 2, Batch: 425, D Loss: 0.09701705525731086, G Loss: 9.569392204284668\n",
      "Epoch: 2, Batch: 426, D Loss: 0.09906662488356233, G Loss: 9.830060005187988\n",
      "Epoch: 2, Batch: 427, D Loss: 0.09503087045959546, G Loss: 9.720455169677734\n",
      "Epoch: 2, Batch: 428, D Loss: 0.09519704824560904, G Loss: 9.621682167053223\n",
      "Epoch: 2, Batch: 429, D Loss: 0.1024630964602693, G Loss: 9.922676086425781\n",
      "Epoch: 2, Batch: 430, D Loss: 0.0989944312186708, G Loss: 10.175941467285156\n",
      "Epoch: 2, Batch: 431, D Loss: 0.09275993809205829, G Loss: 10.293128967285156\n",
      "Epoch: 2, Batch: 432, D Loss: 0.09834380482789129, G Loss: 10.400205612182617\n",
      "Epoch: 2, Batch: 433, D Loss: 0.10266556808983296, G Loss: 10.491576194763184\n",
      "Epoch: 2, Batch: 434, D Loss: 0.0988133958844628, G Loss: 10.651747703552246\n",
      "Epoch: 2, Batch: 435, D Loss: 0.1030189087450708, G Loss: 10.841045379638672\n",
      "Epoch: 2, Batch: 436, D Loss: 0.09610652562969335, G Loss: 10.956653594970703\n",
      "Epoch: 2, Batch: 437, D Loss: 0.10380941171752056, G Loss: 11.075139999389648\n",
      "Epoch: 2, Batch: 438, D Loss: 0.09665281480192789, G Loss: 10.930025100708008\n",
      "Epoch: 2, Batch: 439, D Loss: 0.10280463372328086, G Loss: 10.080350875854492\n",
      "Epoch: 2, Batch: 440, D Loss: 0.09974267151483218, G Loss: 10.051429748535156\n",
      "Epoch: 2, Batch: 441, D Loss: 0.09405450560734607, G Loss: 9.968339920043945\n",
      "Epoch: 2, Batch: 442, D Loss: 0.10071480854458059, G Loss: 9.977873802185059\n",
      "Epoch: 2, Batch: 443, D Loss: 0.0944275984838896, G Loss: 9.992504119873047\n",
      "Epoch: 2, Batch: 444, D Loss: 0.10265334708310547, G Loss: 10.25224494934082\n",
      "Epoch: 2, Batch: 445, D Loss: 0.09595977561184554, G Loss: 10.457894325256348\n",
      "Epoch: 2, Batch: 446, D Loss: 0.09878961063986935, G Loss: 10.620323181152344\n",
      "Epoch: 2, Batch: 447, D Loss: 0.09847526428347919, G Loss: 10.70863151550293\n",
      "Epoch: 2, Batch: 448, D Loss: 0.09753650673155789, G Loss: 10.745254516601562\n",
      "Epoch: 2, Batch: 449, D Loss: 0.09335138626192929, G Loss: 10.648801803588867\n",
      "Epoch: 2, Batch: 450, D Loss: 0.10109692784135405, G Loss: 10.70793628692627\n",
      "Epoch: 2, Batch: 451, D Loss: 0.09627992591686052, G Loss: 10.585081100463867\n",
      "Epoch: 2, Batch: 452, D Loss: 0.10128836515832518, G Loss: 10.799378395080566\n",
      "Epoch: 2, Batch: 453, D Loss: 0.09525897096500557, G Loss: 10.956284523010254\n",
      "Epoch: 2, Batch: 454, D Loss: 0.10292689245852671, G Loss: 11.145177841186523\n",
      "Epoch: 2, Batch: 455, D Loss: 0.10574060855833523, G Loss: 11.296582221984863\n",
      "Epoch: 2, Batch: 456, D Loss: 0.09260850749069505, G Loss: 10.691208839416504\n",
      "Epoch: 2, Batch: 457, D Loss: 0.09853975600344711, G Loss: 10.44604206085205\n",
      "Epoch: 2, Batch: 458, D Loss: 0.10080314390506828, G Loss: 9.97999382019043\n",
      "Epoch: 2, Batch: 459, D Loss: 0.10420008410983428, G Loss: 9.854159355163574\n",
      "Epoch: 2, Batch: 460, D Loss: 0.09973296636962914, G Loss: 10.102901458740234\n",
      "Epoch: 2, Batch: 461, D Loss: 0.10558560250865412, G Loss: 10.456094741821289\n",
      "Epoch: 2, Batch: 462, D Loss: 0.09936399341677316, G Loss: 10.676931381225586\n",
      "Epoch: 2, Batch: 463, D Loss: 0.09783547391089087, G Loss: 10.589653015136719\n",
      "Epoch: 2, Batch: 464, D Loss: 0.10474914606311359, G Loss: 9.686028480529785\n",
      "Epoch: 2, Batch: 465, D Loss: 0.09958786499191774, G Loss: 9.76138687133789\n",
      "Epoch: 2, Batch: 466, D Loss: 0.10350465343253745, G Loss: 10.010555267333984\n",
      "Epoch: 2, Batch: 467, D Loss: 0.09365069559135009, G Loss: 10.169867515563965\n",
      "Epoch: 3, Batch: 0, D Loss: 0.09957652159755526, G Loss: 10.400211334228516\n",
      "Epoch: 3, Batch: 1, D Loss: 0.10017813847025536, G Loss: 10.629581451416016\n",
      "Epoch: 3, Batch: 2, D Loss: 0.10266472596777021, G Loss: 10.893721580505371\n",
      "Epoch: 3, Batch: 3, D Loss: 0.09723955718618527, G Loss: 11.02018928527832\n",
      "Epoch: 3, Batch: 4, D Loss: 0.10047840141032793, G Loss: 10.852222442626953\n",
      "Epoch: 3, Batch: 5, D Loss: 0.10785190824117308, G Loss: 11.027397155761719\n",
      "Epoch: 3, Batch: 6, D Loss: 0.099250534465682, G Loss: 11.125361442565918\n",
      "Epoch: 3, Batch: 7, D Loss: 0.1034069059542162, G Loss: 11.224377632141113\n",
      "Epoch: 3, Batch: 8, D Loss: 0.10207995829387073, G Loss: 11.297933578491211\n",
      "Epoch: 3, Batch: 9, D Loss: 0.09814498406922212, G Loss: 11.29599666595459\n",
      "Epoch: 3, Batch: 10, D Loss: 0.09123774920044525, G Loss: 11.156134605407715\n",
      "Epoch: 3, Batch: 11, D Loss: 0.10391864479606738, G Loss: 11.299139022827148\n",
      "Epoch: 3, Batch: 12, D Loss: 0.10547385322206537, G Loss: 11.657657623291016\n",
      "Epoch: 3, Batch: 13, D Loss: 0.10387459641515306, G Loss: 11.951677322387695\n",
      "Epoch: 3, Batch: 14, D Loss: 0.10181183399572546, G Loss: 11.585223197937012\n",
      "Epoch: 3, Batch: 15, D Loss: 0.09547299399855547, G Loss: 11.03480339050293\n",
      "Epoch: 3, Batch: 16, D Loss: 0.10112141178524325, G Loss: 10.966337203979492\n",
      "Epoch: 3, Batch: 17, D Loss: 0.0988937261281535, G Loss: 10.928520202636719\n",
      "Epoch: 3, Batch: 18, D Loss: 0.09231819069736957, G Loss: 10.760917663574219\n",
      "Epoch: 3, Batch: 19, D Loss: 0.10099386779347697, G Loss: 10.832856178283691\n",
      "Epoch: 3, Batch: 20, D Loss: 0.0928168334885413, G Loss: 11.025242805480957\n",
      "Epoch: 3, Batch: 21, D Loss: 0.1045586181840008, G Loss: 11.37476634979248\n",
      "Epoch: 3, Batch: 22, D Loss: 0.09670514713889133, G Loss: 11.629327774047852\n",
      "Epoch: 3, Batch: 23, D Loss: 0.10274243982485132, G Loss: 11.491226196289062\n",
      "Epoch: 3, Batch: 24, D Loss: 0.10081010578869609, G Loss: 10.9155855178833\n",
      "Epoch: 3, Batch: 25, D Loss: 0.09721365065797727, G Loss: 10.62090015411377\n",
      "Epoch: 3, Batch: 26, D Loss: 0.10193751790757233, G Loss: 10.365549087524414\n",
      "Epoch: 3, Batch: 27, D Loss: 0.09818618007193436, G Loss: 10.122669219970703\n",
      "Epoch: 3, Batch: 28, D Loss: 0.09815739700570703, G Loss: 9.863737106323242\n",
      "Epoch: 3, Batch: 29, D Loss: 0.09617909365624655, G Loss: 9.528173446655273\n",
      "Epoch: 3, Batch: 30, D Loss: 0.1030950476124417, G Loss: 9.815750122070312\n",
      "Epoch: 3, Batch: 31, D Loss: 0.10020885661288048, G Loss: 10.21699333190918\n",
      "Epoch: 3, Batch: 32, D Loss: 0.09950865537575737, G Loss: 10.61694049835205\n",
      "Epoch: 3, Batch: 33, D Loss: 0.10019066143831878, G Loss: 10.881694793701172\n",
      "Epoch: 3, Batch: 34, D Loss: 0.10086467909422936, G Loss: 11.098278999328613\n",
      "Epoch: 3, Batch: 35, D Loss: 0.10171513524574038, G Loss: 11.283848762512207\n",
      "Epoch: 3, Batch: 36, D Loss: 0.09516561258851652, G Loss: 11.304738998413086\n",
      "Epoch: 3, Batch: 37, D Loss: 0.09621377373696305, G Loss: 11.246103286743164\n",
      "Epoch: 3, Batch: 38, D Loss: 0.09971670130335042, G Loss: 11.362135887145996\n",
      "Epoch: 3, Batch: 39, D Loss: 0.10096995752064686, G Loss: 11.6537446975708\n",
      "Epoch: 3, Batch: 40, D Loss: 0.09798851674941034, G Loss: 11.5485258102417\n",
      "Epoch: 3, Batch: 41, D Loss: 0.1020720652595628, G Loss: 11.626626968383789\n",
      "Epoch: 3, Batch: 42, D Loss: 0.09554586034892054, G Loss: 11.658405303955078\n",
      "Epoch: 3, Batch: 43, D Loss: 0.10232158238795819, G Loss: 11.711273193359375\n",
      "Epoch: 3, Batch: 44, D Loss: 0.10702049206975062, G Loss: 11.795544624328613\n",
      "Epoch: 3, Batch: 45, D Loss: 0.09959792816107438, G Loss: 11.840514183044434\n",
      "Epoch: 3, Batch: 46, D Loss: 0.09842869521344255, G Loss: 11.806879043579102\n",
      "Epoch: 3, Batch: 47, D Loss: 0.09608171864147153, G Loss: 11.683568954467773\n",
      "Epoch: 3, Batch: 48, D Loss: 0.10203185222235334, G Loss: 11.611554145812988\n",
      "Epoch: 3, Batch: 49, D Loss: 0.0999837388267224, G Loss: 11.591268539428711\n",
      "Epoch: 3, Batch: 50, D Loss: 0.10034586492747621, G Loss: 11.698646545410156\n",
      "Epoch: 3, Batch: 51, D Loss: 0.09619832990347277, G Loss: 11.768311500549316\n",
      "Epoch: 3, Batch: 52, D Loss: 0.10454145652829538, G Loss: 11.435761451721191\n",
      "Epoch: 3, Batch: 53, D Loss: 0.10171125011493132, G Loss: 11.446321487426758\n",
      "Epoch: 3, Batch: 54, D Loss: 0.09946618385220063, G Loss: 11.429228782653809\n",
      "Epoch: 3, Batch: 55, D Loss: 0.10009230514606315, G Loss: 11.376643180847168\n",
      "Epoch: 3, Batch: 56, D Loss: 0.09149408183111518, G Loss: 11.145156860351562\n",
      "Epoch: 3, Batch: 57, D Loss: 0.09910177177243895, G Loss: 11.100499153137207\n",
      "Epoch: 3, Batch: 58, D Loss: 0.10259681716297564, G Loss: 11.3328857421875\n",
      "Epoch: 3, Batch: 59, D Loss: 0.09257734881975921, G Loss: 11.47944450378418\n",
      "Epoch: 3, Batch: 60, D Loss: 0.0976210287435606, G Loss: 11.61499309539795\n",
      "Epoch: 3, Batch: 61, D Loss: 0.10100174893796066, G Loss: 11.757553100585938\n",
      "Epoch: 3, Batch: 62, D Loss: 0.097753448552794, G Loss: 11.8104248046875\n",
      "Epoch: 3, Batch: 63, D Loss: 0.09717894461778087, G Loss: 11.829326629638672\n",
      "Epoch: 3, Batch: 64, D Loss: 0.1019505171207129, G Loss: 11.880105972290039\n",
      "Epoch: 3, Batch: 65, D Loss: 0.10139062836037738, G Loss: 11.94040584564209\n",
      "Epoch: 3, Batch: 66, D Loss: 0.10020641583696488, G Loss: 11.234532356262207\n",
      "Epoch: 3, Batch: 67, D Loss: 0.09603826492912049, G Loss: 11.056529998779297\n",
      "Epoch: 3, Batch: 68, D Loss: 0.09814386966809252, G Loss: 11.082741737365723\n",
      "Epoch: 3, Batch: 69, D Loss: 0.10719429042092088, G Loss: 11.291718482971191\n",
      "Epoch: 3, Batch: 70, D Loss: 0.0976017905372828, G Loss: 11.48635482788086\n",
      "Epoch: 3, Batch: 71, D Loss: 0.10281595186916093, G Loss: 11.592721939086914\n",
      "Epoch: 3, Batch: 72, D Loss: 0.09974555427697851, G Loss: 11.57609748840332\n",
      "Epoch: 3, Batch: 73, D Loss: 0.10057727658477233, G Loss: 11.520444869995117\n",
      "Epoch: 3, Batch: 74, D Loss: 0.10101368840514624, G Loss: 11.484965324401855\n",
      "Epoch: 3, Batch: 75, D Loss: 0.10355459027323377, G Loss: 11.505094528198242\n",
      "Epoch: 3, Batch: 76, D Loss: 0.10106754140178964, G Loss: 11.571264266967773\n",
      "Epoch: 3, Batch: 77, D Loss: 0.10115103803764214, G Loss: 11.587384223937988\n",
      "Epoch: 3, Batch: 78, D Loss: 0.09623929175313606, G Loss: 11.51827621459961\n",
      "Epoch: 3, Batch: 79, D Loss: 0.09969880475455284, G Loss: 11.479060173034668\n",
      "Epoch: 3, Batch: 80, D Loss: 0.09720192589566068, G Loss: 11.48106575012207\n",
      "Epoch: 3, Batch: 81, D Loss: 0.10141524304526683, G Loss: 11.573929786682129\n",
      "Epoch: 3, Batch: 82, D Loss: 0.10616094808574417, G Loss: 11.767632484436035\n",
      "Epoch: 3, Batch: 83, D Loss: 0.09243451075235498, G Loss: 11.796581268310547\n",
      "Epoch: 3, Batch: 84, D Loss: 0.10335290647071815, G Loss: 11.849111557006836\n",
      "Epoch: 3, Batch: 85, D Loss: 0.10577426481358998, G Loss: 11.939966201782227\n",
      "Epoch: 3, Batch: 86, D Loss: 0.10130219781672167, G Loss: 11.958659172058105\n",
      "Epoch: 3, Batch: 87, D Loss: 0.10074328432369839, G Loss: 11.916303634643555\n",
      "Epoch: 3, Batch: 88, D Loss: 0.09855427692036756, G Loss: 11.84427261352539\n",
      "Epoch: 3, Batch: 89, D Loss: 0.09455709786561783, G Loss: 11.59599494934082\n",
      "Epoch: 3, Batch: 90, D Loss: 0.10171259926119092, G Loss: 11.577719688415527\n",
      "Epoch: 3, Batch: 91, D Loss: 0.09724994206953852, G Loss: 11.685933113098145\n",
      "Epoch: 3, Batch: 92, D Loss: 0.10690012887152989, G Loss: 11.960245132446289\n",
      "Epoch: 3, Batch: 93, D Loss: 0.10476898793490363, G Loss: 12.158699035644531\n",
      "Epoch: 3, Batch: 94, D Loss: 0.10104123467090176, G Loss: 12.222795486450195\n",
      "Epoch: 3, Batch: 95, D Loss: 0.10168626716927065, G Loss: 12.13852310180664\n",
      "Epoch: 3, Batch: 96, D Loss: 0.09450898053000856, G Loss: 11.935080528259277\n",
      "Epoch: 3, Batch: 97, D Loss: 0.09839793352671222, G Loss: 11.667600631713867\n",
      "Epoch: 3, Batch: 98, D Loss: 0.10143610234717926, G Loss: 11.622710227966309\n",
      "Epoch: 3, Batch: 99, D Loss: 0.09612361474046338, G Loss: 11.577844619750977\n",
      "Epoch: 3, Batch: 100, D Loss: 0.10304151373020431, G Loss: 11.860515594482422\n",
      "Epoch: 3, Batch: 101, D Loss: 0.09573279100231957, G Loss: 12.009156227111816\n",
      "Epoch: 3, Batch: 102, D Loss: 0.1026959530449858, G Loss: 12.139505386352539\n",
      "Epoch: 3, Batch: 103, D Loss: 0.09986518578216419, G Loss: 12.156414985656738\n",
      "Epoch: 3, Batch: 104, D Loss: 0.09877832556367139, G Loss: 12.042215347290039\n",
      "Epoch: 3, Batch: 105, D Loss: 0.09924864123854604, G Loss: 11.954695701599121\n",
      "Epoch: 3, Batch: 106, D Loss: 0.09711519740312724, G Loss: 11.909603118896484\n",
      "Epoch: 3, Batch: 107, D Loss: 0.0965604432640248, G Loss: 11.911455154418945\n",
      "Epoch: 3, Batch: 108, D Loss: 0.09262041379588482, G Loss: 11.91317367553711\n",
      "Epoch: 3, Batch: 109, D Loss: 0.09794763720651645, G Loss: 11.963430404663086\n",
      "Epoch: 3, Batch: 110, D Loss: 0.0913451036162769, G Loss: 12.006731033325195\n",
      "Epoch: 3, Batch: 111, D Loss: 0.09650806919853494, G Loss: 11.301090240478516\n",
      "Epoch: 3, Batch: 112, D Loss: 0.09692718985752435, G Loss: 10.776872634887695\n",
      "Epoch: 3, Batch: 113, D Loss: 0.09604380796190526, G Loss: 10.45919132232666\n",
      "Epoch: 3, Batch: 114, D Loss: 0.10074038222410309, G Loss: 10.323053359985352\n",
      "Epoch: 3, Batch: 115, D Loss: 0.09841833003156353, G Loss: 10.176279067993164\n",
      "Epoch: 3, Batch: 116, D Loss: 0.09692354558137595, G Loss: 10.052861213684082\n",
      "Epoch: 3, Batch: 117, D Loss: 0.10266874846274732, G Loss: 10.095518112182617\n",
      "Epoch: 3, Batch: 118, D Loss: 0.1039199067708978, G Loss: 10.266243934631348\n",
      "Epoch: 3, Batch: 119, D Loss: 0.09741900070002885, G Loss: 10.382942199707031\n",
      "Epoch: 3, Batch: 120, D Loss: 0.09975931495500845, G Loss: 10.437278747558594\n",
      "Epoch: 3, Batch: 121, D Loss: 0.09939554263291939, G Loss: 10.5602388381958\n",
      "Epoch: 3, Batch: 122, D Loss: 0.09862998055905337, G Loss: 10.703326225280762\n",
      "Epoch: 3, Batch: 123, D Loss: 0.10650329158215754, G Loss: 11.047477722167969\n",
      "Epoch: 3, Batch: 124, D Loss: 0.10178808603541256, G Loss: 11.373937606811523\n",
      "Epoch: 3, Batch: 125, D Loss: 0.10204865758669257, G Loss: 11.644414901733398\n",
      "Epoch: 3, Batch: 126, D Loss: 0.09957380171272234, G Loss: 11.763687133789062\n",
      "Epoch: 3, Batch: 127, D Loss: 0.09711415658148326, G Loss: 11.721990585327148\n",
      "Epoch: 3, Batch: 128, D Loss: 0.09846246092365618, G Loss: 11.733942031860352\n",
      "Epoch: 3, Batch: 129, D Loss: 0.0964736047480983, G Loss: 11.747206687927246\n",
      "Epoch: 3, Batch: 130, D Loss: 0.09994345029144824, G Loss: 11.882978439331055\n",
      "Epoch: 3, Batch: 131, D Loss: 0.09995770766408896, G Loss: 11.642207145690918\n",
      "Epoch: 3, Batch: 132, D Loss: 0.10591093838138477, G Loss: 11.94074821472168\n",
      "Epoch: 3, Batch: 133, D Loss: 0.09444267696244424, G Loss: 12.029029846191406\n",
      "Epoch: 3, Batch: 134, D Loss: 0.10073561782610341, G Loss: 11.970281600952148\n",
      "Epoch: 3, Batch: 135, D Loss: 0.09842738576116972, G Loss: 11.020211219787598\n",
      "Epoch: 3, Batch: 136, D Loss: 0.09914645368553465, G Loss: 10.989652633666992\n",
      "Epoch: 3, Batch: 137, D Loss: 0.09614474098452774, G Loss: 10.97015380859375\n",
      "Epoch: 3, Batch: 138, D Loss: 0.0983036676861957, G Loss: 11.09164810180664\n",
      "Epoch: 3, Batch: 139, D Loss: 0.09783920170639249, G Loss: 11.324699401855469\n",
      "Epoch: 3, Batch: 140, D Loss: 0.10162778008088935, G Loss: 10.846199035644531\n",
      "Epoch: 3, Batch: 141, D Loss: 0.10562506669521099, G Loss: 11.109477043151855\n",
      "Epoch: 3, Batch: 142, D Loss: 0.10395696212799521, G Loss: 11.349447250366211\n",
      "Epoch: 3, Batch: 143, D Loss: 0.10050162987727163, G Loss: 11.41839599609375\n",
      "Epoch: 3, Batch: 144, D Loss: 0.10261353659734596, G Loss: 11.413006782531738\n",
      "Epoch: 3, Batch: 145, D Loss: 0.09988809428477907, G Loss: 11.358770370483398\n",
      "Epoch: 3, Batch: 146, D Loss: 0.10152399832077208, G Loss: 11.362176895141602\n",
      "Epoch: 3, Batch: 147, D Loss: 0.10043280554737066, G Loss: 11.517621994018555\n",
      "Epoch: 3, Batch: 148, D Loss: 0.0977211430463285, G Loss: 11.688295364379883\n",
      "Epoch: 3, Batch: 149, D Loss: 0.1035387366721352, G Loss: 11.88023567199707\n",
      "Epoch: 3, Batch: 150, D Loss: 0.10739871385703736, G Loss: 12.11807918548584\n",
      "Epoch: 3, Batch: 151, D Loss: 0.09685578779181014, G Loss: 12.136892318725586\n",
      "Epoch: 3, Batch: 152, D Loss: 0.09328134206270988, G Loss: 11.956802368164062\n",
      "Epoch: 3, Batch: 153, D Loss: 0.10018044698176709, G Loss: 11.878887176513672\n",
      "Epoch: 3, Batch: 154, D Loss: 0.09446167799956129, G Loss: 11.770593643188477\n",
      "Epoch: 3, Batch: 155, D Loss: 0.09814794021940543, G Loss: 11.879178047180176\n",
      "Epoch: 3, Batch: 156, D Loss: 0.1017599530860025, G Loss: 11.829442977905273\n",
      "Epoch: 3, Batch: 157, D Loss: 0.10523333423907388, G Loss: 12.147045135498047\n",
      "Epoch: 3, Batch: 158, D Loss: 0.09902766667892138, G Loss: 12.316283226013184\n",
      "Epoch: 3, Batch: 159, D Loss: 0.10347435227618007, G Loss: 12.372220993041992\n",
      "Epoch: 3, Batch: 160, D Loss: 0.10278320711177003, G Loss: 12.32792854309082\n",
      "Epoch: 3, Batch: 161, D Loss: 0.10094230575532492, G Loss: 12.227396965026855\n",
      "Epoch: 3, Batch: 162, D Loss: 0.09576937795236518, G Loss: 12.045461654663086\n",
      "Epoch: 3, Batch: 163, D Loss: 0.09840232950227801, G Loss: 11.952446937561035\n",
      "Epoch: 3, Batch: 164, D Loss: 0.10347171355442697, G Loss: 12.081440925598145\n",
      "Epoch: 3, Batch: 165, D Loss: 0.09895839078103563, G Loss: 12.279319763183594\n",
      "Epoch: 3, Batch: 166, D Loss: 0.09424861330990097, G Loss: 12.377751350402832\n",
      "Epoch: 3, Batch: 167, D Loss: 0.10269818423648758, G Loss: 12.482837677001953\n",
      "Epoch: 3, Batch: 168, D Loss: 0.10173423089213429, G Loss: 12.571090698242188\n",
      "Epoch: 3, Batch: 169, D Loss: 0.10435018608518476, G Loss: 12.658041954040527\n",
      "Epoch: 3, Batch: 170, D Loss: 0.10064245214709899, G Loss: 12.663520812988281\n",
      "Epoch: 3, Batch: 171, D Loss: 0.09515842022301513, G Loss: 12.50727367401123\n",
      "Epoch: 3, Batch: 172, D Loss: 0.0951654706973386, G Loss: 12.32898998260498\n",
      "Epoch: 3, Batch: 173, D Loss: 0.10063178945142681, G Loss: 12.305290222167969\n",
      "Epoch: 3, Batch: 174, D Loss: 0.0970769678256147, G Loss: 12.384685516357422\n",
      "Epoch: 3, Batch: 175, D Loss: 0.09592927801122642, G Loss: 12.436120986938477\n",
      "Epoch: 3, Batch: 176, D Loss: 0.10214778242641387, G Loss: 12.567339897155762\n",
      "Epoch: 3, Batch: 177, D Loss: 0.10202440148805181, G Loss: 12.665879249572754\n",
      "Epoch: 3, Batch: 178, D Loss: 0.10668247631747363, G Loss: 12.782279968261719\n",
      "Epoch: 3, Batch: 179, D Loss: 0.09611443400012831, G Loss: 12.636336326599121\n",
      "Epoch: 3, Batch: 180, D Loss: 0.10074949538898181, G Loss: 12.456198692321777\n",
      "Epoch: 3, Batch: 181, D Loss: 0.09772408484946027, G Loss: 12.239004135131836\n",
      "Epoch: 3, Batch: 182, D Loss: 0.0997496376548952, G Loss: 12.118778228759766\n",
      "Epoch: 3, Batch: 183, D Loss: 0.09705166290041234, G Loss: 12.146366119384766\n",
      "Epoch: 3, Batch: 184, D Loss: 0.09889563181309313, G Loss: 12.21042251586914\n",
      "Epoch: 3, Batch: 185, D Loss: 0.09833849342589929, G Loss: 12.260652542114258\n",
      "Epoch: 3, Batch: 186, D Loss: 0.09570781368211101, G Loss: 12.238125801086426\n",
      "Epoch: 3, Batch: 187, D Loss: 0.09969771349460643, G Loss: 12.233382225036621\n",
      "Epoch: 3, Batch: 188, D Loss: 0.10562680781526979, G Loss: 12.311238288879395\n",
      "Epoch: 3, Batch: 189, D Loss: 0.09672711488428831, G Loss: 12.275016784667969\n",
      "Epoch: 3, Batch: 190, D Loss: 0.09086821743267137, G Loss: 12.070608139038086\n",
      "Epoch: 3, Batch: 191, D Loss: 0.09789199860802, G Loss: 11.941036224365234\n",
      "Epoch: 3, Batch: 192, D Loss: 0.10003160668725286, G Loss: 11.966642379760742\n",
      "Epoch: 3, Batch: 193, D Loss: 0.09799673532938868, G Loss: 12.107101440429688\n",
      "Epoch: 3, Batch: 194, D Loss: 0.10039599731180715, G Loss: 12.305130958557129\n",
      "Epoch: 3, Batch: 195, D Loss: 0.10064359435818915, G Loss: 12.536916732788086\n",
      "Epoch: 3, Batch: 196, D Loss: 0.09951556707039799, G Loss: 12.626757621765137\n",
      "Epoch: 3, Batch: 197, D Loss: 0.10035955752346126, G Loss: 12.617345809936523\n",
      "Epoch: 3, Batch: 198, D Loss: 0.1004553341040264, G Loss: 12.542865753173828\n",
      "Epoch: 3, Batch: 199, D Loss: 0.09945074132667742, G Loss: 12.492179870605469\n",
      "Epoch: 3, Batch: 200, D Loss: 0.10104522095423363, G Loss: 12.519208908081055\n",
      "Epoch: 3, Batch: 201, D Loss: 0.10213365468848679, G Loss: 12.620037078857422\n",
      "Epoch: 3, Batch: 202, D Loss: 0.10249382078325198, G Loss: 12.738327026367188\n",
      "Epoch: 3, Batch: 203, D Loss: 0.10081404589129761, G Loss: 12.788748741149902\n",
      "Epoch: 3, Batch: 204, D Loss: 0.09558740186014347, G Loss: 12.726496696472168\n",
      "Epoch: 3, Batch: 205, D Loss: 0.10220016609468985, G Loss: 12.722933769226074\n",
      "Epoch: 3, Batch: 206, D Loss: 0.10766116710556162, G Loss: 12.852108001708984\n",
      "Epoch: 3, Batch: 207, D Loss: 0.09943148143179315, G Loss: 12.891107559204102\n",
      "Epoch: 3, Batch: 208, D Loss: 0.10526583988769289, G Loss: 12.953774452209473\n",
      "Epoch: 3, Batch: 209, D Loss: 0.09418431317624254, G Loss: 12.866750717163086\n",
      "Epoch: 3, Batch: 210, D Loss: 0.10289725641200675, G Loss: 12.917478561401367\n",
      "Epoch: 3, Batch: 211, D Loss: 0.09402647038984924, G Loss: 12.835390090942383\n",
      "Epoch: 3, Batch: 212, D Loss: 0.10105801193003572, G Loss: 12.796910285949707\n",
      "Epoch: 3, Batch: 213, D Loss: 0.09588846956455654, G Loss: 12.813272476196289\n",
      "Epoch: 3, Batch: 214, D Loss: 0.10030565288025173, G Loss: 12.86860179901123\n",
      "Epoch: 3, Batch: 215, D Loss: 0.10273727770572805, G Loss: 13.00722599029541\n",
      "Epoch: 3, Batch: 216, D Loss: 0.10214835573435721, G Loss: 13.104785919189453\n",
      "Epoch: 3, Batch: 217, D Loss: 0.0978744137440799, G Loss: 13.040984153747559\n",
      "Epoch: 3, Batch: 218, D Loss: 0.09529160233978473, G Loss: 12.84824275970459\n",
      "Epoch: 3, Batch: 219, D Loss: 0.10092775910641194, G Loss: 12.68928337097168\n",
      "Epoch: 3, Batch: 220, D Loss: 0.0974435416446795, G Loss: 11.602888107299805\n",
      "Epoch: 3, Batch: 221, D Loss: 0.09690690014440406, G Loss: 11.59205436706543\n",
      "Epoch: 3, Batch: 222, D Loss: 0.10779336300038267, G Loss: 11.834342956542969\n",
      "Epoch: 3, Batch: 223, D Loss: 0.09635400808406303, G Loss: 11.989866256713867\n",
      "Epoch: 3, Batch: 224, D Loss: 0.09963743668185998, G Loss: 12.061893463134766\n",
      "Epoch: 3, Batch: 225, D Loss: 0.10109857554061819, G Loss: 12.070289611816406\n",
      "Epoch: 3, Batch: 226, D Loss: 0.09437339014311874, G Loss: 11.953859329223633\n",
      "Epoch: 3, Batch: 227, D Loss: 0.10144393335576751, G Loss: 11.911087036132812\n",
      "Epoch: 3, Batch: 228, D Loss: 0.10116847412791685, G Loss: 11.995065689086914\n",
      "Epoch: 3, Batch: 229, D Loss: 0.10633753101774346, G Loss: 12.248040199279785\n",
      "Epoch: 3, Batch: 230, D Loss: 0.0945431693539831, G Loss: 12.358245849609375\n",
      "Epoch: 3, Batch: 231, D Loss: 0.1013656548657309, G Loss: 12.397891998291016\n",
      "Epoch: 3, Batch: 232, D Loss: 0.09358486966061719, G Loss: 12.25946044921875\n",
      "Epoch: 3, Batch: 233, D Loss: 0.09988341525604483, G Loss: 12.132406234741211\n",
      "Epoch: 3, Batch: 234, D Loss: 0.09933282449082981, G Loss: 12.11302661895752\n",
      "Epoch: 3, Batch: 235, D Loss: 0.09843111267468885, G Loss: 12.202751159667969\n",
      "Epoch: 3, Batch: 236, D Loss: 0.0961027042067144, G Loss: 12.288959503173828\n",
      "Epoch: 3, Batch: 237, D Loss: 0.10472578921940112, G Loss: 12.469182968139648\n",
      "Epoch: 3, Batch: 238, D Loss: 0.106396582782736, G Loss: 12.661005973815918\n",
      "Epoch: 3, Batch: 239, D Loss: 0.09442706715185523, G Loss: 12.607223510742188\n",
      "Epoch: 3, Batch: 240, D Loss: 0.09955442478405985, G Loss: 12.448629379272461\n",
      "Epoch: 3, Batch: 241, D Loss: 0.09611568341097154, G Loss: 12.284908294677734\n",
      "Epoch: 3, Batch: 242, D Loss: 0.10285409861990047, G Loss: 12.294046401977539\n",
      "Epoch: 3, Batch: 243, D Loss: 0.10206745627328928, G Loss: 12.447800636291504\n",
      "Epoch: 3, Batch: 244, D Loss: 0.10147674805728002, G Loss: 12.640106201171875\n",
      "Epoch: 3, Batch: 245, D Loss: 0.09727066656239458, G Loss: 12.656990051269531\n",
      "Epoch: 3, Batch: 246, D Loss: 0.09522547863434738, G Loss: 12.461509704589844\n",
      "Epoch: 3, Batch: 247, D Loss: 0.10043891806753891, G Loss: 12.28834056854248\n",
      "Epoch: 3, Batch: 248, D Loss: 0.0954720423389972, G Loss: 12.12017822265625\n",
      "Epoch: 3, Batch: 249, D Loss: 0.10561748842587804, G Loss: 12.143302917480469\n",
      "Epoch: 3, Batch: 250, D Loss: 0.09614498969949636, G Loss: 12.176713943481445\n",
      "Epoch: 3, Batch: 251, D Loss: 0.09336912594039859, G Loss: 12.16370677947998\n",
      "Epoch: 3, Batch: 252, D Loss: 0.10015722496018498, G Loss: 12.163360595703125\n",
      "Epoch: 3, Batch: 253, D Loss: 0.09889914439122549, G Loss: 12.18384075164795\n",
      "Epoch: 3, Batch: 254, D Loss: 0.10253235312711695, G Loss: 11.95887279510498\n",
      "Epoch: 3, Batch: 255, D Loss: 0.09909372143874862, G Loss: 11.747588157653809\n",
      "Epoch: 3, Batch: 256, D Loss: 0.10052838510000583, G Loss: 11.599882125854492\n",
      "Epoch: 3, Batch: 257, D Loss: 0.09573697308405826, G Loss: 11.406399726867676\n",
      "Epoch: 3, Batch: 258, D Loss: 0.09827861014491646, G Loss: 11.228010177612305\n",
      "Epoch: 3, Batch: 259, D Loss: 0.10425701132680842, G Loss: 11.234577178955078\n",
      "Epoch: 3, Batch: 260, D Loss: 0.10085201249785314, G Loss: 11.321708679199219\n",
      "Epoch: 3, Batch: 261, D Loss: 0.10297819918196183, G Loss: 11.4564208984375\n",
      "Epoch: 3, Batch: 262, D Loss: 0.10678019018541818, G Loss: 11.596318244934082\n",
      "Epoch: 3, Batch: 263, D Loss: 0.09784538484291261, G Loss: 11.534889221191406\n",
      "Epoch: 3, Batch: 264, D Loss: 0.10216023296607091, G Loss: 11.4290132522583\n",
      "Epoch: 3, Batch: 265, D Loss: 0.09595114042258501, G Loss: 11.217239379882812\n",
      "Epoch: 3, Batch: 266, D Loss: 0.09759163715580144, G Loss: 11.036417007446289\n",
      "Epoch: 3, Batch: 267, D Loss: 0.10851020975951542, G Loss: 11.388860702514648\n",
      "Epoch: 3, Batch: 268, D Loss: 0.09751078810404579, G Loss: 11.640829086303711\n",
      "Epoch: 3, Batch: 269, D Loss: 0.090274832140949, G Loss: 11.64946174621582\n",
      "Epoch: 3, Batch: 270, D Loss: 0.08840249507102271, G Loss: 11.38990592956543\n",
      "Epoch: 3, Batch: 271, D Loss: 0.10193243322373746, G Loss: 11.472811698913574\n",
      "Epoch: 3, Batch: 272, D Loss: 0.09934855503615836, G Loss: 11.757689476013184\n",
      "Epoch: 3, Batch: 273, D Loss: 0.09413672791561112, G Loss: 11.957084655761719\n",
      "Epoch: 3, Batch: 274, D Loss: 0.10106560378062568, G Loss: 12.152322769165039\n",
      "Epoch: 3, Batch: 275, D Loss: 0.10287713289517342, G Loss: 12.35571002960205\n",
      "Epoch: 3, Batch: 276, D Loss: 0.10163927507619519, G Loss: 12.443397521972656\n",
      "Epoch: 3, Batch: 277, D Loss: 0.10227638375090464, G Loss: 12.440505027770996\n",
      "Epoch: 3, Batch: 278, D Loss: 0.1007897377082827, G Loss: 12.28178596496582\n",
      "Epoch: 3, Batch: 279, D Loss: 0.09707531153208038, G Loss: 12.147811889648438\n",
      "Epoch: 3, Batch: 280, D Loss: 0.09575472627830095, G Loss: 12.040501594543457\n",
      "Epoch: 3, Batch: 281, D Loss: 0.09657769381919934, G Loss: 12.041177749633789\n",
      "Epoch: 3, Batch: 282, D Loss: 0.10433307352832344, G Loss: 12.211743354797363\n",
      "Epoch: 3, Batch: 283, D Loss: 0.09982730485717184, G Loss: 12.380937576293945\n",
      "Epoch: 3, Batch: 284, D Loss: 0.09864455332262878, G Loss: 12.46743106842041\n",
      "Epoch: 3, Batch: 285, D Loss: 0.09756743796583578, G Loss: 12.417705535888672\n",
      "Epoch: 3, Batch: 286, D Loss: 0.09345976937584055, G Loss: 12.272258758544922\n",
      "Epoch: 3, Batch: 287, D Loss: 0.10062170471542231, G Loss: 12.20513916015625\n",
      "Epoch: 3, Batch: 288, D Loss: 0.09773042045299007, G Loss: 12.22313117980957\n",
      "Epoch: 3, Batch: 289, D Loss: 0.09689088284676473, G Loss: 12.319246292114258\n",
      "Epoch: 3, Batch: 290, D Loss: 0.09463786025048648, G Loss: 12.422033309936523\n",
      "Epoch: 3, Batch: 291, D Loss: 0.09516314700931616, G Loss: 12.469127655029297\n",
      "Epoch: 3, Batch: 292, D Loss: 0.10506696136098981, G Loss: 12.619339942932129\n",
      "Epoch: 3, Batch: 293, D Loss: 0.0996207686971502, G Loss: 12.726048469543457\n",
      "Epoch: 3, Batch: 294, D Loss: 0.09893591606908103, G Loss: 12.754569053649902\n",
      "Epoch: 3, Batch: 295, D Loss: 0.09849124012453103, G Loss: 12.694450378417969\n",
      "Epoch: 3, Batch: 296, D Loss: 0.10277222022591559, G Loss: 12.679632186889648\n",
      "Epoch: 3, Batch: 297, D Loss: 0.09426509000536498, G Loss: 12.609880447387695\n",
      "Epoch: 3, Batch: 298, D Loss: 0.09725633291009217, G Loss: 12.563884735107422\n",
      "Epoch: 3, Batch: 299, D Loss: 0.0938367238408091, G Loss: 12.502312660217285\n",
      "Epoch: 3, Batch: 300, D Loss: 0.09769857953904193, G Loss: 12.585296630859375\n",
      "Epoch: 3, Batch: 301, D Loss: 0.09763515944462142, G Loss: 12.68558120727539\n",
      "Epoch: 3, Batch: 302, D Loss: 0.09615525378785605, G Loss: 12.773512840270996\n",
      "Epoch: 3, Batch: 303, D Loss: 0.09908721378303653, G Loss: 12.843158721923828\n",
      "Epoch: 3, Batch: 304, D Loss: 0.10324443171225539, G Loss: 12.915872573852539\n",
      "Epoch: 3, Batch: 305, D Loss: 0.0947676597992313, G Loss: 12.851119995117188\n",
      "Epoch: 3, Batch: 306, D Loss: 0.09620714222285187, G Loss: 12.749261856079102\n",
      "Epoch: 3, Batch: 307, D Loss: 0.10196576594341877, G Loss: 12.757307052612305\n",
      "Epoch: 3, Batch: 308, D Loss: 0.10152661123981943, G Loss: 12.843521118164062\n",
      "Epoch: 3, Batch: 309, D Loss: 0.09985747031601022, G Loss: 12.907398223876953\n",
      "Epoch: 3, Batch: 310, D Loss: 0.09926953275589767, G Loss: 12.901891708374023\n",
      "Epoch: 3, Batch: 311, D Loss: 0.09797544647938139, G Loss: 12.815881729125977\n",
      "Epoch: 3, Batch: 312, D Loss: 0.10198514003297987, G Loss: 12.773366928100586\n",
      "Epoch: 3, Batch: 313, D Loss: 0.10312655788038683, G Loss: 12.79662799835205\n",
      "Epoch: 3, Batch: 314, D Loss: 0.1046783695007889, G Loss: 12.893823623657227\n",
      "Epoch: 3, Batch: 315, D Loss: 0.09588811360322325, G Loss: 12.851680755615234\n",
      "Epoch: 3, Batch: 316, D Loss: 0.09311610727240804, G Loss: 12.703893661499023\n",
      "Epoch: 3, Batch: 317, D Loss: 0.1010930644400787, G Loss: 12.71395492553711\n",
      "Epoch: 3, Batch: 318, D Loss: 0.09929823175787078, G Loss: 12.8419189453125\n",
      "Epoch: 3, Batch: 319, D Loss: 0.10121288285745322, G Loss: 12.958958625793457\n",
      "Epoch: 3, Batch: 320, D Loss: 0.099141154422, G Loss: 12.980093002319336\n",
      "Epoch: 3, Batch: 321, D Loss: 0.10176817476349242, G Loss: 12.929100036621094\n",
      "Epoch: 3, Batch: 322, D Loss: 0.09579361824171428, G Loss: 12.743651390075684\n",
      "Epoch: 3, Batch: 323, D Loss: 0.10131728224519065, G Loss: 12.630983352661133\n",
      "Epoch: 3, Batch: 324, D Loss: 0.09938678313210403, G Loss: 12.603058815002441\n",
      "Epoch: 3, Batch: 325, D Loss: 0.09797498163698037, G Loss: 12.648445129394531\n",
      "Epoch: 3, Batch: 326, D Loss: 0.10187487563189279, G Loss: 12.245367050170898\n",
      "Epoch: 3, Batch: 327, D Loss: 0.09360472490061511, G Loss: 12.14903736114502\n",
      "Epoch: 3, Batch: 328, D Loss: 0.09776184452312009, G Loss: 12.180956840515137\n",
      "Epoch: 3, Batch: 329, D Loss: 0.10520359515453492, G Loss: 12.298666000366211\n",
      "Epoch: 3, Batch: 330, D Loss: 0.10474029936221996, G Loss: 12.425345420837402\n",
      "Epoch: 3, Batch: 331, D Loss: 0.09511270476514255, G Loss: 12.364013671875\n",
      "Epoch: 3, Batch: 332, D Loss: 0.1010492763170987, G Loss: 12.351554870605469\n",
      "Epoch: 3, Batch: 333, D Loss: 0.09880302161195686, G Loss: 12.383699417114258\n",
      "Epoch: 3, Batch: 334, D Loss: 0.09940575831024034, G Loss: 12.478586196899414\n",
      "Epoch: 3, Batch: 335, D Loss: 0.0962987465813967, G Loss: 12.536985397338867\n",
      "Epoch: 3, Batch: 336, D Loss: 0.09482572237061504, G Loss: 12.432046890258789\n",
      "Epoch: 3, Batch: 337, D Loss: 0.09807673159639307, G Loss: 12.48471450805664\n",
      "Epoch: 3, Batch: 338, D Loss: 0.10255662082204253, G Loss: 12.615394592285156\n",
      "Epoch: 3, Batch: 339, D Loss: 0.09852771800376559, G Loss: 12.710193634033203\n",
      "Epoch: 3, Batch: 340, D Loss: 0.09717738826338973, G Loss: 12.737021446228027\n",
      "Epoch: 3, Batch: 341, D Loss: 0.09655560437818167, G Loss: 12.606077194213867\n",
      "Epoch: 3, Batch: 342, D Loss: 0.09889059332238048, G Loss: 12.529356002807617\n",
      "Epoch: 3, Batch: 343, D Loss: 0.09695820124557031, G Loss: 12.544913291931152\n",
      "Epoch: 3, Batch: 344, D Loss: 0.09623122233085724, G Loss: 12.574207305908203\n",
      "Epoch: 3, Batch: 345, D Loss: 0.10345968738124611, G Loss: 12.705378532409668\n",
      "Epoch: 3, Batch: 346, D Loss: 0.09830878248044428, G Loss: 12.846619606018066\n",
      "Epoch: 3, Batch: 347, D Loss: 0.09846539988325276, G Loss: 12.910821914672852\n",
      "Epoch: 3, Batch: 348, D Loss: 0.09396011615081079, G Loss: 12.874757766723633\n",
      "Epoch: 3, Batch: 349, D Loss: 0.09591707945378403, G Loss: 12.839363098144531\n",
      "Epoch: 3, Batch: 350, D Loss: 0.10617993324626696, G Loss: 13.006265640258789\n",
      "Epoch: 3, Batch: 351, D Loss: 0.09931932808319743, G Loss: 13.196208953857422\n",
      "Epoch: 3, Batch: 352, D Loss: 0.0964012745372429, G Loss: 13.270191192626953\n",
      "Epoch: 3, Batch: 353, D Loss: 0.09852149432839497, G Loss: 13.21806526184082\n",
      "Epoch: 3, Batch: 354, D Loss: 0.10445735456414695, G Loss: 12.744125366210938\n",
      "Epoch: 3, Batch: 355, D Loss: 0.10021804814869029, G Loss: 12.135129928588867\n",
      "Epoch: 3, Batch: 356, D Loss: 0.10396005573147704, G Loss: 11.76188850402832\n",
      "Epoch: 3, Batch: 357, D Loss: 0.10808650202943682, G Loss: 11.633811950683594\n",
      "Epoch: 3, Batch: 358, D Loss: 0.09725377621271036, G Loss: 11.40426254272461\n",
      "Epoch: 3, Batch: 359, D Loss: 0.10739811296207336, G Loss: 11.244139671325684\n",
      "Epoch: 3, Batch: 360, D Loss: 0.09604441790361307, G Loss: 10.946928024291992\n",
      "Epoch: 3, Batch: 361, D Loss: 0.09696634969259321, G Loss: 10.61121940612793\n",
      "Epoch: 3, Batch: 362, D Loss: 0.0930678569511656, G Loss: 10.415904998779297\n",
      "Epoch: 3, Batch: 363, D Loss: 0.0952122983217123, G Loss: 10.488947868347168\n",
      "Epoch: 3, Batch: 364, D Loss: 0.10108939602105238, G Loss: 10.207815170288086\n",
      "Epoch: 3, Batch: 365, D Loss: 0.09811846543016145, G Loss: 10.400835037231445\n",
      "Epoch: 3, Batch: 366, D Loss: 0.10072478179154132, G Loss: 10.65456771850586\n",
      "Epoch: 3, Batch: 367, D Loss: 0.10343219512469659, G Loss: 10.820554733276367\n",
      "Epoch: 3, Batch: 368, D Loss: 0.09235222930328746, G Loss: 10.66885757446289\n",
      "Epoch: 3, Batch: 369, D Loss: 0.09153098577189667, G Loss: 10.473176956176758\n",
      "Epoch: 3, Batch: 370, D Loss: 0.10043811243394885, G Loss: 10.582693099975586\n",
      "Epoch: 3, Batch: 371, D Loss: 0.09906738504560053, G Loss: 10.943307876586914\n",
      "Epoch: 3, Batch: 372, D Loss: 0.09981766409555348, G Loss: 11.433403015136719\n",
      "Epoch: 3, Batch: 373, D Loss: 0.09339828873953593, G Loss: 11.781218528747559\n",
      "Epoch: 3, Batch: 374, D Loss: 0.09979420943227524, G Loss: 12.022607803344727\n",
      "Epoch: 3, Batch: 375, D Loss: 0.10067609845532388, G Loss: 12.161267280578613\n",
      "Epoch: 3, Batch: 376, D Loss: 0.09691276249168368, G Loss: 12.17999267578125\n",
      "Epoch: 3, Batch: 377, D Loss: 0.09817738179526714, G Loss: 12.162286758422852\n",
      "Epoch: 3, Batch: 378, D Loss: 0.09832156286302052, G Loss: 11.755990982055664\n",
      "Epoch: 3, Batch: 379, D Loss: 0.09019742122745811, G Loss: 11.756942749023438\n",
      "Epoch: 3, Batch: 380, D Loss: 0.10702157403375168, G Loss: 12.063432693481445\n",
      "Epoch: 3, Batch: 381, D Loss: 0.09884739866197378, G Loss: 12.353849411010742\n",
      "Epoch: 3, Batch: 382, D Loss: 0.09992129253987514, G Loss: 12.513395309448242\n",
      "Epoch: 3, Batch: 383, D Loss: 0.09844936949673411, G Loss: 12.518704414367676\n",
      "Epoch: 3, Batch: 384, D Loss: 0.10319743580146223, G Loss: 12.478354454040527\n",
      "Epoch: 3, Batch: 385, D Loss: 0.1021945728650735, G Loss: 12.455209732055664\n",
      "Epoch: 3, Batch: 386, D Loss: 0.09733141061269635, G Loss: 12.359762191772461\n",
      "Epoch: 3, Batch: 387, D Loss: 0.0981876696469044, G Loss: 12.331466674804688\n",
      "Epoch: 3, Batch: 388, D Loss: 0.09359375532926606, G Loss: 12.304298400878906\n",
      "Epoch: 3, Batch: 389, D Loss: 0.09471379407386848, G Loss: 12.328410148620605\n",
      "Epoch: 3, Batch: 390, D Loss: 0.10265396530303406, G Loss: 12.528302192687988\n",
      "Epoch: 3, Batch: 391, D Loss: 0.10408689734038035, G Loss: 12.80265998840332\n",
      "Epoch: 3, Batch: 392, D Loss: 0.09936429626350218, G Loss: 12.85506534576416\n",
      "Epoch: 3, Batch: 393, D Loss: 0.10437038848363045, G Loss: 12.815011978149414\n",
      "Epoch: 3, Batch: 394, D Loss: 0.10345273246912257, G Loss: 12.695890426635742\n",
      "Epoch: 3, Batch: 395, D Loss: 0.10302858969953377, G Loss: 12.6131591796875\n",
      "Epoch: 3, Batch: 396, D Loss: 0.10206375000177559, G Loss: 12.548370361328125\n",
      "Epoch: 3, Batch: 397, D Loss: 0.0977528036730746, G Loss: 12.49871826171875\n",
      "Epoch: 3, Batch: 398, D Loss: 0.09612757814693396, G Loss: 12.460821151733398\n",
      "Epoch: 3, Batch: 399, D Loss: 0.10011638340392892, G Loss: 12.499606132507324\n",
      "Epoch: 3, Batch: 400, D Loss: 0.10247195014187582, G Loss: 12.62059497833252\n",
      "Epoch: 3, Batch: 401, D Loss: 0.09626703843241557, G Loss: 12.646498680114746\n",
      "Epoch: 3, Batch: 402, D Loss: 0.10064435254867021, G Loss: 12.665655136108398\n",
      "Epoch: 3, Batch: 403, D Loss: 0.09982037729400872, G Loss: 12.666873931884766\n",
      "Epoch: 3, Batch: 404, D Loss: 0.10037778067624004, G Loss: 12.671004295349121\n",
      "Epoch: 3, Batch: 405, D Loss: 0.10306494187273074, G Loss: 12.715658187866211\n",
      "Epoch: 3, Batch: 406, D Loss: 0.09890950978501678, G Loss: 12.728206634521484\n",
      "Epoch: 3, Batch: 407, D Loss: 0.10066805186988859, G Loss: 12.759613037109375\n",
      "Epoch: 3, Batch: 408, D Loss: 0.10356024739667191, G Loss: 12.85194206237793\n",
      "Epoch: 3, Batch: 409, D Loss: 0.09858389446344518, G Loss: 12.840024948120117\n",
      "Epoch: 3, Batch: 410, D Loss: 0.09882351283113167, G Loss: 12.766719818115234\n",
      "Epoch: 3, Batch: 411, D Loss: 0.10396381471014138, G Loss: 12.785867691040039\n",
      "Epoch: 3, Batch: 412, D Loss: 0.09763146272314316, G Loss: 12.777603149414062\n",
      "Epoch: 3, Batch: 413, D Loss: 0.09579507129785725, G Loss: 12.728553771972656\n",
      "Epoch: 3, Batch: 414, D Loss: 0.09820513342174308, G Loss: 12.752758979797363\n",
      "Epoch: 3, Batch: 415, D Loss: 0.09612348934183501, G Loss: 12.775203704833984\n",
      "Epoch: 3, Batch: 416, D Loss: 0.10097575938925729, G Loss: 12.89130973815918\n",
      "Epoch: 3, Batch: 417, D Loss: 0.10055820539992055, G Loss: 13.013267517089844\n",
      "Epoch: 3, Batch: 418, D Loss: 0.10270313932062436, G Loss: 13.116108894348145\n",
      "Epoch: 3, Batch: 419, D Loss: 0.09748427243675906, G Loss: 13.056625366210938\n",
      "Epoch: 3, Batch: 420, D Loss: 0.09802831506431176, G Loss: 12.92672348022461\n",
      "Epoch: 3, Batch: 421, D Loss: 0.09934049985395177, G Loss: 12.82856559753418\n",
      "Epoch: 3, Batch: 422, D Loss: 0.09669581457035292, G Loss: 12.785591125488281\n",
      "Epoch: 3, Batch: 423, D Loss: 0.09538336506045653, G Loss: 12.803756713867188\n",
      "Epoch: 3, Batch: 424, D Loss: 0.09805438211628825, G Loss: 12.904415130615234\n",
      "Epoch: 3, Batch: 425, D Loss: 0.0962328521964082, G Loss: 13.002479553222656\n",
      "Epoch: 3, Batch: 426, D Loss: 0.09511356059306308, G Loss: 13.034869194030762\n",
      "Epoch: 3, Batch: 427, D Loss: 0.10139684972205032, G Loss: 13.086329460144043\n",
      "Epoch: 3, Batch: 428, D Loss: 0.09869970448426102, G Loss: 13.132078170776367\n",
      "Epoch: 3, Batch: 429, D Loss: 0.10840722997897956, G Loss: 13.28580093383789\n",
      "Epoch: 3, Batch: 430, D Loss: 0.10179972055414055, G Loss: 12.891057014465332\n",
      "Epoch: 3, Batch: 431, D Loss: 0.09937276091682179, G Loss: 12.821540832519531\n",
      "Epoch: 3, Batch: 432, D Loss: 0.10206341873993097, G Loss: 12.734938621520996\n",
      "Epoch: 3, Batch: 433, D Loss: 0.09814082673392477, G Loss: 12.617770195007324\n",
      "Epoch: 3, Batch: 434, D Loss: 0.1027112586414205, G Loss: 12.628046035766602\n",
      "Epoch: 3, Batch: 435, D Loss: 0.10181346690740156, G Loss: 12.566556930541992\n",
      "Epoch: 3, Batch: 436, D Loss: 0.1046722396529276, G Loss: 12.70409107208252\n",
      "Epoch: 3, Batch: 437, D Loss: 0.09627865544052838, G Loss: 12.66728687286377\n",
      "Epoch: 3, Batch: 438, D Loss: 0.0973675974590833, G Loss: 12.515677452087402\n",
      "Epoch: 3, Batch: 439, D Loss: 0.09791802809604633, G Loss: 12.379510879516602\n",
      "Epoch: 3, Batch: 440, D Loss: 0.09855083292586642, G Loss: 12.360264778137207\n",
      "Epoch: 3, Batch: 441, D Loss: 0.101497344740892, G Loss: 12.492894172668457\n",
      "Epoch: 3, Batch: 442, D Loss: 0.09512041576931551, G Loss: 12.613001823425293\n",
      "Epoch: 3, Batch: 443, D Loss: 0.10006295880498328, G Loss: 12.727179527282715\n",
      "Epoch: 3, Batch: 444, D Loss: 0.09816601611203168, G Loss: 12.66826057434082\n",
      "Epoch: 3, Batch: 445, D Loss: 0.09638394253397564, G Loss: 11.439325332641602\n",
      "Epoch: 3, Batch: 446, D Loss: 0.10127184687917179, G Loss: 11.45715618133545\n",
      "Epoch: 3, Batch: 447, D Loss: 0.09603591427912761, G Loss: 11.491886138916016\n",
      "Epoch: 3, Batch: 448, D Loss: 0.10221120244659687, G Loss: 11.666956901550293\n",
      "Epoch: 3, Batch: 449, D Loss: 0.1011086648654782, G Loss: 11.87671184539795\n",
      "Epoch: 3, Batch: 450, D Loss: 0.09460805369121772, G Loss: 11.936660766601562\n",
      "Epoch: 3, Batch: 451, D Loss: 0.09868438428566151, G Loss: 11.673157691955566\n",
      "Epoch: 3, Batch: 452, D Loss: 0.0996096720928108, G Loss: 11.732423782348633\n",
      "Epoch: 3, Batch: 453, D Loss: 0.10104073941283787, G Loss: 11.861011505126953\n",
      "Epoch: 3, Batch: 454, D Loss: 0.0990314261803178, G Loss: 12.015389442443848\n",
      "Epoch: 3, Batch: 455, D Loss: 0.09818866499790602, G Loss: 12.073532104492188\n",
      "Epoch: 3, Batch: 456, D Loss: 0.10368430766811798, G Loss: 12.193008422851562\n",
      "Epoch: 3, Batch: 457, D Loss: 0.09896092391250022, G Loss: 12.260107040405273\n",
      "Epoch: 3, Batch: 458, D Loss: 0.1023749470000439, G Loss: 12.352787017822266\n",
      "Epoch: 3, Batch: 459, D Loss: 0.09586093603866175, G Loss: 12.29288387298584\n",
      "Epoch: 3, Batch: 460, D Loss: 0.09466304353554733, G Loss: 12.18608283996582\n",
      "Epoch: 3, Batch: 461, D Loss: 0.09945117420511451, G Loss: 12.197879791259766\n",
      "Epoch: 3, Batch: 462, D Loss: 0.09960646344643465, G Loss: 12.307281494140625\n",
      "Epoch: 3, Batch: 463, D Loss: 0.09920959556552589, G Loss: 12.398675918579102\n",
      "Epoch: 3, Batch: 464, D Loss: 0.1091640886403411, G Loss: 12.597564697265625\n",
      "Epoch: 3, Batch: 465, D Loss: 0.10084259848508736, G Loss: 12.523782730102539\n",
      "Epoch: 3, Batch: 466, D Loss: 0.09884286485225857, G Loss: 12.278404235839844\n",
      "Epoch: 3, Batch: 467, D Loss: 0.09379649970969695, G Loss: 11.907230377197266\n",
      "Epoch: 4, Batch: 0, D Loss: 0.09370766334086511, G Loss: 11.617547988891602\n",
      "Epoch: 4, Batch: 1, D Loss: 0.1007093933849319, G Loss: 11.657922744750977\n",
      "Epoch: 4, Batch: 2, D Loss: 0.10040960938613352, G Loss: 11.980396270751953\n",
      "Epoch: 4, Batch: 3, D Loss: 0.09778201193489622, G Loss: 12.265180587768555\n",
      "Epoch: 4, Batch: 4, D Loss: 0.0982295944429552, G Loss: 12.378608703613281\n",
      "Epoch: 4, Batch: 5, D Loss: 0.10284540478915005, G Loss: 12.397071838378906\n",
      "Epoch: 4, Batch: 6, D Loss: 0.09865349187612082, G Loss: 12.282917022705078\n",
      "Epoch: 4, Batch: 7, D Loss: 0.09585841561283814, G Loss: 12.12669849395752\n",
      "Epoch: 4, Batch: 8, D Loss: 0.1010147547640372, G Loss: 12.20683479309082\n",
      "Epoch: 4, Batch: 9, D Loss: 0.10228619241547676, G Loss: 12.428827285766602\n",
      "Epoch: 4, Batch: 10, D Loss: 0.09318433115549851, G Loss: 12.553539276123047\n",
      "Epoch: 4, Batch: 11, D Loss: 0.09582907443166278, G Loss: 12.660640716552734\n",
      "Epoch: 4, Batch: 12, D Loss: 0.10141886350220375, G Loss: 12.789874076843262\n",
      "Epoch: 4, Batch: 13, D Loss: 0.10123341713722311, G Loss: 12.88652229309082\n",
      "Epoch: 4, Batch: 14, D Loss: 0.0974083762855571, G Loss: 12.889860153198242\n",
      "Epoch: 4, Batch: 15, D Loss: 0.09753754871803721, G Loss: 12.840206146240234\n",
      "Epoch: 4, Batch: 16, D Loss: 0.09955546500725632, G Loss: 12.840394973754883\n",
      "Epoch: 4, Batch: 17, D Loss: 0.09994638604644024, G Loss: 12.899287223815918\n",
      "Epoch: 4, Batch: 18, D Loss: 0.0949023412617862, G Loss: 12.927303314208984\n",
      "Epoch: 4, Batch: 19, D Loss: 0.08884201217938426, G Loss: 12.830137252807617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 11:25:50.488576: W tensorflow/core/data/root_dataset.cc:286] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Batch: 20, D Loss: 0.10014987416320764, G Loss: 12.879034042358398\n",
      "Epoch: 4, Batch: 21, D Loss: 0.09328309664692824, G Loss: 12.926801681518555\n",
      "Epoch: 4, Batch: 22, D Loss: 0.10429363290768379, G Loss: 13.139311790466309\n",
      "Epoch: 4, Batch: 23, D Loss: 0.09897480800896119, G Loss: 12.782103538513184\n",
      "Epoch: 4, Batch: 24, D Loss: 0.10212939338384786, G Loss: 12.063472747802734\n",
      "Epoch: 4, Batch: 25, D Loss: 0.09567428812670187, G Loss: 12.011877059936523\n",
      "Epoch: 4, Batch: 26, D Loss: 0.10081485711225469, G Loss: 11.950011253356934\n",
      "Epoch: 4, Batch: 27, D Loss: 0.10124579665716738, G Loss: 11.962913513183594\n",
      "Epoch: 4, Batch: 28, D Loss: 0.10001949958677869, G Loss: 12.035256385803223\n",
      "Epoch: 4, Batch: 29, D Loss: 0.09874373763341282, G Loss: 12.09211254119873\n",
      "Epoch: 4, Batch: 30, D Loss: 0.09584649571934278, G Loss: 12.08652400970459\n",
      "Epoch: 4, Batch: 31, D Loss: 0.09703331689252082, G Loss: 12.06946849822998\n",
      "Epoch: 4, Batch: 32, D Loss: 0.10150481901882813, G Loss: 12.181730270385742\n",
      "Epoch: 4, Batch: 33, D Loss: 0.09889367167397722, G Loss: 12.3319091796875\n",
      "Epoch: 4, Batch: 34, D Loss: 0.10481568909472117, G Loss: 12.52154541015625\n",
      "Epoch: 4, Batch: 35, D Loss: 0.09591443930310106, G Loss: 12.547666549682617\n",
      "Epoch: 4, Batch: 36, D Loss: 0.09533111461314547, G Loss: 12.468133926391602\n",
      "Epoch: 4, Batch: 37, D Loss: 0.09941045880373167, G Loss: 12.454127311706543\n",
      "Epoch: 4, Batch: 38, D Loss: 0.10034594866181124, G Loss: 12.584137916564941\n",
      "Epoch: 4, Batch: 39, D Loss: 0.10417215821337322, G Loss: 12.887961387634277\n",
      "Epoch: 4, Batch: 40, D Loss: 0.09606609849322467, G Loss: 13.009441375732422\n",
      "Epoch: 4, Batch: 41, D Loss: 0.10157319504537554, G Loss: 12.948877334594727\n",
      "Epoch: 4, Batch: 42, D Loss: 0.09896485975332325, G Loss: 12.775821685791016\n",
      "Epoch: 4, Batch: 43, D Loss: 0.09659122042921808, G Loss: 11.487771987915039\n",
      "Epoch: 4, Batch: 44, D Loss: 0.1042378064694276, G Loss: 11.518580436706543\n",
      "Epoch: 4, Batch: 45, D Loss: 0.09913182885065908, G Loss: 11.64052963256836\n",
      "Epoch: 4, Batch: 46, D Loss: 0.09731612676296209, G Loss: 11.716506004333496\n",
      "Epoch: 4, Batch: 47, D Loss: 0.09946064916130126, G Loss: 11.742412567138672\n",
      "Epoch: 4, Batch: 48, D Loss: 0.10061591634257638, G Loss: 11.251829147338867\n",
      "Epoch: 4, Batch: 49, D Loss: 0.1007377600435575, G Loss: 10.127426147460938\n",
      "Epoch: 4, Batch: 50, D Loss: 0.10056746216287138, G Loss: 10.216038703918457\n",
      "Epoch: 4, Batch: 51, D Loss: 0.10274168183968868, G Loss: 10.381616592407227\n",
      "Epoch: 4, Batch: 52, D Loss: 0.10239079169696197, G Loss: 10.73801040649414\n",
      "Epoch: 4, Batch: 53, D Loss: 0.09692973501842062, G Loss: 10.403264999389648\n",
      "Epoch: 4, Batch: 54, D Loss: 0.1003042115662538, G Loss: 10.23570442199707\n",
      "Epoch: 4, Batch: 55, D Loss: 0.09831534642398765, G Loss: 10.022582054138184\n",
      "Epoch: 4, Batch: 56, D Loss: 0.09389022394134372, G Loss: 10.008310317993164\n",
      "Epoch: 4, Batch: 57, D Loss: 0.09599515314403106, G Loss: 9.666406631469727\n",
      "Epoch: 4, Batch: 58, D Loss: 0.1022269525565207, G Loss: 10.551393508911133\n",
      "Epoch: 4, Batch: 59, D Loss: 0.09502875339603634, G Loss: 11.056236267089844\n",
      "Epoch: 4, Batch: 60, D Loss: 0.09996704180366578, G Loss: 11.471674919128418\n",
      "Epoch: 4, Batch: 61, D Loss: 0.09940119409839099, G Loss: 11.809008598327637\n",
      "Epoch: 4, Batch: 62, D Loss: 0.10325778600054036, G Loss: 12.130352020263672\n",
      "Epoch: 4, Batch: 63, D Loss: 0.10713529677423139, G Loss: 12.476476669311523\n",
      "Epoch: 4, Batch: 64, D Loss: 0.09250725820311345, G Loss: 12.430612564086914\n",
      "Epoch: 4, Batch: 65, D Loss: 0.10117948199467719, G Loss: 12.512986183166504\n",
      "Epoch: 4, Batch: 66, D Loss: 0.10247579408860474, G Loss: 12.578238487243652\n",
      "Epoch: 4, Batch: 67, D Loss: 0.1029430167418468, G Loss: 11.933195114135742\n",
      "Epoch: 4, Batch: 68, D Loss: 0.09918084726086818, G Loss: 11.94880485534668\n",
      "Epoch: 4, Batch: 69, D Loss: 0.09816194985887705, G Loss: 11.138537406921387\n",
      "Epoch: 4, Batch: 70, D Loss: 0.09616238543458167, G Loss: 11.032337188720703\n",
      "Epoch: 4, Batch: 71, D Loss: 0.10059965482651023, G Loss: 11.09158706665039\n",
      "Epoch: 4, Batch: 72, D Loss: 0.09849920734404805, G Loss: 11.179076194763184\n",
      "Epoch: 4, Batch: 73, D Loss: 0.09876598535129233, G Loss: 11.312129974365234\n",
      "Epoch: 4, Batch: 74, D Loss: 0.10135112019497683, G Loss: 11.473566055297852\n",
      "Epoch: 4, Batch: 75, D Loss: 0.09981997184513602, G Loss: 11.585933685302734\n",
      "Epoch: 4, Batch: 76, D Loss: 0.09513237466762803, G Loss: 11.625252723693848\n",
      "Epoch: 4, Batch: 77, D Loss: 0.10253726306746103, G Loss: 11.80594539642334\n",
      "Epoch: 4, Batch: 78, D Loss: 0.09669368705272063, G Loss: 11.999443054199219\n",
      "Epoch: 4, Batch: 79, D Loss: 0.09952641089080316, G Loss: 12.200937271118164\n",
      "Epoch: 4, Batch: 80, D Loss: 0.0900593421429221, G Loss: 12.226747512817383\n",
      "Epoch: 4, Batch: 81, D Loss: 0.10257534151128311, G Loss: 12.413761138916016\n",
      "Epoch: 4, Batch: 82, D Loss: 0.10038358756446542, G Loss: 12.66977596282959\n",
      "Epoch: 4, Batch: 83, D Loss: 0.09887078605618171, G Loss: 12.850948333740234\n",
      "Epoch: 4, Batch: 84, D Loss: 0.09298086783792314, G Loss: 12.858452796936035\n",
      "Epoch: 4, Batch: 85, D Loss: 0.09732934633962032, G Loss: 12.819684982299805\n",
      "Epoch: 4, Batch: 86, D Loss: 0.10107386633012538, G Loss: 12.023564338684082\n",
      "Epoch: 4, Batch: 87, D Loss: 0.09743862283085036, G Loss: 11.741437911987305\n",
      "Epoch: 4, Batch: 88, D Loss: 0.09809189664838414, G Loss: 11.821026802062988\n",
      "Epoch: 4, Batch: 89, D Loss: 0.09785336016670954, G Loss: 11.991734504699707\n",
      "Epoch: 4, Batch: 90, D Loss: 0.09753412232112169, G Loss: 12.161267280578613\n",
      "Epoch: 4, Batch: 91, D Loss: 0.09862862526460958, G Loss: 12.36890983581543\n",
      "Epoch: 4, Batch: 92, D Loss: 0.09795070771860992, G Loss: 12.144292831420898\n",
      "Epoch: 4, Batch: 93, D Loss: 0.09421740325137762, G Loss: 11.922348022460938\n",
      "Epoch: 4, Batch: 94, D Loss: 0.09636456187718068, G Loss: 11.481696128845215\n",
      "Epoch: 4, Batch: 95, D Loss: 0.10249663706690626, G Loss: 11.636503219604492\n",
      "Epoch: 4, Batch: 96, D Loss: 0.09189082698276252, G Loss: 11.562509536743164\n",
      "Epoch: 4, Batch: 97, D Loss: 0.09855011897070654, G Loss: 11.503009796142578\n",
      "Epoch: 4, Batch: 98, D Loss: 0.09964575925914687, G Loss: 11.48369312286377\n",
      "Epoch: 4, Batch: 99, D Loss: 0.10409150772557041, G Loss: 11.589454650878906\n",
      "Epoch: 4, Batch: 100, D Loss: 0.10067745198102784, G Loss: 11.528238296508789\n",
      "Epoch: 4, Batch: 101, D Loss: 0.0967585372418398, G Loss: 11.174784660339355\n",
      "Epoch: 4, Batch: 102, D Loss: 0.10001359082161798, G Loss: 10.823122024536133\n",
      "Epoch: 4, Batch: 103, D Loss: 0.10490255032254936, G Loss: 10.75189208984375\n",
      "Epoch: 4, Batch: 104, D Loss: 0.1026582112581309, G Loss: 10.837535858154297\n",
      "Epoch: 4, Batch: 105, D Loss: 0.094130253943149, G Loss: 10.863340377807617\n",
      "Epoch: 4, Batch: 106, D Loss: 0.0956807778984512, G Loss: 10.575562477111816\n",
      "Epoch: 4, Batch: 107, D Loss: 0.10303172197927779, G Loss: 10.517162322998047\n",
      "Epoch: 4, Batch: 108, D Loss: 0.10073465039113216, G Loss: 10.880905151367188\n",
      "Epoch: 4, Batch: 109, D Loss: 0.09880722905108996, G Loss: 11.175792694091797\n",
      "Epoch: 4, Batch: 110, D Loss: 0.09922542493586661, G Loss: 11.410360336303711\n",
      "Epoch: 4, Batch: 111, D Loss: 0.10014393883102457, G Loss: 11.59333610534668\n",
      "Epoch: 4, Batch: 112, D Loss: 0.10132847667591705, G Loss: 11.793242454528809\n",
      "Epoch: 4, Batch: 113, D Loss: 0.10514814075054346, G Loss: 12.098268508911133\n",
      "Epoch: 4, Batch: 114, D Loss: 0.10396509961742595, G Loss: 12.265480041503906\n",
      "Epoch: 4, Batch: 115, D Loss: 0.0996926691373119, G Loss: 12.194686889648438\n",
      "Epoch: 4, Batch: 116, D Loss: 0.09715282855836449, G Loss: 12.072776794433594\n",
      "Epoch: 4, Batch: 117, D Loss: 0.09855284125592334, G Loss: 11.935324668884277\n",
      "Epoch: 4, Batch: 118, D Loss: 0.098543197338131, G Loss: 12.011714935302734\n",
      "Epoch: 4, Batch: 119, D Loss: 0.10181157949864428, G Loss: 12.37956428527832\n",
      "Epoch: 4, Batch: 120, D Loss: 0.09881873914696371, G Loss: 12.565750122070312\n",
      "Epoch: 4, Batch: 121, D Loss: 0.09619382614368988, G Loss: 12.559488296508789\n",
      "Epoch: 4, Batch: 122, D Loss: 0.09912858795212287, G Loss: 12.390188217163086\n",
      "Epoch: 4, Batch: 123, D Loss: 0.10384518705131995, G Loss: 11.325366973876953\n",
      "Epoch: 4, Batch: 124, D Loss: 0.10313666188631032, G Loss: 11.424354553222656\n",
      "Epoch: 4, Batch: 125, D Loss: 0.10419852470704427, G Loss: 11.70016098022461\n",
      "Epoch: 4, Batch: 126, D Loss: 0.10462480443402455, G Loss: 11.837923049926758\n",
      "Epoch: 4, Batch: 127, D Loss: 0.096276206388211, G Loss: 11.638784408569336\n",
      "Epoch: 4, Batch: 128, D Loss: 0.0942142120520657, G Loss: 10.836861610412598\n",
      "Epoch: 4, Batch: 129, D Loss: 0.09607584471723385, G Loss: 10.850791931152344\n",
      "Epoch: 4, Batch: 130, D Loss: 0.09972387621974121, G Loss: 11.491724967956543\n",
      "Epoch: 4, Batch: 131, D Loss: 0.11106943780669098, G Loss: 12.333722114562988\n",
      "Epoch: 4, Batch: 132, D Loss: 0.10075337622356528, G Loss: 12.767338752746582\n",
      "Epoch: 4, Batch: 133, D Loss: 0.10167056361581217, G Loss: 12.846993446350098\n",
      "Epoch: 4, Batch: 134, D Loss: 0.10048732207667399, G Loss: 12.784854888916016\n",
      "Epoch: 4, Batch: 135, D Loss: 0.09836751224179352, G Loss: 12.811524391174316\n",
      "Epoch: 4, Batch: 136, D Loss: 0.09889821024967205, G Loss: 12.945927619934082\n",
      "Epoch: 4, Batch: 137, D Loss: 0.09977989714434443, G Loss: 13.297477722167969\n",
      "Epoch: 4, Batch: 138, D Loss: 0.09993444920394268, G Loss: 13.75387954711914\n",
      "Epoch: 4, Batch: 139, D Loss: 0.09782587024750455, G Loss: 13.586288452148438\n",
      "Epoch: 4, Batch: 140, D Loss: 0.09392445303751629, G Loss: 12.941556930541992\n",
      "Epoch: 4, Batch: 141, D Loss: 0.10456259222860353, G Loss: 12.555036544799805\n",
      "Epoch: 4, Batch: 142, D Loss: 0.09912551055299446, G Loss: 12.224931716918945\n",
      "Epoch: 4, Batch: 143, D Loss: 0.09798206045797997, G Loss: 12.001175880432129\n",
      "Epoch: 4, Batch: 144, D Loss: 0.1062160975320694, G Loss: 12.086358070373535\n",
      "Epoch: 4, Batch: 145, D Loss: 0.09903195515516927, G Loss: 11.708006858825684\n",
      "Epoch: 4, Batch: 146, D Loss: 0.10065862171995832, G Loss: 11.497945785522461\n",
      "Epoch: 4, Batch: 147, D Loss: 0.10212084990234871, G Loss: 11.414780616760254\n",
      "Epoch: 4, Batch: 148, D Loss: 0.08849611864116014, G Loss: 11.198362350463867\n",
      "Epoch: 4, Batch: 149, D Loss: 0.08928691636174335, G Loss: 11.012879371643066\n",
      "Epoch: 4, Batch: 150, D Loss: 0.10018547077106632, G Loss: 11.205183982849121\n",
      "Epoch: 4, Batch: 151, D Loss: 0.09871541557731689, G Loss: 11.565485000610352\n",
      "Epoch: 4, Batch: 152, D Loss: 0.09799541014763236, G Loss: 11.882713317871094\n",
      "Epoch: 4, Batch: 153, D Loss: 0.10434760635394014, G Loss: 12.162843704223633\n",
      "Epoch: 4, Batch: 154, D Loss: 0.09864127967784952, G Loss: 12.090047836303711\n",
      "Epoch: 4, Batch: 155, D Loss: 0.09591507162258495, G Loss: 11.694282531738281\n",
      "Epoch: 4, Batch: 156, D Loss: 0.10234319664596114, G Loss: 9.101826667785645\n",
      "Epoch: 4, Batch: 157, D Loss: 0.09906341327587143, G Loss: 9.942331314086914\n",
      "Epoch: 4, Batch: 158, D Loss: 0.09994342805839551, G Loss: 11.029572486877441\n",
      "Epoch: 4, Batch: 159, D Loss: 0.09726009228688781, G Loss: 11.932474136352539\n",
      "Epoch: 4, Batch: 160, D Loss: 0.09784051015026307, G Loss: 12.48851490020752\n",
      "Epoch: 4, Batch: 161, D Loss: 0.09534710583864126, G Loss: 12.831574440002441\n",
      "Epoch: 4, Batch: 162, D Loss: 0.09749604814737722, G Loss: 12.594076156616211\n",
      "Epoch: 4, Batch: 163, D Loss: 0.09947582808399602, G Loss: 12.592528343200684\n",
      "Epoch: 4, Batch: 164, D Loss: 0.10135930373985502, G Loss: 12.843143463134766\n",
      "Epoch: 4, Batch: 165, D Loss: 0.09191392704519785, G Loss: 12.902486801147461\n",
      "Epoch: 4, Batch: 166, D Loss: 0.0981207365539376, G Loss: 12.917659759521484\n",
      "Epoch: 4, Batch: 167, D Loss: 0.10494771565868177, G Loss: 13.073466300964355\n",
      "Epoch: 4, Batch: 168, D Loss: 0.10205780188289282, G Loss: 13.1979398727417\n",
      "Epoch: 4, Batch: 169, D Loss: 0.0983819613719561, G Loss: 12.997739791870117\n",
      "Epoch: 4, Batch: 170, D Loss: 0.10130065881230621, G Loss: 12.555654525756836\n",
      "Epoch: 4, Batch: 171, D Loss: 0.09189931675655316, G Loss: 12.20716381072998\n",
      "Epoch: 4, Batch: 172, D Loss: 0.0986589575591097, G Loss: 11.737174987792969\n",
      "Epoch: 4, Batch: 173, D Loss: 0.10299423223477788, G Loss: 11.806350708007812\n",
      "Epoch: 4, Batch: 174, D Loss: 0.10547021492152453, G Loss: 12.193976402282715\n",
      "Epoch: 4, Batch: 175, D Loss: 0.09961733434283815, G Loss: 12.208921432495117\n",
      "Epoch: 4, Batch: 176, D Loss: 0.10503020131000085, G Loss: 12.115833282470703\n",
      "Epoch: 4, Batch: 177, D Loss: 0.09824328888680611, G Loss: 11.718327522277832\n",
      "Epoch: 4, Batch: 178, D Loss: 0.10230981402582984, G Loss: 11.546934127807617\n",
      "Epoch: 4, Batch: 179, D Loss: 0.10151492708428123, G Loss: 11.649212837219238\n",
      "Epoch: 4, Batch: 180, D Loss: 0.09651934120529404, G Loss: 11.774835586547852\n",
      "Epoch: 4, Batch: 181, D Loss: 0.11098453925797003, G Loss: 12.334087371826172\n",
      "Epoch: 4, Batch: 182, D Loss: 0.10313853702291453, G Loss: 12.604182243347168\n",
      "Epoch: 4, Batch: 183, D Loss: 0.09821147503635075, G Loss: 12.483158111572266\n",
      "Epoch: 4, Batch: 184, D Loss: 0.09335083808809941, G Loss: 11.939138412475586\n",
      "Epoch: 4, Batch: 185, D Loss: 0.098645779798062, G Loss: 11.615445137023926\n",
      "Epoch: 4, Batch: 186, D Loss: 0.10499381875843028, G Loss: 12.077653884887695\n",
      "Epoch: 4, Batch: 187, D Loss: 0.09949117610267422, G Loss: 12.631868362426758\n",
      "Epoch: 4, Batch: 188, D Loss: 0.10029245533746689, G Loss: 13.003095626831055\n",
      "Epoch: 4, Batch: 189, D Loss: 0.09572339658313922, G Loss: 12.969002723693848\n",
      "Epoch: 4, Batch: 190, D Loss: 0.10259687884217783, G Loss: 12.130298614501953\n",
      "Epoch: 4, Batch: 191, D Loss: 0.09851256432875743, G Loss: 11.968018531799316\n",
      "Epoch: 4, Batch: 192, D Loss: 0.09882273715766132, G Loss: 12.046529769897461\n",
      "Epoch: 4, Batch: 193, D Loss: 0.09648417248990881, G Loss: 12.24604320526123\n",
      "Epoch: 4, Batch: 194, D Loss: 0.09483343390979826, G Loss: 12.43011474609375\n",
      "Epoch: 4, Batch: 195, D Loss: 0.09669942856703528, G Loss: 12.683662414550781\n",
      "Epoch: 4, Batch: 196, D Loss: 0.09972644549088727, G Loss: 12.944938659667969\n",
      "Epoch: 4, Batch: 197, D Loss: 0.1023710489532732, G Loss: 13.156962394714355\n",
      "Epoch: 4, Batch: 198, D Loss: 0.10797779347797132, G Loss: 13.321572303771973\n",
      "Epoch: 4, Batch: 199, D Loss: 0.1026087702056202, G Loss: 13.22352409362793\n",
      "Epoch: 4, Batch: 200, D Loss: 0.09114939530718402, G Loss: 12.781904220581055\n",
      "Epoch: 4, Batch: 201, D Loss: 0.09542791844410203, G Loss: 12.428277969360352\n",
      "Epoch: 4, Batch: 202, D Loss: 0.10413262929546363, G Loss: 12.397480010986328\n",
      "Epoch: 4, Batch: 203, D Loss: 0.10443302124360798, G Loss: 12.841288566589355\n",
      "Epoch: 4, Batch: 204, D Loss: 0.09887247286928869, G Loss: 13.119208335876465\n",
      "Epoch: 4, Batch: 205, D Loss: 0.09614293053471101, G Loss: 12.9866361618042\n",
      "Epoch: 4, Batch: 206, D Loss: 0.10154250642904117, G Loss: 12.728663444519043\n",
      "Epoch: 4, Batch: 207, D Loss: 0.10076684944385761, G Loss: 12.497085571289062\n",
      "Epoch: 4, Batch: 208, D Loss: 0.10325954859672493, G Loss: 12.526325225830078\n",
      "Epoch: 4, Batch: 209, D Loss: 0.0965246253128953, G Loss: 12.578760147094727\n",
      "Epoch: 4, Batch: 210, D Loss: 0.0917223945226624, G Loss: 12.399643898010254\n",
      "Epoch: 4, Batch: 211, D Loss: 0.09775201391539667, G Loss: 11.656402587890625\n",
      "Epoch: 4, Batch: 212, D Loss: 0.09675026107197482, G Loss: 11.156095504760742\n",
      "Epoch: 4, Batch: 213, D Loss: 0.10097818425765581, G Loss: 11.363174438476562\n",
      "Epoch: 4, Batch: 214, D Loss: 0.0985680250742007, G Loss: 11.588644027709961\n",
      "Epoch: 4, Batch: 215, D Loss: 0.10023796757104719, G Loss: 11.762263298034668\n",
      "Epoch: 4, Batch: 216, D Loss: 0.10767999974245868, G Loss: 12.033382415771484\n",
      "Epoch: 4, Batch: 217, D Loss: 0.09431534328723501, G Loss: 11.97949504852295\n",
      "Epoch: 4, Batch: 218, D Loss: 0.10448680111153408, G Loss: 12.023706436157227\n",
      "Epoch: 4, Batch: 219, D Loss: 0.09950774446519972, G Loss: 12.129197120666504\n",
      "Epoch: 4, Batch: 220, D Loss: 0.09999598807871735, G Loss: 12.315631866455078\n",
      "Epoch: 4, Batch: 221, D Loss: 0.09669624232969909, G Loss: 12.460623741149902\n",
      "Epoch: 4, Batch: 222, D Loss: 0.09550280428993574, G Loss: 12.503656387329102\n",
      "Epoch: 4, Batch: 223, D Loss: 0.09915678559821117, G Loss: 12.642948150634766\n",
      "Epoch: 4, Batch: 224, D Loss: 0.09696787921529904, G Loss: 12.7609224319458\n",
      "Epoch: 4, Batch: 225, D Loss: 0.099890610921193, G Loss: 12.929306983947754\n",
      "Epoch: 4, Batch: 226, D Loss: 0.09575480174191853, G Loss: 13.016234397888184\n",
      "Epoch: 4, Batch: 227, D Loss: 0.10281908777903936, G Loss: 13.137028694152832\n",
      "Epoch: 4, Batch: 228, D Loss: 0.09479787348800528, G Loss: 13.185624122619629\n",
      "Epoch: 4, Batch: 229, D Loss: 0.0952205011390106, G Loss: 13.096378326416016\n",
      "Epoch: 4, Batch: 230, D Loss: 0.092125679291712, G Loss: 12.972888946533203\n",
      "Epoch: 4, Batch: 231, D Loss: 0.10064922557057798, G Loss: 13.096840858459473\n",
      "Epoch: 4, Batch: 232, D Loss: 0.09852534773045818, G Loss: 13.354486465454102\n",
      "Epoch: 4, Batch: 233, D Loss: 0.10111054172080003, G Loss: 13.576216697692871\n",
      "Epoch: 4, Batch: 234, D Loss: 0.09797229836050292, G Loss: 13.412323951721191\n",
      "Epoch: 4, Batch: 235, D Loss: 0.09949917224287219, G Loss: 13.282489776611328\n",
      "Epoch: 4, Batch: 236, D Loss: 0.09242407159547383, G Loss: 13.058440208435059\n",
      "Epoch: 4, Batch: 237, D Loss: 0.09761013470472335, G Loss: 12.983474731445312\n",
      "Epoch: 4, Batch: 238, D Loss: 0.10328210179750386, G Loss: 12.122072219848633\n",
      "Epoch: 4, Batch: 239, D Loss: 0.09295803591840013, G Loss: 12.141243934631348\n",
      "Epoch: 4, Batch: 240, D Loss: 0.10274341827016542, G Loss: 12.418232917785645\n",
      "Epoch: 4, Batch: 241, D Loss: 0.10132212640201033, G Loss: 12.525945663452148\n",
      "Epoch: 4, Batch: 242, D Loss: 0.09697175142400738, G Loss: 12.311052322387695\n",
      "Epoch: 4, Batch: 243, D Loss: 0.09727766770538437, G Loss: 12.105768203735352\n",
      "Epoch: 4, Batch: 244, D Loss: 0.10163410799577832, G Loss: 12.18486499786377\n",
      "Epoch: 4, Batch: 245, D Loss: 0.09772360348461007, G Loss: 12.361523628234863\n",
      "Epoch: 4, Batch: 246, D Loss: 0.10141553052267227, G Loss: 12.640539169311523\n",
      "Epoch: 4, Batch: 247, D Loss: 0.09927817560981111, G Loss: 12.81277084350586\n",
      "Epoch: 4, Batch: 248, D Loss: 0.10007521475881731, G Loss: 12.808257102966309\n",
      "Epoch: 4, Batch: 249, D Loss: 0.10116263225188504, G Loss: 12.629369735717773\n",
      "Epoch: 4, Batch: 250, D Loss: 0.09863318394843645, G Loss: 12.447996139526367\n",
      "Epoch: 4, Batch: 251, D Loss: 0.09118241229793966, G Loss: 12.249780654907227\n",
      "Epoch: 4, Batch: 252, D Loss: 0.09576873914352291, G Loss: 12.318136215209961\n",
      "Epoch: 4, Batch: 253, D Loss: 0.09922834636722655, G Loss: 12.561116218566895\n",
      "Epoch: 4, Batch: 254, D Loss: 0.09872202825249587, G Loss: 12.658968925476074\n",
      "Epoch: 4, Batch: 255, D Loss: 0.09715090872236942, G Loss: 12.702804565429688\n",
      "Epoch: 4, Batch: 256, D Loss: 0.10251222168960794, G Loss: 12.734850883483887\n",
      "Epoch: 4, Batch: 257, D Loss: 0.09921150634863807, G Loss: 12.664305686950684\n",
      "Epoch: 4, Batch: 258, D Loss: 0.09516210308811424, G Loss: 12.444195747375488\n",
      "Epoch: 4, Batch: 259, D Loss: 0.09343894565881783, G Loss: 12.312212944030762\n",
      "Epoch: 4, Batch: 260, D Loss: 0.0968445164928653, G Loss: 12.393224716186523\n",
      "Epoch: 4, Batch: 261, D Loss: 0.0961803091904585, G Loss: 11.658395767211914\n",
      "Epoch: 4, Batch: 262, D Loss: 0.0986507564139174, G Loss: 11.980995178222656\n",
      "Epoch: 4, Batch: 263, D Loss: 0.09856312261013045, G Loss: 12.153660774230957\n",
      "Epoch: 4, Batch: 264, D Loss: 0.09655948080012422, G Loss: 12.126008033752441\n",
      "Epoch: 4, Batch: 265, D Loss: 0.09684322187240468, G Loss: 11.959833145141602\n",
      "Epoch: 4, Batch: 266, D Loss: 0.09441541066280479, G Loss: 11.865854263305664\n",
      "Epoch: 4, Batch: 267, D Loss: 0.09532509276800738, G Loss: 12.040873527526855\n",
      "Epoch: 4, Batch: 268, D Loss: 0.08570273877103318, G Loss: 12.18726921081543\n",
      "Epoch: 4, Batch: 269, D Loss: 0.10608275327513184, G Loss: 12.665085792541504\n",
      "Epoch: 4, Batch: 270, D Loss: 0.10463187856521472, G Loss: 13.073150634765625\n",
      "Epoch: 4, Batch: 271, D Loss: 0.09761561283221454, G Loss: 13.121490478515625\n",
      "Epoch: 4, Batch: 272, D Loss: 0.0988940142589172, G Loss: 12.864870071411133\n",
      "Epoch: 4, Batch: 273, D Loss: 0.10347932121646863, G Loss: 12.77754020690918\n",
      "Epoch: 4, Batch: 274, D Loss: 0.10344553861750683, G Loss: 12.943662643432617\n",
      "Epoch: 4, Batch: 275, D Loss: 0.09832593556825486, G Loss: 13.236467361450195\n",
      "Epoch: 4, Batch: 276, D Loss: 0.09911783167547128, G Loss: 13.541439056396484\n",
      "Epoch: 4, Batch: 277, D Loss: 0.09860182950353646, G Loss: 13.718395233154297\n",
      "Epoch: 4, Batch: 278, D Loss: 0.10085886220440443, G Loss: 13.789302825927734\n",
      "Epoch: 4, Batch: 279, D Loss: 0.1006861663863674, G Loss: 7.157355308532715\n",
      "Epoch: 4, Batch: 280, D Loss: 0.10371369495987892, G Loss: 16.8481502532959\n",
      "Epoch: 4, Batch: 281, D Loss: 0.0999230891478925, G Loss: 36.25883865356445\n",
      "Epoch: 4, Batch: 282, D Loss: 0.10523478686809552, G Loss: 35.581336975097656\n",
      "Epoch: 4, Batch: 283, D Loss: 0.10317406058311483, G Loss: 35.279273986816406\n",
      "Epoch: 4, Batch: 284, D Loss: 0.09917840361595177, G Loss: 35.34724044799805\n",
      "Epoch: 4, Batch: 285, D Loss: 0.09570144116878529, G Loss: 35.61935806274414\n",
      "Epoch: 4, Batch: 286, D Loss: 0.09807961434125914, G Loss: 35.948089599609375\n",
      "Epoch: 4, Batch: 287, D Loss: 0.09770439565181743, G Loss: 36.110172271728516\n",
      "Epoch: 4, Batch: 288, D Loss: 0.10134292393922817, G Loss: 36.05377197265625\n",
      "Epoch: 4, Batch: 289, D Loss: 0.10530975461006176, G Loss: 35.95441818237305\n",
      "Epoch: 4, Batch: 290, D Loss: 0.09829054772853865, G Loss: 35.748268127441406\n",
      "Epoch: 4, Batch: 291, D Loss: 0.09268151223659536, G Loss: 35.286895751953125\n",
      "Epoch: 4, Batch: 292, D Loss: 0.10145391523838067, G Loss: 35.244625091552734\n",
      "Epoch: 4, Batch: 293, D Loss: 0.10049644857645057, G Loss: 35.39231491088867\n",
      "Epoch: 4, Batch: 294, D Loss: 0.09917360544204731, G Loss: 35.56575012207031\n",
      "Epoch: 4, Batch: 295, D Loss: 0.0942023992538454, G Loss: 35.57623291015625\n",
      "Epoch: 4, Batch: 296, D Loss: 0.09906636178493518, G Loss: 35.507720947265625\n",
      "Epoch: 4, Batch: 297, D Loss: 0.10476826131343861, G Loss: 35.51201248168945\n",
      "Epoch: 4, Batch: 298, D Loss: 0.09833581745624562, G Loss: 35.482730865478516\n",
      "Epoch: 4, Batch: 299, D Loss: 0.10571647435426731, G Loss: 35.52814483642578\n",
      "Epoch: 4, Batch: 300, D Loss: 0.10201442241668719, G Loss: 35.59819030761719\n",
      "Epoch: 4, Batch: 301, D Loss: 0.1037410348653795, G Loss: 35.61033630371094\n",
      "Epoch: 4, Batch: 302, D Loss: 0.09668362140655536, G Loss: 35.431671142578125\n",
      "Epoch: 4, Batch: 303, D Loss: 0.09322441369295144, G Loss: 35.107330322265625\n",
      "Epoch: 4, Batch: 304, D Loss: 0.09635081887245205, G Loss: 35.208953857421875\n",
      "Epoch: 4, Batch: 305, D Loss: 0.10083454847335838, G Loss: 35.50794219970703\n",
      "Epoch: 4, Batch: 306, D Loss: 0.10251043736934679, G Loss: 35.67790222167969\n",
      "Epoch: 4, Batch: 307, D Loss: 0.10334555804729477, G Loss: 35.708614349365234\n",
      "Epoch: 4, Batch: 308, D Loss: 0.09274294972419757, G Loss: 35.45846939086914\n",
      "Epoch: 4, Batch: 309, D Loss: 0.09807857871055625, G Loss: 35.225830078125\n",
      "Epoch: 4, Batch: 310, D Loss: 0.09714476764202144, G Loss: 35.11076736450195\n",
      "Epoch: 4, Batch: 311, D Loss: 0.09797918051481275, G Loss: 35.159873962402344\n",
      "Epoch: 4, Batch: 312, D Loss: 0.09963205456733727, G Loss: 35.354225158691406\n",
      "Epoch: 4, Batch: 313, D Loss: 0.09604491293430349, G Loss: 35.49699401855469\n",
      "Epoch: 4, Batch: 314, D Loss: 0.09586986154317877, G Loss: 35.41178894042969\n",
      "Epoch: 4, Batch: 315, D Loss: 0.10323424637317745, G Loss: 33.94811248779297\n",
      "Epoch: 4, Batch: 316, D Loss: 0.10218441486358738, G Loss: 33.85506820678711\n",
      "Epoch: 4, Batch: 317, D Loss: 0.10200507938861947, G Loss: 33.84077835083008\n",
      "Epoch: 4, Batch: 318, D Loss: 0.09659183025360209, G Loss: 33.8294563293457\n",
      "Epoch: 4, Batch: 319, D Loss: 0.09711256623268229, G Loss: 33.842506408691406\n",
      "Epoch: 4, Batch: 320, D Loss: 0.09653110802173714, G Loss: 33.862464904785156\n",
      "Epoch: 4, Batch: 321, D Loss: 0.09509435296058753, G Loss: 33.853675842285156\n",
      "Epoch: 4, Batch: 322, D Loss: 0.09855669736862281, G Loss: 33.876686096191406\n",
      "Epoch: 4, Batch: 323, D Loss: 0.09870350360870457, G Loss: 33.908485412597656\n",
      "Epoch: 4, Batch: 324, D Loss: 0.10131681710481742, G Loss: 33.883792877197266\n",
      "Epoch: 4, Batch: 325, D Loss: 0.09506197273731365, G Loss: 33.540279388427734\n",
      "Epoch: 4, Batch: 326, D Loss: 0.09346905350685326, G Loss: 33.047767639160156\n",
      "Epoch: 4, Batch: 327, D Loss: 0.10455097258091195, G Loss: 33.04315948486328\n",
      "Epoch: 4, Batch: 328, D Loss: 0.09579277038574441, G Loss: 33.04679870605469\n",
      "Epoch: 4, Batch: 329, D Loss: 0.09977266937494499, G Loss: 33.080810546875\n",
      "Epoch: 4, Batch: 330, D Loss: 0.10213401913643098, G Loss: 33.07931900024414\n",
      "Epoch: 4, Batch: 331, D Loss: 0.10214722156524882, G Loss: 33.006736755371094\n",
      "Epoch: 4, Batch: 332, D Loss: 0.10356146842241526, G Loss: 32.944698333740234\n",
      "Epoch: 4, Batch: 333, D Loss: 0.09445121139288215, G Loss: 32.79045104980469\n",
      "Epoch: 4, Batch: 334, D Loss: 0.10151695460081395, G Loss: 32.74708557128906\n",
      "Epoch: 4, Batch: 335, D Loss: 0.09760586917400674, G Loss: 32.693359375\n",
      "Epoch: 4, Batch: 336, D Loss: 0.0961734652519347, G Loss: 31.350574493408203\n",
      "Epoch: 4, Batch: 337, D Loss: 0.0996115356683854, G Loss: 31.344499588012695\n",
      "Epoch: 4, Batch: 338, D Loss: 0.09894043952227852, G Loss: 31.355255126953125\n",
      "Epoch: 4, Batch: 339, D Loss: 0.09697266668082512, G Loss: 31.321754455566406\n",
      "Epoch: 4, Batch: 340, D Loss: 0.09805706888438546, G Loss: 31.28063201904297\n",
      "Epoch: 4, Batch: 341, D Loss: 0.10162757337094705, G Loss: 31.250965118408203\n",
      "Epoch: 4, Batch: 342, D Loss: 0.09878705441953091, G Loss: 31.252357482910156\n",
      "Epoch: 4, Batch: 343, D Loss: 0.10522211343051284, G Loss: 31.333934783935547\n",
      "Epoch: 4, Batch: 344, D Loss: 0.09461905062199898, G Loss: 31.295089721679688\n",
      "Epoch: 4, Batch: 345, D Loss: 0.09830807149411583, G Loss: 31.218151092529297\n",
      "Epoch: 4, Batch: 346, D Loss: 0.09263132512570908, G Loss: 31.099830627441406\n",
      "Epoch: 4, Batch: 347, D Loss: 0.10043492913248549, G Loss: 30.687318801879883\n",
      "Epoch: 4, Batch: 348, D Loss: 0.10111261904241862, G Loss: 30.81822967529297\n",
      "Epoch: 4, Batch: 349, D Loss: 0.10119776427747725, G Loss: 30.970619201660156\n",
      "Epoch: 4, Batch: 350, D Loss: 0.09658771753312971, G Loss: 30.933643341064453\n",
      "Epoch: 4, Batch: 351, D Loss: 0.10417924821379558, G Loss: 30.512094497680664\n",
      "Epoch: 4, Batch: 352, D Loss: 0.10697519034150091, G Loss: 30.507896423339844\n",
      "Epoch: 4, Batch: 353, D Loss: 0.098607249558001, G Loss: 30.45073890686035\n",
      "Epoch: 4, Batch: 354, D Loss: 0.09520253539092552, G Loss: 29.53743553161621\n",
      "Epoch: 4, Batch: 355, D Loss: 0.09890282899163819, G Loss: 28.415512084960938\n",
      "Epoch: 4, Batch: 356, D Loss: 0.09689376503251657, G Loss: 28.442123413085938\n",
      "Epoch: 4, Batch: 357, D Loss: 0.10192790627500817, G Loss: 28.525352478027344\n",
      "Epoch: 4, Batch: 358, D Loss: 0.09788578748722994, G Loss: 28.567718505859375\n",
      "Epoch: 4, Batch: 359, D Loss: 0.10262429714222367, G Loss: 28.57840919494629\n",
      "Epoch: 4, Batch: 360, D Loss: 0.09796963632127258, G Loss: 28.474567413330078\n",
      "Epoch: 4, Batch: 361, D Loss: 0.10866317152998699, G Loss: 28.45691680908203\n",
      "Epoch: 4, Batch: 362, D Loss: 0.1013261526825243, G Loss: 28.448177337646484\n",
      "Epoch: 4, Batch: 363, D Loss: 0.09787444770358666, G Loss: 28.41146469116211\n",
      "Epoch: 4, Batch: 364, D Loss: 0.10258035361789723, G Loss: 28.411643981933594\n",
      "Epoch: 4, Batch: 365, D Loss: 0.10192546248458378, G Loss: 28.453758239746094\n",
      "Epoch: 4, Batch: 366, D Loss: 0.10503730177900447, G Loss: 28.533370971679688\n",
      "Epoch: 4, Batch: 367, D Loss: 0.09186357259771957, G Loss: 28.414352416992188\n",
      "Epoch: 4, Batch: 368, D Loss: 0.09553752094531902, G Loss: 28.26980209350586\n",
      "Epoch: 4, Batch: 369, D Loss: 0.102531731128956, G Loss: 28.274044036865234\n",
      "Epoch: 4, Batch: 370, D Loss: 0.10181552171732212, G Loss: 28.366817474365234\n",
      "Epoch: 4, Batch: 371, D Loss: 0.09460955858254351, G Loss: 28.383501052856445\n",
      "Epoch: 4, Batch: 372, D Loss: 0.10278275609039363, G Loss: 28.433818817138672\n",
      "Epoch: 4, Batch: 373, D Loss: 0.09612977504753265, G Loss: 28.380542755126953\n",
      "Epoch: 4, Batch: 374, D Loss: 0.09244152903582167, G Loss: 28.247955322265625\n",
      "Epoch: 4, Batch: 375, D Loss: 0.09437447041301367, G Loss: 28.160486221313477\n",
      "Epoch: 4, Batch: 376, D Loss: 0.10424186289338962, G Loss: 28.221891403198242\n",
      "Epoch: 4, Batch: 377, D Loss: 0.09967786073710955, G Loss: 28.323177337646484\n",
      "Epoch: 4, Batch: 378, D Loss: 0.10322967171692861, G Loss: 28.41946029663086\n",
      "Epoch: 4, Batch: 379, D Loss: 0.09924761950993398, G Loss: 28.33983612060547\n",
      "Epoch: 4, Batch: 380, D Loss: 0.10244798660304753, G Loss: 28.20635986328125\n",
      "Epoch: 4, Batch: 381, D Loss: 0.09906232357061162, G Loss: 27.897884368896484\n",
      "Epoch: 4, Batch: 382, D Loss: 0.10307878255882891, G Loss: 27.885486602783203\n",
      "Epoch: 4, Batch: 383, D Loss: 0.10331557691134127, G Loss: 27.980924606323242\n",
      "Epoch: 4, Batch: 384, D Loss: 0.09334439039265796, G Loss: 27.969615936279297\n",
      "Epoch: 4, Batch: 385, D Loss: 0.09848352521694269, G Loss: 27.933475494384766\n",
      "Epoch: 4, Batch: 386, D Loss: 0.09705638140478044, G Loss: 27.878190994262695\n",
      "Epoch: 4, Batch: 387, D Loss: 0.10253672301808427, G Loss: 27.88762664794922\n",
      "Epoch: 4, Batch: 388, D Loss: 0.09831929206890655, G Loss: 27.805416107177734\n",
      "Epoch: 4, Batch: 389, D Loss: 0.09395180642647773, G Loss: 27.76371192932129\n",
      "Epoch: 4, Batch: 390, D Loss: 0.09354825317904802, G Loss: 27.7055606842041\n",
      "Epoch: 4, Batch: 391, D Loss: 0.09685267508078205, G Loss: 27.66206169128418\n",
      "Epoch: 4, Batch: 392, D Loss: 0.09938732534694669, G Loss: 27.699602127075195\n",
      "Epoch: 4, Batch: 393, D Loss: 0.09459787607239825, G Loss: 27.69366455078125\n",
      "Epoch: 4, Batch: 394, D Loss: 0.09633308649110744, G Loss: 27.666828155517578\n",
      "Epoch: 4, Batch: 395, D Loss: 0.10153825581121224, G Loss: 27.69772720336914\n",
      "Epoch: 4, Batch: 396, D Loss: 0.10214133560703091, G Loss: 27.746429443359375\n",
      "Epoch: 4, Batch: 397, D Loss: 0.09758666157768338, G Loss: 27.691192626953125\n",
      "Epoch: 4, Batch: 398, D Loss: 0.09771302342464272, G Loss: 27.599441528320312\n",
      "Epoch: 4, Batch: 399, D Loss: 0.09604630619342212, G Loss: 27.49465560913086\n",
      "Epoch: 4, Batch: 400, D Loss: 0.09316489100515891, G Loss: 27.418001174926758\n",
      "Epoch: 4, Batch: 401, D Loss: 0.09859645366729083, G Loss: 27.464244842529297\n",
      "Epoch: 4, Batch: 402, D Loss: 0.09953574836309341, G Loss: 27.59156036376953\n",
      "Epoch: 4, Batch: 403, D Loss: 0.10298501700211302, G Loss: 27.7291202545166\n",
      "Epoch: 4, Batch: 404, D Loss: 0.09758712351368641, G Loss: 27.681968688964844\n",
      "Epoch: 4, Batch: 405, D Loss: 0.09379683435015508, G Loss: 27.500938415527344\n",
      "Epoch: 4, Batch: 406, D Loss: 0.10731355845985839, G Loss: 27.477685928344727\n",
      "Epoch: 4, Batch: 407, D Loss: 0.10062614083346806, G Loss: 27.529876708984375\n",
      "Epoch: 4, Batch: 408, D Loss: 0.09995046258026205, G Loss: 27.593910217285156\n",
      "Epoch: 4, Batch: 409, D Loss: 0.09933660924486201, G Loss: 27.606796264648438\n",
      "Epoch: 4, Batch: 410, D Loss: 0.09848903119616481, G Loss: 27.562835693359375\n",
      "Epoch: 4, Batch: 411, D Loss: 0.09733008593376781, G Loss: 27.4792423248291\n",
      "Epoch: 4, Batch: 412, D Loss: 0.09529873728813146, G Loss: 27.389080047607422\n",
      "Epoch: 4, Batch: 413, D Loss: 0.09540759027069672, G Loss: 27.337665557861328\n",
      "Epoch: 4, Batch: 414, D Loss: 0.09828920662469168, G Loss: 27.36563491821289\n",
      "Epoch: 4, Batch: 415, D Loss: 0.10022228956284533, G Loss: 27.466819763183594\n",
      "Epoch: 4, Batch: 416, D Loss: 0.10077101737317751, G Loss: 27.532588958740234\n",
      "Epoch: 4, Batch: 417, D Loss: 0.09224101901113602, G Loss: 27.398422241210938\n",
      "Epoch: 4, Batch: 418, D Loss: 0.10246062278813448, G Loss: 27.315441131591797\n",
      "Epoch: 4, Batch: 419, D Loss: 0.10028940439293654, G Loss: 27.29177474975586\n",
      "Epoch: 4, Batch: 420, D Loss: 0.09606683254312752, G Loss: 27.27520751953125\n",
      "Epoch: 4, Batch: 421, D Loss: 0.09815461188625067, G Loss: 27.303726196289062\n",
      "Epoch: 4, Batch: 422, D Loss: 0.10653057694499819, G Loss: 27.435489654541016\n",
      "Epoch: 4, Batch: 423, D Loss: 0.09718025475801507, G Loss: 27.426841735839844\n",
      "Epoch: 4, Batch: 424, D Loss: 0.09670422226256037, G Loss: 27.30253028869629\n",
      "Epoch: 4, Batch: 425, D Loss: 0.10193243622852197, G Loss: 27.22433853149414\n",
      "Epoch: 4, Batch: 426, D Loss: 0.09834386408405695, G Loss: 27.18444061279297\n",
      "Epoch: 4, Batch: 427, D Loss: 0.09874396026211793, G Loss: 27.205116271972656\n",
      "Epoch: 4, Batch: 428, D Loss: 0.10298287123514499, G Loss: 27.29955291748047\n",
      "Epoch: 4, Batch: 429, D Loss: 0.09998885542223056, G Loss: 27.32445526123047\n",
      "Epoch: 4, Batch: 430, D Loss: 0.1048500686890648, G Loss: 27.344772338867188\n",
      "Epoch: 4, Batch: 431, D Loss: 0.09623295068811627, G Loss: 27.227867126464844\n",
      "Epoch: 4, Batch: 432, D Loss: 0.09892986714918237, G Loss: 27.14159393310547\n",
      "Epoch: 4, Batch: 433, D Loss: 0.10324978083452839, G Loss: 27.161407470703125\n",
      "Epoch: 4, Batch: 434, D Loss: 0.1000088527806467, G Loss: 27.205280303955078\n",
      "Epoch: 4, Batch: 435, D Loss: 0.1048003882176972, G Loss: 27.30784034729004\n",
      "Epoch: 4, Batch: 436, D Loss: 0.09304209053587503, G Loss: 27.2524356842041\n",
      "Epoch: 4, Batch: 437, D Loss: 0.10101030767038754, G Loss: 27.206539154052734\n",
      "Epoch: 4, Batch: 438, D Loss: 0.10195593535976802, G Loss: 27.200611114501953\n",
      "Epoch: 4, Batch: 439, D Loss: 0.09740363061507316, G Loss: 27.156099319458008\n",
      "Epoch: 4, Batch: 440, D Loss: 0.09747120738111173, G Loss: 27.127456665039062\n",
      "Epoch: 4, Batch: 441, D Loss: 0.09486281126822405, G Loss: 27.080263137817383\n",
      "Epoch: 4, Batch: 442, D Loss: 0.09694801271049543, G Loss: 27.057331085205078\n",
      "Epoch: 4, Batch: 443, D Loss: 0.1003151834019726, G Loss: 27.10633087158203\n",
      "Epoch: 4, Batch: 444, D Loss: 0.09289126843299174, G Loss: 27.09194564819336\n",
      "Epoch: 4, Batch: 445, D Loss: 0.10497152060352434, G Loss: 27.173370361328125\n",
      "Epoch: 4, Batch: 446, D Loss: 0.09480969607910536, G Loss: 27.138328552246094\n",
      "Epoch: 4, Batch: 447, D Loss: 0.09899242967451231, G Loss: 27.087387084960938\n",
      "Epoch: 4, Batch: 448, D Loss: 0.10050156712619213, G Loss: 27.064208984375\n",
      "Epoch: 4, Batch: 449, D Loss: 0.0929102301606862, G Loss: 26.968793869018555\n",
      "Epoch: 4, Batch: 450, D Loss: 0.10096113383866215, G Loss: 26.983137130737305\n",
      "Epoch: 4, Batch: 451, D Loss: 0.10297818482011536, G Loss: 27.110275268554688\n",
      "Epoch: 4, Batch: 452, D Loss: 0.10224564373573058, G Loss: 27.209369659423828\n",
      "Epoch: 4, Batch: 453, D Loss: 0.10033784806805546, G Loss: 27.185609817504883\n",
      "Epoch: 4, Batch: 454, D Loss: 0.10118831694208467, G Loss: 27.084543228149414\n",
      "Epoch: 4, Batch: 455, D Loss: 0.10015863180253469, G Loss: 26.969615936279297\n",
      "Epoch: 4, Batch: 456, D Loss: 0.10156327486176216, G Loss: 26.610628128051758\n",
      "Epoch: 4, Batch: 457, D Loss: 0.0952753275646836, G Loss: 26.598163604736328\n",
      "Epoch: 4, Batch: 458, D Loss: 0.10383450985087571, G Loss: 26.705493927001953\n",
      "Epoch: 4, Batch: 459, D Loss: 0.10208449512842074, G Loss: 26.769744873046875\n",
      "Epoch: 4, Batch: 460, D Loss: 0.10014749318482691, G Loss: 26.720596313476562\n",
      "Epoch: 4, Batch: 461, D Loss: 0.10464342683682917, G Loss: 26.646419525146484\n",
      "Epoch: 4, Batch: 462, D Loss: 0.09923437237878649, G Loss: 26.573318481445312\n",
      "Epoch: 4, Batch: 463, D Loss: 0.09797422588022113, G Loss: 26.488449096679688\n",
      "Epoch: 4, Batch: 464, D Loss: 0.10310135781919962, G Loss: 26.509937286376953\n",
      "Epoch: 4, Batch: 465, D Loss: 0.09093197435298542, G Loss: 26.45469093322754\n",
      "Epoch: 4, Batch: 466, D Loss: 0.10142096877255434, G Loss: 26.51146697998047\n",
      "Epoch: 4, Batch: 467, D Loss: 0.09902780503183158, G Loss: 26.569509506225586\n",
      "Epoch: 5, Batch: 0, D Loss: 0.09981583804034042, G Loss: 26.60440444946289\n",
      "Epoch: 5, Batch: 1, D Loss: 0.0999382883324406, G Loss: 26.586769104003906\n",
      "Epoch: 5, Batch: 2, D Loss: 0.10337384045266355, G Loss: 26.583576202392578\n",
      "Epoch: 5, Batch: 3, D Loss: 0.10863128304618543, G Loss: 26.658321380615234\n",
      "Epoch: 5, Batch: 4, D Loss: 0.10420256853234501, G Loss: 26.67841339111328\n",
      "Epoch: 5, Batch: 5, D Loss: 0.1038015037788324, G Loss: 26.632125854492188\n",
      "Epoch: 5, Batch: 6, D Loss: 0.10110457241678412, G Loss: 26.530384063720703\n",
      "Epoch: 5, Batch: 7, D Loss: 0.09601350873868297, G Loss: 26.416580200195312\n",
      "Epoch: 5, Batch: 8, D Loss: 0.09972572326828652, G Loss: 26.415712356567383\n",
      "Epoch: 5, Batch: 9, D Loss: 0.09250557422806364, G Loss: 26.41731071472168\n",
      "Epoch: 5, Batch: 10, D Loss: 0.0912621244805014, G Loss: 26.415699005126953\n",
      "Epoch: 5, Batch: 11, D Loss: 0.09474000334905555, G Loss: 26.446388244628906\n",
      "Epoch: 5, Batch: 12, D Loss: 0.09955269098437788, G Loss: 26.53617286682129\n",
      "Epoch: 5, Batch: 13, D Loss: 0.09932539612198617, G Loss: 26.609516143798828\n",
      "Epoch: 5, Batch: 14, D Loss: 0.09485685825492247, G Loss: 26.5382080078125\n",
      "Epoch: 5, Batch: 15, D Loss: 0.09411978721826841, G Loss: 26.15688133239746\n",
      "Epoch: 5, Batch: 16, D Loss: 0.0947699249032465, G Loss: 23.71146011352539\n",
      "Epoch: 5, Batch: 17, D Loss: 0.10445652904508629, G Loss: 23.823286056518555\n",
      "Epoch: 5, Batch: 18, D Loss: 0.1021835953203479, G Loss: 23.990354537963867\n",
      "Epoch: 5, Batch: 19, D Loss: 0.10161074252780598, G Loss: 24.052936553955078\n",
      "Epoch: 5, Batch: 20, D Loss: 0.1003991514632217, G Loss: 23.961288452148438\n",
      "Epoch: 5, Batch: 21, D Loss: 0.10410357268746469, G Loss: 23.8485107421875\n",
      "Epoch: 5, Batch: 22, D Loss: 0.10257687421916478, G Loss: 23.79119873046875\n",
      "Epoch: 5, Batch: 23, D Loss: 0.10339175166970344, G Loss: 23.836719512939453\n",
      "Epoch: 5, Batch: 24, D Loss: 0.09456641229249081, G Loss: 23.81985855102539\n",
      "Epoch: 5, Batch: 25, D Loss: 0.09905783834327805, G Loss: 23.824539184570312\n",
      "Epoch: 5, Batch: 26, D Loss: 0.10284495355868799, G Loss: 23.892921447753906\n",
      "Epoch: 5, Batch: 27, D Loss: 0.10318979622951978, G Loss: 23.968994140625\n",
      "Epoch: 5, Batch: 28, D Loss: 0.1036229878854097, G Loss: 24.014633178710938\n",
      "Epoch: 5, Batch: 29, D Loss: 0.10137136282450132, G Loss: 23.960895538330078\n",
      "Epoch: 5, Batch: 30, D Loss: 0.0992733836381255, G Loss: 23.857154846191406\n",
      "Epoch: 5, Batch: 31, D Loss: 0.10330604764006898, G Loss: 23.865402221679688\n",
      "Epoch: 5, Batch: 32, D Loss: 0.09585623445294217, G Loss: 23.858362197875977\n",
      "Epoch: 5, Batch: 33, D Loss: 0.0981658250309354, G Loss: 23.87224769592285\n",
      "Epoch: 5, Batch: 34, D Loss: 0.09641338886968463, G Loss: 23.878273010253906\n",
      "Epoch: 5, Batch: 35, D Loss: 0.09050050380075286, G Loss: 23.79314422607422\n",
      "Epoch: 5, Batch: 36, D Loss: 0.09199117871550444, G Loss: 23.72052764892578\n",
      "Epoch: 5, Batch: 37, D Loss: 0.09767866137051345, G Loss: 23.78902816772461\n",
      "Epoch: 5, Batch: 38, D Loss: 0.09790134432111229, G Loss: 23.916513442993164\n",
      "Epoch: 5, Batch: 39, D Loss: 0.09687099607770724, G Loss: 23.992111206054688\n",
      "Epoch: 5, Batch: 40, D Loss: 0.09303072841983699, G Loss: 23.89898681640625\n",
      "Epoch: 5, Batch: 41, D Loss: 0.09949488940000088, G Loss: 23.849708557128906\n",
      "Epoch: 5, Batch: 42, D Loss: 0.10022772850771193, G Loss: 23.874652862548828\n",
      "Epoch: 5, Batch: 43, D Loss: 0.0967764109584264, G Loss: 23.89961814880371\n",
      "Epoch: 5, Batch: 44, D Loss: 0.10156311841851823, G Loss: 23.94943618774414\n",
      "Epoch: 5, Batch: 45, D Loss: 0.09437173607006573, G Loss: 23.896652221679688\n",
      "Epoch: 5, Batch: 46, D Loss: 0.09733761849185382, G Loss: 23.83138656616211\n",
      "Epoch: 5, Batch: 47, D Loss: 0.09764797987796908, G Loss: 23.823810577392578\n",
      "Epoch: 5, Batch: 48, D Loss: 0.09811257573181327, G Loss: 23.868114471435547\n",
      "Epoch: 5, Batch: 49, D Loss: 0.09607873859157867, G Loss: 23.88330078125\n",
      "Epoch: 5, Batch: 50, D Loss: 0.09946151079866686, G Loss: 23.884971618652344\n",
      "Epoch: 5, Batch: 51, D Loss: 0.09620014580285419, G Loss: 23.828609466552734\n",
      "Epoch: 5, Batch: 52, D Loss: 0.09646786751707419, G Loss: 23.74233627319336\n",
      "Epoch: 5, Batch: 53, D Loss: 0.09479001166981335, G Loss: 23.6640625\n",
      "Epoch: 5, Batch: 54, D Loss: 0.10895174744160696, G Loss: 23.83346176147461\n",
      "Epoch: 5, Batch: 55, D Loss: 0.09650927039155902, G Loss: 23.897903442382812\n",
      "Epoch: 5, Batch: 56, D Loss: 0.1068014502729269, G Loss: 23.94488525390625\n",
      "Epoch: 5, Batch: 57, D Loss: 0.09908917548401498, G Loss: 23.82061767578125\n",
      "Epoch: 5, Batch: 58, D Loss: 0.10033544900463172, G Loss: 23.681350708007812\n",
      "Epoch: 5, Batch: 59, D Loss: 0.10025569054163525, G Loss: 23.635433197021484\n",
      "Epoch: 5, Batch: 60, D Loss: 0.10250169786424447, G Loss: 23.72418212890625\n",
      "Epoch: 5, Batch: 61, D Loss: 0.09941543641086985, G Loss: 23.807138442993164\n",
      "Epoch: 5, Batch: 62, D Loss: 0.0967042744393079, G Loss: 23.770366668701172\n",
      "Epoch: 5, Batch: 63, D Loss: 0.09372401240036851, G Loss: 23.635705947875977\n",
      "Epoch: 5, Batch: 64, D Loss: 0.10248091819616283, G Loss: 23.63782501220703\n",
      "Epoch: 5, Batch: 65, D Loss: 0.09489335122421001, G Loss: 23.64813995361328\n",
      "Epoch: 5, Batch: 66, D Loss: 0.09721164407988536, G Loss: 23.677364349365234\n",
      "Epoch: 5, Batch: 67, D Loss: 0.0972222686072481, G Loss: 23.692378997802734\n",
      "Epoch: 5, Batch: 68, D Loss: 0.09923401477500113, G Loss: 23.707256317138672\n",
      "Epoch: 5, Batch: 69, D Loss: 0.10324065389695126, G Loss: 23.77093505859375\n",
      "Epoch: 5, Batch: 70, D Loss: 0.09778778257366334, G Loss: 23.76529312133789\n",
      "Epoch: 5, Batch: 71, D Loss: 0.1075112447373644, G Loss: 23.827157974243164\n",
      "Epoch: 5, Batch: 72, D Loss: 0.09177548440736263, G Loss: 23.678874969482422\n",
      "Epoch: 5, Batch: 73, D Loss: 0.09807313981424641, G Loss: 23.572120666503906\n",
      "Epoch: 5, Batch: 74, D Loss: 0.0923500433865032, G Loss: 23.499935150146484\n",
      "Epoch: 5, Batch: 75, D Loss: 0.09674914184232168, G Loss: 23.570419311523438\n",
      "Epoch: 5, Batch: 76, D Loss: 0.09906888010775802, G Loss: 23.73605728149414\n",
      "Epoch: 5, Batch: 77, D Loss: 0.10114799442185532, G Loss: 23.87969970703125\n",
      "Epoch: 5, Batch: 78, D Loss: 0.09771573545715719, G Loss: 23.845829010009766\n",
      "Epoch: 5, Batch: 79, D Loss: 0.09768543394810912, G Loss: 23.68912124633789\n",
      "Epoch: 5, Batch: 80, D Loss: 0.09481784704142686, G Loss: 23.534053802490234\n",
      "Epoch: 5, Batch: 81, D Loss: 0.09614683690733994, G Loss: 23.50944709777832\n",
      "Epoch: 5, Batch: 82, D Loss: 0.1059274375713147, G Loss: 23.730876922607422\n",
      "Epoch: 5, Batch: 83, D Loss: 0.09555703403871738, G Loss: 23.86153221130371\n",
      "Epoch: 5, Batch: 84, D Loss: 0.10078825058715869, G Loss: 23.8658447265625\n",
      "Epoch: 5, Batch: 85, D Loss: 0.08840116860965441, G Loss: 23.59931182861328\n",
      "Epoch: 5, Batch: 86, D Loss: 0.097010992498101, G Loss: 23.43658447265625\n",
      "Epoch: 5, Batch: 87, D Loss: 0.09962822500077945, G Loss: 23.511795043945312\n",
      "Epoch: 5, Batch: 88, D Loss: 0.0953506902143602, G Loss: 23.668363571166992\n",
      "Epoch: 5, Batch: 89, D Loss: 0.09919518234773064, G Loss: 23.82038116455078\n",
      "Epoch: 5, Batch: 90, D Loss: 0.10182988645830385, G Loss: 23.88437271118164\n",
      "Epoch: 5, Batch: 91, D Loss: 0.10077251496122377, G Loss: 23.820316314697266\n",
      "Epoch: 5, Batch: 92, D Loss: 0.10187916460034892, G Loss: 23.71979522705078\n",
      "Epoch: 5, Batch: 93, D Loss: 0.10625307264433266, G Loss: 23.728336334228516\n",
      "Epoch: 5, Batch: 94, D Loss: 0.09404399994036512, G Loss: 23.50967788696289\n",
      "Epoch: 5, Batch: 95, D Loss: 0.09432238343619764, G Loss: 23.42178726196289\n",
      "Epoch: 5, Batch: 96, D Loss: 0.10406276586863561, G Loss: 23.52212905883789\n",
      "Epoch: 5, Batch: 97, D Loss: 0.09717017415084109, G Loss: 23.615169525146484\n",
      "Epoch: 5, Batch: 98, D Loss: 0.1051027775072038, G Loss: 23.728761672973633\n",
      "Epoch: 5, Batch: 99, D Loss: 0.10094210507981675, G Loss: 23.71314239501953\n",
      "Epoch: 5, Batch: 100, D Loss: 0.09987266364384649, G Loss: 23.598281860351562\n",
      "Epoch: 5, Batch: 101, D Loss: 0.09456428888547622, G Loss: 23.426565170288086\n",
      "Epoch: 5, Batch: 102, D Loss: 0.10163451734534792, G Loss: 23.437610626220703\n",
      "Epoch: 5, Batch: 103, D Loss: 0.09983040395512652, G Loss: 23.555339813232422\n",
      "Epoch: 5, Batch: 104, D Loss: 0.104734420802853, G Loss: 23.756378173828125\n",
      "Epoch: 5, Batch: 105, D Loss: 0.10362210872068289, G Loss: 23.861019134521484\n",
      "Epoch: 5, Batch: 106, D Loss: 0.10110902788550594, G Loss: 23.7530517578125\n",
      "Epoch: 5, Batch: 107, D Loss: 0.0945368707458978, G Loss: 23.480270385742188\n",
      "Epoch: 5, Batch: 108, D Loss: 0.09906093779633128, G Loss: 23.345561981201172\n",
      "Epoch: 5, Batch: 109, D Loss: 0.09449160847686949, G Loss: 23.362613677978516\n",
      "Epoch: 5, Batch: 110, D Loss: 0.0954192802641585, G Loss: 23.502960205078125\n",
      "Epoch: 5, Batch: 111, D Loss: 0.09982506933636316, G Loss: 23.69305419921875\n",
      "Epoch: 5, Batch: 112, D Loss: 0.09572638573784797, G Loss: 23.725364685058594\n",
      "Epoch: 5, Batch: 113, D Loss: 0.10023325684249562, G Loss: 23.665836334228516\n",
      "Epoch: 5, Batch: 114, D Loss: 0.10109011831668394, G Loss: 23.57265853881836\n",
      "Epoch: 5, Batch: 115, D Loss: 0.09714952114280381, G Loss: 23.481449127197266\n",
      "Epoch: 5, Batch: 116, D Loss: 0.0993423387724113, G Loss: 23.488525390625\n",
      "Epoch: 5, Batch: 117, D Loss: 0.09762411567628208, G Loss: 23.555049896240234\n",
      "Epoch: 5, Batch: 118, D Loss: 0.1061821803718635, G Loss: 23.734588623046875\n",
      "Epoch: 5, Batch: 119, D Loss: 0.0959919989356193, G Loss: 23.726715087890625\n",
      "Epoch: 5, Batch: 120, D Loss: 0.09892036023384997, G Loss: 23.616207122802734\n",
      "Epoch: 5, Batch: 121, D Loss: 0.10103806856161264, G Loss: 23.551326751708984\n",
      "Epoch: 5, Batch: 122, D Loss: 0.09642914685653288, G Loss: 23.506723403930664\n",
      "Epoch: 5, Batch: 123, D Loss: 0.08843898031415245, G Loss: 23.39403533935547\n",
      "Epoch: 5, Batch: 124, D Loss: 0.0998590886929704, G Loss: 23.44498062133789\n",
      "Epoch: 5, Batch: 125, D Loss: 0.10681766274494092, G Loss: 23.682395935058594\n",
      "Epoch: 5, Batch: 126, D Loss: 0.0976098254572211, G Loss: 23.757953643798828\n",
      "Epoch: 5, Batch: 127, D Loss: 0.09657706322856374, G Loss: 23.631103515625\n",
      "Epoch: 5, Batch: 128, D Loss: 0.1033512801215712, G Loss: 23.557228088378906\n",
      "Epoch: 5, Batch: 129, D Loss: 0.10100312533959085, G Loss: 23.540843963623047\n",
      "Epoch: 5, Batch: 130, D Loss: 0.10303312542931496, G Loss: 23.612327575683594\n",
      "Epoch: 5, Batch: 131, D Loss: 0.0975638330258843, G Loss: 23.62641143798828\n",
      "Epoch: 5, Batch: 132, D Loss: 0.10114438089467614, G Loss: 23.642433166503906\n",
      "Epoch: 5, Batch: 133, D Loss: 0.09523445370617128, G Loss: 23.569782257080078\n",
      "Epoch: 5, Batch: 134, D Loss: 0.09148536625625597, G Loss: 23.443035125732422\n",
      "Epoch: 5, Batch: 135, D Loss: 0.09723186496209155, G Loss: 23.44607162475586\n",
      "Epoch: 5, Batch: 136, D Loss: 0.100226983458067, G Loss: 23.613422393798828\n",
      "Epoch: 5, Batch: 137, D Loss: 0.09564408662538115, G Loss: 23.73717498779297\n",
      "Epoch: 5, Batch: 138, D Loss: 0.0974311083797974, G Loss: 23.758602142333984\n",
      "Epoch: 5, Batch: 139, D Loss: 0.09940866383373104, G Loss: 23.727188110351562\n",
      "Epoch: 5, Batch: 140, D Loss: 0.10239815714490937, G Loss: 23.699607849121094\n",
      "Epoch: 5, Batch: 141, D Loss: 0.09787552061312924, G Loss: 23.64997100830078\n",
      "Epoch: 5, Batch: 142, D Loss: 0.10342478754750174, G Loss: 23.696300506591797\n",
      "Epoch: 5, Batch: 143, D Loss: 0.10258717837395949, G Loss: 23.78143310546875\n",
      "Epoch: 5, Batch: 144, D Loss: 0.1028993651498727, G Loss: 23.838970184326172\n",
      "Epoch: 5, Batch: 145, D Loss: 0.100781597219725, G Loss: 23.79696273803711\n",
      "Epoch: 5, Batch: 146, D Loss: 0.09639330210822289, G Loss: 23.63369369506836\n",
      "Epoch: 5, Batch: 147, D Loss: 0.09920082244142184, G Loss: 23.551774978637695\n",
      "Epoch: 5, Batch: 148, D Loss: 0.10138051960486547, G Loss: 23.389312744140625\n",
      "Epoch: 5, Batch: 149, D Loss: 0.10474208000534939, G Loss: 23.556432723999023\n",
      "Epoch: 5, Batch: 150, D Loss: 0.10394015165927702, G Loss: 23.687843322753906\n",
      "Epoch: 5, Batch: 151, D Loss: 0.10085646810812471, G Loss: 23.625518798828125\n",
      "Epoch: 5, Batch: 152, D Loss: 0.09919881823694396, G Loss: 23.44652557373047\n",
      "Epoch: 5, Batch: 153, D Loss: 0.10029464218459734, G Loss: 23.369539260864258\n",
      "Epoch: 5, Batch: 154, D Loss: 0.09503347430195562, G Loss: 23.371196746826172\n",
      "Epoch: 5, Batch: 155, D Loss: 0.09959203008134193, G Loss: 23.506507873535156\n",
      "Epoch: 5, Batch: 156, D Loss: 0.09396344426245715, G Loss: 23.594688415527344\n",
      "Epoch: 5, Batch: 157, D Loss: 0.09535087647870996, G Loss: 23.603965759277344\n",
      "Epoch: 5, Batch: 158, D Loss: 0.09355510029136951, G Loss: 23.52718734741211\n",
      "Epoch: 5, Batch: 159, D Loss: 0.09820112589079671, G Loss: 23.50867462158203\n",
      "Epoch: 5, Batch: 160, D Loss: 0.09977479282002595, G Loss: 23.586816787719727\n",
      "Epoch: 5, Batch: 161, D Loss: 0.09809058162345863, G Loss: 23.652652740478516\n",
      "Epoch: 5, Batch: 162, D Loss: 0.09546379747742005, G Loss: 23.607677459716797\n",
      "Epoch: 5, Batch: 163, D Loss: 0.09997876736378858, G Loss: 23.578659057617188\n",
      "Epoch: 5, Batch: 164, D Loss: 0.09938612583166817, G Loss: 23.58475112915039\n",
      "Epoch: 5, Batch: 165, D Loss: 0.09901919218728263, G Loss: 23.617259979248047\n",
      "Epoch: 5, Batch: 166, D Loss: 0.09869867565969279, G Loss: 23.64920425415039\n",
      "Epoch: 5, Batch: 167, D Loss: 0.0948867649111505, G Loss: 23.624664306640625\n",
      "Epoch: 5, Batch: 168, D Loss: 0.10130844267906547, G Loss: 23.668977737426758\n",
      "Epoch: 5, Batch: 169, D Loss: 0.10423734041528736, G Loss: 23.79425048828125\n",
      "Epoch: 5, Batch: 170, D Loss: 0.10061851891130155, G Loss: 23.864063262939453\n",
      "Epoch: 5, Batch: 171, D Loss: 0.09775280954668997, G Loss: 23.818038940429688\n",
      "Epoch: 5, Batch: 172, D Loss: 0.10090518000076454, G Loss: 23.759742736816406\n",
      "Epoch: 5, Batch: 173, D Loss: 0.09615274521203825, G Loss: 23.700923919677734\n",
      "Epoch: 5, Batch: 174, D Loss: 0.10940641167096005, G Loss: 23.880107879638672\n",
      "Epoch: 5, Batch: 175, D Loss: 0.10363529624494265, G Loss: 24.056257247924805\n",
      "Epoch: 5, Batch: 176, D Loss: 0.1053215488964607, G Loss: 24.113445281982422\n",
      "Epoch: 5, Batch: 177, D Loss: 0.0999769196095927, G Loss: 23.970550537109375\n",
      "Epoch: 5, Batch: 178, D Loss: 0.10499866308813874, G Loss: 23.886245727539062\n",
      "Epoch: 5, Batch: 179, D Loss: 0.09571775796256479, G Loss: 23.788578033447266\n",
      "Epoch: 5, Batch: 180, D Loss: 0.09892273696593412, G Loss: 23.801132202148438\n",
      "Epoch: 5, Batch: 181, D Loss: 0.09820332380348103, G Loss: 23.889244079589844\n",
      "Epoch: 5, Batch: 182, D Loss: 0.09414023163017773, G Loss: 23.912189483642578\n",
      "Epoch: 5, Batch: 183, D Loss: 0.09798702599687997, G Loss: 23.903823852539062\n",
      "Epoch: 5, Batch: 184, D Loss: 0.0926170647365055, G Loss: 23.789142608642578\n",
      "Epoch: 5, Batch: 185, D Loss: 0.10101273658246905, G Loss: 23.76898956298828\n",
      "Epoch: 5, Batch: 186, D Loss: 0.09708135577425228, G Loss: 23.776165008544922\n",
      "Epoch: 5, Batch: 187, D Loss: 0.10445708038617214, G Loss: 23.91510772705078\n",
      "Epoch: 5, Batch: 188, D Loss: 0.1006098017295101, G Loss: 23.97997283935547\n",
      "Epoch: 5, Batch: 189, D Loss: 0.09928293528185539, G Loss: 23.89583969116211\n",
      "Epoch: 5, Batch: 190, D Loss: 0.09642431887328932, G Loss: 23.69759750366211\n",
      "Epoch: 5, Batch: 191, D Loss: 0.092759296326229, G Loss: 23.50908660888672\n",
      "Epoch: 5, Batch: 192, D Loss: 0.09594465795300153, G Loss: 23.486343383789062\n",
      "Epoch: 5, Batch: 193, D Loss: 0.10492701831225014, G Loss: 23.751516342163086\n",
      "Epoch: 5, Batch: 194, D Loss: 0.09715598823852943, G Loss: 23.921337127685547\n",
      "Epoch: 5, Batch: 195, D Loss: 0.09830713274170524, G Loss: 23.890178680419922\n",
      "Epoch: 5, Batch: 196, D Loss: 0.09554648401712479, G Loss: 23.674602508544922\n",
      "Epoch: 5, Batch: 197, D Loss: 0.09559701385984136, G Loss: 23.496597290039062\n",
      "Epoch: 5, Batch: 198, D Loss: 0.10210722687835788, G Loss: 23.5882568359375\n",
      "Epoch: 5, Batch: 199, D Loss: 0.09956167640849786, G Loss: 23.801361083984375\n",
      "Epoch: 5, Batch: 200, D Loss: 0.09949620815268326, G Loss: 23.942886352539062\n",
      "Epoch: 5, Batch: 201, D Loss: 0.09655718507453859, G Loss: 23.874862670898438\n",
      "Epoch: 5, Batch: 202, D Loss: 0.09708435835794982, G Loss: 23.703784942626953\n",
      "Epoch: 5, Batch: 203, D Loss: 0.09380534294022604, G Loss: 23.547855377197266\n",
      "Epoch: 5, Batch: 204, D Loss: 0.09912458810128487, G Loss: 23.592018127441406\n",
      "Epoch: 5, Batch: 205, D Loss: 0.09945734592863585, G Loss: 23.780115127563477\n",
      "Epoch: 5, Batch: 206, D Loss: 0.10344212504358871, G Loss: 23.979076385498047\n",
      "Epoch: 5, Batch: 207, D Loss: 0.103832207638877, G Loss: 24.033212661743164\n",
      "Epoch: 5, Batch: 208, D Loss: 0.09887587281107718, G Loss: 23.83502960205078\n",
      "Epoch: 5, Batch: 209, D Loss: 0.10288462790298653, G Loss: 23.667720794677734\n",
      "Epoch: 5, Batch: 210, D Loss: 0.10432685914269213, G Loss: 23.68057632446289\n",
      "Epoch: 5, Batch: 211, D Loss: 0.09379631283499648, G Loss: 23.678621292114258\n",
      "Epoch: 5, Batch: 212, D Loss: 0.1038030460721589, G Loss: 23.796653747558594\n",
      "Epoch: 5, Batch: 213, D Loss: 0.10819952192011958, G Loss: 23.989521026611328\n",
      "Epoch: 5, Batch: 214, D Loss: 0.09869475664677972, G Loss: 23.928485870361328\n",
      "Epoch: 5, Batch: 215, D Loss: 0.09723690154455317, G Loss: 23.699928283691406\n",
      "Epoch: 5, Batch: 216, D Loss: 0.09636589887563808, G Loss: 23.51667022705078\n",
      "Epoch: 5, Batch: 217, D Loss: 0.09196425977571548, G Loss: 23.430522918701172\n",
      "Epoch: 5, Batch: 218, D Loss: 0.10454589131439095, G Loss: 23.667076110839844\n",
      "Epoch: 5, Batch: 219, D Loss: 0.09816593679102725, G Loss: 23.927358627319336\n",
      "Epoch: 5, Batch: 220, D Loss: 0.09520220758515294, G Loss: 23.970195770263672\n",
      "Epoch: 5, Batch: 221, D Loss: 0.10345424713696261, G Loss: 23.924488067626953\n",
      "Epoch: 5, Batch: 222, D Loss: 0.09901927413745289, G Loss: 23.786521911621094\n",
      "Epoch: 5, Batch: 223, D Loss: 0.09920103850435943, G Loss: 23.692317962646484\n",
      "Epoch: 5, Batch: 224, D Loss: 0.10069693627509868, G Loss: 23.71541404724121\n",
      "Epoch: 5, Batch: 225, D Loss: 0.09476888927304941, G Loss: 23.746826171875\n",
      "Epoch: 5, Batch: 226, D Loss: 0.09706152977943318, G Loss: 23.784217834472656\n",
      "Epoch: 5, Batch: 227, D Loss: 0.10118685664988397, G Loss: 23.867252349853516\n",
      "Epoch: 5, Batch: 228, D Loss: 0.10020343961446548, G Loss: 23.903297424316406\n",
      "Epoch: 5, Batch: 229, D Loss: 0.10229155423336977, G Loss: 23.902637481689453\n",
      "Epoch: 5, Batch: 230, D Loss: 0.09886293115413405, G Loss: 23.812358856201172\n",
      "Epoch: 5, Batch: 231, D Loss: 0.09859296681883793, G Loss: 23.722986221313477\n",
      "Epoch: 5, Batch: 232, D Loss: 0.09815889599462918, G Loss: 23.697376251220703\n",
      "Epoch: 5, Batch: 233, D Loss: 0.09319090845819618, G Loss: 23.650123596191406\n",
      "Epoch: 5, Batch: 234, D Loss: 0.10436624291059876, G Loss: 23.78019142150879\n",
      "Epoch: 5, Batch: 235, D Loss: 0.10033869745577625, G Loss: 23.88066864013672\n",
      "Epoch: 5, Batch: 236, D Loss: 0.1006011963100563, G Loss: 23.90532684326172\n",
      "Epoch: 5, Batch: 237, D Loss: 0.1001419723252918, G Loss: 23.802650451660156\n",
      "Epoch: 5, Batch: 238, D Loss: 0.09536021950429281, G Loss: 23.592296600341797\n",
      "Epoch: 5, Batch: 239, D Loss: 0.10296514633168022, G Loss: 23.583850860595703\n",
      "Epoch: 5, Batch: 240, D Loss: 0.0991993025218651, G Loss: 23.670642852783203\n",
      "Epoch: 5, Batch: 241, D Loss: 0.1068634391064053, G Loss: 23.8966007232666\n",
      "Epoch: 5, Batch: 242, D Loss: 0.10548871012521069, G Loss: 24.002992630004883\n",
      "Epoch: 5, Batch: 243, D Loss: 0.0993993804063188, G Loss: 23.84555435180664\n",
      "Epoch: 5, Batch: 244, D Loss: 0.098090820039871, G Loss: 23.57601547241211\n",
      "Epoch: 5, Batch: 245, D Loss: 0.10539560022907277, G Loss: 23.541439056396484\n",
      "Epoch: 5, Batch: 246, D Loss: 0.0980193168210371, G Loss: 23.626689910888672\n",
      "Epoch: 5, Batch: 247, D Loss: 0.09588976206997091, G Loss: 23.726207733154297\n",
      "Epoch: 5, Batch: 248, D Loss: 0.10205888750492854, G Loss: 23.85184097290039\n",
      "Epoch: 5, Batch: 249, D Loss: 0.09753988685448116, G Loss: 23.821348190307617\n",
      "Epoch: 5, Batch: 250, D Loss: 0.10234657677334426, G Loss: 23.78008270263672\n",
      "Epoch: 5, Batch: 251, D Loss: 0.10691478850767652, G Loss: 23.814128875732422\n",
      "Epoch: 5, Batch: 252, D Loss: 0.10155790301461835, G Loss: 23.804527282714844\n",
      "Epoch: 5, Batch: 253, D Loss: 0.10606762024041848, G Loss: 23.832239151000977\n",
      "Epoch: 5, Batch: 254, D Loss: 0.09831900896972201, G Loss: 23.750961303710938\n",
      "Epoch: 5, Batch: 255, D Loss: 0.10285215827300634, G Loss: 23.722274780273438\n",
      "Epoch: 5, Batch: 256, D Loss: 0.1003335863600617, G Loss: 23.725221633911133\n",
      "Epoch: 5, Batch: 257, D Loss: 0.10349731894757025, G Loss: 23.78329849243164\n",
      "Epoch: 5, Batch: 258, D Loss: 0.10494792463659632, G Loss: 23.849365234375\n",
      "Epoch: 5, Batch: 259, D Loss: 0.10225990416844609, G Loss: 23.822933197021484\n",
      "Epoch: 5, Batch: 260, D Loss: 0.09860351684137833, G Loss: 23.680648803710938\n",
      "Epoch: 5, Batch: 261, D Loss: 0.09551110121463939, G Loss: 23.51346206665039\n",
      "Epoch: 5, Batch: 262, D Loss: 0.09976238015391117, G Loss: 23.50925064086914\n",
      "Epoch: 5, Batch: 263, D Loss: 0.10249859097438635, G Loss: 23.67951202392578\n",
      "Epoch: 5, Batch: 264, D Loss: 0.10363034161301334, G Loss: 23.868022918701172\n",
      "Epoch: 5, Batch: 265, D Loss: 0.10496263208117212, G Loss: 23.90522003173828\n",
      "Epoch: 5, Batch: 266, D Loss: 0.10588826241337851, G Loss: 23.76944351196289\n",
      "Epoch: 5, Batch: 267, D Loss: 0.100053675499459, G Loss: 23.547260284423828\n",
      "Epoch: 5, Batch: 268, D Loss: 0.09619206193338069, G Loss: 23.387317657470703\n",
      "Epoch: 5, Batch: 269, D Loss: 0.09408529106364322, G Loss: 23.344806671142578\n",
      "Epoch: 5, Batch: 270, D Loss: 0.0957834720953697, G Loss: 23.45958137512207\n",
      "Epoch: 5, Batch: 271, D Loss: 0.10101045670983878, G Loss: 23.69739532470703\n",
      "Epoch: 5, Batch: 272, D Loss: 0.1044463068476374, G Loss: 23.90166473388672\n",
      "Epoch: 5, Batch: 273, D Loss: 0.09907715769796677, G Loss: 23.819416046142578\n",
      "Epoch: 5, Batch: 274, D Loss: 0.09734801950673966, G Loss: 23.55156707763672\n",
      "Epoch: 5, Batch: 275, D Loss: 0.09430035952098581, G Loss: 23.315975189208984\n",
      "Epoch: 5, Batch: 276, D Loss: 0.10564828667578599, G Loss: 23.434646606445312\n",
      "Epoch: 5, Batch: 277, D Loss: 0.09614738824969003, G Loss: 23.637371063232422\n",
      "Epoch: 5, Batch: 278, D Loss: 0.10096260162673608, G Loss: 23.818552017211914\n",
      "Epoch: 5, Batch: 279, D Loss: 0.10035425426807423, G Loss: 23.845169067382812\n",
      "Epoch: 5, Batch: 280, D Loss: 0.0986257344724851, G Loss: 23.678945541381836\n",
      "Epoch: 5, Batch: 281, D Loss: 0.09791477027414208, G Loss: 23.49987030029297\n",
      "Epoch: 5, Batch: 282, D Loss: 0.0961029082861697, G Loss: 23.417659759521484\n",
      "Epoch: 5, Batch: 283, D Loss: 0.09946247938498287, G Loss: 23.51922607421875\n",
      "Epoch: 5, Batch: 284, D Loss: 0.09052765372384461, G Loss: 23.571985244750977\n",
      "Epoch: 5, Batch: 285, D Loss: 0.10389365258466327, G Loss: 23.7522029876709\n",
      "Epoch: 5, Batch: 286, D Loss: 0.10278182479014261, G Loss: 23.885711669921875\n",
      "Epoch: 5, Batch: 287, D Loss: 0.10212239625221732, G Loss: 23.853775024414062\n",
      "Epoch: 5, Batch: 288, D Loss: 0.09749934824758265, G Loss: 23.64687728881836\n",
      "Epoch: 5, Batch: 289, D Loss: 0.09613266590232275, G Loss: 23.453197479248047\n",
      "Epoch: 5, Batch: 290, D Loss: 0.09740434590259917, G Loss: 23.45499038696289\n",
      "Epoch: 5, Batch: 291, D Loss: 0.09600974622471178, G Loss: 23.55854034423828\n",
      "Epoch: 5, Batch: 292, D Loss: 0.10310012104707862, G Loss: 23.803508758544922\n",
      "Epoch: 5, Batch: 293, D Loss: 0.10120202603076697, G Loss: 23.95545196533203\n",
      "Epoch: 5, Batch: 294, D Loss: 0.10551543535770555, G Loss: 23.96030616760254\n",
      "Epoch: 5, Batch: 295, D Loss: 0.10200420024159618, G Loss: 23.789234161376953\n",
      "Epoch: 5, Batch: 296, D Loss: 0.10095784070634736, G Loss: 23.635637283325195\n",
      "Epoch: 5, Batch: 297, D Loss: 0.10210186245765943, G Loss: 23.641681671142578\n",
      "Epoch: 5, Batch: 298, D Loss: 0.09779110553484825, G Loss: 23.710861206054688\n",
      "Epoch: 5, Batch: 299, D Loss: 0.10293392839369776, G Loss: 23.867431640625\n",
      "Epoch: 5, Batch: 300, D Loss: 0.09673723580569221, G Loss: 23.902122497558594\n",
      "Epoch: 5, Batch: 301, D Loss: 0.1014487818096045, G Loss: 23.862483978271484\n",
      "Epoch: 5, Batch: 302, D Loss: 0.10695428403355128, G Loss: 23.900115966796875\n",
      "Epoch: 5, Batch: 303, D Loss: 0.09971901776517975, G Loss: 23.87683868408203\n",
      "Epoch: 5, Batch: 304, D Loss: 0.09803124519444423, G Loss: 23.783775329589844\n",
      "Epoch: 5, Batch: 305, D Loss: 0.10357700290619137, G Loss: 23.79989242553711\n",
      "Epoch: 5, Batch: 306, D Loss: 0.09756285699518762, G Loss: 23.807092666625977\n",
      "Epoch: 5, Batch: 307, D Loss: 0.09604128452487294, G Loss: 23.771839141845703\n",
      "Epoch: 5, Batch: 308, D Loss: 0.10798285903740225, G Loss: 23.919639587402344\n",
      "Epoch: 5, Batch: 309, D Loss: 0.09922602774726888, G Loss: 23.94896697998047\n",
      "Epoch: 5, Batch: 310, D Loss: 0.10037167372387833, G Loss: 23.871990203857422\n",
      "Epoch: 5, Batch: 311, D Loss: 0.09566495569899529, G Loss: 23.707378387451172\n",
      "Epoch: 5, Batch: 312, D Loss: 0.10293369742769773, G Loss: 23.712772369384766\n",
      "Epoch: 5, Batch: 313, D Loss: 0.10226380827402456, G Loss: 23.834331512451172\n",
      "Epoch: 5, Batch: 314, D Loss: 0.09971290828943796, G Loss: 23.9051456451416\n",
      "Epoch: 5, Batch: 315, D Loss: 0.0967987627007006, G Loss: 23.829235076904297\n",
      "Epoch: 5, Batch: 316, D Loss: 0.09427493813118912, G Loss: 23.646265029907227\n",
      "Epoch: 5, Batch: 317, D Loss: 0.10084860774622062, G Loss: 23.618892669677734\n",
      "Epoch: 5, Batch: 318, D Loss: 0.1005844623108363, G Loss: 23.74956512451172\n",
      "Epoch: 5, Batch: 319, D Loss: 0.09906720372331872, G Loss: 23.868331909179688\n",
      "Epoch: 5, Batch: 320, D Loss: 0.09829156102900075, G Loss: 23.871070861816406\n",
      "Epoch: 5, Batch: 321, D Loss: 0.09815178068749428, G Loss: 23.776077270507812\n",
      "Epoch: 5, Batch: 322, D Loss: 0.09753130378845395, G Loss: 23.66265106201172\n",
      "Epoch: 5, Batch: 323, D Loss: 0.10279114547002512, G Loss: 23.687259674072266\n",
      "Epoch: 5, Batch: 324, D Loss: 0.09720154109125946, G Loss: 23.740732192993164\n",
      "Epoch: 5, Batch: 325, D Loss: 0.09423969688507325, G Loss: 23.717784881591797\n",
      "Epoch: 5, Batch: 326, D Loss: 0.10260717573211618, G Loss: 23.77410125732422\n",
      "Epoch: 5, Batch: 327, D Loss: 0.09479481729308423, G Loss: 23.727947235107422\n",
      "Epoch: 5, Batch: 328, D Loss: 0.0976665839805174, G Loss: 23.693565368652344\n",
      "Epoch: 5, Batch: 329, D Loss: 0.09885285052245656, G Loss: 23.690326690673828\n",
      "Epoch: 5, Batch: 330, D Loss: 0.1003287211314689, G Loss: 23.713397979736328\n",
      "Epoch: 5, Batch: 331, D Loss: 0.09869880976823192, G Loss: 23.7010440826416\n",
      "Epoch: 5, Batch: 332, D Loss: 0.09777293356862299, G Loss: 23.668346405029297\n",
      "Epoch: 5, Batch: 333, D Loss: 0.1011806950234215, G Loss: 23.681976318359375\n",
      "Epoch: 5, Batch: 334, D Loss: 0.10604522379679206, G Loss: 23.80854034423828\n",
      "Epoch: 5, Batch: 335, D Loss: 0.09811603280232134, G Loss: 23.788230895996094\n",
      "Epoch: 5, Batch: 336, D Loss: 0.1029453054309806, G Loss: 23.739810943603516\n",
      "Epoch: 5, Batch: 337, D Loss: 0.10300885888461957, G Loss: 23.69515037536621\n",
      "Epoch: 5, Batch: 338, D Loss: 0.10496775063605664, G Loss: 23.65275764465332\n",
      "Epoch: 5, Batch: 339, D Loss: 0.10036487137665809, G Loss: 22.953601837158203\n",
      "Epoch: 5, Batch: 340, D Loss: 0.09441628312851158, G Loss: 22.827999114990234\n",
      "Epoch: 5, Batch: 341, D Loss: 0.09730483597904935, G Loss: 22.750225067138672\n",
      "Epoch: 5, Batch: 342, D Loss: 0.10208246863232633, G Loss: 22.833337783813477\n",
      "Epoch: 5, Batch: 343, D Loss: 0.09907626366341254, G Loss: 22.95461654663086\n",
      "Epoch: 5, Batch: 344, D Loss: 0.09509550785428883, G Loss: 22.95397186279297\n",
      "Epoch: 5, Batch: 345, D Loss: 0.1013407707757967, G Loss: 22.931636810302734\n",
      "Epoch: 5, Batch: 346, D Loss: 0.09418759500895163, G Loss: 22.804035186767578\n",
      "Epoch: 5, Batch: 347, D Loss: 0.09784413880576598, G Loss: 22.748348236083984\n",
      "Epoch: 5, Batch: 348, D Loss: 0.10311792797075779, G Loss: 22.871112823486328\n",
      "Epoch: 5, Batch: 349, D Loss: 0.10157686477333347, G Loss: 23.020843505859375\n",
      "Epoch: 5, Batch: 350, D Loss: 0.09032648062147369, G Loss: 22.88336181640625\n",
      "Epoch: 5, Batch: 351, D Loss: 0.1012293100952221, G Loss: 22.823020935058594\n",
      "Epoch: 5, Batch: 352, D Loss: 0.09697013354534854, G Loss: 22.80156707763672\n",
      "Epoch: 5, Batch: 353, D Loss: 0.0963843316456472, G Loss: 22.82912826538086\n",
      "Epoch: 5, Batch: 354, D Loss: 0.09950804716210934, G Loss: 22.913429260253906\n",
      "Epoch: 5, Batch: 355, D Loss: 0.0992210507932918, G Loss: 22.98078155517578\n",
      "Epoch: 5, Batch: 356, D Loss: 0.10337563609171754, G Loss: 23.04397201538086\n",
      "Epoch: 5, Batch: 357, D Loss: 0.10751173649997839, G Loss: 23.11102294921875\n",
      "Epoch: 5, Batch: 358, D Loss: 0.09811634575257133, G Loss: 22.989013671875\n",
      "Epoch: 5, Batch: 359, D Loss: 0.09944739943403032, G Loss: 22.836517333984375\n",
      "Epoch: 5, Batch: 360, D Loss: 0.09858267760608719, G Loss: 22.75937843322754\n",
      "Epoch: 5, Batch: 361, D Loss: 0.09716661280848374, G Loss: 22.792123794555664\n",
      "Epoch: 5, Batch: 362, D Loss: 0.1000182927234961, G Loss: 22.954097747802734\n",
      "Epoch: 5, Batch: 363, D Loss: 0.10765455667884244, G Loss: 23.216384887695312\n",
      "Epoch: 5, Batch: 364, D Loss: 0.09956945483089766, G Loss: 23.19610595703125\n",
      "Epoch: 5, Batch: 365, D Loss: 0.1017945409277416, G Loss: 23.046146392822266\n",
      "Epoch: 5, Batch: 366, D Loss: 0.09923429047397235, G Loss: 22.89944839477539\n",
      "Epoch: 5, Batch: 367, D Loss: 0.09870845085160337, G Loss: 22.87790298461914\n",
      "Epoch: 5, Batch: 368, D Loss: 0.09606711572081371, G Loss: 22.932464599609375\n",
      "Epoch: 5, Batch: 369, D Loss: 0.10454772417699826, G Loss: 23.13962173461914\n",
      "Epoch: 5, Batch: 370, D Loss: 0.10276257995940571, G Loss: 23.277477264404297\n",
      "Epoch: 5, Batch: 371, D Loss: 0.10215292129956315, G Loss: 23.215749740600586\n",
      "Epoch: 5, Batch: 372, D Loss: 0.10045599941935263, G Loss: 23.056509017944336\n",
      "Epoch: 5, Batch: 373, D Loss: 0.0970628113088843, G Loss: 22.873939514160156\n",
      "Epoch: 5, Batch: 374, D Loss: 0.10459460323740094, G Loss: 22.930145263671875\n",
      "Epoch: 5, Batch: 375, D Loss: 0.09717798238256506, G Loss: 23.028942108154297\n",
      "Epoch: 5, Batch: 376, D Loss: 0.10705003146848893, G Loss: 23.22637176513672\n",
      "Epoch: 5, Batch: 377, D Loss: 0.10806754235291605, G Loss: 23.34695053100586\n",
      "Epoch: 5, Batch: 378, D Loss: 0.10090240840104023, G Loss: 23.178550720214844\n",
      "Epoch: 5, Batch: 379, D Loss: 0.10013835882147848, G Loss: 22.900978088378906\n",
      "Epoch: 5, Batch: 380, D Loss: 0.10356783872732382, G Loss: 22.83987808227539\n",
      "Epoch: 5, Batch: 381, D Loss: 0.10493757581220226, G Loss: 23.02286148071289\n",
      "Epoch: 5, Batch: 382, D Loss: 0.09294752036429905, G Loss: 23.080467224121094\n",
      "Epoch: 5, Batch: 383, D Loss: 0.09886194770312101, G Loss: 23.076416015625\n",
      "Epoch: 5, Batch: 384, D Loss: 0.10209368174035507, G Loss: 23.086694717407227\n",
      "Epoch: 5, Batch: 385, D Loss: 0.10339823369809506, G Loss: 23.130325317382812\n",
      "Epoch: 5, Batch: 386, D Loss: 0.10434699062948923, G Loss: 23.167724609375\n",
      "Epoch: 5, Batch: 387, D Loss: 0.10405763988079512, G Loss: 23.16144561767578\n",
      "Epoch: 5, Batch: 388, D Loss: 0.10035368804716416, G Loss: 23.081634521484375\n",
      "Epoch: 5, Batch: 389, D Loss: 0.09655256574385256, G Loss: 22.97616195678711\n",
      "Epoch: 5, Batch: 390, D Loss: 0.10679395501759607, G Loss: 23.10394287109375\n",
      "Epoch: 5, Batch: 391, D Loss: 0.10389687125165631, G Loss: 23.264291763305664\n",
      "Epoch: 5, Batch: 392, D Loss: 0.0991390496893001, G Loss: 23.232303619384766\n",
      "Epoch: 5, Batch: 393, D Loss: 0.09750045840463586, G Loss: 23.044227600097656\n",
      "Epoch: 5, Batch: 394, D Loss: 0.09540183847540551, G Loss: 22.8775634765625\n",
      "Epoch: 5, Batch: 395, D Loss: 0.09938829397905377, G Loss: 22.906803131103516\n",
      "Epoch: 5, Batch: 396, D Loss: 0.09661097084759165, G Loss: 23.042339324951172\n",
      "Epoch: 5, Batch: 397, D Loss: 0.1035840213736595, G Loss: 23.263853073120117\n",
      "Epoch: 5, Batch: 398, D Loss: 0.09931838516323085, G Loss: 23.282485961914062\n",
      "Epoch: 5, Batch: 399, D Loss: 0.101460441988377, G Loss: 23.154159545898438\n",
      "Epoch: 5, Batch: 400, D Loss: 0.09115751092814761, G Loss: 22.852272033691406\n",
      "Epoch: 5, Batch: 401, D Loss: 0.10251853621145177, G Loss: 22.804363250732422\n",
      "Epoch: 5, Batch: 402, D Loss: 0.10177426045827959, G Loss: 22.99142837524414\n",
      "Epoch: 5, Batch: 403, D Loss: 0.09177818899325024, G Loss: 23.080219268798828\n",
      "Epoch: 5, Batch: 404, D Loss: 0.10472823683918475, G Loss: 23.18938446044922\n",
      "Epoch: 5, Batch: 405, D Loss: 0.09528481219692117, G Loss: 23.09839630126953\n",
      "Epoch: 5, Batch: 406, D Loss: 0.09691144531104626, G Loss: 22.924179077148438\n",
      "Epoch: 5, Batch: 407, D Loss: 0.09564612066674287, G Loss: 22.806602478027344\n",
      "Epoch: 5, Batch: 408, D Loss: 0.10331736510779502, G Loss: 22.958438873291016\n",
      "Epoch: 5, Batch: 409, D Loss: 0.10475303237264641, G Loss: 23.24602508544922\n",
      "Epoch: 5, Batch: 410, D Loss: 0.09792683277496095, G Loss: 23.27928924560547\n",
      "Epoch: 5, Batch: 411, D Loss: 0.10232470933797737, G Loss: 23.14020538330078\n",
      "Epoch: 5, Batch: 412, D Loss: 0.10354981576241762, G Loss: 22.99803924560547\n",
      "Epoch: 5, Batch: 413, D Loss: 0.09897915279318255, G Loss: 22.900293350219727\n",
      "Epoch: 5, Batch: 414, D Loss: 0.09890098875462738, G Loss: 22.90255355834961\n",
      "Epoch: 5, Batch: 415, D Loss: 0.09899508213406571, G Loss: 23.001708984375\n",
      "Epoch: 5, Batch: 416, D Loss: 0.09752655034293828, G Loss: 23.04656982421875\n",
      "Epoch: 5, Batch: 417, D Loss: 0.09796190266855379, G Loss: 23.001663208007812\n",
      "Epoch: 5, Batch: 418, D Loss: 0.09931123261948896, G Loss: 22.949848175048828\n",
      "Epoch: 5, Batch: 419, D Loss: 0.10507626091741955, G Loss: 22.99544906616211\n",
      "Epoch: 5, Batch: 420, D Loss: 0.09982489054607255, G Loss: 22.988725662231445\n",
      "Epoch: 5, Batch: 421, D Loss: 0.0937126726475016, G Loss: 22.834505081176758\n",
      "Epoch: 5, Batch: 422, D Loss: 0.0937570930171106, G Loss: 22.720348358154297\n",
      "Epoch: 5, Batch: 423, D Loss: 0.10289441800625922, G Loss: 22.81744384765625\n",
      "Epoch: 5, Batch: 424, D Loss: 0.09479933983029273, G Loss: 22.898193359375\n",
      "Epoch: 5, Batch: 425, D Loss: 0.1031354219246749, G Loss: 23.047447204589844\n",
      "Epoch: 5, Batch: 426, D Loss: 0.09854642306746847, G Loss: 23.02588653564453\n",
      "Epoch: 5, Batch: 427, D Loss: 0.09854426985386092, G Loss: 22.89191246032715\n",
      "Epoch: 5, Batch: 428, D Loss: 0.10208213335243965, G Loss: 22.82262420654297\n",
      "Epoch: 5, Batch: 429, D Loss: 0.10725398367442847, G Loss: 22.940326690673828\n",
      "Epoch: 5, Batch: 430, D Loss: 0.09509776538165872, G Loss: 22.916244506835938\n",
      "Epoch: 5, Batch: 431, D Loss: 0.0976258814919646, G Loss: 22.82689666748047\n",
      "Epoch: 5, Batch: 432, D Loss: 0.09730578965366884, G Loss: 22.742155075073242\n",
      "Epoch: 5, Batch: 433, D Loss: 0.10474197572834498, G Loss: 22.834407806396484\n",
      "Epoch: 5, Batch: 434, D Loss: 0.10064210003395602, G Loss: 22.936885833740234\n",
      "Epoch: 5, Batch: 435, D Loss: 0.09401842212446918, G Loss: 22.847881317138672\n",
      "Epoch: 5, Batch: 436, D Loss: 0.09974649554793419, G Loss: 22.758209228515625\n",
      "Epoch: 5, Batch: 437, D Loss: 0.10178936279314581, G Loss: 22.7813777923584\n",
      "Epoch: 5, Batch: 438, D Loss: 0.10120235389674859, G Loss: 22.848278045654297\n",
      "Epoch: 5, Batch: 439, D Loss: 0.10031241184353772, G Loss: 22.890228271484375\n",
      "Epoch: 5, Batch: 440, D Loss: 0.10338240122465153, G Loss: 22.922264099121094\n",
      "Epoch: 5, Batch: 441, D Loss: 0.10082905000171181, G Loss: 22.875638961791992\n",
      "Epoch: 5, Batch: 442, D Loss: 0.1005560681828049, G Loss: 22.801395416259766\n",
      "Epoch: 5, Batch: 443, D Loss: 0.09301876283456045, G Loss: 22.66497039794922\n",
      "Epoch: 5, Batch: 444, D Loss: 0.0961052180068094, G Loss: 22.627573013305664\n",
      "Epoch: 5, Batch: 445, D Loss: 0.09926190979333703, G Loss: 22.743423461914062\n",
      "Epoch: 5, Batch: 446, D Loss: 0.09662255651060127, G Loss: 22.852733612060547\n",
      "Epoch: 5, Batch: 447, D Loss: 0.10068014269745802, G Loss: 22.9544677734375\n",
      "Epoch: 5, Batch: 448, D Loss: 0.09778369223624361, G Loss: 22.904438018798828\n",
      "Epoch: 5, Batch: 449, D Loss: 0.09392598277607461, G Loss: 22.715635299682617\n",
      "Epoch: 5, Batch: 450, D Loss: 0.10336726910660343, G Loss: 22.738201141357422\n",
      "Epoch: 5, Batch: 451, D Loss: 0.09817696369766209, G Loss: 22.745695114135742\n",
      "Epoch: 5, Batch: 452, D Loss: 0.10041260731093433, G Loss: 22.240066528320312\n",
      "Epoch: 5, Batch: 453, D Loss: 0.09643756609283849, G Loss: 22.229633331298828\n",
      "Epoch: 5, Batch: 454, D Loss: 0.09665689633254254, G Loss: 21.8062801361084\n",
      "Epoch: 5, Batch: 455, D Loss: 0.1008503662324769, G Loss: 21.740480422973633\n",
      "Epoch: 5, Batch: 456, D Loss: 0.10004802065743974, G Loss: 21.798343658447266\n",
      "Epoch: 5, Batch: 457, D Loss: 0.10070198790596321, G Loss: 21.890419006347656\n",
      "Epoch: 5, Batch: 458, D Loss: 0.0986723230858604, G Loss: 21.8742733001709\n",
      "Epoch: 5, Batch: 459, D Loss: 0.0973125548840485, G Loss: 21.771011352539062\n",
      "Epoch: 5, Batch: 460, D Loss: 0.1009071471080892, G Loss: 21.749347686767578\n",
      "Epoch: 5, Batch: 461, D Loss: 0.09396860022034169, G Loss: 21.686954498291016\n",
      "Epoch: 5, Batch: 462, D Loss: 0.09304390904330118, G Loss: 20.59308624267578\n",
      "Epoch: 5, Batch: 463, D Loss: 0.10258513749914533, G Loss: 20.5961856842041\n",
      "Epoch: 5, Batch: 464, D Loss: 0.09753088706880336, G Loss: 20.69875717163086\n",
      "Epoch: 5, Batch: 465, D Loss: 0.09269391054592169, G Loss: 20.587684631347656\n",
      "Epoch: 5, Batch: 466, D Loss: 0.09767963052145462, G Loss: 20.50025177001953\n",
      "Epoch: 5, Batch: 467, D Loss: 0.09603262756317271, G Loss: 20.46603012084961\n",
      "Epoch: 6, Batch: 0, D Loss: 0.0973732030724821, G Loss: 20.517587661743164\n",
      "Epoch: 6, Batch: 1, D Loss: 0.098797694428441, G Loss: 20.626863479614258\n",
      "Epoch: 6, Batch: 2, D Loss: 0.10099218838032009, G Loss: 20.725650787353516\n",
      "Epoch: 6, Batch: 3, D Loss: 0.09506265126749147, G Loss: 20.619869232177734\n",
      "Epoch: 6, Batch: 4, D Loss: 0.10396140125528686, G Loss: 20.57541275024414\n",
      "Epoch: 6, Batch: 5, D Loss: 0.10071642755585752, G Loss: 20.550613403320312\n",
      "Epoch: 6, Batch: 6, D Loss: 0.10026095122456569, G Loss: 20.533432006835938\n",
      "Epoch: 6, Batch: 7, D Loss: 0.09468058560896364, G Loss: 20.419597625732422\n",
      "Epoch: 6, Batch: 8, D Loss: 0.09749526601098207, G Loss: 20.3411865234375\n",
      "Epoch: 6, Batch: 9, D Loss: 0.09616621657881413, G Loss: 20.317604064941406\n",
      "Epoch: 6, Batch: 10, D Loss: 0.09812669528993456, G Loss: 20.36959457397461\n",
      "Epoch: 6, Batch: 11, D Loss: 0.09618051420838492, G Loss: 20.382774353027344\n",
      "Epoch: 6, Batch: 12, D Loss: 0.10280634530819033, G Loss: 20.445850372314453\n",
      "Epoch: 6, Batch: 13, D Loss: 0.10237152939714833, G Loss: 20.467296600341797\n",
      "Epoch: 6, Batch: 14, D Loss: 0.09812551805288194, G Loss: 20.356605529785156\n",
      "Epoch: 6, Batch: 15, D Loss: 0.09838249611255562, G Loss: 20.235525131225586\n",
      "Epoch: 6, Batch: 16, D Loss: 0.10115724883533567, G Loss: 20.233562469482422\n",
      "Epoch: 6, Batch: 17, D Loss: 0.0912522980099521, G Loss: 20.162769317626953\n",
      "Epoch: 6, Batch: 18, D Loss: 0.0962985464622968, G Loss: 20.190025329589844\n",
      "Epoch: 6, Batch: 19, D Loss: 0.09931934704868667, G Loss: 20.311080932617188\n",
      "Epoch: 6, Batch: 20, D Loss: 0.09836629105966332, G Loss: 20.378368377685547\n",
      "Epoch: 6, Batch: 21, D Loss: 0.09535899087289224, G Loss: 20.288616180419922\n",
      "Epoch: 6, Batch: 22, D Loss: 0.10115281572993168, G Loss: 20.226818084716797\n",
      "Epoch: 6, Batch: 23, D Loss: 0.1007581069826946, G Loss: 19.65264892578125\n",
      "Epoch: 6, Batch: 24, D Loss: 0.10005091274541966, G Loss: 19.68231964111328\n",
      "Epoch: 6, Batch: 25, D Loss: 0.09567162539488927, G Loss: 19.63759994506836\n",
      "Epoch: 6, Batch: 26, D Loss: 0.10227771247851691, G Loss: 19.684417724609375\n",
      "Epoch: 6, Batch: 27, D Loss: 0.09646155828946801, G Loss: 19.65160369873047\n",
      "Epoch: 6, Batch: 28, D Loss: 0.10475843541661123, G Loss: 19.705585479736328\n",
      "Epoch: 6, Batch: 29, D Loss: 0.10537001623340247, G Loss: 19.783985137939453\n",
      "Epoch: 6, Batch: 30, D Loss: 0.10299200693722232, G Loss: 19.766357421875\n",
      "Epoch: 6, Batch: 31, D Loss: 0.09582142678153627, G Loss: 19.545055389404297\n",
      "Epoch: 6, Batch: 32, D Loss: 0.10565694586894125, G Loss: 19.510997772216797\n",
      "Epoch: 6, Batch: 33, D Loss: 0.09891360420762496, G Loss: 19.51539421081543\n",
      "Epoch: 6, Batch: 34, D Loss: 0.09597998281156683, G Loss: 19.50094985961914\n",
      "Epoch: 6, Batch: 35, D Loss: 0.10001867433471168, G Loss: 19.50981903076172\n",
      "Epoch: 6, Batch: 36, D Loss: 0.10087588596249675, G Loss: 19.526363372802734\n",
      "Epoch: 6, Batch: 37, D Loss: 0.09674132788553802, G Loss: 19.43978500366211\n",
      "Epoch: 6, Batch: 38, D Loss: 0.09538202180057587, G Loss: 19.31903839111328\n",
      "Epoch: 6, Batch: 39, D Loss: 0.10265720086763563, G Loss: 19.390079498291016\n",
      "Epoch: 6, Batch: 40, D Loss: 0.10203124758651794, G Loss: 19.533161163330078\n",
      "Epoch: 6, Batch: 41, D Loss: 0.10367752767923322, G Loss: 19.629127502441406\n",
      "Epoch: 6, Batch: 42, D Loss: 0.09622861608302813, G Loss: 19.459247589111328\n",
      "Epoch: 6, Batch: 43, D Loss: 0.10155755472479511, G Loss: 19.313932418823242\n",
      "Epoch: 6, Batch: 44, D Loss: 0.0965217671312133, G Loss: 19.23128890991211\n",
      "Epoch: 6, Batch: 45, D Loss: 0.10128046779350486, G Loss: 19.365638732910156\n",
      "Epoch: 6, Batch: 46, D Loss: 0.1037588285666714, G Loss: 19.603675842285156\n",
      "Epoch: 6, Batch: 47, D Loss: 0.10409735285802868, G Loss: 19.737220764160156\n",
      "Epoch: 6, Batch: 48, D Loss: 0.10037225625693103, G Loss: 19.64288330078125\n",
      "Epoch: 6, Batch: 49, D Loss: 0.10404540755460523, G Loss: 19.521690368652344\n",
      "Epoch: 6, Batch: 50, D Loss: 0.09758147773581127, G Loss: 19.410572052001953\n",
      "Epoch: 6, Batch: 51, D Loss: 0.09535423853351821, G Loss: 19.397289276123047\n",
      "Epoch: 6, Batch: 52, D Loss: 0.10642919108134896, G Loss: 19.666542053222656\n",
      "Epoch: 6, Batch: 53, D Loss: 0.1068319094408392, G Loss: 19.98440933227539\n",
      "Epoch: 6, Batch: 54, D Loss: 0.10603095692153652, G Loss: 20.050748825073242\n",
      "Epoch: 6, Batch: 55, D Loss: 0.10085222984003295, G Loss: 19.762325286865234\n",
      "Epoch: 6, Batch: 56, D Loss: 0.10329182593094766, G Loss: 19.538562774658203\n",
      "Epoch: 6, Batch: 57, D Loss: 0.09895089436955828, G Loss: 19.483718872070312\n",
      "Epoch: 6, Batch: 58, D Loss: 0.10134662844868747, G Loss: 19.663551330566406\n",
      "Epoch: 6, Batch: 59, D Loss: 0.0962746976261305, G Loss: 19.81014633178711\n",
      "Epoch: 6, Batch: 60, D Loss: 0.10314079492129036, G Loss: 19.912033081054688\n",
      "Epoch: 6, Batch: 61, D Loss: 0.09910287080157565, G Loss: 19.835186004638672\n",
      "Epoch: 6, Batch: 62, D Loss: 0.10311094054647518, G Loss: 19.73238754272461\n",
      "Epoch: 6, Batch: 63, D Loss: 0.09996120774743433, G Loss: 19.617908477783203\n",
      "Epoch: 6, Batch: 64, D Loss: 0.1001867145566373, G Loss: 19.609607696533203\n",
      "Epoch: 6, Batch: 65, D Loss: 0.09579524550355645, G Loss: 19.60672378540039\n",
      "Epoch: 6, Batch: 66, D Loss: 0.10159453896120019, G Loss: 19.68609619140625\n",
      "Epoch: 6, Batch: 67, D Loss: 0.09644004844434761, G Loss: 19.675270080566406\n",
      "Epoch: 6, Batch: 68, D Loss: 0.09995852556648066, G Loss: 19.632328033447266\n",
      "Epoch: 6, Batch: 69, D Loss: 0.10014894010430542, G Loss: 19.60757064819336\n",
      "Epoch: 6, Batch: 70, D Loss: 0.09569474466873262, G Loss: 19.551044464111328\n",
      "Epoch: 6, Batch: 71, D Loss: 0.09601061211227169, G Loss: 19.508609771728516\n",
      "Epoch: 6, Batch: 72, D Loss: 0.09480166601911877, G Loss: 19.528888702392578\n",
      "Epoch: 6, Batch: 73, D Loss: 0.09980017847520539, G Loss: 19.64031982421875\n",
      "Epoch: 6, Batch: 74, D Loss: 0.09608428323245144, G Loss: 19.701004028320312\n",
      "Epoch: 6, Batch: 75, D Loss: 0.09525829695289434, G Loss: 19.66427230834961\n",
      "Epoch: 6, Batch: 76, D Loss: 0.0966828033330267, G Loss: 19.601242065429688\n",
      "Epoch: 6, Batch: 77, D Loss: 0.10523244137366938, G Loss: 19.72524642944336\n",
      "Epoch: 6, Batch: 78, D Loss: 0.09949778151023092, G Loss: 19.79596710205078\n",
      "Epoch: 6, Batch: 79, D Loss: 0.09472911938025108, G Loss: 19.696735382080078\n",
      "Epoch: 6, Batch: 80, D Loss: 0.09653899223217977, G Loss: 19.56448745727539\n",
      "Epoch: 6, Batch: 81, D Loss: 0.09920944432505441, G Loss: 19.567710876464844\n",
      "Epoch: 6, Batch: 82, D Loss: 0.09889190793247127, G Loss: 19.6856689453125\n",
      "Epoch: 6, Batch: 83, D Loss: 0.10085993390959391, G Loss: 19.829669952392578\n",
      "Epoch: 6, Batch: 84, D Loss: 0.10399722424588953, G Loss: 19.91757583618164\n",
      "Epoch: 6, Batch: 85, D Loss: 0.09998328355941832, G Loss: 19.829517364501953\n",
      "Epoch: 6, Batch: 86, D Loss: 0.0914285346200876, G Loss: 19.538246154785156\n",
      "Epoch: 6, Batch: 87, D Loss: 0.10016448963450642, G Loss: 19.490970611572266\n",
      "Epoch: 6, Batch: 88, D Loss: 0.09975326961099484, G Loss: 19.68327522277832\n",
      "Epoch: 6, Batch: 89, D Loss: 0.10157097997925923, G Loss: 19.966304779052734\n",
      "Epoch: 6, Batch: 90, D Loss: 0.09968382220950578, G Loss: 20.07187271118164\n",
      "Epoch: 6, Batch: 91, D Loss: 0.10379290678231023, G Loss: 20.040939331054688\n",
      "Epoch: 6, Batch: 92, D Loss: 0.09764506034201004, G Loss: 19.813077926635742\n",
      "Epoch: 6, Batch: 93, D Loss: 0.10001853240085601, G Loss: 19.702444076538086\n",
      "Epoch: 6, Batch: 94, D Loss: 0.0984098626841281, G Loss: 19.743757247924805\n",
      "Epoch: 6, Batch: 95, D Loss: 0.09812226271322633, G Loss: 19.86611557006836\n",
      "Epoch: 6, Batch: 96, D Loss: 0.09962038805876072, G Loss: 19.997291564941406\n",
      "Epoch: 6, Batch: 97, D Loss: 0.09826424198168349, G Loss: 19.220108032226562\n",
      "Epoch: 6, Batch: 98, D Loss: 0.09206903269771516, G Loss: 18.86886215209961\n",
      "Epoch: 6, Batch: 99, D Loss: 0.09767532686514824, G Loss: 18.76165771484375\n",
      "Epoch: 6, Batch: 100, D Loss: 0.10004585573568692, G Loss: 18.861961364746094\n",
      "Epoch: 6, Batch: 101, D Loss: 0.09504413907251297, G Loss: 18.977359771728516\n",
      "Epoch: 6, Batch: 102, D Loss: 0.09814100986537633, G Loss: 19.065967559814453\n",
      "Epoch: 6, Batch: 103, D Loss: 0.09993113837104506, G Loss: 19.084312438964844\n",
      "Epoch: 6, Batch: 104, D Loss: 0.09487834854057087, G Loss: 18.918193817138672\n",
      "Epoch: 6, Batch: 105, D Loss: 0.10035355703306603, G Loss: 18.854921340942383\n",
      "Epoch: 6, Batch: 106, D Loss: 0.10594457686719361, G Loss: 19.009265899658203\n",
      "Epoch: 6, Batch: 107, D Loss: 0.09504713393840758, G Loss: 19.02157211303711\n",
      "Epoch: 6, Batch: 108, D Loss: 0.0976061028308084, G Loss: 19.058536529541016\n",
      "Epoch: 6, Batch: 109, D Loss: 0.09756222627805977, G Loss: 19.085289001464844\n",
      "Epoch: 6, Batch: 110, D Loss: 0.09992745773385181, G Loss: 19.107738494873047\n",
      "Epoch: 6, Batch: 111, D Loss: 0.10428124167146402, G Loss: 19.150224685668945\n",
      "Epoch: 6, Batch: 112, D Loss: 0.10032817230047808, G Loss: 19.05301284790039\n",
      "Epoch: 6, Batch: 113, D Loss: 0.09450859116899801, G Loss: 18.89738655090332\n",
      "Epoch: 6, Batch: 114, D Loss: 0.09509698580920278, G Loss: 19.02826690673828\n",
      "Epoch: 6, Batch: 115, D Loss: 0.0981346246359529, G Loss: 19.13866424560547\n",
      "Epoch: 6, Batch: 116, D Loss: 0.10107039143216978, G Loss: 19.265878677368164\n",
      "Epoch: 6, Batch: 117, D Loss: 0.10140747801106897, G Loss: 19.18460464477539\n",
      "Epoch: 6, Batch: 118, D Loss: 0.1026297386589583, G Loss: 19.012306213378906\n",
      "Epoch: 6, Batch: 119, D Loss: 0.10043216190328597, G Loss: 18.536550521850586\n",
      "Epoch: 6, Batch: 120, D Loss: 0.10332087090969111, G Loss: 18.689266204833984\n",
      "Epoch: 6, Batch: 121, D Loss: 0.0987363196845128, G Loss: 18.741310119628906\n",
      "Epoch: 6, Batch: 122, D Loss: 0.10398453833701371, G Loss: 18.758108139038086\n",
      "Epoch: 6, Batch: 123, D Loss: 0.094713796105935, G Loss: 18.58087921142578\n",
      "Epoch: 6, Batch: 124, D Loss: 0.09393510688385565, G Loss: 18.410057067871094\n",
      "Epoch: 6, Batch: 125, D Loss: 0.10199867640454352, G Loss: 18.623245239257812\n",
      "Epoch: 6, Batch: 126, D Loss: 0.1006092613120011, G Loss: 18.910125732421875\n",
      "Epoch: 6, Batch: 127, D Loss: 0.09491822432556019, G Loss: 18.894325256347656\n",
      "Epoch: 6, Batch: 128, D Loss: 0.10240093944284867, G Loss: 18.809017181396484\n",
      "Epoch: 6, Batch: 129, D Loss: 0.09230501582380812, G Loss: 18.596240997314453\n",
      "Epoch: 6, Batch: 130, D Loss: 0.09945182172872524, G Loss: 18.613677978515625\n",
      "Epoch: 6, Batch: 131, D Loss: 0.09826313333429137, G Loss: 18.791183471679688\n",
      "Epoch: 6, Batch: 132, D Loss: 0.10288198600915743, G Loss: 19.003087997436523\n",
      "Epoch: 6, Batch: 133, D Loss: 0.09665079705143831, G Loss: 18.929492950439453\n",
      "Epoch: 6, Batch: 134, D Loss: 0.10318199866090838, G Loss: 18.804874420166016\n",
      "Epoch: 6, Batch: 135, D Loss: 0.09117685640977369, G Loss: 18.575572967529297\n",
      "Epoch: 6, Batch: 136, D Loss: 0.0950111641871878, G Loss: 18.520057678222656\n",
      "Epoch: 6, Batch: 137, D Loss: 0.09952020297753572, G Loss: 18.761266708374023\n",
      "Epoch: 6, Batch: 138, D Loss: 0.10101841699291958, G Loss: 19.027408599853516\n",
      "Epoch: 6, Batch: 139, D Loss: 0.1002766963959496, G Loss: 19.05034637451172\n",
      "Epoch: 6, Batch: 140, D Loss: 0.09683883666084903, G Loss: 18.345829010009766\n",
      "Epoch: 6, Batch: 141, D Loss: 0.10275720756705375, G Loss: 18.019176483154297\n",
      "Epoch: 6, Batch: 142, D Loss: 0.09884548182210384, G Loss: 18.0372314453125\n",
      "Epoch: 6, Batch: 143, D Loss: 0.10079391965737994, G Loss: 18.223880767822266\n",
      "Epoch: 6, Batch: 144, D Loss: 0.10486729980247755, G Loss: 18.45886993408203\n",
      "Epoch: 6, Batch: 145, D Loss: 0.10072411338514131, G Loss: 18.437170028686523\n",
      "Epoch: 6, Batch: 146, D Loss: 0.10477199197035958, G Loss: 18.27004623413086\n",
      "Epoch: 6, Batch: 147, D Loss: 0.09912355885189106, G Loss: 18.084075927734375\n",
      "Epoch: 6, Batch: 148, D Loss: 0.10151580682844585, G Loss: 18.066181182861328\n",
      "Epoch: 6, Batch: 149, D Loss: 0.09864877102826108, G Loss: 18.145719528198242\n",
      "Epoch: 6, Batch: 150, D Loss: 0.09949642303287476, G Loss: 18.233707427978516\n",
      "Epoch: 6, Batch: 151, D Loss: 0.10116714836475449, G Loss: 18.254581451416016\n",
      "Epoch: 6, Batch: 152, D Loss: 0.09697320324484338, G Loss: 17.93512535095215\n",
      "Epoch: 6, Batch: 153, D Loss: 0.10755089783239136, G Loss: 17.906967163085938\n",
      "Epoch: 6, Batch: 154, D Loss: 0.10340445554009214, G Loss: 17.966529846191406\n",
      "Epoch: 6, Batch: 155, D Loss: 0.10135189495041796, G Loss: 17.945297241210938\n",
      "Epoch: 6, Batch: 156, D Loss: 0.1046832433065914, G Loss: 17.951412200927734\n",
      "Epoch: 6, Batch: 157, D Loss: 0.10554546157093192, G Loss: 17.99136734008789\n",
      "Epoch: 6, Batch: 158, D Loss: 0.10017072677596062, G Loss: 17.703697204589844\n",
      "Epoch: 6, Batch: 159, D Loss: 0.0977613586440107, G Loss: 17.613121032714844\n",
      "Epoch: 6, Batch: 160, D Loss: 0.0994090179008742, G Loss: 17.586872100830078\n",
      "Epoch: 6, Batch: 161, D Loss: 0.1001446506267385, G Loss: 17.67044448852539\n",
      "Epoch: 6, Batch: 162, D Loss: 0.09910150876213297, G Loss: 17.771759033203125\n",
      "Epoch: 6, Batch: 163, D Loss: 0.09849959885223836, G Loss: 17.7268009185791\n",
      "Epoch: 6, Batch: 164, D Loss: 0.10218283477687429, G Loss: 17.386199951171875\n",
      "Epoch: 6, Batch: 165, D Loss: 0.1007903956083398, G Loss: 17.371957778930664\n",
      "Epoch: 6, Batch: 166, D Loss: 0.09774556037149473, G Loss: 17.256610870361328\n",
      "Epoch: 6, Batch: 167, D Loss: 0.10624748534204898, G Loss: 17.3115234375\n",
      "Epoch: 6, Batch: 168, D Loss: 0.09551297211056564, G Loss: 17.241371154785156\n",
      "Epoch: 6, Batch: 169, D Loss: 0.0969858484798447, G Loss: 17.199569702148438\n",
      "Epoch: 6, Batch: 170, D Loss: 0.09808773015146954, G Loss: 17.19136619567871\n",
      "Epoch: 6, Batch: 171, D Loss: 0.0992411019621926, G Loss: 17.24573516845703\n",
      "Epoch: 6, Batch: 172, D Loss: 0.09730759390249233, G Loss: 17.247779846191406\n",
      "Epoch: 6, Batch: 173, D Loss: 0.0983959002276702, G Loss: 17.243907928466797\n",
      "Epoch: 6, Batch: 174, D Loss: 0.0989061830902056, G Loss: 17.241891860961914\n",
      "Epoch: 6, Batch: 175, D Loss: 0.09741693875423607, G Loss: 17.235929489135742\n",
      "Epoch: 6, Batch: 176, D Loss: 0.10079000973790997, G Loss: 17.308618545532227\n",
      "Epoch: 6, Batch: 177, D Loss: 0.1013842222052368, G Loss: 17.38575553894043\n",
      "Epoch: 6, Batch: 178, D Loss: 0.0899033850634865, G Loss: 17.200151443481445\n",
      "Epoch: 6, Batch: 179, D Loss: 0.09700107855965179, G Loss: 17.116043090820312\n",
      "Epoch: 6, Batch: 180, D Loss: 0.09792524280194925, G Loss: 17.10118865966797\n",
      "Epoch: 6, Batch: 181, D Loss: 0.10857606985079826, G Loss: 16.69742202758789\n",
      "Epoch: 6, Batch: 182, D Loss: 0.09297838764994637, G Loss: 16.226642608642578\n",
      "Epoch: 6, Batch: 183, D Loss: 0.10596662962600334, G Loss: 16.157442092895508\n",
      "Epoch: 6, Batch: 184, D Loss: 0.0975714329085271, G Loss: 15.99105453491211\n",
      "Epoch: 6, Batch: 185, D Loss: 0.09623941862476926, G Loss: 15.872472763061523\n",
      "Epoch: 6, Batch: 186, D Loss: 0.0935648129980251, G Loss: 15.864356994628906\n",
      "Epoch: 6, Batch: 187, D Loss: 0.09648320300241409, G Loss: 15.978755950927734\n",
      "Epoch: 6, Batch: 188, D Loss: 0.10384002065214304, G Loss: 15.196573257446289\n",
      "Epoch: 6, Batch: 189, D Loss: 0.09524451690229796, G Loss: 15.225003242492676\n",
      "Epoch: 6, Batch: 190, D Loss: 0.10167829183551191, G Loss: 15.121427536010742\n",
      "Epoch: 6, Batch: 191, D Loss: 0.0954128615418881, G Loss: 14.892271041870117\n",
      "Epoch: 6, Batch: 192, D Loss: 0.10376605852908938, G Loss: 14.913756370544434\n",
      "Epoch: 6, Batch: 193, D Loss: 0.09633393052104111, G Loss: 15.009029388427734\n",
      "Epoch: 6, Batch: 194, D Loss: 0.10112354808299528, G Loss: 15.15257453918457\n",
      "Epoch: 6, Batch: 195, D Loss: 0.1003370531705059, G Loss: 15.187433242797852\n",
      "Epoch: 6, Batch: 196, D Loss: 0.09327877378134986, G Loss: 14.970099449157715\n",
      "Epoch: 6, Batch: 197, D Loss: 0.10050483381041886, G Loss: 14.857904434204102\n",
      "Epoch: 6, Batch: 198, D Loss: 0.10182213369603232, G Loss: 14.959348678588867\n",
      "Epoch: 6, Batch: 199, D Loss: 0.10420481125193248, G Loss: 15.182441711425781\n",
      "Epoch: 6, Batch: 200, D Loss: 0.09981551552259305, G Loss: 15.227344512939453\n",
      "Epoch: 6, Batch: 201, D Loss: 0.09600831826595879, G Loss: 15.009828567504883\n",
      "Epoch: 6, Batch: 202, D Loss: 0.10318433763383439, G Loss: 14.916105270385742\n",
      "Epoch: 6, Batch: 203, D Loss: 0.10377981322204732, G Loss: 14.970847129821777\n",
      "Epoch: 6, Batch: 204, D Loss: 0.1004999507982518, G Loss: 14.978997230529785\n",
      "Epoch: 6, Batch: 205, D Loss: 0.09566234453269828, G Loss: 14.851327896118164\n",
      "Epoch: 6, Batch: 206, D Loss: 0.10114528266058187, G Loss: 14.751602172851562\n",
      "Epoch: 6, Batch: 207, D Loss: 0.09488958565751204, G Loss: 14.732894897460938\n",
      "Epoch: 6, Batch: 208, D Loss: 0.09931149986917376, G Loss: 14.801919937133789\n",
      "Epoch: 6, Batch: 209, D Loss: 0.098969185595152, G Loss: 14.864250183105469\n",
      "Epoch: 6, Batch: 210, D Loss: 0.09475149310966913, G Loss: 14.81620979309082\n",
      "Epoch: 6, Batch: 211, D Loss: 0.09125944780711848, G Loss: 14.663962364196777\n",
      "Epoch: 6, Batch: 212, D Loss: 0.09651639281250368, G Loss: 14.650169372558594\n",
      "Epoch: 6, Batch: 213, D Loss: 0.10091752620002126, G Loss: 14.86098861694336\n",
      "Epoch: 6, Batch: 214, D Loss: 0.10067783692220189, G Loss: 15.12348747253418\n",
      "Epoch: 6, Batch: 215, D Loss: 0.09947467228380447, G Loss: 15.192166328430176\n",
      "Epoch: 6, Batch: 216, D Loss: 0.10735726239937549, G Loss: 15.203786849975586\n",
      "Epoch: 6, Batch: 217, D Loss: 0.09958095970591785, G Loss: 15.049738883972168\n",
      "Epoch: 6, Batch: 218, D Loss: 0.10230988784056194, G Loss: 14.940498352050781\n",
      "Epoch: 6, Batch: 219, D Loss: 0.0973951326126894, G Loss: 14.898061752319336\n",
      "Epoch: 6, Batch: 220, D Loss: 0.10182385539107486, G Loss: 14.608283996582031\n",
      "Epoch: 6, Batch: 221, D Loss: 0.09371183372257974, G Loss: 14.674057006835938\n",
      "Epoch: 6, Batch: 222, D Loss: 0.10542036941596677, G Loss: 14.887439727783203\n",
      "Epoch: 6, Batch: 223, D Loss: 0.10338982605358638, G Loss: 14.814397811889648\n",
      "Epoch: 6, Batch: 224, D Loss: 0.09562588271660388, G Loss: 14.602778434753418\n",
      "Epoch: 6, Batch: 225, D Loss: 0.0985463554449666, G Loss: 14.436864852905273\n",
      "Epoch: 6, Batch: 226, D Loss: 0.10192730938967998, G Loss: 14.020116806030273\n",
      "Epoch: 6, Batch: 227, D Loss: 0.10406483338806538, G Loss: 14.290842056274414\n",
      "Epoch: 6, Batch: 228, D Loss: 0.10550119310750006, G Loss: 14.550342559814453\n",
      "Epoch: 6, Batch: 229, D Loss: 0.09839896683877214, G Loss: 14.40466594696045\n",
      "Epoch: 6, Batch: 230, D Loss: 0.10712230139154144, G Loss: 14.274812698364258\n",
      "Epoch: 6, Batch: 231, D Loss: 0.09666130496992764, G Loss: 14.090184211730957\n",
      "Epoch: 6, Batch: 232, D Loss: 0.0975365121006746, G Loss: 14.05354118347168\n",
      "Epoch: 6, Batch: 233, D Loss: 0.10008071631099824, G Loss: 14.225367546081543\n",
      "Epoch: 6, Batch: 234, D Loss: 0.09624461066698586, G Loss: 14.386068344116211\n",
      "Epoch: 6, Batch: 235, D Loss: 0.10192705734186802, G Loss: 14.537296295166016\n",
      "Epoch: 6, Batch: 236, D Loss: 0.09876121111864222, G Loss: 14.494848251342773\n",
      "Epoch: 6, Batch: 237, D Loss: 0.10025714627604998, G Loss: 14.368621826171875\n",
      "Epoch: 6, Batch: 238, D Loss: 0.09857736840550047, G Loss: 14.28260612487793\n",
      "Epoch: 6, Batch: 239, D Loss: 0.09797050591063794, G Loss: 14.277609825134277\n",
      "Epoch: 6, Batch: 240, D Loss: 0.10142272438392297, G Loss: 14.414098739624023\n",
      "Epoch: 6, Batch: 241, D Loss: 0.09654675562831017, G Loss: 14.452021598815918\n",
      "Epoch: 6, Batch: 242, D Loss: 0.09850643076194388, G Loss: 14.410322189331055\n",
      "Epoch: 6, Batch: 243, D Loss: 0.10152582970334834, G Loss: 14.40316104888916\n",
      "Epoch: 6, Batch: 244, D Loss: 0.09071063092022769, G Loss: 14.234050750732422\n",
      "Epoch: 6, Batch: 245, D Loss: 0.10005082068357751, G Loss: 14.250015258789062\n",
      "Epoch: 6, Batch: 246, D Loss: 0.1015998655392707, G Loss: 14.451282501220703\n",
      "Epoch: 6, Batch: 247, D Loss: 0.09210591908794186, G Loss: 14.471273422241211\n",
      "Epoch: 6, Batch: 248, D Loss: 0.09631496773977233, G Loss: 14.402790069580078\n",
      "Epoch: 6, Batch: 249, D Loss: 0.10035420063411493, G Loss: 14.430072784423828\n",
      "Epoch: 6, Batch: 250, D Loss: 0.10127042051848889, G Loss: 14.569578170776367\n",
      "Epoch: 6, Batch: 251, D Loss: 0.09755566127536497, G Loss: 14.654769897460938\n",
      "Epoch: 6, Batch: 252, D Loss: 0.09632237134584898, G Loss: 14.601609230041504\n",
      "Epoch: 6, Batch: 253, D Loss: 0.10023571720894608, G Loss: 14.562999725341797\n",
      "Epoch: 6, Batch: 254, D Loss: 0.09366763950418999, G Loss: 14.449586868286133\n",
      "Epoch: 6, Batch: 255, D Loss: 0.10071523349915878, G Loss: 14.493404388427734\n",
      "Epoch: 6, Batch: 256, D Loss: 0.10120000486328706, G Loss: 14.630218505859375\n",
      "Epoch: 6, Batch: 257, D Loss: 0.10008953979601642, G Loss: 14.702319145202637\n",
      "Epoch: 6, Batch: 258, D Loss: 0.10037307739111156, G Loss: 14.652605056762695\n",
      "Epoch: 6, Batch: 259, D Loss: 0.09785538702212193, G Loss: 14.487308502197266\n",
      "Epoch: 6, Batch: 260, D Loss: 0.10166174227703095, G Loss: 14.445470809936523\n",
      "Epoch: 6, Batch: 261, D Loss: 0.1039494090593962, G Loss: 14.569530487060547\n",
      "Epoch: 6, Batch: 262, D Loss: 0.09461929809643266, G Loss: 14.533021926879883\n",
      "Epoch: 6, Batch: 263, D Loss: 0.09436381619451595, G Loss: 14.378778457641602\n",
      "Epoch: 6, Batch: 264, D Loss: 0.10025702369239298, G Loss: 12.353693008422852\n",
      "Epoch: 6, Batch: 265, D Loss: 0.09967524938838324, G Loss: 12.449893951416016\n",
      "Epoch: 6, Batch: 266, D Loss: 0.09557980603312899, G Loss: 12.4945068359375\n",
      "Epoch: 6, Batch: 267, D Loss: 0.09780180501775249, G Loss: 12.501298904418945\n",
      "Epoch: 6, Batch: 268, D Loss: 0.096911413326211, G Loss: 12.535743713378906\n",
      "Epoch: 6, Batch: 269, D Loss: 0.09328077883242258, G Loss: 12.547426223754883\n",
      "Epoch: 6, Batch: 270, D Loss: 0.1060093070154835, G Loss: 12.795604705810547\n",
      "Epoch: 6, Batch: 271, D Loss: 0.10452122271033204, G Loss: 13.079072952270508\n",
      "Epoch: 6, Batch: 272, D Loss: 0.10027717790171664, G Loss: 13.101507186889648\n",
      "Epoch: 6, Batch: 273, D Loss: 0.09601451050889409, G Loss: 12.891796112060547\n",
      "Epoch: 6, Batch: 274, D Loss: 0.09989496927187247, G Loss: 12.811634063720703\n",
      "Epoch: 6, Batch: 275, D Loss: 0.10103043107744725, G Loss: 12.972787857055664\n",
      "Epoch: 6, Batch: 276, D Loss: 0.10259843150947745, G Loss: 13.293386459350586\n",
      "Epoch: 6, Batch: 277, D Loss: 0.0998521724462762, G Loss: 13.500821113586426\n",
      "Epoch: 6, Batch: 278, D Loss: 0.0979905746677332, G Loss: 13.410028457641602\n",
      "Epoch: 6, Batch: 279, D Loss: 0.10013315432820491, G Loss: 12.477734565734863\n",
      "Epoch: 6, Batch: 280, D Loss: 0.10210864543387288, G Loss: 12.509490966796875\n",
      "Epoch: 6, Batch: 281, D Loss: 0.09513955767874904, G Loss: 12.555061340332031\n",
      "Epoch: 6, Batch: 282, D Loss: 0.10439019193722743, G Loss: 12.842988014221191\n",
      "Epoch: 6, Batch: 283, D Loss: 0.10068211362499824, G Loss: 13.102365493774414\n",
      "Epoch: 6, Batch: 284, D Loss: 0.10189173379535532, G Loss: 13.192800521850586\n",
      "Epoch: 6, Batch: 285, D Loss: 0.10316351374530086, G Loss: 13.178741455078125\n",
      "Epoch: 6, Batch: 286, D Loss: 0.0956853815159775, G Loss: 13.046615600585938\n",
      "Epoch: 6, Batch: 287, D Loss: 0.10316053381677648, G Loss: 13.137727737426758\n",
      "Epoch: 6, Batch: 288, D Loss: 0.0967147170950966, G Loss: 13.272793769836426\n",
      "Epoch: 6, Batch: 289, D Loss: 0.09489397283869039, G Loss: 13.38039779663086\n",
      "Epoch: 6, Batch: 290, D Loss: 0.10297009969451665, G Loss: 13.59706974029541\n",
      "Epoch: 6, Batch: 291, D Loss: 0.10356780541451371, G Loss: 13.725010871887207\n",
      "Epoch: 6, Batch: 292, D Loss: 0.09902875478388751, G Loss: 13.652862548828125\n",
      "Epoch: 6, Batch: 293, D Loss: 0.09852429437148658, G Loss: 13.495795249938965\n",
      "Epoch: 6, Batch: 294, D Loss: 0.10002182951444638, G Loss: 13.494046211242676\n",
      "Epoch: 6, Batch: 295, D Loss: 0.09424543128557161, G Loss: 13.558891296386719\n",
      "Epoch: 6, Batch: 296, D Loss: 0.09469266638132012, G Loss: 13.657561302185059\n",
      "Epoch: 6, Batch: 297, D Loss: 0.09700980470194054, G Loss: 13.78748893737793\n",
      "Epoch: 6, Batch: 298, D Loss: 0.09489704291831913, G Loss: 13.506296157836914\n",
      "Epoch: 6, Batch: 299, D Loss: 0.09953917798702605, G Loss: 12.37980842590332\n",
      "Epoch: 6, Batch: 300, D Loss: 0.09625514729509632, G Loss: 12.417767524719238\n",
      "Epoch: 6, Batch: 301, D Loss: 0.09502783425250527, G Loss: 12.440214157104492\n",
      "Epoch: 6, Batch: 302, D Loss: 0.10532604542640911, G Loss: 12.573195457458496\n",
      "Epoch: 6, Batch: 303, D Loss: 0.09824284348451329, G Loss: 11.844626426696777\n",
      "Epoch: 6, Batch: 304, D Loss: 0.09990417471908586, G Loss: 11.903745651245117\n",
      "Epoch: 6, Batch: 305, D Loss: 0.0951249694278431, G Loss: 11.858654975891113\n",
      "Epoch: 6, Batch: 306, D Loss: 0.09687023087940361, G Loss: 11.923609733581543\n",
      "Epoch: 6, Batch: 307, D Loss: 0.09535201862308895, G Loss: 12.129999160766602\n",
      "Epoch: 6, Batch: 308, D Loss: 0.10733696224770028, G Loss: 12.624204635620117\n",
      "Epoch: 6, Batch: 309, D Loss: 0.10063684335898415, G Loss: 12.91883659362793\n",
      "Epoch: 6, Batch: 310, D Loss: 0.10064264160280345, G Loss: 12.595489501953125\n",
      "Epoch: 6, Batch: 311, D Loss: 0.10767873197323752, G Loss: 12.631187438964844\n",
      "Epoch: 6, Batch: 312, D Loss: 0.10260577748977084, G Loss: 12.569148063659668\n",
      "Epoch: 6, Batch: 313, D Loss: 0.09419277380948188, G Loss: 11.411914825439453\n",
      "Epoch: 6, Batch: 314, D Loss: 0.10372163258580258, G Loss: 9.812583923339844\n",
      "Epoch: 6, Batch: 315, D Loss: 0.09416785987923504, G Loss: 10.486174583435059\n",
      "Epoch: 6, Batch: 316, D Loss: 0.10112756692251423, G Loss: 11.275264739990234\n",
      "Epoch: 6, Batch: 317, D Loss: 0.10252649107269463, G Loss: 11.681167602539062\n",
      "Epoch: 6, Batch: 318, D Loss: 0.09967496271292475, G Loss: 11.849499702453613\n",
      "Epoch: 6, Batch: 319, D Loss: 0.0968548868841026, G Loss: 9.92662239074707\n",
      "Epoch: 6, Batch: 320, D Loss: 0.0976267173900851, G Loss: 10.225825309753418\n",
      "Epoch: 6, Batch: 321, D Loss: 0.10013512063596863, G Loss: 10.187115669250488\n",
      "Epoch: 6, Batch: 322, D Loss: 0.10220590673270635, G Loss: 9.717382431030273\n",
      "Epoch: 6, Batch: 323, D Loss: 0.09923712888758018, G Loss: 13.389817237854004\n",
      "Epoch: 6, Batch: 324, D Loss: 0.09745026357722963, G Loss: 13.434609413146973\n",
      "Epoch: 6, Batch: 325, D Loss: 0.09958566357886411, G Loss: 14.046605110168457\n",
      "Epoch: 6, Batch: 326, D Loss: 0.09822759786766255, G Loss: 10.661581039428711\n",
      "Epoch: 6, Batch: 327, D Loss: 0.1008462125191727, G Loss: 12.147797584533691\n",
      "Epoch: 6, Batch: 328, D Loss: 0.09427634235908045, G Loss: 10.197901725769043\n",
      "Epoch: 6, Batch: 329, D Loss: 0.10474884998984635, G Loss: 10.806465148925781\n",
      "Epoch: 6, Batch: 330, D Loss: 0.09842243398270512, G Loss: 12.690958976745605\n",
      "Epoch: 6, Batch: 331, D Loss: 0.0988468382533938, G Loss: 14.289534568786621\n",
      "Epoch: 6, Batch: 332, D Loss: 0.09587559959800274, G Loss: 12.505899429321289\n",
      "Epoch: 6, Batch: 333, D Loss: 0.10403100950634325, G Loss: 13.327028274536133\n",
      "Epoch: 6, Batch: 334, D Loss: 0.09835615179554225, G Loss: 13.083223342895508\n",
      "Epoch: 6, Batch: 335, D Loss: 0.10029383600692654, G Loss: 13.394923210144043\n",
      "Epoch: 6, Batch: 336, D Loss: 0.0945787552583397, G Loss: 12.632768630981445\n",
      "Epoch: 6, Batch: 337, D Loss: 0.09883424176314293, G Loss: 11.091533660888672\n",
      "Epoch: 6, Batch: 338, D Loss: 0.09946864081939566, G Loss: 10.013466835021973\n",
      "Epoch: 6, Batch: 339, D Loss: 0.0999214495823253, G Loss: 9.75782585144043\n",
      "Epoch: 6, Batch: 340, D Loss: 0.09895488737674896, G Loss: 10.84366512298584\n",
      "Epoch: 6, Batch: 341, D Loss: 0.09759258617850719, G Loss: 10.586377143859863\n",
      "Epoch: 6, Batch: 342, D Loss: 0.10126956713429536, G Loss: 10.75255012512207\n",
      "Epoch: 6, Batch: 343, D Loss: 0.10066114115852542, G Loss: 12.13975715637207\n",
      "Epoch: 6, Batch: 344, D Loss: 0.09724331153881849, G Loss: 13.429903030395508\n",
      "Epoch: 6, Batch: 345, D Loss: 0.10077604146408703, G Loss: 11.865334510803223\n",
      "Epoch: 6, Batch: 346, D Loss: 0.09877771223568743, G Loss: 12.434104919433594\n",
      "Epoch: 6, Batch: 347, D Loss: 0.10164301764962147, G Loss: 12.172774314880371\n",
      "Epoch: 6, Batch: 348, D Loss: 0.10387846387470745, G Loss: 12.440561294555664\n",
      "Epoch: 6, Batch: 349, D Loss: 0.09826885321672307, G Loss: 11.532285690307617\n",
      "Epoch: 6, Batch: 350, D Loss: 0.1016242179521214, G Loss: 11.39928150177002\n",
      "Epoch: 6, Batch: 351, D Loss: 0.09828025129900197, G Loss: 11.149559020996094\n",
      "Epoch: 6, Batch: 352, D Loss: 0.09622596531698946, G Loss: 9.740347862243652\n",
      "Epoch: 6, Batch: 353, D Loss: 0.10218619097577175, G Loss: 10.19743537902832\n",
      "Epoch: 6, Batch: 354, D Loss: 0.10438687276564451, G Loss: 12.072505950927734\n",
      "Epoch: 6, Batch: 355, D Loss: 0.10249704982061303, G Loss: 13.311906814575195\n",
      "Epoch: 6, Batch: 356, D Loss: 0.0990222646064467, G Loss: 13.301263809204102\n",
      "Epoch: 6, Batch: 357, D Loss: 0.09337150181295328, G Loss: 12.93350601196289\n",
      "Epoch: 6, Batch: 358, D Loss: 0.0956908197363191, G Loss: 12.53593635559082\n",
      "Epoch: 6, Batch: 359, D Loss: 0.09577664001358244, G Loss: 13.673961639404297\n",
      "Epoch: 6, Batch: 360, D Loss: 0.10172239788133197, G Loss: 14.51870346069336\n",
      "Epoch: 6, Batch: 361, D Loss: 0.09429904478025719, G Loss: 14.19875431060791\n",
      "Epoch: 6, Batch: 362, D Loss: 0.10438847915639826, G Loss: 13.411697387695312\n",
      "Epoch: 6, Batch: 363, D Loss: 0.10024469829062355, G Loss: 13.321307182312012\n",
      "Epoch: 6, Batch: 364, D Loss: 0.09757138008080801, G Loss: 13.011982917785645\n",
      "Epoch: 6, Batch: 365, D Loss: 0.0918094105882119, G Loss: 12.016611099243164\n",
      "Epoch: 6, Batch: 366, D Loss: 0.10722999242807418, G Loss: 11.907105445861816\n",
      "Epoch: 6, Batch: 367, D Loss: 0.09990451907287934, G Loss: 12.081892013549805\n",
      "Epoch: 6, Batch: 368, D Loss: 0.096094045992686, G Loss: 11.539300918579102\n",
      "Epoch: 6, Batch: 369, D Loss: 0.09654444543593854, G Loss: 10.66782283782959\n",
      "Epoch: 6, Batch: 370, D Loss: 0.09892551875964273, G Loss: 9.7955322265625\n",
      "Epoch: 6, Batch: 371, D Loss: 0.10249316387489671, G Loss: 11.732598304748535\n",
      "Epoch: 6, Batch: 372, D Loss: 0.10002697704385355, G Loss: 13.240381240844727\n",
      "Epoch: 6, Batch: 373, D Loss: 0.10206365982844545, G Loss: 14.429561614990234\n",
      "Epoch: 6, Batch: 374, D Loss: 0.09675770717686305, G Loss: 15.046426773071289\n",
      "Epoch: 6, Batch: 375, D Loss: 0.1020741634493163, G Loss: 15.757290840148926\n",
      "Epoch: 6, Batch: 376, D Loss: 0.10700602077801591, G Loss: 15.108745574951172\n",
      "Epoch: 6, Batch: 377, D Loss: 0.11056071151961078, G Loss: 12.77523422241211\n",
      "Epoch: 6, Batch: 378, D Loss: 0.1036385184397659, G Loss: 10.656692504882812\n",
      "Epoch: 6, Batch: 379, D Loss: 0.09851515475020278, G Loss: 11.142752647399902\n",
      "Epoch: 6, Batch: 380, D Loss: 0.10095411954716837, G Loss: 11.631380081176758\n",
      "Epoch: 6, Batch: 381, D Loss: 0.10336326418291719, G Loss: 12.020889282226562\n",
      "Epoch: 6, Batch: 382, D Loss: 0.1017766383529306, G Loss: 13.599151611328125\n",
      "Epoch: 6, Batch: 383, D Loss: 0.09913954479986842, G Loss: 14.358800888061523\n",
      "Epoch: 6, Batch: 384, D Loss: 0.09580504147308488, G Loss: 14.597679138183594\n",
      "Epoch: 6, Batch: 385, D Loss: 0.09273596658272254, G Loss: 14.376132011413574\n",
      "Epoch: 6, Batch: 386, D Loss: 0.10303634877573131, G Loss: 12.543967247009277\n",
      "Epoch: 6, Batch: 387, D Loss: 0.10209194426806789, G Loss: 11.98143196105957\n",
      "Epoch: 6, Batch: 388, D Loss: 0.09806429706577546, G Loss: 12.200608253479004\n",
      "Epoch: 6, Batch: 389, D Loss: 0.09704556962515198, G Loss: 11.249602317810059\n",
      "Epoch: 6, Batch: 390, D Loss: 0.09714642045582877, G Loss: 10.817215919494629\n",
      "Epoch: 6, Batch: 391, D Loss: 0.09503006626982824, G Loss: 12.119590759277344\n",
      "Epoch: 6, Batch: 392, D Loss: 0.10052431730628086, G Loss: 13.07869815826416\n",
      "Epoch: 6, Batch: 393, D Loss: 0.09536922825463989, G Loss: 12.594547271728516\n",
      "Epoch: 6, Batch: 394, D Loss: 0.098704074827765, G Loss: 12.905277252197266\n",
      "Epoch: 6, Batch: 395, D Loss: 0.09818229752636398, G Loss: 13.251435279846191\n",
      "Epoch: 6, Batch: 396, D Loss: 0.09421607566764578, G Loss: 13.492012023925781\n",
      "Epoch: 6, Batch: 397, D Loss: 0.09762557742760691, G Loss: 15.915365219116211\n",
      "Epoch: 6, Batch: 398, D Loss: 0.09245434099264216, G Loss: 19.612258911132812\n",
      "Epoch: 6, Batch: 399, D Loss: 0.10056883175554926, G Loss: 23.228195190429688\n",
      "Epoch: 6, Batch: 400, D Loss: 0.1001667530924065, G Loss: 24.42607307434082\n",
      "Epoch: 6, Batch: 401, D Loss: 0.09716656805362006, G Loss: 26.141464233398438\n",
      "Epoch: 6, Batch: 402, D Loss: 0.09795062244106381, G Loss: 27.930011749267578\n",
      "Epoch: 6, Batch: 403, D Loss: 0.09651531279138528, G Loss: 28.756288528442383\n",
      "Epoch: 6, Batch: 404, D Loss: 0.10018739104336756, G Loss: 28.284839630126953\n",
      "Epoch: 6, Batch: 405, D Loss: 0.09890931099682611, G Loss: 29.032867431640625\n",
      "Epoch: 6, Batch: 406, D Loss: 0.1002800613652083, G Loss: 27.407676696777344\n",
      "Epoch: 6, Batch: 407, D Loss: 0.0967993587279068, G Loss: 26.313520431518555\n",
      "Epoch: 6, Batch: 408, D Loss: 0.09638297558173589, G Loss: 25.789880752563477\n",
      "Epoch: 6, Batch: 409, D Loss: 0.10081610084331259, G Loss: 25.01344871520996\n",
      "Epoch: 6, Batch: 410, D Loss: 0.1002626717231348, G Loss: 24.41156768798828\n",
      "Epoch: 6, Batch: 411, D Loss: 0.09984357666078131, G Loss: 22.38247299194336\n",
      "Epoch: 6, Batch: 412, D Loss: 0.09930145823945058, G Loss: 20.231950759887695\n",
      "Epoch: 6, Batch: 413, D Loss: 0.09996459875903896, G Loss: 19.19500732421875\n",
      "Epoch: 6, Batch: 414, D Loss: 0.10101730565328637, G Loss: 17.804492950439453\n",
      "Epoch: 6, Batch: 415, D Loss: 0.1001378691120145, G Loss: 17.812423706054688\n",
      "Epoch: 6, Batch: 416, D Loss: 0.10258534309992129, G Loss: 17.089868545532227\n",
      "Epoch: 6, Batch: 417, D Loss: 0.09807656918389185, G Loss: 16.8579158782959\n",
      "Epoch: 6, Batch: 418, D Loss: 0.0935881398535372, G Loss: 16.767391204833984\n",
      "Epoch: 6, Batch: 419, D Loss: 0.09909526873596874, G Loss: 16.697235107421875\n",
      "Epoch: 6, Batch: 420, D Loss: 0.09110139808575113, G Loss: 16.306989669799805\n",
      "Epoch: 6, Batch: 421, D Loss: 0.095604654294565, G Loss: 16.35675048828125\n",
      "Epoch: 6, Batch: 422, D Loss: 0.09769942685445443, G Loss: 16.447776794433594\n",
      "Epoch: 6, Batch: 423, D Loss: 0.10005257751758379, G Loss: 16.179893493652344\n",
      "Epoch: 6, Batch: 424, D Loss: 0.09607974316644174, G Loss: 15.750240325927734\n",
      "Epoch: 6, Batch: 425, D Loss: 0.0954119549388679, G Loss: 14.546825408935547\n",
      "Epoch: 6, Batch: 426, D Loss: 0.0940906255040943, G Loss: 14.482491493225098\n",
      "Epoch: 6, Batch: 427, D Loss: 0.0946709486474333, G Loss: 14.639131546020508\n",
      "Epoch: 6, Batch: 428, D Loss: 0.09627338901867688, G Loss: 14.604361534118652\n",
      "Epoch: 6, Batch: 429, D Loss: 0.09832616983577225, G Loss: 14.881343841552734\n",
      "Epoch: 6, Batch: 430, D Loss: 0.10338528480571085, G Loss: 15.176047325134277\n",
      "Epoch: 6, Batch: 431, D Loss: 0.09791854181619897, G Loss: 15.190189361572266\n",
      "Epoch: 6, Batch: 432, D Loss: 0.10078754480043983, G Loss: 15.23283576965332\n",
      "Epoch: 6, Batch: 433, D Loss: 0.10222738146481447, G Loss: 15.354166030883789\n",
      "Epoch: 6, Batch: 434, D Loss: 0.09806162796533613, G Loss: 15.423091888427734\n",
      "Epoch: 6, Batch: 435, D Loss: 0.09917118480812093, G Loss: 15.63787841796875\n",
      "Epoch: 6, Batch: 436, D Loss: 0.0973187077768074, G Loss: 15.833141326904297\n",
      "Epoch: 6, Batch: 437, D Loss: 0.10407882908552324, G Loss: 16.05819320678711\n",
      "Epoch: 6, Batch: 438, D Loss: 0.0982363027301929, G Loss: 16.0789737701416\n",
      "Epoch: 6, Batch: 439, D Loss: 0.09776246551464851, G Loss: 15.942445755004883\n",
      "Epoch: 6, Batch: 440, D Loss: 0.1016632623791125, G Loss: 15.863603591918945\n",
      "Epoch: 6, Batch: 441, D Loss: 0.0942498960120588, G Loss: 15.890771865844727\n",
      "Epoch: 6, Batch: 442, D Loss: 0.0941846803369728, G Loss: 15.378780364990234\n",
      "Epoch: 6, Batch: 443, D Loss: 0.09787770652935279, G Loss: 15.663412094116211\n",
      "Epoch: 6, Batch: 444, D Loss: 0.0983936622839181, G Loss: 15.646524429321289\n",
      "Epoch: 6, Batch: 445, D Loss: 0.09621232183838657, G Loss: 15.761748313903809\n",
      "Epoch: 6, Batch: 446, D Loss: 0.09639214316552369, G Loss: 15.922712326049805\n",
      "Epoch: 6, Batch: 447, D Loss: 0.0978471598545525, G Loss: 14.64932632446289\n",
      "Epoch: 6, Batch: 448, D Loss: 0.09846862222551067, G Loss: 14.76059627532959\n",
      "Epoch: 6, Batch: 449, D Loss: 0.11270021682426545, G Loss: 15.401029586791992\n",
      "Epoch: 6, Batch: 450, D Loss: 0.09844271847030939, G Loss: 14.996910095214844\n",
      "Epoch: 6, Batch: 451, D Loss: 0.09408070784489553, G Loss: 14.611858367919922\n",
      "Epoch: 6, Batch: 452, D Loss: 0.0975300562743655, G Loss: 14.6570405960083\n",
      "Epoch: 6, Batch: 453, D Loss: 0.10511659685676022, G Loss: 15.011846542358398\n",
      "Epoch: 6, Batch: 454, D Loss: 0.10444242747223598, G Loss: 15.343006134033203\n",
      "Epoch: 6, Batch: 455, D Loss: 0.09480696640989095, G Loss: 15.301092147827148\n",
      "Epoch: 6, Batch: 456, D Loss: 0.09817260524580718, G Loss: 15.482789993286133\n",
      "Epoch: 6, Batch: 457, D Loss: 0.0996983715858164, G Loss: 15.460660934448242\n",
      "Epoch: 6, Batch: 458, D Loss: 0.09607421448620102, G Loss: 15.49843978881836\n",
      "Epoch: 6, Batch: 459, D Loss: 0.10200862607492667, G Loss: 15.624198913574219\n",
      "Epoch: 6, Batch: 460, D Loss: 0.09688611055813112, G Loss: 14.848392486572266\n",
      "Epoch: 6, Batch: 461, D Loss: 0.09419756101669918, G Loss: 14.460395812988281\n",
      "Epoch: 6, Batch: 462, D Loss: 0.10178163495106674, G Loss: 12.845097541809082\n",
      "Epoch: 6, Batch: 463, D Loss: 0.09546002665092601, G Loss: 12.774463653564453\n",
      "Epoch: 6, Batch: 464, D Loss: 0.10951504023989855, G Loss: 13.998917579650879\n",
      "Epoch: 6, Batch: 465, D Loss: 0.09800189122216807, G Loss: 15.04678726196289\n",
      "Epoch: 6, Batch: 466, D Loss: 0.09594906193601105, G Loss: 14.863316535949707\n",
      "Epoch: 6, Batch: 467, D Loss: 0.09302365729675444, G Loss: 14.601411819458008\n",
      "Epoch: 7, Batch: 0, D Loss: 0.10280927660340922, G Loss: 14.264326095581055\n",
      "Epoch: 7, Batch: 1, D Loss: 0.09778018953721812, G Loss: 14.90998363494873\n",
      "Epoch: 7, Batch: 2, D Loss: 0.09607543005029129, G Loss: 13.4517183303833\n",
      "Epoch: 7, Batch: 3, D Loss: 0.10007279843284778, G Loss: 13.015302658081055\n",
      "Epoch: 7, Batch: 4, D Loss: 0.09579782995206187, G Loss: 13.937938690185547\n",
      "Epoch: 7, Batch: 5, D Loss: 0.09802879388513475, G Loss: 18.204524993896484\n",
      "Epoch: 7, Batch: 6, D Loss: 0.09607754991018314, G Loss: 22.409923553466797\n",
      "Epoch: 7, Batch: 7, D Loss: 0.10297375336820103, G Loss: 22.353729248046875\n",
      "Epoch: 7, Batch: 8, D Loss: 0.10137911616473616, G Loss: 20.73841094970703\n",
      "Epoch: 7, Batch: 9, D Loss: 0.10234396210876451, G Loss: 19.997642517089844\n",
      "Epoch: 7, Batch: 10, D Loss: 0.10118368372087616, G Loss: 15.459710121154785\n",
      "Epoch: 7, Batch: 11, D Loss: 0.09692614804953337, G Loss: 32.017818450927734\n",
      "Epoch: 7, Batch: 12, D Loss: 0.10391460359096527, G Loss: 77.40657806396484\n",
      "Epoch: 7, Batch: 13, D Loss: 0.2145361305840347, G Loss: 1.667682409286499\n",
      "Epoch: 7, Batch: 14, D Loss: 3.400428980588913, G Loss: 3.1954965591430664\n",
      "Epoch: 7, Batch: 15, D Loss: 0.17331366632060963, G Loss: 26.49879264831543\n",
      "Epoch: 7, Batch: 16, D Loss: 1.6736798286556946, G Loss: 33.654850006103516\n",
      "Epoch: 7, Batch: 17, D Loss: 0.17439334208287227, G Loss: 18.261089324951172\n",
      "Epoch: 7, Batch: 18, D Loss: 0.15741389342292678, G Loss: 14.03947639465332\n",
      "Epoch: 7, Batch: 19, D Loss: 0.11935043775638521, G Loss: 25.416406631469727\n",
      "Epoch: 7, Batch: 20, D Loss: 1.9951802901923656, G Loss: 0.0894646942615509\n",
      "Epoch: 7, Batch: 21, D Loss: 3.526701331138611, G Loss: 32.270530700683594\n",
      "Epoch: 7, Batch: 22, D Loss: 0.24195927381515503, G Loss: 120.2916030883789\n",
      "Epoch: 7, Batch: 23, D Loss: 3.983175277709961, G Loss: 92.6973876953125\n",
      "Epoch: 7, Batch: 24, D Loss: 0.1275380253791809, G Loss: 67.68383026123047\n",
      "Epoch: 7, Batch: 25, D Loss: 0.18039971590042114, G Loss: 39.5462646484375\n",
      "Epoch: 7, Batch: 26, D Loss: 0.19208285219479718, G Loss: 18.431621551513672\n",
      "Epoch: 7, Batch: 27, D Loss: 0.19768552525056293, G Loss: 9.130120277404785\n",
      "Epoch: 7, Batch: 28, D Loss: 0.13547905773157254, G Loss: 8.242133140563965\n",
      "Epoch: 7, Batch: 29, D Loss: 0.26647331565618515, G Loss: 5.231785774230957\n",
      "Epoch: 7, Batch: 30, D Loss: 0.12394498696085066, G Loss: 10.039312362670898\n",
      "Epoch: 7, Batch: 31, D Loss: 0.10376956319919373, G Loss: 16.25164031982422\n",
      "Epoch: 7, Batch: 32, D Loss: 0.2800340826050842, G Loss: 10.254465103149414\n",
      "Epoch: 7, Batch: 33, D Loss: 0.19779504627513234, G Loss: 6.384698867797852\n",
      "Epoch: 7, Batch: 34, D Loss: 0.2791660400107503, G Loss: 4.836851119995117\n",
      "Epoch: 7, Batch: 35, D Loss: 0.32514768512919545, G Loss: 6.185657978057861\n",
      "Epoch: 7, Batch: 36, D Loss: 0.27567108580842614, G Loss: 9.779623985290527\n",
      "Epoch: 7, Batch: 37, D Loss: 0.2548801971533976, G Loss: 14.12410831451416\n",
      "Epoch: 7, Batch: 38, D Loss: 0.1746694201543093, G Loss: 18.988603591918945\n",
      "Epoch: 7, Batch: 39, D Loss: 0.11150141906827316, G Loss: 22.239952087402344\n",
      "Epoch: 7, Batch: 40, D Loss: 0.8666474932853951, G Loss: 14.42221450805664\n",
      "Epoch: 7, Batch: 41, D Loss: 0.15188676223624498, G Loss: 5.586605548858643\n",
      "Epoch: 7, Batch: 42, D Loss: 0.3554263934493065, G Loss: 6.587723255157471\n",
      "Epoch: 7, Batch: 43, D Loss: 0.2943045220890781, G Loss: 13.735960006713867\n",
      "Epoch: 7, Batch: 44, D Loss: 0.26791728806447246, G Loss: 21.996950149536133\n",
      "Epoch: 7, Batch: 45, D Loss: 0.23887944221748242, G Loss: 30.39322280883789\n",
      "Epoch: 7, Batch: 46, D Loss: 0.22968021035239192, G Loss: 31.711706161499023\n",
      "Epoch: 7, Batch: 47, D Loss: 0.14498786628246482, G Loss: 36.86982727050781\n",
      "Epoch: 7, Batch: 48, D Loss: 0.14947962760925315, G Loss: 36.16468811035156\n",
      "Epoch: 7, Batch: 49, D Loss: 0.13692674040794423, G Loss: 34.07532501220703\n",
      "Epoch: 7, Batch: 50, D Loss: 0.11534404009582047, G Loss: 30.747472763061523\n",
      "Epoch: 7, Batch: 51, D Loss: 0.124762818217318, G Loss: 30.057117462158203\n",
      "Epoch: 7, Batch: 52, D Loss: 0.12198837101761895, G Loss: 25.981143951416016\n",
      "Epoch: 7, Batch: 53, D Loss: 0.10351443291137531, G Loss: 25.909866333007812\n",
      "Epoch: 7, Batch: 54, D Loss: 0.10258153117298735, G Loss: 21.18606948852539\n",
      "Epoch: 7, Batch: 55, D Loss: 0.11471105711819529, G Loss: 18.529348373413086\n",
      "Epoch: 7, Batch: 56, D Loss: 0.10609752495632563, G Loss: 15.81453800201416\n",
      "Epoch: 7, Batch: 57, D Loss: 0.10382562587363964, G Loss: 13.41969108581543\n",
      "Epoch: 7, Batch: 58, D Loss: 0.10774526991554012, G Loss: 11.360392570495605\n",
      "Epoch: 7, Batch: 59, D Loss: 0.10298388966475613, G Loss: 7.853105545043945\n",
      "Epoch: 7, Batch: 60, D Loss: 0.10770431626588106, G Loss: 6.164401054382324\n",
      "Epoch: 7, Batch: 61, D Loss: 0.098520269501023, G Loss: 6.803349494934082\n",
      "Epoch: 7, Batch: 62, D Loss: 0.10502274730242789, G Loss: 7.213252544403076\n",
      "Epoch: 7, Batch: 63, D Loss: 0.09978674573358148, G Loss: 6.824356555938721\n",
      "Epoch: 7, Batch: 64, D Loss: 0.0999674053164199, G Loss: 6.844475269317627\n",
      "Epoch: 7, Batch: 65, D Loss: 0.10451309505151585, G Loss: 7.793941497802734\n",
      "Epoch: 7, Batch: 66, D Loss: 0.1045438062865287, G Loss: 8.753175735473633\n",
      "Epoch: 7, Batch: 67, D Loss: 0.09847089171671541, G Loss: 9.26755428314209\n",
      "Epoch: 7, Batch: 68, D Loss: 0.10350365490012337, G Loss: 8.898256301879883\n",
      "Epoch: 7, Batch: 69, D Loss: 0.1037636635301169, G Loss: 9.013406753540039\n",
      "Epoch: 7, Batch: 70, D Loss: 0.10249949875287712, G Loss: 8.292269706726074\n",
      "Epoch: 7, Batch: 71, D Loss: 0.10178124414960621, G Loss: 8.753175735473633\n",
      "Epoch: 7, Batch: 72, D Loss: 0.09268720238469541, G Loss: 7.835141181945801\n",
      "Epoch: 7, Batch: 73, D Loss: 0.09944020112743601, G Loss: 7.953279495239258\n",
      "Epoch: 7, Batch: 74, D Loss: 0.0984131934819743, G Loss: 8.05116081237793\n",
      "Epoch: 7, Batch: 75, D Loss: 0.10308962452108972, G Loss: 7.782647609710693\n",
      "Epoch: 7, Batch: 76, D Loss: 0.10276405008335132, G Loss: 8.524344444274902\n",
      "Epoch: 7, Batch: 77, D Loss: 0.10102822828048375, G Loss: 8.731423377990723\n",
      "Epoch: 7, Batch: 78, D Loss: 0.10552026121877134, G Loss: 6.675410747528076\n",
      "Epoch: 7, Batch: 79, D Loss: 0.09723273781128228, G Loss: 7.890615463256836\n",
      "Epoch: 7, Batch: 80, D Loss: 0.10327119546127506, G Loss: 9.508039474487305\n",
      "Epoch: 7, Batch: 81, D Loss: 0.10816744255134836, G Loss: 7.470476150512695\n",
      "Epoch: 7, Batch: 82, D Loss: 0.10340922785690054, G Loss: 7.145735740661621\n",
      "Epoch: 7, Batch: 83, D Loss: 0.09452709363540635, G Loss: 7.253459930419922\n",
      "Epoch: 7, Batch: 84, D Loss: 0.10803439281880856, G Loss: 7.16923713684082\n",
      "Epoch: 7, Batch: 85, D Loss: 0.09445724888064433, G Loss: 8.921853065490723\n",
      "Epoch: 7, Batch: 86, D Loss: 0.0999714469871833, G Loss: 10.377729415893555\n",
      "Epoch: 7, Batch: 87, D Loss: 0.10348676447028993, G Loss: 10.77744197845459\n",
      "Epoch: 7, Batch: 88, D Loss: 0.09388592827417597, G Loss: 10.111981391906738\n",
      "Epoch: 7, Batch: 89, D Loss: 0.09433389226251165, G Loss: 9.884777069091797\n",
      "Epoch: 7, Batch: 90, D Loss: 0.1007202642467746, G Loss: 9.366533279418945\n",
      "Epoch: 7, Batch: 91, D Loss: 0.09506931637588423, G Loss: 9.630216598510742\n",
      "Epoch: 7, Batch: 92, D Loss: 0.10258830343809677, G Loss: 9.565667152404785\n",
      "Epoch: 7, Batch: 93, D Loss: 0.09743091599375475, G Loss: 7.831550598144531\n",
      "Epoch: 7, Batch: 94, D Loss: 0.10526797268539667, G Loss: 7.840370178222656\n",
      "Epoch: 7, Batch: 95, D Loss: 0.10443560645217076, G Loss: 8.05036449432373\n",
      "Epoch: 7, Batch: 96, D Loss: 0.1028221616288647, G Loss: 8.067691802978516\n",
      "Epoch: 7, Batch: 97, D Loss: 0.09484390821307898, G Loss: 8.472965240478516\n",
      "Epoch: 7, Batch: 98, D Loss: 0.0957958516664803, G Loss: 8.208171844482422\n",
      "Epoch: 7, Batch: 99, D Loss: 0.09764957500738092, G Loss: 8.467541694641113\n",
      "Epoch: 7, Batch: 100, D Loss: 0.10351239109877497, G Loss: 8.252721786499023\n",
      "Epoch: 7, Batch: 101, D Loss: 0.1039709853939712, G Loss: 9.720152854919434\n",
      "Epoch: 7, Batch: 102, D Loss: 0.10004541654780041, G Loss: 9.764322280883789\n",
      "Epoch: 7, Batch: 103, D Loss: 0.09937001079015317, G Loss: 8.934616088867188\n",
      "Epoch: 7, Batch: 104, D Loss: 0.09886227302195039, G Loss: 8.488086700439453\n",
      "Epoch: 7, Batch: 105, D Loss: 0.10458704253687756, G Loss: 8.742730140686035\n",
      "Epoch: 7, Batch: 106, D Loss: 0.10241941136337118, G Loss: 8.860071182250977\n",
      "Epoch: 7, Batch: 107, D Loss: 0.09612265365285566, G Loss: 9.021814346313477\n",
      "Epoch: 7, Batch: 108, D Loss: 0.10432485561614158, G Loss: 9.229791641235352\n",
      "Epoch: 7, Batch: 109, D Loss: 0.096131852005783, G Loss: 9.356033325195312\n",
      "Epoch: 7, Batch: 110, D Loss: 0.1001232029266248, G Loss: 9.692217826843262\n",
      "Epoch: 7, Batch: 111, D Loss: 0.09804402704321546, G Loss: 9.496929168701172\n",
      "Epoch: 7, Batch: 112, D Loss: 0.10309737873467384, G Loss: 10.363166809082031\n",
      "Epoch: 7, Batch: 113, D Loss: 0.09691990760620683, G Loss: 8.626904487609863\n",
      "Epoch: 7, Batch: 114, D Loss: 0.09834915760438889, G Loss: 7.595523834228516\n",
      "Epoch: 7, Batch: 115, D Loss: 0.09958939079660922, G Loss: 7.871847152709961\n",
      "Epoch: 7, Batch: 116, D Loss: 0.09048550011357293, G Loss: 8.28366470336914\n",
      "Epoch: 7, Batch: 117, D Loss: 0.09900204147561453, G Loss: 8.997645378112793\n",
      "Epoch: 7, Batch: 118, D Loss: 0.10141303827549564, G Loss: 11.278623580932617\n",
      "Epoch: 7, Batch: 119, D Loss: 0.0976578163040358, G Loss: 12.185317039489746\n",
      "Epoch: 7, Batch: 120, D Loss: 0.09756463417318173, G Loss: 13.031290054321289\n",
      "Epoch: 7, Batch: 121, D Loss: 0.09941039397563145, G Loss: 13.098973274230957\n",
      "Epoch: 7, Batch: 122, D Loss: 0.09431301697497929, G Loss: 13.086959838867188\n",
      "Epoch: 7, Batch: 123, D Loss: 0.10673002447015278, G Loss: 12.879175186157227\n",
      "Epoch: 7, Batch: 124, D Loss: 0.1040745372620222, G Loss: 11.181787490844727\n",
      "Epoch: 7, Batch: 125, D Loss: 0.1030108799568552, G Loss: 10.240110397338867\n",
      "Epoch: 7, Batch: 126, D Loss: 0.10020126494055148, G Loss: 8.863847732543945\n",
      "Epoch: 7, Batch: 127, D Loss: 0.10199924514745362, G Loss: 9.040961265563965\n",
      "Epoch: 7, Batch: 128, D Loss: 0.10614039197389502, G Loss: 9.23760986328125\n",
      "Epoch: 7, Batch: 129, D Loss: 0.10114008250820916, G Loss: 9.498605728149414\n",
      "Epoch: 7, Batch: 130, D Loss: 0.10015068922439241, G Loss: 10.093120574951172\n",
      "Epoch: 7, Batch: 131, D Loss: 0.09358711837194278, G Loss: 10.301437377929688\n",
      "Epoch: 7, Batch: 132, D Loss: 0.09688760741664737, G Loss: 10.743304252624512\n",
      "Epoch: 7, Batch: 133, D Loss: 0.10430773340476662, G Loss: 11.62240219116211\n",
      "Epoch: 7, Batch: 134, D Loss: 0.09733374443521825, G Loss: 12.182140350341797\n",
      "Epoch: 7, Batch: 135, D Loss: 0.09327623230592508, G Loss: 11.992534637451172\n",
      "Epoch: 7, Batch: 136, D Loss: 0.09982515851879725, G Loss: 10.404797554016113\n",
      "Epoch: 7, Batch: 137, D Loss: 0.09494638621981721, G Loss: 10.270389556884766\n",
      "Epoch: 7, Batch: 138, D Loss: 0.09727656316681532, G Loss: 10.538178443908691\n",
      "Epoch: 7, Batch: 139, D Loss: 0.10662104510629433, G Loss: 10.425207138061523\n",
      "Epoch: 7, Batch: 140, D Loss: 0.1054320677776559, G Loss: 10.48560905456543\n",
      "Epoch: 7, Batch: 141, D Loss: 0.09879371504030132, G Loss: 10.31203842163086\n",
      "Epoch: 7, Batch: 142, D Loss: 0.09397361910851032, G Loss: 9.61583137512207\n",
      "Epoch: 7, Batch: 143, D Loss: 0.10463358060951577, G Loss: 9.605995178222656\n",
      "Epoch: 7, Batch: 144, D Loss: 0.0968614872017497, G Loss: 10.022710800170898\n",
      "Epoch: 7, Batch: 145, D Loss: 0.09484381960282917, G Loss: 10.532464981079102\n",
      "Epoch: 7, Batch: 146, D Loss: 0.101272311527282, G Loss: 11.01688003540039\n",
      "Epoch: 7, Batch: 147, D Loss: 0.09851808724761213, G Loss: 11.254806518554688\n",
      "Epoch: 7, Batch: 148, D Loss: 0.09732399239601364, G Loss: 11.434341430664062\n",
      "Epoch: 7, Batch: 149, D Loss: 0.10399089591328448, G Loss: 11.628376007080078\n",
      "Epoch: 7, Batch: 150, D Loss: 0.09892021552241204, G Loss: 11.764786720275879\n",
      "Epoch: 7, Batch: 151, D Loss: 0.10539885275557026, G Loss: 11.973543167114258\n",
      "Epoch: 7, Batch: 152, D Loss: 0.09778921791712492, G Loss: 11.845508575439453\n",
      "Epoch: 7, Batch: 153, D Loss: 0.09665621186650242, G Loss: 11.206900596618652\n",
      "Epoch: 7, Batch: 154, D Loss: 0.09571284611138253, G Loss: 10.808507919311523\n",
      "Epoch: 7, Batch: 155, D Loss: 0.09507116452368791, G Loss: 9.90115737915039\n",
      "Epoch: 7, Batch: 156, D Loss: 0.09693532602977939, G Loss: 9.722911834716797\n",
      "Epoch: 7, Batch: 157, D Loss: 0.09160391950172198, G Loss: 10.42757511138916\n",
      "Epoch: 7, Batch: 158, D Loss: 0.09981355855188667, G Loss: 11.731456756591797\n",
      "Epoch: 7, Batch: 159, D Loss: 0.0998762765138963, G Loss: 10.858552932739258\n",
      "Epoch: 7, Batch: 160, D Loss: 0.10221860407546046, G Loss: 10.098427772521973\n",
      "Epoch: 7, Batch: 161, D Loss: 0.09300664160400629, G Loss: 8.814261436462402\n",
      "Epoch: 7, Batch: 162, D Loss: 0.10363845482061151, G Loss: 9.551522254943848\n",
      "Epoch: 7, Batch: 163, D Loss: 0.10106143734992656, G Loss: 10.61660099029541\n",
      "Epoch: 7, Batch: 164, D Loss: 0.0966841808258323, G Loss: 10.545991897583008\n",
      "Epoch: 7, Batch: 165, D Loss: 0.09973865979918628, G Loss: 10.816703796386719\n",
      "Epoch: 7, Batch: 166, D Loss: 0.09968205332006619, G Loss: 11.18539047241211\n",
      "Epoch: 7, Batch: 167, D Loss: 0.09756336072496197, G Loss: 11.888399124145508\n",
      "Epoch: 7, Batch: 168, D Loss: 0.09911386683165802, G Loss: 12.760177612304688\n",
      "Epoch: 7, Batch: 169, D Loss: 0.09671078584528914, G Loss: 13.351970672607422\n",
      "Epoch: 7, Batch: 170, D Loss: 0.09100817029411701, G Loss: 12.903827667236328\n",
      "Epoch: 7, Batch: 171, D Loss: 0.09110683772166794, G Loss: 12.779743194580078\n",
      "Epoch: 7, Batch: 172, D Loss: 0.10049818638208308, G Loss: 13.283612251281738\n",
      "Epoch: 7, Batch: 173, D Loss: 0.09968325770080355, G Loss: 13.917043685913086\n",
      "Epoch: 7, Batch: 174, D Loss: 0.09136352336508935, G Loss: 14.067813873291016\n",
      "Epoch: 7, Batch: 175, D Loss: 0.10062490871018781, G Loss: 13.150873184204102\n",
      "Epoch: 7, Batch: 176, D Loss: 0.0971827840073729, G Loss: 12.924072265625\n",
      "Epoch: 7, Batch: 177, D Loss: 0.09954584228580643, G Loss: 12.850041389465332\n",
      "Epoch: 7, Batch: 178, D Loss: 0.10086331194725062, G Loss: 13.01015853881836\n",
      "Epoch: 7, Batch: 179, D Loss: 0.101783505689923, G Loss: 13.276820182800293\n",
      "Epoch: 7, Batch: 180, D Loss: 0.09340325318117948, G Loss: 13.225980758666992\n",
      "Epoch: 7, Batch: 181, D Loss: 0.10257244397428167, G Loss: 13.272507667541504\n",
      "Epoch: 7, Batch: 182, D Loss: 0.09726408276549137, G Loss: 13.265859603881836\n",
      "Epoch: 7, Batch: 183, D Loss: 0.09989061455581805, G Loss: 13.494539260864258\n",
      "Epoch: 7, Batch: 184, D Loss: 0.09873825393742663, G Loss: 13.724719047546387\n",
      "Epoch: 7, Batch: 185, D Loss: 0.10563584297017314, G Loss: 13.509153366088867\n",
      "Epoch: 7, Batch: 186, D Loss: 0.10673714385166022, G Loss: 13.110410690307617\n",
      "Epoch: 7, Batch: 187, D Loss: 0.1010201709013927, G Loss: 11.870719909667969\n",
      "Epoch: 7, Batch: 188, D Loss: 0.09762081905819286, G Loss: 11.417264938354492\n",
      "Epoch: 7, Batch: 189, D Loss: 0.09856580731229769, G Loss: 11.374011039733887\n",
      "Epoch: 7, Batch: 190, D Loss: 0.09784945825094837, G Loss: 11.691905975341797\n",
      "Epoch: 7, Batch: 191, D Loss: 0.09504115913705391, G Loss: 11.97603988647461\n",
      "Epoch: 7, Batch: 192, D Loss: 0.09116640073284543, G Loss: 11.999492645263672\n",
      "Epoch: 7, Batch: 193, D Loss: 0.0973176259808497, G Loss: 12.207900047302246\n",
      "Epoch: 7, Batch: 194, D Loss: 0.10047784817220418, G Loss: 12.403594970703125\n",
      "Epoch: 7, Batch: 195, D Loss: 0.0956125351767696, G Loss: 12.63513469696045\n",
      "Epoch: 7, Batch: 196, D Loss: 0.10168205601030422, G Loss: 12.923870086669922\n",
      "Epoch: 7, Batch: 197, D Loss: 0.10274813077705858, G Loss: 13.03857421875\n",
      "Epoch: 7, Batch: 198, D Loss: 0.1032424379538952, G Loss: 13.175168991088867\n",
      "Epoch: 7, Batch: 199, D Loss: 0.10069035427591189, G Loss: 13.006570816040039\n",
      "Epoch: 7, Batch: 200, D Loss: 0.10306185964338965, G Loss: 12.600793838500977\n",
      "Epoch: 7, Batch: 201, D Loss: 0.09707048122641027, G Loss: 12.17921257019043\n",
      "Epoch: 7, Batch: 202, D Loss: 0.10014490133471554, G Loss: 12.237326622009277\n",
      "Epoch: 7, Batch: 203, D Loss: 0.10315106930283946, G Loss: 12.335624694824219\n",
      "Epoch: 7, Batch: 204, D Loss: 0.10631530595833283, G Loss: 12.53105354309082\n",
      "Epoch: 7, Batch: 205, D Loss: 0.09570177250793677, G Loss: 12.149812698364258\n",
      "Epoch: 7, Batch: 206, D Loss: 0.09734108028806077, G Loss: 11.460208892822266\n",
      "Epoch: 7, Batch: 207, D Loss: 0.10126280249050978, G Loss: 11.460694313049316\n",
      "Epoch: 7, Batch: 208, D Loss: 0.09663159709089086, G Loss: 10.222248077392578\n",
      "Epoch: 7, Batch: 209, D Loss: 0.09894809301113128, G Loss: 10.671783447265625\n",
      "Epoch: 7, Batch: 210, D Loss: 0.09525428394317714, G Loss: 10.675213813781738\n",
      "Epoch: 7, Batch: 211, D Loss: 0.10170566088527266, G Loss: 10.830655097961426\n",
      "Epoch: 7, Batch: 212, D Loss: 0.09354513001198939, G Loss: 11.254823684692383\n",
      "Epoch: 7, Batch: 213, D Loss: 0.09898586724739289, G Loss: 11.751228332519531\n",
      "Epoch: 7, Batch: 214, D Loss: 0.10417841318076171, G Loss: 12.66861343383789\n",
      "Epoch: 7, Batch: 215, D Loss: 0.09357353174550553, G Loss: 13.094377517700195\n",
      "Epoch: 7, Batch: 216, D Loss: 0.09568532163177679, G Loss: 12.947927474975586\n",
      "Epoch: 7, Batch: 217, D Loss: 0.09603509830196799, G Loss: 12.865930557250977\n",
      "Epoch: 7, Batch: 218, D Loss: 0.09430137236370228, G Loss: 13.200510025024414\n",
      "Epoch: 7, Batch: 219, D Loss: 0.10281319360075258, G Loss: 14.378546714782715\n",
      "Epoch: 7, Batch: 220, D Loss: 0.10171097559029363, G Loss: 14.599931716918945\n",
      "Epoch: 7, Batch: 221, D Loss: 0.09762098453944645, G Loss: 13.300743103027344\n",
      "Epoch: 7, Batch: 222, D Loss: 0.09674494772798425, G Loss: 11.583662033081055\n",
      "Epoch: 7, Batch: 223, D Loss: 0.09835384587677254, G Loss: 11.145906448364258\n",
      "Epoch: 7, Batch: 224, D Loss: 0.10063388317666977, G Loss: 11.15962028503418\n",
      "Epoch: 7, Batch: 225, D Loss: 0.10237323135970655, G Loss: 11.225882530212402\n",
      "Epoch: 7, Batch: 226, D Loss: 0.09863428325479617, G Loss: 11.0050048828125\n",
      "Epoch: 7, Batch: 227, D Loss: 0.09596539864742226, G Loss: 10.57406234741211\n",
      "Epoch: 7, Batch: 228, D Loss: 0.09515260844636941, G Loss: 10.397695541381836\n",
      "Epoch: 7, Batch: 229, D Loss: 0.09647994881561317, G Loss: 10.684842109680176\n",
      "Epoch: 7, Batch: 230, D Loss: 0.10314757813284814, G Loss: 11.55392074584961\n",
      "Epoch: 7, Batch: 231, D Loss: 0.10273025825676996, G Loss: 12.390262603759766\n",
      "Epoch: 7, Batch: 232, D Loss: 0.10274293290444803, G Loss: 12.726763725280762\n",
      "Epoch: 7, Batch: 233, D Loss: 0.10067586952891361, G Loss: 12.555931091308594\n",
      "Epoch: 7, Batch: 234, D Loss: 0.0938310991959952, G Loss: 12.12464714050293\n",
      "Epoch: 7, Batch: 235, D Loss: 0.10399328479843462, G Loss: 12.194995880126953\n",
      "Epoch: 7, Batch: 236, D Loss: 0.09840499119582091, G Loss: 12.675865173339844\n",
      "Epoch: 7, Batch: 237, D Loss: 0.10182932629595598, G Loss: 13.29130744934082\n",
      "Epoch: 7, Batch: 238, D Loss: 0.09730179637233505, G Loss: 13.534342765808105\n",
      "Epoch: 7, Batch: 239, D Loss: 0.10104607675191346, G Loss: 13.650135040283203\n",
      "Epoch: 7, Batch: 240, D Loss: 0.10281138622730168, G Loss: 13.666726112365723\n",
      "Epoch: 7, Batch: 241, D Loss: 0.09841993114565639, G Loss: 13.607156753540039\n",
      "Epoch: 7, Batch: 242, D Loss: 0.09612756126102795, G Loss: 13.561651229858398\n",
      "Epoch: 7, Batch: 243, D Loss: 0.1044942410941303, G Loss: 13.924398422241211\n",
      "Epoch: 7, Batch: 244, D Loss: 0.09908349625084156, G Loss: 14.364566802978516\n",
      "Epoch: 7, Batch: 245, D Loss: 0.10084837383880085, G Loss: 14.527507781982422\n",
      "Epoch: 7, Batch: 246, D Loss: 0.10155399899571194, G Loss: 14.46774673461914\n",
      "Epoch: 7, Batch: 247, D Loss: 0.09762612204835364, G Loss: 14.151354789733887\n",
      "Epoch: 7, Batch: 248, D Loss: 0.10425350662012534, G Loss: 14.160846710205078\n",
      "Epoch: 7, Batch: 249, D Loss: 0.10650911441967992, G Loss: 14.52154541015625\n",
      "Epoch: 7, Batch: 250, D Loss: 0.09741707885783057, G Loss: 14.588552474975586\n",
      "Epoch: 7, Batch: 251, D Loss: 0.10639029418516088, G Loss: 14.678869247436523\n",
      "Epoch: 7, Batch: 252, D Loss: 0.09625699705784996, G Loss: 14.358358383178711\n",
      "Epoch: 7, Batch: 253, D Loss: 0.10055332086494673, G Loss: 14.1197509765625\n",
      "Epoch: 7, Batch: 254, D Loss: 0.10526325835331818, G Loss: 14.28799057006836\n",
      "Epoch: 7, Batch: 255, D Loss: 0.10408652734582802, G Loss: 14.726221084594727\n",
      "Epoch: 7, Batch: 256, D Loss: 0.09740838554394315, G Loss: 14.644505500793457\n",
      "Epoch: 7, Batch: 257, D Loss: 0.10059408723896013, G Loss: 14.372283935546875\n",
      "Epoch: 7, Batch: 258, D Loss: 0.09969575351428261, G Loss: 14.228691101074219\n",
      "Epoch: 7, Batch: 259, D Loss: 0.10505854609959897, G Loss: 14.459634780883789\n",
      "Epoch: 7, Batch: 260, D Loss: 0.09852957174473431, G Loss: 14.688789367675781\n",
      "Epoch: 7, Batch: 261, D Loss: 0.10616421091842199, G Loss: 14.970270156860352\n",
      "Epoch: 7, Batch: 262, D Loss: 0.09834704119268167, G Loss: 14.696826934814453\n",
      "Epoch: 7, Batch: 263, D Loss: 0.10670186525761949, G Loss: 14.622852325439453\n",
      "Epoch: 7, Batch: 264, D Loss: 0.10358475126463418, G Loss: 14.622255325317383\n",
      "Epoch: 7, Batch: 265, D Loss: 0.09541614616011884, G Loss: 14.419880867004395\n",
      "Epoch: 7, Batch: 266, D Loss: 0.10405332826721292, G Loss: 14.493682861328125\n",
      "Epoch: 7, Batch: 267, D Loss: 0.09966884668941134, G Loss: 14.546867370605469\n",
      "Epoch: 7, Batch: 268, D Loss: 0.09219319517694657, G Loss: 14.181100845336914\n",
      "Epoch: 7, Batch: 269, D Loss: 0.10093074936338553, G Loss: 14.149133682250977\n",
      "Epoch: 7, Batch: 270, D Loss: 0.09892461079664372, G Loss: 13.75656795501709\n",
      "Epoch: 7, Batch: 271, D Loss: 0.09719379972807474, G Loss: 13.793414115905762\n",
      "Epoch: 7, Batch: 272, D Loss: 0.09902761982789343, G Loss: 13.81032943725586\n",
      "Epoch: 7, Batch: 273, D Loss: 0.10487287579869076, G Loss: 14.001523971557617\n",
      "Epoch: 7, Batch: 274, D Loss: 0.09339976566332098, G Loss: 13.791727066040039\n",
      "Epoch: 7, Batch: 275, D Loss: 0.09596774697706678, G Loss: 13.532596588134766\n",
      "Epoch: 7, Batch: 276, D Loss: 0.0972458512470098, G Loss: 13.43117904663086\n",
      "Epoch: 7, Batch: 277, D Loss: 0.10391081201072438, G Loss: 13.67110538482666\n",
      "Epoch: 7, Batch: 278, D Loss: 0.09489766266142396, G Loss: 13.824784278869629\n",
      "Epoch: 7, Batch: 279, D Loss: 0.09805939137424957, G Loss: 13.794015884399414\n",
      "Epoch: 7, Batch: 280, D Loss: 0.09953390597104317, G Loss: 13.76654052734375\n",
      "Epoch: 7, Batch: 281, D Loss: 0.09569510675214588, G Loss: 13.582863807678223\n",
      "Epoch: 7, Batch: 282, D Loss: 0.10304588875169429, G Loss: 13.49239730834961\n",
      "Epoch: 7, Batch: 283, D Loss: 0.09366952089169445, G Loss: 13.293464660644531\n",
      "Epoch: 7, Batch: 284, D Loss: 0.1031715951970682, G Loss: 13.55077075958252\n",
      "Epoch: 7, Batch: 285, D Loss: 0.10336401220502012, G Loss: 13.800308227539062\n",
      "Epoch: 7, Batch: 286, D Loss: 0.09895464613759941, G Loss: 13.732303619384766\n",
      "Epoch: 7, Batch: 287, D Loss: 0.10027494474763898, G Loss: 13.50790023803711\n",
      "Epoch: 7, Batch: 288, D Loss: 0.09938980204151449, G Loss: 13.351707458496094\n",
      "Epoch: 7, Batch: 289, D Loss: 0.09970657775335212, G Loss: 13.295024871826172\n",
      "Epoch: 7, Batch: 290, D Loss: 0.09912178637586067, G Loss: 13.38720703125\n",
      "Epoch: 7, Batch: 291, D Loss: 0.10916946488862322, G Loss: 13.859109878540039\n",
      "Epoch: 7, Batch: 292, D Loss: 0.10001776723214562, G Loss: 13.91598892211914\n",
      "Epoch: 7, Batch: 293, D Loss: 0.09786543662437452, G Loss: 13.479260444641113\n",
      "Epoch: 7, Batch: 294, D Loss: 0.09237007321559076, G Loss: 12.93881607055664\n",
      "Epoch: 7, Batch: 295, D Loss: 0.09957787877840474, G Loss: 12.819611549377441\n",
      "Epoch: 7, Batch: 296, D Loss: 0.10102578674786855, G Loss: 13.249652862548828\n",
      "Epoch: 7, Batch: 297, D Loss: 0.10089918576852597, G Loss: 13.827082633972168\n",
      "Epoch: 7, Batch: 298, D Loss: 0.0999887522048084, G Loss: 14.08123779296875\n",
      "Epoch: 7, Batch: 299, D Loss: 0.1027861034958164, G Loss: 13.948270797729492\n",
      "Epoch: 7, Batch: 300, D Loss: 0.09915305109899464, G Loss: 13.560629844665527\n",
      "Epoch: 7, Batch: 301, D Loss: 0.09667750249184337, G Loss: 13.298480987548828\n",
      "Epoch: 7, Batch: 302, D Loss: 0.09406145033329949, G Loss: 13.346199035644531\n",
      "Epoch: 7, Batch: 303, D Loss: 0.10219031620107444, G Loss: 13.815437316894531\n",
      "Epoch: 7, Batch: 304, D Loss: 0.10523869071255376, G Loss: 14.456670761108398\n",
      "Epoch: 7, Batch: 305, D Loss: 0.09470112167323919, G Loss: 14.352211952209473\n",
      "Epoch: 7, Batch: 306, D Loss: 0.10744348831593697, G Loss: 14.142139434814453\n",
      "Epoch: 7, Batch: 307, D Loss: 0.1057170696420826, G Loss: 14.050164222717285\n",
      "Epoch: 7, Batch: 308, D Loss: 0.09767292768390234, G Loss: 14.005329132080078\n",
      "Epoch: 7, Batch: 309, D Loss: 0.1011258193820197, G Loss: 14.142967224121094\n",
      "Epoch: 7, Batch: 310, D Loss: 0.10039012836926986, G Loss: 14.37188720703125\n",
      "Epoch: 7, Batch: 311, D Loss: 0.09473769759441097, G Loss: 14.371572494506836\n",
      "Epoch: 7, Batch: 312, D Loss: 0.09959265996849354, G Loss: 14.420896530151367\n",
      "Epoch: 7, Batch: 313, D Loss: 0.09983233585742823, G Loss: 14.493593215942383\n",
      "Epoch: 7, Batch: 314, D Loss: 0.10237717207049002, G Loss: 14.648338317871094\n",
      "Epoch: 7, Batch: 315, D Loss: 0.10574185493513255, G Loss: 14.904513359069824\n",
      "Epoch: 7, Batch: 316, D Loss: 0.09219906196625516, G Loss: 14.606828689575195\n",
      "Epoch: 7, Batch: 317, D Loss: 0.09872415004093682, G Loss: 14.445842742919922\n",
      "Epoch: 7, Batch: 318, D Loss: 0.09174249286655822, G Loss: 14.383842468261719\n",
      "Epoch: 7, Batch: 319, D Loss: 0.10045330367455563, G Loss: 14.951955795288086\n",
      "Epoch: 7, Batch: 320, D Loss: 0.09787614844255188, G Loss: 15.483960151672363\n",
      "Epoch: 7, Batch: 321, D Loss: 0.09575789089210218, G Loss: 15.499540328979492\n",
      "Epoch: 7, Batch: 322, D Loss: 0.1062930005116769, G Loss: 15.563615798950195\n",
      "Epoch: 7, Batch: 323, D Loss: 0.0952482052475716, G Loss: 15.258338928222656\n",
      "Epoch: 7, Batch: 324, D Loss: 0.10647530909513137, G Loss: 15.0669527053833\n",
      "Epoch: 7, Batch: 325, D Loss: 0.10301196564375914, G Loss: 15.09035587310791\n",
      "Epoch: 7, Batch: 326, D Loss: 0.10655316158255346, G Loss: 15.249542236328125\n",
      "Epoch: 7, Batch: 327, D Loss: 0.09507204842881833, G Loss: 14.794727325439453\n",
      "Epoch: 7, Batch: 328, D Loss: 0.09822711392567385, G Loss: 14.462191581726074\n",
      "Epoch: 7, Batch: 329, D Loss: 0.10487640623003358, G Loss: 14.474586486816406\n",
      "Epoch: 7, Batch: 330, D Loss: 0.09853019932904772, G Loss: 14.54505729675293\n",
      "Epoch: 7, Batch: 331, D Loss: 0.09429524042315052, G Loss: 14.401840209960938\n",
      "Epoch: 7, Batch: 332, D Loss: 0.09411903787656684, G Loss: 14.11772632598877\n",
      "Epoch: 7, Batch: 333, D Loss: 0.09990936705875697, G Loss: 14.059083938598633\n",
      "Epoch: 7, Batch: 334, D Loss: 0.09625480653386376, G Loss: 14.104887008666992\n",
      "Epoch: 7, Batch: 335, D Loss: 0.0956608537716761, G Loss: 14.177265167236328\n",
      "Epoch: 7, Batch: 336, D Loss: 0.09817699484216291, G Loss: 14.244356155395508\n",
      "Epoch: 7, Batch: 337, D Loss: 0.09925669231498091, G Loss: 14.246167182922363\n",
      "Epoch: 7, Batch: 338, D Loss: 0.09908247951008775, G Loss: 14.136871337890625\n",
      "Epoch: 7, Batch: 339, D Loss: 0.09545621404404869, G Loss: 14.008115768432617\n",
      "Epoch: 7, Batch: 340, D Loss: 0.09580796574513784, G Loss: 13.973369598388672\n",
      "Epoch: 7, Batch: 341, D Loss: 0.1040306759522025, G Loss: 14.314765930175781\n",
      "Epoch: 7, Batch: 342, D Loss: 0.10073251388587323, G Loss: 14.597341537475586\n",
      "Epoch: 7, Batch: 343, D Loss: 0.10316028469767957, G Loss: 14.705924987792969\n",
      "Epoch: 7, Batch: 344, D Loss: 0.09439343091167984, G Loss: 14.317632675170898\n",
      "Epoch: 7, Batch: 345, D Loss: 0.09638273693417432, G Loss: 13.965660095214844\n",
      "Epoch: 7, Batch: 346, D Loss: 0.10913548817390506, G Loss: 14.12282943725586\n",
      "Epoch: 7, Batch: 347, D Loss: 0.10031632692806625, G Loss: 14.502214431762695\n",
      "Epoch: 7, Batch: 348, D Loss: 0.1027956427245158, G Loss: 14.75389575958252\n",
      "Epoch: 7, Batch: 349, D Loss: 0.09694857419229663, G Loss: 14.41865348815918\n",
      "Epoch: 7, Batch: 350, D Loss: 0.08982188440018035, G Loss: 13.681118965148926\n",
      "Epoch: 7, Batch: 351, D Loss: 0.09994572305350857, G Loss: 13.473946571350098\n",
      "Epoch: 7, Batch: 352, D Loss: 0.10167955136643059, G Loss: 13.739187240600586\n",
      "Epoch: 7, Batch: 353, D Loss: 0.09793911128463151, G Loss: 14.133035659790039\n",
      "Epoch: 7, Batch: 354, D Loss: 0.09887202844197418, G Loss: 14.249580383300781\n",
      "Epoch: 7, Batch: 355, D Loss: 0.09748084283265257, G Loss: 13.940732955932617\n",
      "Epoch: 7, Batch: 356, D Loss: 0.09726328198183865, G Loss: 13.5552396774292\n",
      "Epoch: 7, Batch: 357, D Loss: 0.09520415928210468, G Loss: 13.337972640991211\n",
      "Epoch: 7, Batch: 358, D Loss: 0.09734431762547047, G Loss: 13.472833633422852\n",
      "Epoch: 7, Batch: 359, D Loss: 0.10462028350536912, G Loss: 14.028610229492188\n",
      "Epoch: 7, Batch: 360, D Loss: 0.09602719051360964, G Loss: 14.330770492553711\n",
      "Epoch: 7, Batch: 361, D Loss: 0.1001447345277029, G Loss: 14.398503303527832\n",
      "Epoch: 7, Batch: 362, D Loss: 0.10699802489688182, G Loss: 14.434881210327148\n",
      "Epoch: 7, Batch: 363, D Loss: 0.09767754403742401, G Loss: 14.195531845092773\n",
      "Epoch: 7, Batch: 364, D Loss: 0.09751496987536257, G Loss: 14.009721755981445\n",
      "Epoch: 7, Batch: 365, D Loss: 0.10452727108884119, G Loss: 14.28731632232666\n",
      "Epoch: 7, Batch: 366, D Loss: 0.10153921385344233, G Loss: 14.598844528198242\n",
      "Epoch: 7, Batch: 367, D Loss: 0.0969517495358474, G Loss: 14.671163558959961\n",
      "Epoch: 7, Batch: 368, D Loss: 0.1008295228324414, G Loss: 14.547786712646484\n",
      "Epoch: 7, Batch: 369, D Loss: 0.09769064358818014, G Loss: 14.33030891418457\n",
      "Epoch: 7, Batch: 370, D Loss: 0.0961174902479911, G Loss: 14.107912063598633\n",
      "Epoch: 7, Batch: 371, D Loss: 0.10468586803668245, G Loss: 14.217899322509766\n",
      "Epoch: 7, Batch: 372, D Loss: 0.09783733719052634, G Loss: 14.38742733001709\n",
      "Epoch: 7, Batch: 373, D Loss: 0.10459808511060942, G Loss: 14.690468788146973\n",
      "Epoch: 7, Batch: 374, D Loss: 0.10687950109394251, G Loss: 15.080057144165039\n",
      "Epoch: 7, Batch: 375, D Loss: 0.1004768737008419, G Loss: 15.006754875183105\n",
      "Epoch: 7, Batch: 376, D Loss: 0.10121191938945628, G Loss: 14.709339141845703\n",
      "Epoch: 7, Batch: 377, D Loss: 0.10145727828091822, G Loss: 14.582552909851074\n",
      "Epoch: 7, Batch: 378, D Loss: 0.10093176423231398, G Loss: 14.782784461975098\n",
      "Epoch: 7, Batch: 379, D Loss: 0.09732621579013312, G Loss: 15.018119812011719\n",
      "Epoch: 7, Batch: 380, D Loss: 0.09864828169861539, G Loss: 15.209617614746094\n",
      "Epoch: 7, Batch: 381, D Loss: 0.09383092298065776, G Loss: 15.137863159179688\n",
      "Epoch: 7, Batch: 382, D Loss: 0.09288023201810347, G Loss: 14.953953742980957\n",
      "Epoch: 7, Batch: 383, D Loss: 0.09464621831247655, G Loss: 14.878534317016602\n",
      "Epoch: 7, Batch: 384, D Loss: 0.10126486976821525, G Loss: 15.184703826904297\n",
      "Epoch: 7, Batch: 385, D Loss: 0.09899242951596676, G Loss: 15.565152168273926\n",
      "Epoch: 7, Batch: 386, D Loss: 0.09981367372468952, G Loss: 15.76262092590332\n",
      "Epoch: 7, Batch: 387, D Loss: 0.09479530665364422, G Loss: 15.553886413574219\n",
      "Epoch: 7, Batch: 388, D Loss: 0.10543039331903259, G Loss: 15.545870780944824\n",
      "Epoch: 7, Batch: 389, D Loss: 0.09481299686232347, G Loss: 15.374290466308594\n",
      "Epoch: 7, Batch: 390, D Loss: 0.09928556508025821, G Loss: 15.395761489868164\n",
      "Epoch: 7, Batch: 391, D Loss: 0.10007032608753264, G Loss: 15.69567584991455\n",
      "Epoch: 7, Batch: 392, D Loss: 0.09748420316067552, G Loss: 15.88643741607666\n",
      "Epoch: 7, Batch: 393, D Loss: 0.0942502714839506, G Loss: 15.706939697265625\n",
      "Epoch: 7, Batch: 394, D Loss: 0.1004383576015826, G Loss: 15.522381782531738\n",
      "Epoch: 7, Batch: 395, D Loss: 0.09547475122712967, G Loss: 15.371177673339844\n",
      "Epoch: 7, Batch: 396, D Loss: 0.09575687442865188, G Loss: 15.37718391418457\n",
      "Epoch: 7, Batch: 397, D Loss: 0.09574725777805781, G Loss: 15.471879959106445\n",
      "Epoch: 7, Batch: 398, D Loss: 0.1016019363626981, G Loss: 15.751607894897461\n",
      "Epoch: 7, Batch: 399, D Loss: 0.09534551722725126, G Loss: 15.749246597290039\n",
      "Epoch: 7, Batch: 400, D Loss: 0.10148758982840889, G Loss: 15.745569229125977\n",
      "Epoch: 7, Batch: 401, D Loss: 0.09355887376851513, G Loss: 15.435619354248047\n",
      "Epoch: 7, Batch: 402, D Loss: 0.09045387909360159, G Loss: 15.062295913696289\n",
      "Epoch: 7, Batch: 403, D Loss: 0.10135202665189524, G Loss: 15.220342636108398\n",
      "Epoch: 7, Batch: 404, D Loss: 0.10206477525854751, G Loss: 15.785042762756348\n",
      "Epoch: 7, Batch: 405, D Loss: 0.09952183000551074, G Loss: 16.106393814086914\n",
      "Epoch: 7, Batch: 406, D Loss: 0.09736243378618781, G Loss: 15.879048347473145\n",
      "Epoch: 7, Batch: 407, D Loss: 0.10096235271216614, G Loss: 15.466567993164062\n",
      "Epoch: 7, Batch: 408, D Loss: 0.09638827642829284, G Loss: 15.119134902954102\n",
      "Epoch: 7, Batch: 409, D Loss: 0.10078784136604213, G Loss: 15.243759155273438\n",
      "Epoch: 7, Batch: 410, D Loss: 0.09603300468235432, G Loss: 15.416142463684082\n",
      "Epoch: 7, Batch: 411, D Loss: 0.1068447946260278, G Loss: 15.885448455810547\n",
      "Epoch: 7, Batch: 412, D Loss: 0.09842719525458676, G Loss: 15.874500274658203\n",
      "Epoch: 7, Batch: 413, D Loss: 0.10346250090897513, G Loss: 15.61764907836914\n",
      "Epoch: 7, Batch: 414, D Loss: 0.10046073499697883, G Loss: 15.226951599121094\n",
      "Epoch: 7, Batch: 415, D Loss: 0.1008845925113917, G Loss: 15.068391799926758\n",
      "Epoch: 7, Batch: 416, D Loss: 0.09517911238751253, G Loss: 14.968957901000977\n",
      "Epoch: 7, Batch: 417, D Loss: 0.09452961278265093, G Loss: 14.999424934387207\n",
      "Epoch: 7, Batch: 418, D Loss: 0.1046401133413184, G Loss: 15.33043098449707\n",
      "Epoch: 7, Batch: 419, D Loss: 0.09644660957590645, G Loss: 15.32404899597168\n",
      "Epoch: 7, Batch: 420, D Loss: 0.09273569627309541, G Loss: 14.911849975585938\n",
      "Epoch: 7, Batch: 421, D Loss: 0.10616110386771993, G Loss: 14.935489654541016\n",
      "Epoch: 7, Batch: 422, D Loss: 0.09628037770013975, G Loss: 14.967805862426758\n",
      "Epoch: 7, Batch: 423, D Loss: 0.09956740676025788, G Loss: 15.165779113769531\n",
      "Epoch: 7, Batch: 424, D Loss: 0.1016631394472256, G Loss: 15.373998641967773\n",
      "Epoch: 7, Batch: 425, D Loss: 0.10010968884078153, G Loss: 15.3934965133667\n",
      "Epoch: 7, Batch: 426, D Loss: 0.09642475655846994, G Loss: 15.150776863098145\n",
      "Epoch: 7, Batch: 427, D Loss: 0.09837048023317152, G Loss: 14.977231979370117\n",
      "Epoch: 7, Batch: 428, D Loss: 0.09454673558002469, G Loss: 14.887262344360352\n",
      "Epoch: 7, Batch: 429, D Loss: 0.09604748233738292, G Loss: 14.898900032043457\n",
      "Epoch: 7, Batch: 430, D Loss: 0.09782713999236137, G Loss: 15.0984525680542\n",
      "Epoch: 7, Batch: 431, D Loss: 0.10757864232785863, G Loss: 15.514805793762207\n",
      "Epoch: 7, Batch: 432, D Loss: 0.0990655449724187, G Loss: 15.500174522399902\n",
      "Epoch: 7, Batch: 433, D Loss: 0.0935634210909484, G Loss: 14.931905746459961\n",
      "Epoch: 7, Batch: 434, D Loss: 0.1021895369511725, G Loss: 14.653069496154785\n",
      "Epoch: 7, Batch: 435, D Loss: 0.10328701591339495, G Loss: 14.82153034210205\n",
      "Epoch: 7, Batch: 436, D Loss: 0.09980043275044181, G Loss: 15.180212020874023\n",
      "Epoch: 7, Batch: 437, D Loss: 0.10392395241424879, G Loss: 15.463647842407227\n",
      "Epoch: 7, Batch: 438, D Loss: 0.09555077027011549, G Loss: 15.143203735351562\n",
      "Epoch: 7, Batch: 439, D Loss: 0.10010087085780128, G Loss: 14.788752555847168\n",
      "Epoch: 7, Batch: 440, D Loss: 0.095122011612645, G Loss: 14.583574295043945\n",
      "Epoch: 7, Batch: 441, D Loss: 0.09620050467370334, G Loss: 14.645578384399414\n",
      "Epoch: 7, Batch: 442, D Loss: 0.0889724899545854, G Loss: 14.634984970092773\n",
      "Epoch: 7, Batch: 443, D Loss: 0.10251045067775522, G Loss: 15.050503730773926\n",
      "Epoch: 7, Batch: 444, D Loss: 0.10186162627950068, G Loss: 15.423771858215332\n",
      "Epoch: 7, Batch: 445, D Loss: 0.09563953407391779, G Loss: 15.219703674316406\n",
      "Epoch: 7, Batch: 446, D Loss: 0.09346151528899327, G Loss: 14.739036560058594\n",
      "Epoch: 7, Batch: 447, D Loss: 0.09987128048413751, G Loss: 14.60220718383789\n",
      "Epoch: 7, Batch: 448, D Loss: 0.09989921081471209, G Loss: 14.832212448120117\n",
      "Epoch: 7, Batch: 449, D Loss: 0.10124046876322268, G Loss: 15.220318794250488\n",
      "Epoch: 7, Batch: 450, D Loss: 0.10215832646392897, G Loss: 15.466678619384766\n",
      "Epoch: 7, Batch: 451, D Loss: 0.0992349563382362, G Loss: 15.257589340209961\n",
      "Epoch: 7, Batch: 452, D Loss: 0.098880268672346, G Loss: 14.916252136230469\n",
      "Epoch: 7, Batch: 453, D Loss: 0.10534187525360039, G Loss: 14.931866645812988\n",
      "Epoch: 7, Batch: 454, D Loss: 0.09631824162482872, G Loss: 14.968480110168457\n",
      "Epoch: 7, Batch: 455, D Loss: 0.09903153120457375, G Loss: 15.068310737609863\n",
      "Epoch: 7, Batch: 456, D Loss: 0.09351862020341173, G Loss: 15.01542854309082\n",
      "Epoch: 7, Batch: 457, D Loss: 0.09230477349559862, G Loss: 14.946234703063965\n",
      "Epoch: 7, Batch: 458, D Loss: 0.10171210471690983, G Loss: 15.23686408996582\n",
      "Epoch: 7, Batch: 459, D Loss: 0.09139276260043516, G Loss: 15.151426315307617\n",
      "Epoch: 7, Batch: 460, D Loss: 0.1035639837466249, G Loss: 15.26850700378418\n",
      "Epoch: 7, Batch: 461, D Loss: 0.09157910865627628, G Loss: 15.020511627197266\n",
      "Epoch: 7, Batch: 462, D Loss: 0.09647455960532625, G Loss: 14.823173522949219\n",
      "Epoch: 7, Batch: 463, D Loss: 0.09914202672582917, G Loss: 14.743494033813477\n",
      "Epoch: 7, Batch: 464, D Loss: 0.10262206986908495, G Loss: 14.838499069213867\n",
      "Epoch: 7, Batch: 465, D Loss: 0.10158252525386047, G Loss: 15.037877082824707\n",
      "Epoch: 7, Batch: 466, D Loss: 0.10785096468126198, G Loss: 15.277009963989258\n",
      "Epoch: 7, Batch: 467, D Loss: 0.09944478412781166, G Loss: 15.003266334533691\n",
      "Epoch: 8, Batch: 0, D Loss: 0.09997968800055901, G Loss: 14.657691955566406\n",
      "Epoch: 8, Batch: 1, D Loss: 0.10606308255276531, G Loss: 14.792146682739258\n",
      "Epoch: 8, Batch: 2, D Loss: 0.09844182300847137, G Loss: 14.987558364868164\n",
      "Epoch: 8, Batch: 3, D Loss: 0.09350743667326356, G Loss: 14.996953964233398\n",
      "Epoch: 8, Batch: 4, D Loss: 0.09929917894193352, G Loss: 15.035839080810547\n",
      "Epoch: 8, Batch: 5, D Loss: 0.09837920806023703, G Loss: 15.039142608642578\n",
      "Epoch: 8, Batch: 6, D Loss: 0.09992996104111285, G Loss: 15.080657005310059\n",
      "Epoch: 8, Batch: 7, D Loss: 0.0945369414881867, G Loss: 15.026796340942383\n",
      "Epoch: 8, Batch: 8, D Loss: 0.09740523811602486, G Loss: 14.956714630126953\n",
      "Epoch: 8, Batch: 9, D Loss: 0.10126136547313536, G Loss: 15.051830291748047\n",
      "Epoch: 8, Batch: 10, D Loss: 0.09829094153658957, G Loss: 15.116395950317383\n",
      "Epoch: 8, Batch: 11, D Loss: 0.10284136767070606, G Loss: 15.28735637664795\n",
      "Epoch: 8, Batch: 12, D Loss: 0.10439550201432723, G Loss: 15.457145690917969\n",
      "Epoch: 8, Batch: 13, D Loss: 0.09971093805850018, G Loss: 15.377204895019531\n",
      "Epoch: 8, Batch: 14, D Loss: 0.10408507673757583, G Loss: 15.319869995117188\n",
      "Epoch: 8, Batch: 15, D Loss: 0.09839305355660599, G Loss: 15.175273895263672\n",
      "Epoch: 8, Batch: 16, D Loss: 0.10127775021241803, G Loss: 15.143670082092285\n",
      "Epoch: 8, Batch: 17, D Loss: 0.0976460797368901, G Loss: 15.23379898071289\n",
      "Epoch: 8, Batch: 18, D Loss: 0.10159412864418016, G Loss: 15.371294021606445\n",
      "Epoch: 8, Batch: 19, D Loss: 0.09922096113918855, G Loss: 15.397762298583984\n",
      "Epoch: 8, Batch: 20, D Loss: 0.09810837592829103, G Loss: 15.328164100646973\n",
      "Epoch: 8, Batch: 21, D Loss: 0.10049451314737468, G Loss: 15.273006439208984\n",
      "Epoch: 8, Batch: 22, D Loss: 0.09067923068579375, G Loss: 14.972160339355469\n",
      "Epoch: 8, Batch: 23, D Loss: 0.10152583006622251, G Loss: 15.053218841552734\n",
      "Epoch: 8, Batch: 24, D Loss: 0.10037293289931881, G Loss: 15.311336517333984\n",
      "Epoch: 8, Batch: 25, D Loss: 0.10216286206108549, G Loss: 15.555509567260742\n",
      "Epoch: 8, Batch: 26, D Loss: 0.10194297919974105, G Loss: 15.51269245147705\n",
      "Epoch: 8, Batch: 27, D Loss: 0.09655987412519096, G Loss: 15.146066665649414\n",
      "Epoch: 8, Batch: 28, D Loss: 0.10190206865991058, G Loss: 14.907087326049805\n",
      "Epoch: 8, Batch: 29, D Loss: 0.09839003636142252, G Loss: 14.858172416687012\n",
      "Epoch: 8, Batch: 30, D Loss: 0.09967344290282654, G Loss: 15.08198070526123\n",
      "Epoch: 8, Batch: 31, D Loss: 0.09067349084183718, G Loss: 15.08177661895752\n",
      "Epoch: 8, Batch: 32, D Loss: 0.10222643355378125, G Loss: 15.214654922485352\n",
      "Epoch: 8, Batch: 33, D Loss: 0.09911494234933116, G Loss: 15.237944602966309\n",
      "Epoch: 8, Batch: 34, D Loss: 0.09712145444453313, G Loss: 15.041814804077148\n",
      "Epoch: 8, Batch: 35, D Loss: 0.09785368526729599, G Loss: 14.892707824707031\n",
      "Epoch: 8, Batch: 36, D Loss: 0.0948328426167393, G Loss: 14.749224662780762\n",
      "Epoch: 8, Batch: 37, D Loss: 0.10418745886158831, G Loss: 14.929832458496094\n",
      "Epoch: 8, Batch: 38, D Loss: 0.09841677377193037, G Loss: 15.042488098144531\n",
      "Epoch: 8, Batch: 39, D Loss: 0.10214085656795646, G Loss: 15.04127311706543\n",
      "Epoch: 8, Batch: 40, D Loss: 0.09767687332845298, G Loss: 14.831764221191406\n",
      "Epoch: 8, Batch: 41, D Loss: 0.09890664423575402, G Loss: 14.627861022949219\n",
      "Epoch: 8, Batch: 42, D Loss: 0.10046726580057452, G Loss: 14.606905937194824\n",
      "Epoch: 8, Batch: 43, D Loss: 0.10258481435703004, G Loss: 14.786273956298828\n",
      "Epoch: 8, Batch: 44, D Loss: 0.09955304707143853, G Loss: 14.914029121398926\n",
      "Epoch: 8, Batch: 45, D Loss: 0.10000352580404126, G Loss: 14.945636749267578\n",
      "Epoch: 8, Batch: 46, D Loss: 0.10024944687842208, G Loss: 14.835451126098633\n",
      "Epoch: 8, Batch: 47, D Loss: 0.1051869463675672, G Loss: 14.940032005310059\n",
      "Epoch: 8, Batch: 48, D Loss: 0.10592435212117834, G Loss: 14.241990089416504\n",
      "Epoch: 8, Batch: 49, D Loss: 0.10315044950220909, G Loss: 14.379547119140625\n",
      "Epoch: 8, Batch: 50, D Loss: 0.0983221212669605, G Loss: 14.214218139648438\n",
      "Epoch: 8, Batch: 51, D Loss: 0.10545277917773888, G Loss: 14.287071228027344\n",
      "Epoch: 8, Batch: 52, D Loss: 0.10235648239296324, G Loss: 14.449539184570312\n",
      "Epoch: 8, Batch: 53, D Loss: 0.10313093738079715, G Loss: 14.64876937866211\n",
      "Epoch: 8, Batch: 54, D Loss: 0.09326494307089206, G Loss: 14.43088150024414\n",
      "Epoch: 8, Batch: 55, D Loss: 0.09121782545469159, G Loss: 14.055325508117676\n",
      "Epoch: 8, Batch: 56, D Loss: 0.10318597320772938, G Loss: 14.167451858520508\n",
      "Epoch: 8, Batch: 57, D Loss: 0.10314719958503815, G Loss: 14.644848823547363\n",
      "Epoch: 8, Batch: 58, D Loss: 0.10021175626111756, G Loss: 15.005781173706055\n",
      "Epoch: 8, Batch: 59, D Loss: 0.0964848380711203, G Loss: 14.886703491210938\n",
      "Epoch: 8, Batch: 60, D Loss: 0.09740214287172932, G Loss: 14.493370056152344\n",
      "Epoch: 8, Batch: 61, D Loss: 0.0991762935684335, G Loss: 14.350473403930664\n",
      "Epoch: 8, Batch: 62, D Loss: 0.09772036348675783, G Loss: 14.460002899169922\n",
      "Epoch: 8, Batch: 63, D Loss: 0.09828467878158165, G Loss: 14.750103950500488\n",
      "Epoch: 8, Batch: 64, D Loss: 0.09934377141770767, G Loss: 14.907376289367676\n",
      "Epoch: 8, Batch: 65, D Loss: 0.10327141395927697, G Loss: 14.99311637878418\n",
      "Epoch: 8, Batch: 66, D Loss: 0.10433689460498385, G Loss: 14.97024154663086\n",
      "Epoch: 8, Batch: 67, D Loss: 0.0974217322463744, G Loss: 14.688302040100098\n",
      "Epoch: 8, Batch: 68, D Loss: 0.10692574971221802, G Loss: 14.748886108398438\n",
      "Epoch: 8, Batch: 69, D Loss: 0.09428293817127553, G Loss: 14.65568733215332\n",
      "Epoch: 8, Batch: 70, D Loss: 0.10188449260519405, G Loss: 14.783538818359375\n",
      "Epoch: 8, Batch: 71, D Loss: 0.09605830098834645, G Loss: 14.829133987426758\n",
      "Epoch: 8, Batch: 72, D Loss: 0.09635626639951056, G Loss: 14.769855499267578\n",
      "Epoch: 8, Batch: 73, D Loss: 0.1030195682825763, G Loss: 14.881526947021484\n",
      "Epoch: 8, Batch: 74, D Loss: 0.10215418373155671, G Loss: 15.116233825683594\n",
      "Epoch: 8, Batch: 75, D Loss: 0.09897116778590487, G Loss: 15.117706298828125\n",
      "Epoch: 8, Batch: 76, D Loss: 0.10305569124503222, G Loss: 15.173469543457031\n",
      "Epoch: 8, Batch: 77, D Loss: 0.10013183052696206, G Loss: 15.226943016052246\n",
      "Epoch: 8, Batch: 78, D Loss: 0.09922017287124163, G Loss: 15.250139236450195\n",
      "Epoch: 8, Batch: 79, D Loss: 0.097882917737806, G Loss: 15.270278930664062\n",
      "Epoch: 8, Batch: 80, D Loss: 0.09838159370810473, G Loss: 15.356231689453125\n",
      "Epoch: 8, Batch: 81, D Loss: 0.1043291596560394, G Loss: 15.582151412963867\n",
      "Epoch: 8, Batch: 82, D Loss: 0.10044269560102492, G Loss: 15.595052719116211\n",
      "Epoch: 8, Batch: 83, D Loss: 0.09643464777159494, G Loss: 15.286910057067871\n",
      "Epoch: 8, Batch: 84, D Loss: 0.09856588933993748, G Loss: 15.022336959838867\n",
      "Epoch: 8, Batch: 85, D Loss: 0.09424779960598073, G Loss: 14.891141891479492\n",
      "Epoch: 8, Batch: 86, D Loss: 0.09628190103011036, G Loss: 14.9681396484375\n",
      "Epoch: 8, Batch: 87, D Loss: 0.10058530612698746, G Loss: 15.2529878616333\n",
      "Epoch: 8, Batch: 88, D Loss: 0.0982591836373885, G Loss: 15.449724197387695\n",
      "Epoch: 8, Batch: 89, D Loss: 0.09541983942283849, G Loss: 15.186026573181152\n",
      "Epoch: 8, Batch: 90, D Loss: 0.09443346644242467, G Loss: 14.763343811035156\n",
      "Epoch: 8, Batch: 91, D Loss: 0.10581890401948613, G Loss: 14.850252151489258\n",
      "Epoch: 8, Batch: 92, D Loss: 0.09789195995108457, G Loss: 15.053056716918945\n",
      "Epoch: 8, Batch: 93, D Loss: 0.09226119889100914, G Loss: 14.95695686340332\n",
      "Epoch: 8, Batch: 94, D Loss: 0.09686658002121362, G Loss: 14.884382247924805\n",
      "Epoch: 8, Batch: 95, D Loss: 0.09690252396330834, G Loss: 14.840963363647461\n",
      "Epoch: 8, Batch: 96, D Loss: 0.0994771282268232, G Loss: 14.917864799499512\n",
      "Epoch: 8, Batch: 97, D Loss: 0.10214574146340283, G Loss: 15.092987060546875\n",
      "Epoch: 8, Batch: 98, D Loss: 0.099263246967638, G Loss: 15.117561340332031\n",
      "Epoch: 8, Batch: 99, D Loss: 0.10612362770969241, G Loss: 15.232109069824219\n",
      "Epoch: 8, Batch: 100, D Loss: 0.10501719746105209, G Loss: 15.308845520019531\n",
      "Epoch: 8, Batch: 101, D Loss: 0.10424887413324058, G Loss: 15.315452575683594\n",
      "Epoch: 8, Batch: 102, D Loss: 0.09717228924094456, G Loss: 15.088706970214844\n",
      "Epoch: 8, Batch: 103, D Loss: 0.10355370505666883, G Loss: 15.067070007324219\n",
      "Epoch: 8, Batch: 104, D Loss: 0.09366233803696389, G Loss: 14.970855712890625\n",
      "Epoch: 8, Batch: 105, D Loss: 0.09422658489329194, G Loss: 14.97232437133789\n",
      "Epoch: 8, Batch: 106, D Loss: 0.09759819179609508, G Loss: 15.118602752685547\n",
      "Epoch: 8, Batch: 107, D Loss: 0.09859667116015203, G Loss: 15.345724105834961\n",
      "Epoch: 8, Batch: 108, D Loss: 0.1015641918012875, G Loss: 15.54807186126709\n",
      "Epoch: 8, Batch: 109, D Loss: 0.10015414717376103, G Loss: 15.514839172363281\n",
      "Epoch: 8, Batch: 110, D Loss: 0.10343172314152582, G Loss: 15.42304515838623\n",
      "Epoch: 8, Batch: 111, D Loss: 0.10036820390703127, G Loss: 15.308619499206543\n",
      "Epoch: 8, Batch: 112, D Loss: 0.1078608288552374, G Loss: 15.535624504089355\n",
      "Epoch: 8, Batch: 113, D Loss: 0.09660527393223362, G Loss: 15.480005264282227\n",
      "Epoch: 8, Batch: 114, D Loss: 0.09714466203752181, G Loss: 15.320329666137695\n",
      "Epoch: 8, Batch: 115, D Loss: 0.09441803617218625, G Loss: 15.151792526245117\n",
      "Epoch: 8, Batch: 116, D Loss: 0.09577019705466228, G Loss: 15.19467830657959\n",
      "Epoch: 8, Batch: 117, D Loss: 0.097832729328033, G Loss: 15.466772079467773\n",
      "Epoch: 8, Batch: 118, D Loss: 0.10327501112313087, G Loss: 15.881928443908691\n",
      "Epoch: 8, Batch: 119, D Loss: 0.10221685247102741, G Loss: 16.069738388061523\n",
      "Epoch: 8, Batch: 120, D Loss: 0.1007177228616527, G Loss: 15.845155715942383\n",
      "Epoch: 8, Batch: 121, D Loss: 0.0979257137652425, G Loss: 15.458351135253906\n",
      "Epoch: 8, Batch: 122, D Loss: 0.10264598997821395, G Loss: 15.37893009185791\n",
      "Epoch: 8, Batch: 123, D Loss: 0.10066440618356864, G Loss: 13.874207496643066\n",
      "Epoch: 8, Batch: 124, D Loss: 0.10062873089538016, G Loss: 14.110172271728516\n",
      "Epoch: 8, Batch: 125, D Loss: 0.10108926639696847, G Loss: 14.127063751220703\n",
      "Epoch: 8, Batch: 126, D Loss: 0.09753512017329058, G Loss: 13.876497268676758\n",
      "Epoch: 8, Batch: 127, D Loss: 0.10034161812700404, G Loss: 13.741724014282227\n",
      "Epoch: 8, Batch: 128, D Loss: 0.1010918455399974, G Loss: 13.868144989013672\n",
      "Epoch: 8, Batch: 129, D Loss: 0.10208175531937513, G Loss: 14.142301559448242\n",
      "Epoch: 8, Batch: 130, D Loss: 0.09842870523823422, G Loss: 14.277217864990234\n",
      "Epoch: 8, Batch: 131, D Loss: 0.10443671579810143, G Loss: 14.353408813476562\n",
      "Epoch: 8, Batch: 132, D Loss: 0.0980860448465819, G Loss: 14.221918106079102\n",
      "Epoch: 8, Batch: 133, D Loss: 0.1020824550703594, G Loss: 14.205497741699219\n",
      "Epoch: 8, Batch: 134, D Loss: 0.10122217940244127, G Loss: 14.361651420593262\n",
      "Epoch: 8, Batch: 135, D Loss: 0.10104234450977856, G Loss: 14.515483856201172\n",
      "Epoch: 8, Batch: 136, D Loss: 0.09688183610171563, G Loss: 14.481014251708984\n",
      "Epoch: 8, Batch: 137, D Loss: 0.09800580169698492, G Loss: 14.34963321685791\n",
      "Epoch: 8, Batch: 138, D Loss: 0.10107580874307587, G Loss: 14.350179672241211\n",
      "Epoch: 8, Batch: 139, D Loss: 0.09936988285608095, G Loss: 14.42318344116211\n",
      "Epoch: 8, Batch: 140, D Loss: 0.10145460149507812, G Loss: 14.50312614440918\n",
      "Epoch: 8, Batch: 141, D Loss: 0.10463357894856529, G Loss: 14.652642250061035\n",
      "Epoch: 8, Batch: 142, D Loss: 0.09349682730555742, G Loss: 14.262659072875977\n",
      "Epoch: 8, Batch: 143, D Loss: 0.09382643907306942, G Loss: 13.849660873413086\n",
      "Epoch: 8, Batch: 144, D Loss: 0.09562137632872236, G Loss: 13.826583862304688\n",
      "Epoch: 8, Batch: 145, D Loss: 0.09889161276061031, G Loss: 14.23882007598877\n",
      "Epoch: 8, Batch: 146, D Loss: 0.09731804821595347, G Loss: 14.657686233520508\n",
      "Epoch: 8, Batch: 147, D Loss: 0.09791348745494588, G Loss: 14.874597549438477\n",
      "Epoch: 8, Batch: 148, D Loss: 0.09930753503131484, G Loss: 14.83482551574707\n",
      "Epoch: 8, Batch: 149, D Loss: 0.10360298596870621, G Loss: 14.747314453125\n",
      "Epoch: 8, Batch: 150, D Loss: 0.096485685042353, G Loss: 14.545909881591797\n",
      "Epoch: 8, Batch: 151, D Loss: 0.1019108997950866, G Loss: 14.543179512023926\n",
      "Epoch: 8, Batch: 152, D Loss: 0.10467601288470973, G Loss: 14.850021362304688\n",
      "Epoch: 8, Batch: 153, D Loss: 0.10608748541206126, G Loss: 15.162226676940918\n",
      "Epoch: 8, Batch: 154, D Loss: 0.0975257471725115, G Loss: 14.886035919189453\n",
      "Epoch: 8, Batch: 155, D Loss: 0.09827776109416675, G Loss: 14.274023056030273\n",
      "Epoch: 8, Batch: 156, D Loss: 0.10099446257748923, G Loss: 14.032230377197266\n",
      "Epoch: 8, Batch: 157, D Loss: 0.10287553598237764, G Loss: 14.273783683776855\n",
      "Epoch: 8, Batch: 158, D Loss: 0.09813619275121255, G Loss: 14.547159194946289\n",
      "Epoch: 8, Batch: 159, D Loss: 0.0984358617292429, G Loss: 14.645153045654297\n",
      "Epoch: 8, Batch: 160, D Loss: 0.10611790799259779, G Loss: 14.765974044799805\n",
      "Epoch: 8, Batch: 161, D Loss: 0.09551687320664826, G Loss: 14.511490821838379\n",
      "Epoch: 8, Batch: 162, D Loss: 0.09528839373535902, G Loss: 14.190145492553711\n",
      "Epoch: 8, Batch: 163, D Loss: 0.1037855532055687, G Loss: 14.36631965637207\n",
      "Epoch: 8, Batch: 164, D Loss: 0.09721376530927728, G Loss: 14.688691139221191\n",
      "Epoch: 8, Batch: 165, D Loss: 0.09844455625312776, G Loss: 14.933338165283203\n",
      "Epoch: 8, Batch: 166, D Loss: 0.10019480271742509, G Loss: 14.94999885559082\n",
      "Epoch: 8, Batch: 167, D Loss: 0.10461125825358408, G Loss: 15.058549880981445\n",
      "Epoch: 8, Batch: 168, D Loss: 0.09324328962421191, G Loss: 14.694252014160156\n",
      "Epoch: 8, Batch: 169, D Loss: 0.10003783875919225, G Loss: 14.530348777770996\n",
      "Epoch: 8, Batch: 170, D Loss: 0.0977986014568728, G Loss: 14.577301025390625\n",
      "Epoch: 8, Batch: 171, D Loss: 0.09904046052355397, G Loss: 14.821554183959961\n",
      "Epoch: 8, Batch: 172, D Loss: 0.10201322258501477, G Loss: 15.03474235534668\n",
      "Epoch: 8, Batch: 173, D Loss: 0.09505347700508082, G Loss: 14.69660758972168\n",
      "Epoch: 8, Batch: 174, D Loss: 0.09986688018918244, G Loss: 14.331441879272461\n",
      "Epoch: 8, Batch: 175, D Loss: 0.10111346632047002, G Loss: 14.213761329650879\n",
      "Epoch: 8, Batch: 176, D Loss: 0.10263420213152585, G Loss: 14.37810230255127\n",
      "Epoch: 8, Batch: 177, D Loss: 0.0998172165535891, G Loss: 14.603606224060059\n",
      "Epoch: 8, Batch: 178, D Loss: 0.09453673547139374, G Loss: 14.523582458496094\n",
      "Epoch: 8, Batch: 179, D Loss: 0.09581038649020002, G Loss: 14.243496894836426\n",
      "Epoch: 8, Batch: 180, D Loss: 0.10208430218949616, G Loss: 14.276256561279297\n",
      "Epoch: 8, Batch: 181, D Loss: 0.09874684379175847, G Loss: 14.435352325439453\n",
      "Epoch: 8, Batch: 182, D Loss: 0.09549877729855893, G Loss: 14.557640075683594\n",
      "Epoch: 8, Batch: 183, D Loss: 0.09568509228355992, G Loss: 14.517646789550781\n",
      "Epoch: 8, Batch: 184, D Loss: 0.10501899678699544, G Loss: 14.645402908325195\n",
      "Epoch: 8, Batch: 185, D Loss: 0.09525379580574622, G Loss: 14.475586891174316\n",
      "Epoch: 8, Batch: 186, D Loss: 0.09361975689279234, G Loss: 14.158540725708008\n",
      "Epoch: 8, Batch: 187, D Loss: 0.09969745375104822, G Loss: 14.36833381652832\n",
      "Epoch: 8, Batch: 188, D Loss: 0.09975485166582132, G Loss: 14.841720581054688\n",
      "Epoch: 8, Batch: 189, D Loss: 0.09237101015506255, G Loss: 14.919300079345703\n",
      "Epoch: 8, Batch: 190, D Loss: 0.09811226888589886, G Loss: 14.8740234375\n",
      "Epoch: 8, Batch: 191, D Loss: 0.0992870545027813, G Loss: 14.910148620605469\n",
      "Epoch: 8, Batch: 192, D Loss: 0.09614452945507423, G Loss: 15.012800216674805\n",
      "Epoch: 8, Batch: 193, D Loss: 0.10453503230458239, G Loss: 15.401874542236328\n",
      "Epoch: 8, Batch: 194, D Loss: 0.0970789146612816, G Loss: 15.603342056274414\n",
      "Epoch: 8, Batch: 195, D Loss: 0.09512571866447672, G Loss: 15.504992485046387\n",
      "Epoch: 8, Batch: 196, D Loss: 0.09880836711593588, G Loss: 15.483023643493652\n",
      "Epoch: 8, Batch: 197, D Loss: 0.09354513350864124, G Loss: 15.393648147583008\n",
      "Epoch: 8, Batch: 198, D Loss: 0.10481957966519673, G Loss: 15.69409465789795\n",
      "Epoch: 8, Batch: 199, D Loss: 0.09951579538247302, G Loss: 15.952400207519531\n",
      "Epoch: 8, Batch: 200, D Loss: 0.09770280339891002, G Loss: 15.866044044494629\n",
      "Epoch: 8, Batch: 201, D Loss: 0.10556089130638213, G Loss: 15.788946151733398\n",
      "Epoch: 8, Batch: 202, D Loss: 0.09366684786778023, G Loss: 15.390678405761719\n",
      "Epoch: 8, Batch: 203, D Loss: 0.10411926905234736, G Loss: 15.280251502990723\n",
      "Epoch: 8, Batch: 204, D Loss: 0.09997765287899796, G Loss: 15.420490264892578\n",
      "Epoch: 8, Batch: 205, D Loss: 0.1052617655625312, G Loss: 15.805204391479492\n",
      "Epoch: 8, Batch: 206, D Loss: 0.09493971360478781, G Loss: 15.52212142944336\n",
      "Epoch: 8, Batch: 207, D Loss: 0.09675995188705855, G Loss: 15.016979217529297\n",
      "Epoch: 8, Batch: 208, D Loss: 0.09630183994640618, G Loss: 14.677963256835938\n",
      "Epoch: 8, Batch: 209, D Loss: 0.09990102416490743, G Loss: 14.808544158935547\n",
      "Epoch: 8, Batch: 210, D Loss: 0.09999228185593267, G Loss: 15.141829490661621\n",
      "Epoch: 8, Batch: 211, D Loss: 0.0968803523761892, G Loss: 15.256938934326172\n",
      "Epoch: 8, Batch: 212, D Loss: 0.09983139272867447, G Loss: 15.161094665527344\n",
      "Epoch: 8, Batch: 213, D Loss: 0.1056488456751481, G Loss: 15.103403091430664\n",
      "Epoch: 8, Batch: 214, D Loss: 0.09204572099284292, G Loss: 14.731527328491211\n",
      "Epoch: 8, Batch: 215, D Loss: 0.10015154929405412, G Loss: 14.695927619934082\n",
      "Epoch: 8, Batch: 216, D Loss: 0.10108597032203193, G Loss: 14.881882667541504\n",
      "Epoch: 8, Batch: 217, D Loss: 0.10160888095728637, G Loss: 15.1444730758667\n",
      "Epoch: 8, Batch: 218, D Loss: 0.10325985018305062, G Loss: 15.2886962890625\n",
      "Epoch: 8, Batch: 219, D Loss: 0.10307022614520633, G Loss: 15.148200988769531\n",
      "Epoch: 8, Batch: 220, D Loss: 0.09921010618845116, G Loss: 14.733634948730469\n",
      "Epoch: 8, Batch: 221, D Loss: 0.09901203732474073, G Loss: 14.478819847106934\n",
      "Epoch: 8, Batch: 222, D Loss: 0.10348714440316087, G Loss: 14.665322303771973\n",
      "Epoch: 8, Batch: 223, D Loss: 0.09712230208870665, G Loss: 14.875511169433594\n",
      "Epoch: 8, Batch: 224, D Loss: 0.10434524867355321, G Loss: 15.144704818725586\n",
      "Epoch: 8, Batch: 225, D Loss: 0.09027943746131939, G Loss: 14.830747604370117\n",
      "Epoch: 8, Batch: 226, D Loss: 0.10175244372749148, G Loss: 14.719825744628906\n",
      "Epoch: 8, Batch: 227, D Loss: 0.10164760523274197, G Loss: 14.908845901489258\n",
      "Epoch: 8, Batch: 228, D Loss: 0.0992128781172994, G Loss: 15.222509384155273\n",
      "Epoch: 8, Batch: 229, D Loss: 0.1023641901210155, G Loss: 15.525165557861328\n",
      "Epoch: 8, Batch: 230, D Loss: 0.09845786948170598, G Loss: 15.464454650878906\n",
      "Epoch: 8, Batch: 231, D Loss: 0.08962000276676463, G Loss: 14.925426483154297\n",
      "Epoch: 8, Batch: 232, D Loss: 0.1034996111775115, G Loss: 14.967545509338379\n",
      "Epoch: 8, Batch: 233, D Loss: 0.106315475696249, G Loss: 15.553169250488281\n",
      "Epoch: 8, Batch: 234, D Loss: 0.10132020288946819, G Loss: 15.97818374633789\n",
      "Epoch: 8, Batch: 235, D Loss: 0.09970778216541021, G Loss: 15.913515090942383\n",
      "Epoch: 8, Batch: 236, D Loss: 0.10428678534822211, G Loss: 15.665119171142578\n",
      "Epoch: 8, Batch: 237, D Loss: 0.09512176171916309, G Loss: 15.165935516357422\n",
      "Epoch: 8, Batch: 238, D Loss: 0.09866727971059674, G Loss: 14.988862037658691\n",
      "Epoch: 8, Batch: 239, D Loss: 0.10409706705709709, G Loss: 15.279792785644531\n",
      "Epoch: 8, Batch: 240, D Loss: 0.10243138124008055, G Loss: 15.579444885253906\n",
      "Epoch: 8, Batch: 241, D Loss: 0.09463773474023185, G Loss: 15.243084907531738\n",
      "Epoch: 8, Batch: 242, D Loss: 0.10004255331509171, G Loss: 14.813570022583008\n",
      "Epoch: 8, Batch: 243, D Loss: 0.09873482385144428, G Loss: 14.532384872436523\n",
      "Epoch: 8, Batch: 244, D Loss: 0.09344206599052995, G Loss: 14.368474960327148\n",
      "Epoch: 8, Batch: 245, D Loss: 0.10344599998825288, G Loss: 14.665273666381836\n",
      "Epoch: 8, Batch: 246, D Loss: 0.10210823119768975, G Loss: 15.104690551757812\n",
      "Epoch: 8, Batch: 247, D Loss: 0.09706412884270321, G Loss: 15.0706787109375\n",
      "Epoch: 8, Batch: 248, D Loss: 0.09826487486481028, G Loss: 14.702983856201172\n",
      "Epoch: 8, Batch: 249, D Loss: 0.09852857652022351, G Loss: 14.446467399597168\n",
      "Epoch: 8, Batch: 250, D Loss: 0.0974041332649449, G Loss: 14.463537216186523\n",
      "Epoch: 8, Batch: 251, D Loss: 0.10672177251304049, G Loss: 14.840866088867188\n",
      "Epoch: 8, Batch: 252, D Loss: 0.09692808029051037, G Loss: 14.953548431396484\n",
      "Epoch: 8, Batch: 253, D Loss: 0.1024353072830877, G Loss: 14.894720077514648\n",
      "Epoch: 8, Batch: 254, D Loss: 0.1026275734010369, G Loss: 14.821972846984863\n",
      "Epoch: 8, Batch: 255, D Loss: 0.10043322572994384, G Loss: 14.760597229003906\n",
      "Epoch: 8, Batch: 256, D Loss: 0.10655855711834761, G Loss: 14.966669082641602\n",
      "Epoch: 8, Batch: 257, D Loss: 0.10119986130825964, G Loss: 15.134044647216797\n",
      "Epoch: 8, Batch: 258, D Loss: 0.09828141813088109, G Loss: 15.064294815063477\n",
      "Epoch: 8, Batch: 259, D Loss: 0.09749512485588241, G Loss: 14.888029098510742\n",
      "Epoch: 8, Batch: 260, D Loss: 0.10042661890784643, G Loss: 14.919098854064941\n",
      "Epoch: 8, Batch: 261, D Loss: 0.09938065496288573, G Loss: 15.151968002319336\n",
      "Epoch: 8, Batch: 262, D Loss: 0.10240596745508412, G Loss: 15.55411148071289\n",
      "Epoch: 8, Batch: 263, D Loss: 0.09983939630174632, G Loss: 15.699151039123535\n",
      "Epoch: 8, Batch: 264, D Loss: 0.09590677754498245, G Loss: 15.416582107543945\n",
      "Epoch: 8, Batch: 265, D Loss: 0.10010164258441279, G Loss: 15.220369338989258\n",
      "Epoch: 8, Batch: 266, D Loss: 0.10009758391387891, G Loss: 14.690206527709961\n",
      "Epoch: 8, Batch: 267, D Loss: 0.09531136321646727, G Loss: 14.788382530212402\n",
      "Epoch: 8, Batch: 268, D Loss: 0.09944684474680798, G Loss: 15.092828750610352\n",
      "Epoch: 8, Batch: 269, D Loss: 0.09972952620286435, G Loss: 15.230414390563965\n",
      "Epoch: 8, Batch: 270, D Loss: 0.09883877563194687, G Loss: 15.054728507995605\n",
      "Epoch: 8, Batch: 271, D Loss: 0.09454810932146529, G Loss: 14.624011993408203\n",
      "Epoch: 8, Batch: 272, D Loss: 0.09943161536759249, G Loss: 14.469042778015137\n",
      "Epoch: 8, Batch: 273, D Loss: 0.10258686099777492, G Loss: 14.735292434692383\n",
      "Epoch: 8, Batch: 274, D Loss: 0.09574209748171825, G Loss: 14.882271766662598\n",
      "Epoch: 8, Batch: 275, D Loss: 0.10272461221235574, G Loss: 15.059951782226562\n",
      "Epoch: 8, Batch: 276, D Loss: 0.09804334908213264, G Loss: 14.945710182189941\n",
      "Epoch: 8, Batch: 277, D Loss: 0.09963014842530526, G Loss: 14.742208480834961\n",
      "Epoch: 8, Batch: 278, D Loss: 0.09437855697657938, G Loss: 14.547452926635742\n",
      "Epoch: 8, Batch: 279, D Loss: 0.1012235113936697, G Loss: 14.772953987121582\n",
      "Epoch: 8, Batch: 280, D Loss: 0.10562967469462592, G Loss: 15.35947322845459\n",
      "Epoch: 8, Batch: 281, D Loss: 0.09861408756370338, G Loss: 15.578191757202148\n",
      "Epoch: 8, Batch: 282, D Loss: 0.09924221385674059, G Loss: 15.428991317749023\n",
      "Epoch: 8, Batch: 283, D Loss: 0.09719554427156396, G Loss: 15.196344375610352\n",
      "Epoch: 8, Batch: 284, D Loss: 0.0998803898070264, G Loss: 15.184671401977539\n",
      "Epoch: 8, Batch: 285, D Loss: 0.0990629755299608, G Loss: 15.369064331054688\n",
      "Epoch: 8, Batch: 286, D Loss: 0.09690048138181595, G Loss: 15.619186401367188\n",
      "Epoch: 8, Batch: 287, D Loss: 0.09813894889887109, G Loss: 15.673299789428711\n",
      "Epoch: 8, Batch: 288, D Loss: 0.09859018994823288, G Loss: 15.530141830444336\n",
      "Epoch: 8, Batch: 289, D Loss: 0.10047571081720719, G Loss: 15.447872161865234\n",
      "Epoch: 8, Batch: 290, D Loss: 0.09759347888669367, G Loss: 15.325396537780762\n",
      "Epoch: 8, Batch: 291, D Loss: 0.0962354883568679, G Loss: 15.112785339355469\n",
      "Epoch: 8, Batch: 292, D Loss: 0.09569645288755169, G Loss: 15.0001220703125\n",
      "Epoch: 8, Batch: 293, D Loss: 0.09146948749258854, G Loss: 14.803958892822266\n",
      "Epoch: 8, Batch: 294, D Loss: 0.101451572586015, G Loss: 14.9166259765625\n",
      "Epoch: 8, Batch: 295, D Loss: 0.09815479572783659, G Loss: 15.064229011535645\n",
      "Epoch: 8, Batch: 296, D Loss: 0.09939404052670398, G Loss: 15.163276672363281\n",
      "Epoch: 8, Batch: 297, D Loss: 0.09897308696710638, G Loss: 15.119247436523438\n",
      "Epoch: 8, Batch: 298, D Loss: 0.10140623764330314, G Loss: 15.059980392456055\n",
      "Epoch: 8, Batch: 299, D Loss: 0.10213702014652881, G Loss: 15.116678237915039\n",
      "Epoch: 8, Batch: 300, D Loss: 0.10277734635653246, G Loss: 15.380474090576172\n",
      "Epoch: 8, Batch: 301, D Loss: 0.10118017289939019, G Loss: 15.538304328918457\n",
      "Epoch: 8, Batch: 302, D Loss: 0.09895548579990532, G Loss: 15.463150024414062\n",
      "Epoch: 8, Batch: 303, D Loss: 0.09857658681072223, G Loss: 15.379002571105957\n",
      "Epoch: 8, Batch: 304, D Loss: 0.10737562931294775, G Loss: 15.679353713989258\n",
      "Epoch: 8, Batch: 305, D Loss: 0.09745713964119318, G Loss: 15.78322982788086\n",
      "Epoch: 8, Batch: 306, D Loss: 0.10434771709455504, G Loss: 15.969160079956055\n",
      "Epoch: 8, Batch: 307, D Loss: 0.10157344284347047, G Loss: 15.986141204833984\n",
      "Epoch: 8, Batch: 308, D Loss: 0.10744409345083739, G Loss: 16.128089904785156\n",
      "Epoch: 8, Batch: 309, D Loss: 0.09759316425451203, G Loss: 15.83023452758789\n",
      "Epoch: 8, Batch: 310, D Loss: 0.09523228730614619, G Loss: 15.399724006652832\n",
      "Epoch: 8, Batch: 311, D Loss: 0.10013003689957145, G Loss: 15.361566543579102\n",
      "Epoch: 8, Batch: 312, D Loss: 0.09300727855129765, G Loss: 15.45666790008545\n",
      "Epoch: 8, Batch: 313, D Loss: 0.10264492674971848, G Loss: 15.800553321838379\n",
      "Epoch: 8, Batch: 314, D Loss: 0.1005162377594715, G Loss: 16.05706787109375\n",
      "Epoch: 8, Batch: 315, D Loss: 0.09539042860303937, G Loss: 15.702836990356445\n",
      "Epoch: 8, Batch: 316, D Loss: 0.10226762863559458, G Loss: 15.426984786987305\n",
      "Epoch: 8, Batch: 317, D Loss: 0.10219294452026162, G Loss: 15.510299682617188\n",
      "Epoch: 8, Batch: 318, D Loss: 0.09910357829632233, G Loss: 15.707803726196289\n",
      "Epoch: 8, Batch: 319, D Loss: 0.09459127294347525, G Loss: 15.780293464660645\n",
      "Epoch: 8, Batch: 320, D Loss: 0.10231170271661938, G Loss: 16.02259063720703\n",
      "Epoch: 8, Batch: 321, D Loss: 0.09339810517498393, G Loss: 15.999881744384766\n",
      "Epoch: 8, Batch: 322, D Loss: 0.0976972879380682, G Loss: 15.88720703125\n",
      "Epoch: 8, Batch: 323, D Loss: 0.10261231555330852, G Loss: 16.02706527709961\n",
      "Epoch: 8, Batch: 324, D Loss: 0.09972186878281164, G Loss: 16.215423583984375\n",
      "Epoch: 8, Batch: 325, D Loss: 0.10186531898905216, G Loss: 16.34920883178711\n",
      "Epoch: 8, Batch: 326, D Loss: 0.10440225309885776, G Loss: 16.392162322998047\n",
      "Epoch: 8, Batch: 327, D Loss: 0.09976368180997497, G Loss: 16.179100036621094\n",
      "Epoch: 8, Batch: 328, D Loss: 0.09547515666925221, G Loss: 15.825491905212402\n",
      "Epoch: 8, Batch: 329, D Loss: 0.09618009711175546, G Loss: 15.60336971282959\n",
      "Epoch: 8, Batch: 330, D Loss: 0.09785391076009375, G Loss: 15.718191146850586\n",
      "Epoch: 8, Batch: 331, D Loss: 0.10077844557861226, G Loss: 16.145984649658203\n",
      "Epoch: 8, Batch: 332, D Loss: 0.10466588590446335, G Loss: 16.502016067504883\n",
      "Epoch: 8, Batch: 333, D Loss: 0.09662752135817598, G Loss: 16.19001007080078\n",
      "Epoch: 8, Batch: 334, D Loss: 0.10031486879404383, G Loss: 15.77508544921875\n",
      "Epoch: 8, Batch: 335, D Loss: 0.10139738250040864, G Loss: 15.613398551940918\n",
      "Epoch: 8, Batch: 336, D Loss: 0.10051908166080636, G Loss: 15.67658805847168\n",
      "Epoch: 8, Batch: 337, D Loss: 0.10418800670395001, G Loss: 16.0578556060791\n",
      "Epoch: 8, Batch: 338, D Loss: 0.10336784023631651, G Loss: 16.18636131286621\n",
      "Epoch: 8, Batch: 339, D Loss: 0.1039746177520513, G Loss: 15.98724365234375\n",
      "Epoch: 8, Batch: 340, D Loss: 0.09913950929212234, G Loss: 15.539649963378906\n",
      "Epoch: 8, Batch: 341, D Loss: 0.09264737440997806, G Loss: 14.540952682495117\n",
      "Epoch: 8, Batch: 342, D Loss: 0.09606272832695595, G Loss: 14.450044631958008\n",
      "Epoch: 8, Batch: 343, D Loss: 0.10571850512499736, G Loss: 15.081886291503906\n",
      "Epoch: 8, Batch: 344, D Loss: 0.10257878768910444, G Loss: 15.6768798828125\n",
      "Epoch: 8, Batch: 345, D Loss: 0.10440626716091828, G Loss: 15.764894485473633\n",
      "Epoch: 8, Batch: 346, D Loss: 0.10217117115495, G Loss: 15.256879806518555\n",
      "Epoch: 8, Batch: 347, D Loss: 0.09771608482449778, G Loss: 14.737757682800293\n",
      "Epoch: 8, Batch: 348, D Loss: 0.1027570453820914, G Loss: 14.851943969726562\n",
      "Epoch: 8, Batch: 349, D Loss: 0.09943211404959129, G Loss: 15.34012222290039\n",
      "Epoch: 8, Batch: 350, D Loss: 0.10304731645210552, G Loss: 15.929206848144531\n",
      "Epoch: 8, Batch: 351, D Loss: 0.09929037145938935, G Loss: 15.938873291015625\n",
      "Epoch: 8, Batch: 352, D Loss: 0.10129873453351479, G Loss: 15.518392562866211\n",
      "Epoch: 8, Batch: 353, D Loss: 0.1066141994403651, G Loss: 15.314611434936523\n",
      "Epoch: 8, Batch: 354, D Loss: 0.10564311450971786, G Loss: 15.4722261428833\n",
      "Epoch: 8, Batch: 355, D Loss: 0.09474259718679434, G Loss: 15.285375595092773\n",
      "Epoch: 8, Batch: 356, D Loss: 0.09458862340832752, G Loss: 14.981884002685547\n",
      "Epoch: 8, Batch: 357, D Loss: 0.09473391749740756, G Loss: 14.789377212524414\n",
      "Epoch: 8, Batch: 358, D Loss: 0.09786639214556203, G Loss: 14.911733627319336\n",
      "Epoch: 8, Batch: 359, D Loss: 0.1020810711299589, G Loss: 15.185819625854492\n",
      "Epoch: 8, Batch: 360, D Loss: 0.098943244441557, G Loss: 15.141653060913086\n",
      "Epoch: 8, Batch: 361, D Loss: 0.09701548151926431, G Loss: 14.786738395690918\n",
      "Epoch: 8, Batch: 362, D Loss: 0.1024719020464886, G Loss: 14.61438274383545\n",
      "Epoch: 8, Batch: 363, D Loss: 0.09792398249044254, G Loss: 14.481695175170898\n",
      "Epoch: 8, Batch: 364, D Loss: 0.09541303811241164, G Loss: 14.34214973449707\n",
      "Epoch: 8, Batch: 365, D Loss: 0.10260656457961659, G Loss: 14.639575004577637\n",
      "Epoch: 8, Batch: 366, D Loss: 0.10184351740014108, G Loss: 14.99059772491455\n",
      "Epoch: 8, Batch: 367, D Loss: 0.10707018558822767, G Loss: 15.255509376525879\n",
      "Epoch: 8, Batch: 368, D Loss: 0.1024125240525251, G Loss: 15.097232818603516\n",
      "Epoch: 8, Batch: 369, D Loss: 0.10123908795458192, G Loss: 14.752376556396484\n",
      "Epoch: 8, Batch: 370, D Loss: 0.09687541056015903, G Loss: 14.474593162536621\n",
      "Epoch: 8, Batch: 371, D Loss: 0.09515418522678942, G Loss: 14.388530731201172\n",
      "Epoch: 8, Batch: 372, D Loss: 0.10322795191382284, G Loss: 12.824685096740723\n",
      "Epoch: 8, Batch: 373, D Loss: 0.101837054607131, G Loss: 13.350931167602539\n",
      "Epoch: 8, Batch: 374, D Loss: 0.10072642904810891, G Loss: 13.57718276977539\n",
      "Epoch: 8, Batch: 375, D Loss: 0.10146908206036187, G Loss: 13.40926742553711\n",
      "Epoch: 8, Batch: 376, D Loss: 0.09767110203330276, G Loss: 13.134553909301758\n",
      "Epoch: 8, Batch: 377, D Loss: 0.09915386781085544, G Loss: 13.093132019042969\n",
      "Epoch: 8, Batch: 378, D Loss: 0.10206489949121078, G Loss: 13.427180290222168\n",
      "Epoch: 8, Batch: 379, D Loss: 0.09634325504919161, G Loss: 13.800180435180664\n",
      "Epoch: 8, Batch: 380, D Loss: 0.10329416911002909, G Loss: 14.124772071838379\n",
      "Epoch: 8, Batch: 381, D Loss: 0.10739740327011305, G Loss: 14.325122833251953\n",
      "Epoch: 8, Batch: 382, D Loss: 0.09252399570158332, G Loss: 13.654403686523438\n",
      "Epoch: 8, Batch: 383, D Loss: 0.09684163230235754, G Loss: 13.182318687438965\n",
      "Epoch: 8, Batch: 384, D Loss: 0.09919899392593834, G Loss: 13.21401309967041\n",
      "Epoch: 8, Batch: 385, D Loss: 0.10446016441619577, G Loss: 12.503592491149902\n",
      "Epoch: 8, Batch: 386, D Loss: 0.10017718608310133, G Loss: 12.853248596191406\n",
      "Epoch: 8, Batch: 387, D Loss: 0.0993875841074896, G Loss: 12.987699508666992\n",
      "Epoch: 8, Batch: 388, D Loss: 0.09922256287427444, G Loss: 12.765291213989258\n",
      "Epoch: 8, Batch: 389, D Loss: 0.10091226561621625, G Loss: 12.714666366577148\n",
      "Epoch: 8, Batch: 390, D Loss: 0.09604649528648679, G Loss: 12.933356285095215\n",
      "Epoch: 8, Batch: 391, D Loss: 0.10134341989510176, G Loss: 13.627230644226074\n",
      "Epoch: 8, Batch: 392, D Loss: 0.09612326057060727, G Loss: 14.187150955200195\n",
      "Epoch: 8, Batch: 393, D Loss: 0.09624389908901776, G Loss: 14.251640319824219\n",
      "Epoch: 8, Batch: 394, D Loss: 0.093618174410949, G Loss: 11.189912796020508\n",
      "Epoch: 8, Batch: 395, D Loss: 0.09833115321043806, G Loss: 11.690860748291016\n",
      "Epoch: 8, Batch: 396, D Loss: 0.09512643031484913, G Loss: 12.396242141723633\n",
      "Epoch: 8, Batch: 397, D Loss: 0.09884370491135996, G Loss: 13.4869384765625\n",
      "Epoch: 8, Batch: 398, D Loss: 0.09087710658889137, G Loss: 13.725818634033203\n",
      "Epoch: 8, Batch: 399, D Loss: 0.1003303059168843, G Loss: 14.005243301391602\n",
      "Epoch: 8, Batch: 400, D Loss: 0.10426140446691079, G Loss: 14.505484580993652\n",
      "Epoch: 8, Batch: 401, D Loss: 0.10377478233161241, G Loss: 14.893814086914062\n",
      "Epoch: 8, Batch: 402, D Loss: 0.10226274723477502, G Loss: 15.003308296203613\n",
      "Epoch: 8, Batch: 403, D Loss: 0.0944439144097089, G Loss: 14.580718994140625\n",
      "Epoch: 8, Batch: 404, D Loss: 0.09730783611766469, G Loss: 14.387006759643555\n",
      "Epoch: 8, Batch: 405, D Loss: 0.10103411985592459, G Loss: 14.85999870300293\n",
      "Epoch: 8, Batch: 406, D Loss: 0.09559538627655684, G Loss: 15.021373748779297\n",
      "Epoch: 8, Batch: 407, D Loss: 0.10302785841387418, G Loss: 15.700560569763184\n",
      "Epoch: 8, Batch: 408, D Loss: 0.09596140070992476, G Loss: 15.526264190673828\n",
      "Epoch: 8, Batch: 409, D Loss: 0.10394912737233852, G Loss: 15.296567916870117\n",
      "Epoch: 8, Batch: 410, D Loss: 0.10302927758669966, G Loss: 15.52397346496582\n",
      "Epoch: 8, Batch: 411, D Loss: 0.09845843403702048, G Loss: 15.837287902832031\n",
      "Epoch: 8, Batch: 412, D Loss: 0.09892054864624811, G Loss: 15.754057884216309\n",
      "Epoch: 8, Batch: 413, D Loss: 0.09789724233267805, G Loss: 15.607215881347656\n",
      "Epoch: 8, Batch: 414, D Loss: 0.09937310275655875, G Loss: 15.463462829589844\n",
      "Epoch: 8, Batch: 415, D Loss: 0.10466621485925032, G Loss: 15.676532745361328\n",
      "Epoch: 8, Batch: 416, D Loss: 0.09280584082031851, G Loss: 14.977383613586426\n",
      "Epoch: 8, Batch: 417, D Loss: 0.09408259109849837, G Loss: 14.393218994140625\n",
      "Epoch: 8, Batch: 418, D Loss: 0.10146526637140596, G Loss: 14.307840347290039\n",
      "Epoch: 8, Batch: 419, D Loss: 0.09849937929092789, G Loss: 14.414752960205078\n",
      "Epoch: 8, Batch: 420, D Loss: 0.10318150318256869, G Loss: 14.753134727478027\n",
      "Epoch: 8, Batch: 421, D Loss: 0.10381151723703397, G Loss: 14.777137756347656\n",
      "Epoch: 8, Batch: 422, D Loss: 0.09699613466167989, G Loss: 14.313026428222656\n",
      "Epoch: 8, Batch: 423, D Loss: 0.09781116843092263, G Loss: 13.90424633026123\n",
      "Epoch: 8, Batch: 424, D Loss: 0.09542862243586114, G Loss: 13.839086532592773\n",
      "Epoch: 8, Batch: 425, D Loss: 0.09666032320120621, G Loss: 14.288568496704102\n",
      "Epoch: 8, Batch: 426, D Loss: 0.09719049005188651, G Loss: 15.058073043823242\n",
      "Epoch: 8, Batch: 427, D Loss: 0.09929562661295677, G Loss: 15.387920379638672\n",
      "Epoch: 8, Batch: 428, D Loss: 0.09034894703496832, G Loss: 14.319169998168945\n",
      "Epoch: 8, Batch: 429, D Loss: 0.09857775802066726, G Loss: 13.593793869018555\n",
      "Epoch: 8, Batch: 430, D Loss: 0.10049295085678978, G Loss: 13.481338500976562\n",
      "Epoch: 8, Batch: 431, D Loss: 0.08940842017807427, G Loss: 13.246454238891602\n",
      "Epoch: 8, Batch: 432, D Loss: 0.10491503473696184, G Loss: 13.501285552978516\n",
      "Epoch: 8, Batch: 433, D Loss: 0.09423344748017826, G Loss: 13.314970016479492\n",
      "Epoch: 8, Batch: 434, D Loss: 0.09694734357174184, G Loss: 12.98486328125\n",
      "Epoch: 8, Batch: 435, D Loss: 0.09451819702383091, G Loss: 12.784341812133789\n",
      "Epoch: 8, Batch: 436, D Loss: 0.10847258672868065, G Loss: 13.275879859924316\n",
      "Epoch: 8, Batch: 437, D Loss: 0.09902276803074983, G Loss: 13.67751693725586\n",
      "Epoch: 8, Batch: 438, D Loss: 0.10158314644513666, G Loss: 13.770184516906738\n",
      "Epoch: 8, Batch: 439, D Loss: 0.09818420854264787, G Loss: 13.422067642211914\n",
      "Epoch: 8, Batch: 440, D Loss: 0.10610130512395699, G Loss: 13.542612075805664\n",
      "Epoch: 8, Batch: 441, D Loss: 0.10123112585233685, G Loss: 13.723787307739258\n",
      "Epoch: 8, Batch: 442, D Loss: 0.09402948936713074, G Loss: 13.61495590209961\n",
      "Epoch: 8, Batch: 443, D Loss: 0.09827712945929079, G Loss: 13.56045913696289\n",
      "Epoch: 8, Batch: 444, D Loss: 0.10733825071469028, G Loss: 13.92000961303711\n",
      "Epoch: 8, Batch: 445, D Loss: 0.09717764246488514, G Loss: 13.932262420654297\n",
      "Epoch: 8, Batch: 446, D Loss: 0.09426800150004055, G Loss: 13.563390731811523\n",
      "Epoch: 8, Batch: 447, D Loss: 0.09366676203217139, G Loss: 13.301761627197266\n",
      "Epoch: 8, Batch: 448, D Loss: 0.08904615847194464, G Loss: 13.177230834960938\n",
      "Epoch: 8, Batch: 449, D Loss: 0.10458173189942954, G Loss: 13.659903526306152\n",
      "Epoch: 8, Batch: 450, D Loss: 0.09996217172738397, G Loss: 14.256927490234375\n",
      "Epoch: 8, Batch: 451, D Loss: 0.0987069010510595, G Loss: 14.408480644226074\n",
      "Epoch: 8, Batch: 452, D Loss: 0.09568549492601619, G Loss: 13.898581504821777\n",
      "Epoch: 8, Batch: 453, D Loss: 0.09578565679635176, G Loss: 13.345999717712402\n",
      "Epoch: 8, Batch: 454, D Loss: 0.0989646276568692, G Loss: 13.37906551361084\n",
      "Epoch: 8, Batch: 455, D Loss: 0.10498580058595053, G Loss: 13.850702285766602\n",
      "Epoch: 8, Batch: 456, D Loss: 0.09961527900236433, G Loss: 14.226823806762695\n",
      "Epoch: 8, Batch: 457, D Loss: 0.09757963025447225, G Loss: 14.243608474731445\n",
      "Epoch: 8, Batch: 458, D Loss: 0.09925923060075093, G Loss: 14.020652770996094\n",
      "Epoch: 8, Batch: 459, D Loss: 0.10449842061797199, G Loss: 14.032855033874512\n",
      "Epoch: 8, Batch: 460, D Loss: 0.09657070716940552, G Loss: 14.045684814453125\n",
      "Epoch: 8, Batch: 461, D Loss: 0.0956887472605672, G Loss: 14.09329605102539\n",
      "Epoch: 8, Batch: 462, D Loss: 0.0883375668630606, G Loss: 14.00514030456543\n",
      "Epoch: 8, Batch: 463, D Loss: 0.0998746207187935, G Loss: 14.226568222045898\n",
      "Epoch: 8, Batch: 464, D Loss: 0.10158246347941713, G Loss: 13.227924346923828\n",
      "Epoch: 8, Batch: 465, D Loss: 0.10116012505659455, G Loss: 12.731973648071289\n",
      "Epoch: 8, Batch: 466, D Loss: 0.09801408336966233, G Loss: 12.861984252929688\n",
      "Epoch: 8, Batch: 467, D Loss: 0.09999161241387355, G Loss: 12.800776481628418\n",
      "Epoch: 9, Batch: 0, D Loss: 0.09599062465645147, G Loss: 12.841197967529297\n",
      "Epoch: 9, Batch: 1, D Loss: 0.09699685153805149, G Loss: 13.230283737182617\n",
      "Epoch: 9, Batch: 2, D Loss: 0.10502783959645967, G Loss: 12.821481704711914\n",
      "Epoch: 9, Batch: 3, D Loss: 0.09742998641058875, G Loss: 13.39897346496582\n",
      "Epoch: 9, Batch: 4, D Loss: 0.10176218436254203, G Loss: 12.568498611450195\n",
      "Epoch: 9, Batch: 5, D Loss: 0.09951587496107095, G Loss: 10.37959098815918\n",
      "Epoch: 9, Batch: 6, D Loss: 0.0980714252400503, G Loss: 11.485025405883789\n",
      "Epoch: 9, Batch: 7, D Loss: 0.10539296140291299, G Loss: 13.621825218200684\n",
      "Epoch: 9, Batch: 8, D Loss: 0.1034199565036431, G Loss: 15.836339950561523\n",
      "Epoch: 9, Batch: 9, D Loss: 0.09896789408615092, G Loss: 16.62291717529297\n",
      "Epoch: 9, Batch: 10, D Loss: 0.10332310817332768, G Loss: 16.460357666015625\n",
      "Epoch: 9, Batch: 11, D Loss: 0.10100245375722494, G Loss: 15.610018730163574\n",
      "Epoch: 9, Batch: 12, D Loss: 0.09680287388522402, G Loss: 14.101356506347656\n",
      "Epoch: 9, Batch: 13, D Loss: 0.09747097055770837, G Loss: 13.785938262939453\n",
      "Epoch: 9, Batch: 14, D Loss: 0.093068870781849, G Loss: 13.536689758300781\n",
      "Epoch: 9, Batch: 15, D Loss: 0.09540628430875131, G Loss: 13.122275352478027\n",
      "Epoch: 9, Batch: 16, D Loss: 0.09341097504875506, G Loss: 11.737344741821289\n",
      "Epoch: 9, Batch: 17, D Loss: 0.09929311183350364, G Loss: 11.651250839233398\n",
      "Epoch: 9, Batch: 18, D Loss: 0.09758308201344335, G Loss: 11.321050643920898\n",
      "Epoch: 9, Batch: 19, D Loss: 0.10444720166879051, G Loss: 12.222373008728027\n",
      "Epoch: 9, Batch: 20, D Loss: 0.09747300856361107, G Loss: 12.103594779968262\n",
      "Epoch: 9, Batch: 21, D Loss: 0.09885516912709136, G Loss: 12.720298767089844\n",
      "Epoch: 9, Batch: 22, D Loss: 0.10749410476364574, G Loss: 13.49156379699707\n",
      "Epoch: 9, Batch: 23, D Loss: 0.09886283743776403, G Loss: 13.477836608886719\n",
      "Epoch: 9, Batch: 24, D Loss: 0.09891028452551609, G Loss: 13.565438270568848\n",
      "Epoch: 9, Batch: 25, D Loss: 0.10054540107967114, G Loss: 12.996036529541016\n",
      "Epoch: 9, Batch: 26, D Loss: 0.09799575145734707, G Loss: 12.889421463012695\n",
      "Epoch: 9, Batch: 27, D Loss: 0.09725634686310514, G Loss: 13.262165069580078\n",
      "Epoch: 9, Batch: 28, D Loss: 0.10050786999818229, G Loss: 10.962606430053711\n",
      "Epoch: 9, Batch: 29, D Loss: 0.10111523938940081, G Loss: 11.861433982849121\n",
      "Epoch: 9, Batch: 30, D Loss: 0.09952257466648007, G Loss: 10.929616928100586\n",
      "Epoch: 9, Batch: 31, D Loss: 0.10355689662810619, G Loss: 13.323887825012207\n",
      "Epoch: 9, Batch: 32, D Loss: 0.09444416369501596, G Loss: 14.23903751373291\n",
      "Epoch: 9, Batch: 33, D Loss: 0.09962657660105378, G Loss: 16.080514907836914\n",
      "Epoch: 9, Batch: 34, D Loss: 0.10571589953104876, G Loss: 11.12652587890625\n",
      "Epoch: 9, Batch: 35, D Loss: 0.09490161089343019, G Loss: 9.742877006530762\n",
      "Epoch: 9, Batch: 36, D Loss: 0.10060526049619511, G Loss: 13.258445739746094\n",
      "Epoch: 9, Batch: 37, D Loss: 0.09846791465224669, G Loss: 15.9094877243042\n",
      "Epoch: 9, Batch: 38, D Loss: 0.10386379104758703, G Loss: 15.277066230773926\n",
      "Epoch: 9, Batch: 39, D Loss: 0.0980450494881211, G Loss: 16.612382888793945\n",
      "Epoch: 9, Batch: 40, D Loss: 0.090346050266362, G Loss: 12.70707893371582\n",
      "Epoch: 9, Batch: 41, D Loss: 0.10269495351531077, G Loss: 12.171199798583984\n",
      "Epoch: 9, Batch: 42, D Loss: 0.10613526260476647, G Loss: 13.142059326171875\n",
      "Epoch: 9, Batch: 43, D Loss: 0.10429443323437226, G Loss: 13.8838472366333\n",
      "Epoch: 9, Batch: 44, D Loss: 0.10010892457853515, G Loss: 11.563228607177734\n",
      "Epoch: 9, Batch: 45, D Loss: 0.10123586424742825, G Loss: 9.621538162231445\n",
      "Epoch: 9, Batch: 46, D Loss: 0.0988368522375822, G Loss: 10.905614852905273\n",
      "Epoch: 9, Batch: 47, D Loss: 0.10189153682040342, G Loss: 13.171728134155273\n",
      "Epoch: 9, Batch: 48, D Loss: 0.10101043809668653, G Loss: 17.452816009521484\n",
      "Epoch: 9, Batch: 49, D Loss: 0.09715574006190852, G Loss: 19.894495010375977\n",
      "Epoch: 9, Batch: 50, D Loss: 0.1004155149753867, G Loss: 20.278444290161133\n",
      "Epoch: 9, Batch: 51, D Loss: 0.10162587606995532, G Loss: 20.554916381835938\n",
      "Epoch: 9, Batch: 52, D Loss: 0.09886463016614044, G Loss: 14.977940559387207\n",
      "Epoch: 9, Batch: 53, D Loss: 0.09851614747367421, G Loss: 11.755110740661621\n",
      "Epoch: 9, Batch: 54, D Loss: 0.10512365796830636, G Loss: 10.981523513793945\n",
      "Epoch: 9, Batch: 55, D Loss: 0.09498730959603563, G Loss: 10.414449691772461\n",
      "Epoch: 9, Batch: 56, D Loss: 0.10212315425451379, G Loss: 12.028437614440918\n",
      "Epoch: 9, Batch: 57, D Loss: 0.09852208701563825, G Loss: 17.535005569458008\n",
      "Epoch: 9, Batch: 58, D Loss: 0.09927715170514251, G Loss: 20.221364974975586\n",
      "Epoch: 9, Batch: 59, D Loss: 0.09629649755759656, G Loss: 21.4267578125\n",
      "Epoch: 9, Batch: 60, D Loss: 0.0966702179165924, G Loss: 23.080860137939453\n",
      "Epoch: 9, Batch: 61, D Loss: 0.10623918475207117, G Loss: 25.278268814086914\n",
      "Epoch: 9, Batch: 62, D Loss: 0.09132487327185941, G Loss: 26.19169044494629\n",
      "Epoch: 9, Batch: 63, D Loss: 0.09761540591883044, G Loss: 26.715179443359375\n",
      "Epoch: 9, Batch: 64, D Loss: 0.10651022199157635, G Loss: 23.828147888183594\n",
      "Epoch: 9, Batch: 65, D Loss: 0.10571509600958186, G Loss: 24.9049129486084\n",
      "Epoch: 9, Batch: 66, D Loss: 0.10236044228701387, G Loss: 25.28774070739746\n",
      "Epoch: 9, Batch: 67, D Loss: 0.10574184358840148, G Loss: 24.914653778076172\n",
      "Epoch: 9, Batch: 68, D Loss: 0.1011818647499271, G Loss: 24.140270233154297\n",
      "Epoch: 9, Batch: 69, D Loss: 0.10806966576597038, G Loss: 23.276321411132812\n",
      "Epoch: 9, Batch: 70, D Loss: 0.09479455655225397, G Loss: 22.660049438476562\n",
      "Epoch: 9, Batch: 71, D Loss: 0.09023390722987579, G Loss: 21.685304641723633\n",
      "Epoch: 9, Batch: 72, D Loss: 0.10245053490148509, G Loss: 21.59714126586914\n",
      "Epoch: 9, Batch: 73, D Loss: 0.09924358149750717, G Loss: 21.65460205078125\n",
      "Epoch: 9, Batch: 74, D Loss: 0.091148451196953, G Loss: 21.40045166015625\n",
      "Epoch: 9, Batch: 75, D Loss: 0.09874746261137024, G Loss: 20.491390228271484\n",
      "Epoch: 9, Batch: 76, D Loss: 0.09488869532169159, G Loss: 20.203018188476562\n",
      "Epoch: 9, Batch: 77, D Loss: 0.09290317545292659, G Loss: 19.887937545776367\n",
      "Epoch: 9, Batch: 78, D Loss: 0.09714460493373578, G Loss: 19.804603576660156\n",
      "Epoch: 9, Batch: 79, D Loss: 0.10135903314563799, G Loss: 20.13860511779785\n",
      "Epoch: 9, Batch: 80, D Loss: 0.0972543963547296, G Loss: 20.199363708496094\n",
      "Epoch: 9, Batch: 81, D Loss: 0.09962909768032635, G Loss: 19.941394805908203\n",
      "Epoch: 9, Batch: 82, D Loss: 0.09788720471539081, G Loss: 19.40547752380371\n",
      "Epoch: 9, Batch: 83, D Loss: 0.09792390671713136, G Loss: 19.219785690307617\n",
      "Epoch: 9, Batch: 84, D Loss: 0.09347541873624565, G Loss: 19.0695858001709\n",
      "Epoch: 9, Batch: 85, D Loss: 0.0924022374167992, G Loss: 18.97723388671875\n",
      "Epoch: 9, Batch: 86, D Loss: 0.0992400076364992, G Loss: 19.148723602294922\n",
      "Epoch: 9, Batch: 87, D Loss: 0.09619145371756299, G Loss: 19.055889129638672\n",
      "Epoch: 9, Batch: 88, D Loss: 0.09619257132066084, G Loss: 18.966293334960938\n",
      "Epoch: 9, Batch: 89, D Loss: 0.09885342729054614, G Loss: 18.838773727416992\n",
      "Epoch: 9, Batch: 90, D Loss: 0.0954780316129531, G Loss: 18.698287963867188\n",
      "Epoch: 9, Batch: 91, D Loss: 0.09870170619101826, G Loss: 18.322237014770508\n",
      "Epoch: 9, Batch: 92, D Loss: 0.09559670619173044, G Loss: 18.404983520507812\n",
      "Epoch: 9, Batch: 93, D Loss: 0.0970225755960521, G Loss: 18.463146209716797\n",
      "Epoch: 9, Batch: 94, D Loss: 0.09612118198081054, G Loss: 18.419599533081055\n",
      "Epoch: 9, Batch: 95, D Loss: 0.09757046923218571, G Loss: 18.34332275390625\n",
      "Epoch: 9, Batch: 96, D Loss: 0.09561059541204742, G Loss: 18.116174697875977\n",
      "Epoch: 9, Batch: 97, D Loss: 0.10319675362193426, G Loss: 17.531864166259766\n",
      "Epoch: 9, Batch: 98, D Loss: 0.10197981230615127, G Loss: 17.598041534423828\n",
      "Epoch: 9, Batch: 99, D Loss: 0.10570627436981894, G Loss: 17.421714782714844\n",
      "Epoch: 9, Batch: 100, D Loss: 0.0980000198479285, G Loss: 17.236970901489258\n",
      "Epoch: 9, Batch: 101, D Loss: 0.09886487909440334, G Loss: 17.025197982788086\n",
      "Epoch: 9, Batch: 102, D Loss: 0.08952696775237534, G Loss: 16.70447540283203\n",
      "Epoch: 9, Batch: 103, D Loss: 0.10081523318592645, G Loss: 16.803035736083984\n",
      "Epoch: 9, Batch: 104, D Loss: 0.10073255541481352, G Loss: 17.217472076416016\n",
      "Epoch: 9, Batch: 105, D Loss: 0.0921409002499729, G Loss: 17.239032745361328\n",
      "Epoch: 9, Batch: 106, D Loss: 0.09825815755127465, G Loss: 16.993864059448242\n",
      "Epoch: 9, Batch: 107, D Loss: 0.10277587837602553, G Loss: 16.93196678161621\n",
      "Epoch: 9, Batch: 108, D Loss: 0.09613540912503815, G Loss: 16.797382354736328\n",
      "Epoch: 9, Batch: 109, D Loss: 0.0897682737674188, G Loss: 16.355976104736328\n",
      "Epoch: 9, Batch: 110, D Loss: 0.11004963728203876, G Loss: 16.52082061767578\n",
      "Epoch: 9, Batch: 111, D Loss: 0.09467221094073608, G Loss: 16.712642669677734\n",
      "Epoch: 9, Batch: 112, D Loss: 0.09932026757193313, G Loss: 16.73651885986328\n",
      "Epoch: 9, Batch: 113, D Loss: 0.10180868782883934, G Loss: 16.657424926757812\n",
      "Epoch: 9, Batch: 114, D Loss: 0.0999408448419814, G Loss: 16.5560302734375\n",
      "Epoch: 9, Batch: 115, D Loss: 0.1009906852702187, G Loss: 16.558725357055664\n",
      "Epoch: 9, Batch: 116, D Loss: 0.09885030346710266, G Loss: 16.638614654541016\n",
      "Epoch: 9, Batch: 117, D Loss: 0.09987370488141423, G Loss: 16.75106430053711\n",
      "Epoch: 9, Batch: 118, D Loss: 0.10132441886332089, G Loss: 16.390390396118164\n",
      "Epoch: 9, Batch: 119, D Loss: 0.090997493915566, G Loss: 16.123714447021484\n",
      "Epoch: 9, Batch: 120, D Loss: 0.10022339870014463, G Loss: 16.070560455322266\n",
      "Epoch: 9, Batch: 121, D Loss: 0.09748865453934386, G Loss: 16.160053253173828\n",
      "Epoch: 9, Batch: 122, D Loss: 0.09124504831339308, G Loss: 16.057628631591797\n",
      "Epoch: 9, Batch: 123, D Loss: 0.09886111965631983, G Loss: 15.683191299438477\n",
      "Epoch: 9, Batch: 124, D Loss: 0.09808683170606969, G Loss: 15.811330795288086\n",
      "Epoch: 9, Batch: 125, D Loss: 0.09858483015244701, G Loss: 15.855106353759766\n",
      "Epoch: 9, Batch: 126, D Loss: 0.09685083520724902, G Loss: 15.786611557006836\n",
      "Epoch: 9, Batch: 127, D Loss: 0.09291054482555694, G Loss: 15.616491317749023\n",
      "Epoch: 9, Batch: 128, D Loss: 0.10287480946323058, G Loss: 15.782808303833008\n",
      "Epoch: 9, Batch: 129, D Loss: 0.09252871979434474, G Loss: 15.782434463500977\n",
      "Epoch: 9, Batch: 130, D Loss: 0.10390458532536684, G Loss: 16.016586303710938\n",
      "Epoch: 9, Batch: 131, D Loss: 0.0932742179342938, G Loss: 15.359750747680664\n",
      "Epoch: 9, Batch: 132, D Loss: 0.09808859606133069, G Loss: 14.714279174804688\n",
      "Epoch: 9, Batch: 133, D Loss: 0.09920272389490492, G Loss: 14.725828170776367\n",
      "Epoch: 9, Batch: 134, D Loss: 0.10177244849217004, G Loss: 14.890459060668945\n",
      "Epoch: 9, Batch: 135, D Loss: 0.10896808762359456, G Loss: 15.233604431152344\n",
      "Epoch: 9, Batch: 136, D Loss: 0.09957636737254916, G Loss: 15.064136505126953\n",
      "Epoch: 9, Batch: 137, D Loss: 0.1033201973810094, G Loss: 14.801310539245605\n",
      "Epoch: 9, Batch: 138, D Loss: 0.09837921172274378, G Loss: 14.5791654586792\n",
      "Epoch: 9, Batch: 139, D Loss: 0.09742116151727487, G Loss: 14.18518352508545\n",
      "Epoch: 9, Batch: 140, D Loss: 0.10487793420662683, G Loss: 14.56690788269043\n",
      "Epoch: 9, Batch: 141, D Loss: 0.09951228709799409, G Loss: 14.798640251159668\n",
      "Epoch: 9, Batch: 142, D Loss: 0.09631408722276547, G Loss: 14.598605155944824\n",
      "Epoch: 9, Batch: 143, D Loss: 0.1012188648315373, G Loss: 14.403972625732422\n",
      "Epoch: 9, Batch: 144, D Loss: 0.09911269969836667, G Loss: 14.349849700927734\n",
      "Epoch: 9, Batch: 145, D Loss: 0.1023425787003589, G Loss: 13.730891227722168\n",
      "Epoch: 9, Batch: 146, D Loss: 0.09322775213809109, G Loss: 13.740287780761719\n",
      "Epoch: 9, Batch: 147, D Loss: 0.10172773278787872, G Loss: 13.808372497558594\n",
      "Epoch: 9, Batch: 148, D Loss: 0.09299256664405675, G Loss: 13.646217346191406\n",
      "Epoch: 9, Batch: 149, D Loss: 0.09464755426836291, G Loss: 13.537849426269531\n",
      "Epoch: 9, Batch: 150, D Loss: 0.09909205796992637, G Loss: 13.654226303100586\n",
      "Epoch: 9, Batch: 151, D Loss: 0.09991719167419433, G Loss: 13.910271644592285\n",
      "Epoch: 9, Batch: 152, D Loss: 0.0940005455516939, G Loss: 13.570745468139648\n",
      "Epoch: 9, Batch: 153, D Loss: 0.10308595102219442, G Loss: 13.197334289550781\n",
      "Epoch: 9, Batch: 154, D Loss: 0.10461137859465452, G Loss: 13.355932235717773\n",
      "Epoch: 9, Batch: 155, D Loss: 0.09723733783903299, G Loss: 13.330904960632324\n",
      "Epoch: 9, Batch: 156, D Loss: 0.1038477851967059, G Loss: 13.456485748291016\n",
      "Epoch: 9, Batch: 157, D Loss: 0.10091598215547037, G Loss: 13.639833450317383\n",
      "Epoch: 9, Batch: 158, D Loss: 0.10318720761182476, G Loss: 13.91534423828125\n",
      "Epoch: 9, Batch: 159, D Loss: 0.09982192479304786, G Loss: 14.012959480285645\n",
      "Epoch: 9, Batch: 160, D Loss: 0.1005822241640999, G Loss: 14.03759765625\n",
      "Epoch: 9, Batch: 161, D Loss: 0.10027740874625124, G Loss: 14.10890007019043\n",
      "Epoch: 9, Batch: 162, D Loss: 0.10500279562899095, G Loss: 14.374610900878906\n",
      "Epoch: 9, Batch: 163, D Loss: 0.09793049800157405, G Loss: 14.451929092407227\n",
      "Epoch: 9, Batch: 164, D Loss: 0.09886306134319511, G Loss: 14.406454086303711\n",
      "Epoch: 9, Batch: 165, D Loss: 0.09693230751756232, G Loss: 14.316446304321289\n",
      "Epoch: 9, Batch: 166, D Loss: 0.10302148636117181, G Loss: 14.459059715270996\n",
      "Epoch: 9, Batch: 167, D Loss: 0.0984270509260341, G Loss: 14.581319808959961\n",
      "Epoch: 9, Batch: 168, D Loss: 0.0975226341484472, G Loss: 14.574996948242188\n",
      "Epoch: 9, Batch: 169, D Loss: 0.10048001408242158, G Loss: 14.59186840057373\n",
      "Epoch: 9, Batch: 170, D Loss: 0.09281349071497402, G Loss: 14.366596221923828\n",
      "Epoch: 9, Batch: 171, D Loss: 0.10928526021234575, G Loss: 14.598033905029297\n",
      "Epoch: 9, Batch: 172, D Loss: 0.10573356278581514, G Loss: 14.875602722167969\n",
      "Epoch: 9, Batch: 173, D Loss: 0.1018232277788087, G Loss: 14.796005249023438\n",
      "Epoch: 9, Batch: 174, D Loss: 0.09008405347182702, G Loss: 13.988499641418457\n",
      "Epoch: 9, Batch: 175, D Loss: 0.1014508272664898, G Loss: 13.566316604614258\n",
      "Epoch: 9, Batch: 176, D Loss: 0.1017919422120599, G Loss: 13.85986042022705\n",
      "Epoch: 9, Batch: 177, D Loss: 0.10045563781258693, G Loss: 14.400480270385742\n",
      "Epoch: 9, Batch: 178, D Loss: 0.09851175527739997, G Loss: 14.587553024291992\n",
      "Epoch: 9, Batch: 179, D Loss: 0.10120517835520104, G Loss: 14.412160873413086\n",
      "Epoch: 9, Batch: 180, D Loss: 0.10167362889876586, G Loss: 14.11018180847168\n",
      "Epoch: 9, Batch: 181, D Loss: 0.1011706531415939, G Loss: 14.109310150146484\n",
      "Epoch: 9, Batch: 182, D Loss: 0.10076700541725359, G Loss: 14.254058837890625\n",
      "Epoch: 9, Batch: 183, D Loss: 0.10099661800603599, G Loss: 14.477408409118652\n",
      "Epoch: 9, Batch: 184, D Loss: 0.09837332609245664, G Loss: 14.556278228759766\n",
      "Epoch: 9, Batch: 185, D Loss: 0.09840800525995519, G Loss: 13.535075187683105\n",
      "Epoch: 9, Batch: 186, D Loss: 0.09403858896428119, G Loss: 13.417821884155273\n",
      "Epoch: 9, Batch: 187, D Loss: 0.10767067180546519, G Loss: 13.784101486206055\n",
      "Epoch: 9, Batch: 188, D Loss: 0.09815392848929605, G Loss: 14.089168548583984\n",
      "Epoch: 9, Batch: 189, D Loss: 0.10525894477189013, G Loss: 14.026716232299805\n",
      "Epoch: 9, Batch: 190, D Loss: 0.1000230276779348, G Loss: 13.811311721801758\n",
      "Epoch: 9, Batch: 191, D Loss: 0.10001256982201312, G Loss: 13.597076416015625\n",
      "Epoch: 9, Batch: 192, D Loss: 0.09941509021393813, G Loss: 13.541946411132812\n",
      "Epoch: 9, Batch: 193, D Loss: 0.1021077866852238, G Loss: 13.833703994750977\n",
      "Epoch: 9, Batch: 194, D Loss: 0.10040071045563081, G Loss: 14.247268676757812\n",
      "Epoch: 9, Batch: 195, D Loss: 0.10317883352180957, G Loss: 14.483266830444336\n",
      "Epoch: 9, Batch: 196, D Loss: 0.1028390304612401, G Loss: 14.455846786499023\n",
      "Epoch: 9, Batch: 197, D Loss: 0.0977973963669001, G Loss: 14.120750427246094\n",
      "Epoch: 9, Batch: 198, D Loss: 0.102533423671332, G Loss: 14.064013481140137\n",
      "Epoch: 9, Batch: 199, D Loss: 0.09315815857206644, G Loss: 14.070551872253418\n",
      "Epoch: 9, Batch: 200, D Loss: 0.09599136306405853, G Loss: 14.283868789672852\n",
      "Epoch: 9, Batch: 201, D Loss: 0.10069637966785194, G Loss: 14.675050735473633\n",
      "Epoch: 9, Batch: 202, D Loss: 0.10172636168972815, G Loss: 14.911247253417969\n",
      "Epoch: 9, Batch: 203, D Loss: 0.09730816663119413, G Loss: 14.705450057983398\n",
      "Epoch: 9, Batch: 204, D Loss: 0.10133509336495194, G Loss: 14.549270629882812\n",
      "Epoch: 9, Batch: 205, D Loss: 0.10114274059552031, G Loss: 14.636951446533203\n",
      "Epoch: 9, Batch: 206, D Loss: 0.10640541318326768, G Loss: 15.131011962890625\n",
      "Epoch: 9, Batch: 207, D Loss: 0.10430564281563903, G Loss: 15.558917045593262\n",
      "Epoch: 9, Batch: 208, D Loss: 0.10014649388335783, G Loss: 15.385360717773438\n",
      "Epoch: 9, Batch: 209, D Loss: 0.1012232766307335, G Loss: 15.104686737060547\n",
      "Epoch: 9, Batch: 210, D Loss: 0.10019767981344785, G Loss: 15.062419891357422\n",
      "Epoch: 9, Batch: 211, D Loss: 0.1032612970590776, G Loss: 15.34152603149414\n",
      "Epoch: 9, Batch: 212, D Loss: 0.09871338870568991, G Loss: 15.622995376586914\n",
      "Epoch: 9, Batch: 213, D Loss: 0.10368673036984433, G Loss: 15.73794174194336\n",
      "Epoch: 9, Batch: 214, D Loss: 0.09564084930840977, G Loss: 15.438541412353516\n",
      "Epoch: 9, Batch: 215, D Loss: 0.09666970736103053, G Loss: 15.09483814239502\n",
      "Epoch: 9, Batch: 216, D Loss: 0.09810662749673327, G Loss: 14.65906047821045\n",
      "Epoch: 9, Batch: 217, D Loss: 0.09820363094924289, G Loss: 14.91966724395752\n",
      "Epoch: 9, Batch: 218, D Loss: 0.098742333513826, G Loss: 15.256820678710938\n",
      "Epoch: 9, Batch: 219, D Loss: 0.09876709761751812, G Loss: 15.31228256225586\n",
      "Epoch: 9, Batch: 220, D Loss: 0.09032240976409867, G Loss: 14.907018661499023\n",
      "Epoch: 9, Batch: 221, D Loss: 0.0921582259571494, G Loss: 14.518753051757812\n",
      "Epoch: 9, Batch: 222, D Loss: 0.10220738912553884, G Loss: 14.745766639709473\n",
      "Epoch: 9, Batch: 223, D Loss: 0.10013987843753114, G Loss: 15.192537307739258\n",
      "Epoch: 9, Batch: 224, D Loss: 0.1044319857978806, G Loss: 15.57497787475586\n",
      "Epoch: 9, Batch: 225, D Loss: 0.09343002410295753, G Loss: 15.011722564697266\n",
      "Epoch: 9, Batch: 226, D Loss: 0.09604191942560192, G Loss: 14.38992691040039\n",
      "Epoch: 9, Batch: 227, D Loss: 0.10666859639962922, G Loss: 14.453447341918945\n",
      "Epoch: 9, Batch: 228, D Loss: 0.10113618622725085, G Loss: 14.767807006835938\n",
      "Epoch: 9, Batch: 229, D Loss: 0.09849188267916986, G Loss: 14.860153198242188\n",
      "Epoch: 9, Batch: 230, D Loss: 0.10566641768639329, G Loss: 14.793392181396484\n",
      "Epoch: 9, Batch: 231, D Loss: 0.10485981694692725, G Loss: 14.509236335754395\n",
      "Epoch: 9, Batch: 232, D Loss: 0.09734388569330577, G Loss: 14.036771774291992\n",
      "Epoch: 9, Batch: 233, D Loss: 0.10386295696247316, G Loss: 13.899787902832031\n",
      "Epoch: 9, Batch: 234, D Loss: 0.10174933228080363, G Loss: 13.987741470336914\n",
      "Epoch: 9, Batch: 235, D Loss: 0.10642266948798351, G Loss: 14.270072937011719\n",
      "Epoch: 9, Batch: 236, D Loss: 0.09831747808993896, G Loss: 14.236114501953125\n",
      "Epoch: 9, Batch: 237, D Loss: 0.09663453747054973, G Loss: 13.8921537399292\n",
      "Epoch: 9, Batch: 238, D Loss: 0.09649933644800512, G Loss: 13.632884979248047\n",
      "Epoch: 9, Batch: 239, D Loss: 0.100757999188545, G Loss: 13.763090133666992\n",
      "Epoch: 9, Batch: 240, D Loss: 0.10334831379896059, G Loss: 14.186745643615723\n",
      "Epoch: 9, Batch: 241, D Loss: 0.09878588592093251, G Loss: 14.463567733764648\n",
      "Epoch: 9, Batch: 242, D Loss: 0.09255754068504984, G Loss: 14.18387508392334\n",
      "Epoch: 9, Batch: 243, D Loss: 0.10277841685260114, G Loss: 14.06696891784668\n",
      "Epoch: 9, Batch: 244, D Loss: 0.09638454975464583, G Loss: 14.146236419677734\n",
      "Epoch: 9, Batch: 245, D Loss: 0.100687960960272, G Loss: 14.444819450378418\n",
      "Epoch: 9, Batch: 246, D Loss: 0.10263086267256938, G Loss: 14.83474349975586\n",
      "Epoch: 9, Batch: 247, D Loss: 0.10811832778000507, G Loss: 15.172813415527344\n",
      "Epoch: 9, Batch: 248, D Loss: 0.09712242708400254, G Loss: 14.945554733276367\n",
      "Epoch: 9, Batch: 249, D Loss: 0.10177020642689172, G Loss: 14.765569686889648\n",
      "Epoch: 9, Batch: 250, D Loss: 0.10001884225535207, G Loss: 14.78382682800293\n",
      "Epoch: 9, Batch: 251, D Loss: 0.10496314055815503, G Loss: 15.132823944091797\n",
      "Epoch: 9, Batch: 252, D Loss: 0.10055952731478612, G Loss: 15.44367790222168\n",
      "Epoch: 9, Batch: 253, D Loss: 0.09784072022087997, G Loss: 15.444936752319336\n",
      "Epoch: 9, Batch: 254, D Loss: 0.09961824210201087, G Loss: 15.312736511230469\n",
      "Epoch: 9, Batch: 255, D Loss: 0.09968078607050757, G Loss: 15.239018440246582\n",
      "Epoch: 9, Batch: 256, D Loss: 0.109302435391605, G Loss: 15.577778816223145\n",
      "Epoch: 9, Batch: 257, D Loss: 0.1037051225113288, G Loss: 15.862493515014648\n",
      "Epoch: 9, Batch: 258, D Loss: 0.10233061815021927, G Loss: 15.776542663574219\n",
      "Epoch: 9, Batch: 259, D Loss: 0.10099834056755697, G Loss: 15.522869110107422\n",
      "Epoch: 9, Batch: 260, D Loss: 0.10247897049811172, G Loss: 15.46084976196289\n",
      "Epoch: 9, Batch: 261, D Loss: 0.0934560547804395, G Loss: 15.40649700164795\n",
      "Epoch: 9, Batch: 262, D Loss: 0.09937355981200824, G Loss: 15.590982437133789\n",
      "Epoch: 9, Batch: 263, D Loss: 0.09660732681035711, G Loss: 15.853172302246094\n",
      "Epoch: 9, Batch: 264, D Loss: 0.09770089395993864, G Loss: 16.02157211303711\n",
      "Epoch: 9, Batch: 265, D Loss: 0.09841749298266222, G Loss: 16.045421600341797\n",
      "Epoch: 9, Batch: 266, D Loss: 0.09857442576111097, G Loss: 15.982587814331055\n",
      "Epoch: 9, Batch: 267, D Loss: 0.10541107375192027, G Loss: 16.20931625366211\n",
      "Epoch: 9, Batch: 268, D Loss: 0.09749246165442926, G Loss: 16.34712791442871\n",
      "Epoch: 9, Batch: 269, D Loss: 0.10050252973815077, G Loss: 16.397628784179688\n",
      "Epoch: 9, Batch: 270, D Loss: 0.10207154523787665, G Loss: 16.46670913696289\n",
      "Epoch: 9, Batch: 271, D Loss: 0.10094656485904707, G Loss: 16.52906036376953\n",
      "Epoch: 9, Batch: 272, D Loss: 0.10311331055165596, G Loss: 16.608566284179688\n",
      "Epoch: 9, Batch: 273, D Loss: 0.09906296663032776, G Loss: 16.518674850463867\n",
      "Epoch: 9, Batch: 274, D Loss: 0.09906284989484249, G Loss: 16.458572387695312\n",
      "Epoch: 9, Batch: 275, D Loss: 0.09361959274944809, G Loss: 16.35837173461914\n",
      "Epoch: 9, Batch: 276, D Loss: 0.10256153128621648, G Loss: 16.575637817382812\n",
      "Epoch: 9, Batch: 277, D Loss: 0.10053066705288849, G Loss: 16.824703216552734\n",
      "Epoch: 9, Batch: 278, D Loss: 0.09729140533228531, G Loss: 16.787200927734375\n",
      "Epoch: 9, Batch: 279, D Loss: 0.09603872915545608, G Loss: 16.485130310058594\n",
      "Epoch: 9, Batch: 280, D Loss: 0.09634000337717197, G Loss: 16.21269989013672\n",
      "Epoch: 9, Batch: 281, D Loss: 0.09660115181200979, G Loss: 16.209640502929688\n",
      "Epoch: 9, Batch: 282, D Loss: 0.09647065904265517, G Loss: 16.355209350585938\n",
      "Epoch: 9, Batch: 283, D Loss: 0.10818706610783835, G Loss: 16.788694381713867\n",
      "Epoch: 9, Batch: 284, D Loss: 0.09966252338590742, G Loss: 16.776283264160156\n",
      "Epoch: 9, Batch: 285, D Loss: 0.10229266578163987, G Loss: 16.420433044433594\n",
      "Epoch: 9, Batch: 286, D Loss: 0.09670845052090016, G Loss: 15.905433654785156\n",
      "Epoch: 9, Batch: 287, D Loss: 0.0977485341652411, G Loss: 15.717818260192871\n",
      "Epoch: 9, Batch: 288, D Loss: 0.10194196878502026, G Loss: 16.04492950439453\n",
      "Epoch: 9, Batch: 289, D Loss: 0.09940180815940991, G Loss: 16.443954467773438\n",
      "Epoch: 9, Batch: 290, D Loss: 0.0980054366700287, G Loss: 16.369121551513672\n",
      "Epoch: 9, Batch: 291, D Loss: 0.10191877301960517, G Loss: 16.055896759033203\n",
      "Epoch: 9, Batch: 292, D Loss: 0.09466323444387825, G Loss: 15.565967559814453\n",
      "Epoch: 9, Batch: 293, D Loss: 0.1028121576309502, G Loss: 15.48033618927002\n",
      "Epoch: 9, Batch: 294, D Loss: 0.10230303144710717, G Loss: 15.679450035095215\n",
      "Epoch: 9, Batch: 295, D Loss: 0.1001494989583307, G Loss: 15.913084983825684\n",
      "Epoch: 9, Batch: 296, D Loss: 0.09926954468661364, G Loss: 15.800617218017578\n",
      "Epoch: 9, Batch: 297, D Loss: 0.10178513095297603, G Loss: 15.643838882446289\n",
      "Epoch: 9, Batch: 298, D Loss: 0.09196859966100135, G Loss: 15.366296768188477\n",
      "Epoch: 9, Batch: 299, D Loss: 0.10349511477532047, G Loss: 15.517017364501953\n",
      "Epoch: 9, Batch: 300, D Loss: 0.10343150473975982, G Loss: 15.986979484558105\n",
      "Epoch: 9, Batch: 301, D Loss: 0.09383687805136987, G Loss: 16.00743865966797\n",
      "Epoch: 9, Batch: 302, D Loss: 0.10372820152313267, G Loss: 15.998228073120117\n",
      "Epoch: 9, Batch: 303, D Loss: 0.10646701366848532, G Loss: 15.970748901367188\n",
      "Epoch: 9, Batch: 304, D Loss: 0.09509075573629389, G Loss: 15.655380249023438\n",
      "Epoch: 9, Batch: 305, D Loss: 0.09503561307244013, G Loss: 15.422100067138672\n",
      "Epoch: 9, Batch: 306, D Loss: 0.09596268099889471, G Loss: 15.488229751586914\n",
      "Epoch: 9, Batch: 307, D Loss: 0.10685727763165431, G Loss: 15.848288536071777\n",
      "Epoch: 9, Batch: 308, D Loss: 0.1008582771470401, G Loss: 15.846705436706543\n",
      "Epoch: 9, Batch: 309, D Loss: 0.10108034293561019, G Loss: 15.610614776611328\n",
      "Epoch: 9, Batch: 310, D Loss: 0.09883695799017289, G Loss: 15.188077926635742\n",
      "Epoch: 9, Batch: 311, D Loss: 0.10607854388956639, G Loss: 15.175521850585938\n",
      "Epoch: 9, Batch: 312, D Loss: 0.10514630385976886, G Loss: 15.439462661743164\n",
      "Epoch: 9, Batch: 313, D Loss: 0.09986502042360712, G Loss: 15.603588104248047\n",
      "Epoch: 9, Batch: 314, D Loss: 0.096386427816185, G Loss: 15.424427032470703\n",
      "Epoch: 9, Batch: 315, D Loss: 0.09726817654151176, G Loss: 15.135098457336426\n",
      "Epoch: 9, Batch: 316, D Loss: 0.10275591265988737, G Loss: 15.1171875\n",
      "Epoch: 9, Batch: 317, D Loss: 0.0917709439374903, G Loss: 15.086252212524414\n",
      "Epoch: 9, Batch: 318, D Loss: 0.10360390368140315, G Loss: 15.333216667175293\n",
      "Epoch: 9, Batch: 319, D Loss: 0.1074435276629302, G Loss: 15.695728302001953\n",
      "Epoch: 9, Batch: 320, D Loss: 0.10083272114999886, G Loss: 15.606613159179688\n",
      "Epoch: 9, Batch: 321, D Loss: 0.09952589725439509, G Loss: 15.21054458618164\n",
      "Epoch: 9, Batch: 322, D Loss: 0.09474128660539805, G Loss: 14.84171199798584\n",
      "Epoch: 9, Batch: 323, D Loss: 0.09784314374637404, G Loss: 14.814554214477539\n",
      "Epoch: 9, Batch: 324, D Loss: 0.09588953284220736, G Loss: 15.019184112548828\n",
      "Epoch: 9, Batch: 325, D Loss: 0.10234132438576182, G Loss: 15.454834938049316\n",
      "Epoch: 9, Batch: 326, D Loss: 0.09626544132247261, G Loss: 15.48805046081543\n",
      "Epoch: 9, Batch: 327, D Loss: 0.10032795841406994, G Loss: 15.238676071166992\n",
      "Epoch: 9, Batch: 328, D Loss: 0.09938510611348761, G Loss: 14.529081344604492\n",
      "Epoch: 9, Batch: 329, D Loss: 0.09634800677528688, G Loss: 14.38654899597168\n",
      "Epoch: 9, Batch: 330, D Loss: 0.09573627793423611, G Loss: 14.403642654418945\n",
      "Epoch: 9, Batch: 331, D Loss: 0.10246658339596593, G Loss: 14.697914123535156\n",
      "Epoch: 9, Batch: 332, D Loss: 0.09412689250795836, G Loss: 14.853100776672363\n",
      "Epoch: 9, Batch: 333, D Loss: 0.10607536509498061, G Loss: 15.048505783081055\n",
      "Epoch: 9, Batch: 334, D Loss: 0.11018204344111382, G Loss: 15.258996963500977\n",
      "Epoch: 9, Batch: 335, D Loss: 0.09914098407355709, G Loss: 15.059024810791016\n",
      "Epoch: 9, Batch: 336, D Loss: 0.09671295097697907, G Loss: 14.772848129272461\n",
      "Epoch: 9, Batch: 337, D Loss: 0.09825877341310729, G Loss: 14.736968040466309\n",
      "Epoch: 9, Batch: 338, D Loss: 0.10132529454384098, G Loss: 15.039953231811523\n",
      "Epoch: 9, Batch: 339, D Loss: 0.09933931299385534, G Loss: 15.45387077331543\n",
      "Epoch: 9, Batch: 340, D Loss: 0.09689503994268023, G Loss: 15.595802307128906\n",
      "Epoch: 9, Batch: 341, D Loss: 0.10072863163232171, G Loss: 15.473275184631348\n",
      "Epoch: 9, Batch: 342, D Loss: 0.08837058711895907, G Loss: 14.898271560668945\n",
      "Epoch: 9, Batch: 343, D Loss: 0.09669504991040867, G Loss: 14.73281478881836\n",
      "Epoch: 9, Batch: 344, D Loss: 0.10212997554197045, G Loss: 15.005813598632812\n",
      "Epoch: 9, Batch: 345, D Loss: 0.10338418744245814, G Loss: 15.501437187194824\n",
      "Epoch: 9, Batch: 346, D Loss: 0.10956482723568683, G Loss: 15.88033676147461\n",
      "Epoch: 9, Batch: 347, D Loss: 0.1036336563686362, G Loss: 15.593605995178223\n",
      "Epoch: 9, Batch: 348, D Loss: 0.09837209272926373, G Loss: 14.968624114990234\n",
      "Epoch: 9, Batch: 349, D Loss: 0.09908406268297654, G Loss: 14.675586700439453\n",
      "Epoch: 9, Batch: 350, D Loss: 0.1047677294612015, G Loss: 14.951416015625\n",
      "Epoch: 9, Batch: 351, D Loss: 0.09849639933062804, G Loss: 15.413287162780762\n",
      "Epoch: 9, Batch: 352, D Loss: 0.09993669847608544, G Loss: 15.617429733276367\n",
      "Epoch: 9, Batch: 353, D Loss: 0.1032646619054276, G Loss: 15.580913543701172\n",
      "Epoch: 9, Batch: 354, D Loss: 0.09799760359376108, G Loss: 15.247846603393555\n",
      "Epoch: 9, Batch: 355, D Loss: 0.10068697080244249, G Loss: 15.088138580322266\n",
      "Epoch: 9, Batch: 356, D Loss: 0.09631960125324213, G Loss: 15.169431686401367\n",
      "Epoch: 9, Batch: 357, D Loss: 0.10380825618000245, G Loss: 15.561965942382812\n",
      "Epoch: 9, Batch: 358, D Loss: 0.09470004004634802, G Loss: 14.510368347167969\n",
      "Epoch: 9, Batch: 359, D Loss: 0.1057320760313587, G Loss: 14.694172859191895\n",
      "Epoch: 9, Batch: 360, D Loss: 0.10140923050030892, G Loss: 14.656269073486328\n",
      "Epoch: 9, Batch: 361, D Loss: 0.095551418734658, G Loss: 14.452778816223145\n",
      "Epoch: 9, Batch: 362, D Loss: 0.09671728236696708, G Loss: 14.348466873168945\n",
      "Epoch: 9, Batch: 363, D Loss: 0.10492495509899413, G Loss: 14.68628978729248\n",
      "Epoch: 9, Batch: 364, D Loss: 0.1022526037811815, G Loss: 15.141408920288086\n",
      "Epoch: 9, Batch: 365, D Loss: 0.10275179854738781, G Loss: 15.355511665344238\n",
      "Epoch: 9, Batch: 366, D Loss: 0.10022516464744058, G Loss: 15.170182228088379\n",
      "Epoch: 9, Batch: 367, D Loss: 0.09753589999564838, G Loss: 14.817384719848633\n",
      "Epoch: 9, Batch: 368, D Loss: 0.10150798785235793, G Loss: 14.757076263427734\n",
      "Epoch: 9, Batch: 369, D Loss: 0.1069910192622956, G Loss: 15.133171081542969\n",
      "Epoch: 9, Batch: 370, D Loss: 0.10508071793159246, G Loss: 15.581104278564453\n",
      "Epoch: 9, Batch: 371, D Loss: 0.10085329720882896, G Loss: 15.594752311706543\n",
      "Epoch: 9, Batch: 372, D Loss: 0.10207092040730714, G Loss: 15.33076286315918\n",
      "Epoch: 9, Batch: 373, D Loss: 0.10411659585362543, G Loss: 15.185831069946289\n",
      "Epoch: 9, Batch: 374, D Loss: 0.09210215021249724, G Loss: 15.050007820129395\n",
      "Epoch: 9, Batch: 375, D Loss: 0.09769729239397407, G Loss: 15.144405364990234\n",
      "Epoch: 9, Batch: 376, D Loss: 0.10054157597522106, G Loss: 15.482328414916992\n",
      "Epoch: 9, Batch: 377, D Loss: 0.09864071726318002, G Loss: 15.760677337646484\n",
      "Epoch: 9, Batch: 378, D Loss: 0.09984977190134714, G Loss: 15.776117324829102\n",
      "Epoch: 9, Batch: 379, D Loss: 0.09011147524837781, G Loss: 15.409128189086914\n",
      "Epoch: 9, Batch: 380, D Loss: 0.10367068032097393, G Loss: 15.477372169494629\n",
      "Epoch: 9, Batch: 381, D Loss: 0.09794077887743668, G Loss: 15.789495468139648\n",
      "Epoch: 9, Batch: 382, D Loss: 0.09696809041889054, G Loss: 16.13353729248047\n",
      "Epoch: 9, Batch: 383, D Loss: 0.09734743903405985, G Loss: 16.28875732421875\n",
      "Epoch: 9, Batch: 384, D Loss: 0.10302537255000388, G Loss: 16.36794662475586\n",
      "Epoch: 9, Batch: 385, D Loss: 0.09920029607221181, G Loss: 16.322895050048828\n",
      "Epoch: 9, Batch: 386, D Loss: 0.10260085242251193, G Loss: 16.38223648071289\n",
      "Epoch: 9, Batch: 387, D Loss: 0.09703125923306999, G Loss: 16.38103485107422\n",
      "Epoch: 9, Batch: 388, D Loss: 0.10131680097699558, G Loss: 16.505226135253906\n",
      "Epoch: 9, Batch: 389, D Loss: 0.10461389973322355, G Loss: 16.782634735107422\n",
      "Epoch: 9, Batch: 390, D Loss: 0.09707738126240884, G Loss: 16.72882843017578\n",
      "Epoch: 9, Batch: 391, D Loss: 0.10237386707830609, G Loss: 16.626953125\n",
      "Epoch: 9, Batch: 392, D Loss: 0.09877640328997472, G Loss: 16.45069122314453\n",
      "Epoch: 9, Batch: 393, D Loss: 0.09658746119551154, G Loss: 16.167463302612305\n",
      "Epoch: 9, Batch: 394, D Loss: 0.0977580871867545, G Loss: 15.835270881652832\n",
      "Epoch: 9, Batch: 395, D Loss: 0.0883347398029315, G Loss: 15.630858421325684\n",
      "Epoch: 9, Batch: 396, D Loss: 0.09826338662087863, G Loss: 15.708633422851562\n",
      "Epoch: 9, Batch: 397, D Loss: 0.0942637726535196, G Loss: 15.848690032958984\n",
      "Epoch: 9, Batch: 398, D Loss: 0.0987756627090377, G Loss: 16.021169662475586\n",
      "Epoch: 9, Batch: 399, D Loss: 0.09906740024186433, G Loss: 16.026432037353516\n",
      "Epoch: 9, Batch: 400, D Loss: 0.10155436926293504, G Loss: 15.938264846801758\n",
      "Epoch: 9, Batch: 401, D Loss: 0.10395731466075375, G Loss: 15.81422233581543\n",
      "Epoch: 9, Batch: 402, D Loss: 0.09926738778432309, G Loss: 15.58836841583252\n",
      "Epoch: 9, Batch: 403, D Loss: 0.10059354900037931, G Loss: 15.55764389038086\n",
      "Epoch: 9, Batch: 404, D Loss: 0.09925645294170948, G Loss: 15.58449935913086\n",
      "Epoch: 9, Batch: 405, D Loss: 0.0989921816581969, G Loss: 15.71207046508789\n",
      "Epoch: 9, Batch: 406, D Loss: 0.09393471113828866, G Loss: 15.633430480957031\n",
      "Epoch: 9, Batch: 407, D Loss: 0.09614890351576832, G Loss: 15.553205490112305\n",
      "Epoch: 9, Batch: 408, D Loss: 0.09896811310589726, G Loss: 15.641220092773438\n",
      "Epoch: 9, Batch: 409, D Loss: 0.10164619534086228, G Loss: 15.909345626831055\n",
      "Epoch: 9, Batch: 410, D Loss: 0.10270575643748003, G Loss: 16.151805877685547\n",
      "Epoch: 9, Batch: 411, D Loss: 0.10261795113141048, G Loss: 16.223350524902344\n",
      "Epoch: 9, Batch: 412, D Loss: 0.10328099441866456, G Loss: 16.109325408935547\n",
      "Epoch: 9, Batch: 413, D Loss: 0.09703667592896181, G Loss: 15.752537727355957\n",
      "Epoch: 9, Batch: 414, D Loss: 0.09781696424710162, G Loss: 15.562746047973633\n",
      "Epoch: 9, Batch: 415, D Loss: 0.09778124385410081, G Loss: 15.614962577819824\n",
      "Epoch: 9, Batch: 416, D Loss: 0.10241288872085619, G Loss: 15.964941024780273\n",
      "Epoch: 9, Batch: 417, D Loss: 0.10984334316520261, G Loss: 16.481895446777344\n",
      "Epoch: 9, Batch: 418, D Loss: 0.10326846511529908, G Loss: 16.44353485107422\n",
      "Epoch: 9, Batch: 419, D Loss: 0.10593455170209509, G Loss: 16.08762550354004\n",
      "Epoch: 9, Batch: 420, D Loss: 0.09994561654333722, G Loss: 15.681514739990234\n",
      "Epoch: 9, Batch: 421, D Loss: 0.10226227820903944, G Loss: 15.637283325195312\n",
      "Epoch: 9, Batch: 422, D Loss: 0.09794769462246222, G Loss: 15.788443565368652\n",
      "Epoch: 9, Batch: 423, D Loss: 0.10324370631764879, G Loss: 16.157245635986328\n",
      "Epoch: 9, Batch: 424, D Loss: 0.09768270788597988, G Loss: 16.259708404541016\n",
      "Epoch: 9, Batch: 425, D Loss: 0.0967285383885006, G Loss: 16.00695037841797\n",
      "Epoch: 9, Batch: 426, D Loss: 0.10316837488162278, G Loss: 15.915092468261719\n",
      "Epoch: 9, Batch: 427, D Loss: 0.09988640989558206, G Loss: 15.969996452331543\n",
      "Epoch: 9, Batch: 428, D Loss: 0.10286187315579198, G Loss: 16.196659088134766\n",
      "Epoch: 9, Batch: 429, D Loss: 0.10381477683846185, G Loss: 16.431968688964844\n",
      "Epoch: 9, Batch: 430, D Loss: 0.09601807761363901, G Loss: 16.311702728271484\n",
      "Epoch: 9, Batch: 431, D Loss: 0.09517808856426768, G Loss: 15.919517517089844\n",
      "Epoch: 9, Batch: 432, D Loss: 0.09719171047494513, G Loss: 15.836172103881836\n",
      "Epoch: 9, Batch: 433, D Loss: 0.10222749188498881, G Loss: 16.112497329711914\n",
      "Epoch: 9, Batch: 434, D Loss: 0.09421866378766097, G Loss: 16.341148376464844\n",
      "Epoch: 9, Batch: 435, D Loss: 0.09688504209524496, G Loss: 16.39722442626953\n",
      "Epoch: 9, Batch: 436, D Loss: 0.1049570958904198, G Loss: 16.51163673400879\n",
      "Epoch: 9, Batch: 437, D Loss: 0.09827242634906952, G Loss: 16.405792236328125\n",
      "Epoch: 9, Batch: 438, D Loss: 0.10678634802604137, G Loss: 16.414321899414062\n",
      "Epoch: 9, Batch: 439, D Loss: 0.09563775189544899, G Loss: 16.138961791992188\n",
      "Epoch: 9, Batch: 440, D Loss: 0.10418910169055806, G Loss: 16.15808868408203\n",
      "Epoch: 9, Batch: 441, D Loss: 0.0969066222441981, G Loss: 16.096294403076172\n",
      "Epoch: 9, Batch: 442, D Loss: 0.0982881185139135, G Loss: 16.070934295654297\n",
      "Epoch: 9, Batch: 443, D Loss: 0.09666720189634148, G Loss: 16.025604248046875\n",
      "Epoch: 9, Batch: 444, D Loss: 0.09599214542583212, G Loss: 15.950414657592773\n",
      "Epoch: 9, Batch: 445, D Loss: 0.11046827926985969, G Loss: 16.34147071838379\n",
      "Epoch: 9, Batch: 446, D Loss: 0.09925732984564917, G Loss: 16.366939544677734\n",
      "Epoch: 9, Batch: 447, D Loss: 0.10224820266605761, G Loss: 15.967923164367676\n",
      "Epoch: 9, Batch: 448, D Loss: 0.09951484325893745, G Loss: 15.466705322265625\n",
      "Epoch: 9, Batch: 449, D Loss: 0.09937292042170043, G Loss: 15.10456657409668\n",
      "Epoch: 9, Batch: 450, D Loss: 0.09384869786592276, G Loss: 14.86695671081543\n",
      "Epoch: 9, Batch: 451, D Loss: 0.10210128198784219, G Loss: 14.984893798828125\n",
      "Epoch: 9, Batch: 452, D Loss: 0.0960697555355523, G Loss: 15.037637710571289\n",
      "Epoch: 9, Batch: 453, D Loss: 0.09870380047610183, G Loss: 14.941543579101562\n",
      "Epoch: 9, Batch: 454, D Loss: 0.10109795442430425, G Loss: 14.780902862548828\n",
      "Epoch: 9, Batch: 455, D Loss: 0.09457457896201049, G Loss: 14.539536476135254\n",
      "Epoch: 9, Batch: 456, D Loss: 0.08957319602802727, G Loss: 14.210837364196777\n",
      "Epoch: 9, Batch: 457, D Loss: 0.0949108734095887, G Loss: 14.096494674682617\n",
      "Epoch: 9, Batch: 458, D Loss: 0.09845986694767817, G Loss: 12.782139778137207\n",
      "Epoch: 9, Batch: 459, D Loss: 0.0998310371903699, G Loss: 12.827508926391602\n",
      "Epoch: 9, Batch: 460, D Loss: 0.09688674064261704, G Loss: 12.94540023803711\n",
      "Epoch: 9, Batch: 461, D Loss: 0.10522519823314269, G Loss: 13.114051818847656\n",
      "Epoch: 9, Batch: 462, D Loss: 0.09554366623115129, G Loss: 13.081871032714844\n",
      "Epoch: 9, Batch: 463, D Loss: 0.09839986754673191, G Loss: 13.181262016296387\n",
      "Epoch: 9, Batch: 464, D Loss: 0.09691648878697379, G Loss: 13.455157279968262\n",
      "Epoch: 9, Batch: 465, D Loss: 0.09661016475683937, G Loss: 13.803999900817871\n",
      "Epoch: 9, Batch: 466, D Loss: 0.10330761718694248, G Loss: 14.334210395812988\n",
      "Epoch: 9, Batch: 467, D Loss: 0.10008964427260025, G Loss: 14.612203598022461\n",
      "Epoch: 10, Batch: 0, D Loss: 0.09769791139342487, G Loss: 14.472406387329102\n",
      "Epoch: 10, Batch: 1, D Loss: 0.10420338977144183, G Loss: 13.602560997009277\n",
      "Epoch: 10, Batch: 2, D Loss: 0.10147519037582242, G Loss: 13.787544250488281\n",
      "Epoch: 10, Batch: 3, D Loss: 0.10231998468600523, G Loss: 14.102224349975586\n",
      "Epoch: 10, Batch: 4, D Loss: 0.1020458371749271, G Loss: 14.351279258728027\n",
      "Epoch: 10, Batch: 5, D Loss: 0.09553537957458502, G Loss: 14.251408576965332\n",
      "Epoch: 10, Batch: 6, D Loss: 0.10016844778422751, G Loss: 14.21435546875\n",
      "Epoch: 10, Batch: 7, D Loss: 0.10074501153820847, G Loss: 14.376287460327148\n",
      "Epoch: 10, Batch: 8, D Loss: 0.09949917350004966, G Loss: 14.609940528869629\n",
      "Epoch: 10, Batch: 9, D Loss: 0.09735788615142837, G Loss: 14.816720962524414\n",
      "Epoch: 10, Batch: 10, D Loss: 0.09939458997850181, G Loss: 14.870080947875977\n",
      "Epoch: 10, Batch: 11, D Loss: 0.09969873209965385, G Loss: 14.880922317504883\n",
      "Epoch: 10, Batch: 12, D Loss: 0.09675089417669369, G Loss: 14.880025863647461\n",
      "Epoch: 10, Batch: 13, D Loss: 0.09671374107158215, G Loss: 14.930959701538086\n",
      "Epoch: 10, Batch: 14, D Loss: 0.10265511984061959, G Loss: 15.218179702758789\n",
      "Epoch: 10, Batch: 15, D Loss: 0.10060744758881413, G Loss: 15.529340744018555\n",
      "Epoch: 10, Batch: 16, D Loss: 0.10036358424926561, G Loss: 15.668582916259766\n",
      "Epoch: 10, Batch: 17, D Loss: 0.10288858923762234, G Loss: 15.641439437866211\n",
      "Epoch: 10, Batch: 18, D Loss: 0.10319483978243937, G Loss: 15.62158489227295\n",
      "Epoch: 10, Batch: 19, D Loss: 0.0974043103486224, G Loss: 15.588888168334961\n",
      "Epoch: 10, Batch: 20, D Loss: 0.09821886465569918, G Loss: 15.68214225769043\n",
      "Epoch: 10, Batch: 21, D Loss: 0.09565405210663869, G Loss: 15.842769622802734\n",
      "Epoch: 10, Batch: 22, D Loss: 0.09748434948374296, G Loss: 16.057044982910156\n",
      "Epoch: 10, Batch: 23, D Loss: 0.09998035600960975, G Loss: 16.31932258605957\n",
      "Epoch: 10, Batch: 24, D Loss: 0.10038762666724921, G Loss: 16.47217559814453\n",
      "Epoch: 10, Batch: 25, D Loss: 0.0969958747016264, G Loss: 16.392372131347656\n",
      "Epoch: 10, Batch: 26, D Loss: 0.09841958630904202, G Loss: 16.333412170410156\n",
      "Epoch: 10, Batch: 27, D Loss: 0.10264377869285113, G Loss: 16.57428741455078\n",
      "Epoch: 10, Batch: 28, D Loss: 0.09641224136629312, G Loss: 16.69750213623047\n",
      "Epoch: 10, Batch: 29, D Loss: 0.09594100320861543, G Loss: 16.849205017089844\n",
      "Epoch: 10, Batch: 30, D Loss: 0.09536571899136348, G Loss: 16.908681869506836\n",
      "Epoch: 10, Batch: 31, D Loss: 0.09423636697422388, G Loss: 16.892925262451172\n",
      "Epoch: 10, Batch: 32, D Loss: 0.09832245675124796, G Loss: 17.111907958984375\n",
      "Epoch: 10, Batch: 33, D Loss: 0.09754932864804111, G Loss: 17.292903900146484\n",
      "Epoch: 10, Batch: 34, D Loss: 0.10288192224985604, G Loss: 17.50262451171875\n",
      "Epoch: 10, Batch: 35, D Loss: 0.09601927370181151, G Loss: 17.41490936279297\n",
      "Epoch: 10, Batch: 36, D Loss: 0.09979102739088042, G Loss: 17.27899932861328\n",
      "Epoch: 10, Batch: 37, D Loss: 0.09963543039029332, G Loss: 17.285457611083984\n",
      "Epoch: 10, Batch: 38, D Loss: 0.09972313776978403, G Loss: 17.38677215576172\n",
      "Epoch: 10, Batch: 39, D Loss: 0.09085056409877623, G Loss: 17.010574340820312\n",
      "Epoch: 10, Batch: 40, D Loss: 0.10344356133337662, G Loss: 16.996347427368164\n",
      "Epoch: 10, Batch: 41, D Loss: 0.09358422725131987, G Loss: 16.07532501220703\n",
      "Epoch: 10, Batch: 42, D Loss: 0.10105000711727286, G Loss: 16.004501342773438\n",
      "Epoch: 10, Batch: 43, D Loss: 0.09695475813845889, G Loss: 15.805610656738281\n",
      "Epoch: 10, Batch: 44, D Loss: 0.09798765077742644, G Loss: 15.670637130737305\n",
      "Epoch: 10, Batch: 45, D Loss: 0.10040786360622178, G Loss: 15.704326629638672\n",
      "Epoch: 10, Batch: 46, D Loss: 0.0992849294090874, G Loss: 15.802576065063477\n",
      "Epoch: 10, Batch: 47, D Loss: 0.09868276644626661, G Loss: 15.703283309936523\n",
      "Epoch: 10, Batch: 48, D Loss: 0.10459088656600102, G Loss: 15.70496940612793\n",
      "Epoch: 10, Batch: 49, D Loss: 0.09627089115460308, G Loss: 15.505231857299805\n",
      "Epoch: 10, Batch: 50, D Loss: 0.09725345459476387, G Loss: 15.314643859863281\n",
      "Epoch: 10, Batch: 51, D Loss: 0.09899801946659181, G Loss: 15.285200119018555\n",
      "Epoch: 10, Batch: 52, D Loss: 0.10353869003677119, G Loss: 15.509904861450195\n",
      "Epoch: 10, Batch: 53, D Loss: 0.09809723543985172, G Loss: 15.553936004638672\n",
      "Epoch: 10, Batch: 54, D Loss: 0.1034815666222002, G Loss: 15.562418937683105\n",
      "Epoch: 10, Batch: 55, D Loss: 0.10132398043558055, G Loss: 15.447535514831543\n",
      "Epoch: 10, Batch: 56, D Loss: 0.1010630456944881, G Loss: 15.277181625366211\n",
      "Epoch: 10, Batch: 57, D Loss: 0.0980012143307647, G Loss: 15.18921184539795\n",
      "Epoch: 10, Batch: 58, D Loss: 0.10049546803125509, G Loss: 15.260913848876953\n",
      "Epoch: 10, Batch: 59, D Loss: 0.10392885492333903, G Loss: 15.525680541992188\n",
      "Epoch: 10, Batch: 60, D Loss: 0.09637841878907949, G Loss: 15.487883567810059\n",
      "Epoch: 10, Batch: 61, D Loss: 0.09833794923367378, G Loss: 15.274882316589355\n",
      "Epoch: 10, Batch: 62, D Loss: 0.09607665287262535, G Loss: 15.107955932617188\n",
      "Epoch: 10, Batch: 63, D Loss: 0.10140304588577465, G Loss: 15.217758178710938\n",
      "Epoch: 10, Batch: 64, D Loss: 0.09464182128729703, G Loss: 15.254611015319824\n",
      "Epoch: 10, Batch: 65, D Loss: 0.09661292169665359, G Loss: 15.266521453857422\n",
      "Epoch: 10, Batch: 66, D Loss: 0.0963498481911671, G Loss: 15.27123737335205\n",
      "Epoch: 10, Batch: 67, D Loss: 0.09816469069261302, G Loss: 15.38701057434082\n",
      "Epoch: 10, Batch: 68, D Loss: 0.09537483445024719, G Loss: 15.438785552978516\n",
      "Epoch: 10, Batch: 69, D Loss: 0.09794032346817971, G Loss: 15.52118968963623\n",
      "Epoch: 10, Batch: 70, D Loss: 0.10239144177499782, G Loss: 15.774906158447266\n",
      "Epoch: 10, Batch: 71, D Loss: 0.09920947958919157, G Loss: 15.88956356048584\n",
      "Epoch: 10, Batch: 72, D Loss: 0.09804390852691824, G Loss: 15.734045028686523\n",
      "Epoch: 10, Batch: 73, D Loss: 0.10008662186645267, G Loss: 15.710241317749023\n",
      "Epoch: 10, Batch: 74, D Loss: 0.09697931308426178, G Loss: 15.717395782470703\n",
      "Epoch: 10, Batch: 75, D Loss: 0.09635071998019384, G Loss: 15.775873184204102\n",
      "Epoch: 10, Batch: 76, D Loss: 0.10176771867272194, G Loss: 16.09807586669922\n",
      "Epoch: 10, Batch: 77, D Loss: 0.10108414778650854, G Loss: 16.461801528930664\n",
      "Epoch: 10, Batch: 78, D Loss: 0.09462347279784566, G Loss: 16.554826736450195\n",
      "Epoch: 10, Batch: 79, D Loss: 0.09803271423441018, G Loss: 16.62788200378418\n",
      "Epoch: 10, Batch: 80, D Loss: 0.09836324717966427, G Loss: 16.867332458496094\n",
      "Epoch: 10, Batch: 81, D Loss: 0.1024260037347311, G Loss: 17.313579559326172\n",
      "Epoch: 10, Batch: 82, D Loss: 0.10073306946657468, G Loss: 17.63130760192871\n",
      "Epoch: 10, Batch: 83, D Loss: 0.10239243154799027, G Loss: 17.5695858001709\n",
      "Epoch: 10, Batch: 84, D Loss: 0.09987538862477585, G Loss: 17.37213134765625\n",
      "Epoch: 10, Batch: 85, D Loss: 0.09353608011395309, G Loss: 17.144575119018555\n",
      "Epoch: 10, Batch: 86, D Loss: 0.09812538542612259, G Loss: 17.23691749572754\n",
      "Epoch: 10, Batch: 87, D Loss: 0.09977618483492279, G Loss: 17.573741912841797\n",
      "Epoch: 10, Batch: 88, D Loss: 0.10141342479585269, G Loss: 17.787315368652344\n",
      "Epoch: 10, Batch: 89, D Loss: 0.10268976003179997, G Loss: 17.7818546295166\n",
      "Epoch: 10, Batch: 90, D Loss: 0.09683815280811814, G Loss: 17.067575454711914\n",
      "Epoch: 10, Batch: 91, D Loss: 0.0997101187946825, G Loss: 16.485958099365234\n",
      "Epoch: 10, Batch: 92, D Loss: 0.09713863519770882, G Loss: 15.826226234436035\n",
      "Epoch: 10, Batch: 93, D Loss: 0.10208511848627211, G Loss: 16.129940032958984\n",
      "Epoch: 10, Batch: 94, D Loss: 0.09567744955322155, G Loss: 16.35369300842285\n",
      "Epoch: 10, Batch: 95, D Loss: 0.10493172386323835, G Loss: 16.63646697998047\n",
      "Epoch: 10, Batch: 96, D Loss: 0.0981425682568684, G Loss: 16.39874839782715\n",
      "Epoch: 10, Batch: 97, D Loss: 0.10128339974727751, G Loss: 16.1446533203125\n",
      "Epoch: 10, Batch: 98, D Loss: 0.10185385075571673, G Loss: 15.900867462158203\n",
      "Epoch: 10, Batch: 99, D Loss: 0.10542710275579736, G Loss: 15.934410095214844\n",
      "Epoch: 10, Batch: 100, D Loss: 0.09683708254679857, G Loss: 15.685175895690918\n",
      "Epoch: 10, Batch: 101, D Loss: 0.09814210718947436, G Loss: 15.30606746673584\n",
      "Epoch: 10, Batch: 102, D Loss: 0.10499843670452691, G Loss: 15.247932434082031\n",
      "Epoch: 10, Batch: 103, D Loss: 0.08719246682851178, G Loss: 14.953561782836914\n",
      "Epoch: 10, Batch: 104, D Loss: 0.098040093272175, G Loss: 14.458006858825684\n",
      "Epoch: 10, Batch: 105, D Loss: 0.09842353716803132, G Loss: 14.680892944335938\n",
      "Epoch: 10, Batch: 106, D Loss: 0.09600557205180849, G Loss: 14.86265754699707\n",
      "Epoch: 10, Batch: 107, D Loss: 0.09865448510336705, G Loss: 14.925979614257812\n",
      "Epoch: 10, Batch: 108, D Loss: 0.09408886935885619, G Loss: 14.754144668579102\n",
      "Epoch: 10, Batch: 109, D Loss: 0.0996099697187276, G Loss: 14.719924926757812\n",
      "Epoch: 10, Batch: 110, D Loss: 0.10149908314475908, G Loss: 14.85888671875\n",
      "Epoch: 10, Batch: 111, D Loss: 0.09781996472365506, G Loss: 14.965372085571289\n",
      "Epoch: 10, Batch: 112, D Loss: 0.1004366943758157, G Loss: 14.999937057495117\n",
      "Epoch: 10, Batch: 113, D Loss: 0.09877921603785467, G Loss: 14.966742515563965\n",
      "Epoch: 10, Batch: 114, D Loss: 0.10360338005520475, G Loss: 15.057857513427734\n",
      "Epoch: 10, Batch: 115, D Loss: 0.10155168465168174, G Loss: 15.161791801452637\n",
      "Epoch: 10, Batch: 116, D Loss: 0.09526976157111733, G Loss: 15.011701583862305\n",
      "Epoch: 10, Batch: 117, D Loss: 0.09236605177414958, G Loss: 14.729161262512207\n",
      "Epoch: 10, Batch: 118, D Loss: 0.10027546189445502, G Loss: 14.753311157226562\n",
      "Epoch: 10, Batch: 119, D Loss: 0.09260721774771241, G Loss: 14.753440856933594\n",
      "Epoch: 10, Batch: 120, D Loss: 0.102263241660566, G Loss: 14.934896469116211\n",
      "Epoch: 10, Batch: 121, D Loss: 0.1025281674548637, G Loss: 15.048858642578125\n",
      "Epoch: 10, Batch: 122, D Loss: 0.09924221962326385, G Loss: 14.726322174072266\n",
      "Epoch: 10, Batch: 123, D Loss: 0.09729995811727576, G Loss: 14.278726577758789\n",
      "Epoch: 10, Batch: 124, D Loss: 0.0959959475493406, G Loss: 14.048521995544434\n",
      "Epoch: 10, Batch: 125, D Loss: 0.0995616271562767, G Loss: 14.125865936279297\n",
      "Epoch: 10, Batch: 126, D Loss: 0.09916331982014981, G Loss: 14.371362686157227\n",
      "Epoch: 10, Batch: 127, D Loss: 0.09958505430026321, G Loss: 14.469812393188477\n",
      "Epoch: 10, Batch: 128, D Loss: 0.09895887396072567, G Loss: 14.256937026977539\n",
      "Epoch: 10, Batch: 129, D Loss: 0.1045866911128428, G Loss: 14.145133972167969\n",
      "Epoch: 10, Batch: 130, D Loss: 0.09265537560651183, G Loss: 13.911226272583008\n",
      "Epoch: 10, Batch: 131, D Loss: 0.0999509959078182, G Loss: 13.970874786376953\n",
      "Epoch: 10, Batch: 132, D Loss: 0.09811138594832869, G Loss: 14.236103057861328\n",
      "Epoch: 10, Batch: 133, D Loss: 0.10278889354850662, G Loss: 14.53980827331543\n",
      "Epoch: 10, Batch: 134, D Loss: 0.1011008542526497, G Loss: 14.592737197875977\n",
      "Epoch: 10, Batch: 135, D Loss: 0.09907841245080817, G Loss: 14.029322624206543\n",
      "Epoch: 10, Batch: 136, D Loss: 0.09891795866781194, G Loss: 13.894184112548828\n",
      "Epoch: 10, Batch: 137, D Loss: 0.09453405515205304, G Loss: 13.84872817993164\n",
      "Epoch: 10, Batch: 138, D Loss: 0.09862620319643156, G Loss: 14.113812446594238\n",
      "Epoch: 10, Batch: 139, D Loss: 0.09873579146278644, G Loss: 14.466327667236328\n",
      "Epoch: 10, Batch: 140, D Loss: 0.09524492647540228, G Loss: 14.495807647705078\n",
      "Epoch: 10, Batch: 141, D Loss: 0.09608257528094555, G Loss: 14.3465576171875\n",
      "Epoch: 10, Batch: 142, D Loss: 0.0982522565192312, G Loss: 14.301427841186523\n",
      "Epoch: 10, Batch: 143, D Loss: 0.1016163016069811, G Loss: 14.512788772583008\n",
      "Epoch: 10, Batch: 144, D Loss: 0.09029513291466174, G Loss: 14.512020111083984\n",
      "Epoch: 10, Batch: 145, D Loss: 0.09667075377959122, G Loss: 14.54985523223877\n",
      "Epoch: 10, Batch: 146, D Loss: 0.10016253164570799, G Loss: 14.728910446166992\n",
      "Epoch: 10, Batch: 147, D Loss: 0.10491892240648326, G Loss: 15.000877380371094\n",
      "Epoch: 10, Batch: 148, D Loss: 0.09402448440752664, G Loss: 14.901897430419922\n",
      "Epoch: 10, Batch: 149, D Loss: 0.09611572391705181, G Loss: 14.713671684265137\n",
      "Epoch: 10, Batch: 150, D Loss: 0.10117972734938974, G Loss: 14.80685806274414\n",
      "Epoch: 10, Batch: 151, D Loss: 0.09243307471625428, G Loss: 14.94124698638916\n",
      "Epoch: 10, Batch: 152, D Loss: 0.09614019923392902, G Loss: 15.193960189819336\n",
      "Epoch: 10, Batch: 153, D Loss: 0.09932351433936759, G Loss: 15.499073028564453\n",
      "Epoch: 10, Batch: 154, D Loss: 0.0928560842798305, G Loss: 15.472295761108398\n",
      "Epoch: 10, Batch: 155, D Loss: 0.08967158164443845, G Loss: 15.178520202636719\n",
      "Epoch: 10, Batch: 156, D Loss: 0.10470501124246567, G Loss: 15.350933074951172\n",
      "Epoch: 10, Batch: 157, D Loss: 0.10254210100718808, G Loss: 15.736133575439453\n",
      "Epoch: 10, Batch: 158, D Loss: 0.10516093913173563, G Loss: 16.054792404174805\n",
      "Epoch: 10, Batch: 159, D Loss: 0.0993603998110757, G Loss: 15.816234588623047\n",
      "Epoch: 10, Batch: 160, D Loss: 0.10540919192953879, G Loss: 15.58770751953125\n",
      "Epoch: 10, Batch: 161, D Loss: 0.097512987278634, G Loss: 15.401203155517578\n",
      "Epoch: 10, Batch: 162, D Loss: 0.09986268082494121, G Loss: 15.491096496582031\n",
      "Epoch: 10, Batch: 163, D Loss: 0.10086285183266597, G Loss: 15.779253005981445\n",
      "Epoch: 10, Batch: 164, D Loss: 0.10034783474753795, G Loss: 16.00127410888672\n",
      "Epoch: 10, Batch: 165, D Loss: 0.09917250835430735, G Loss: 15.951546669006348\n",
      "Epoch: 10, Batch: 166, D Loss: 0.09737984070169148, G Loss: 15.71875\n",
      "Epoch: 10, Batch: 167, D Loss: 0.09112548469732218, G Loss: 15.451927185058594\n",
      "Epoch: 10, Batch: 168, D Loss: 0.10413601522877514, G Loss: 15.718188285827637\n",
      "Epoch: 10, Batch: 169, D Loss: 0.10275822631373899, G Loss: 16.226694107055664\n",
      "Epoch: 10, Batch: 170, D Loss: 0.10194676672399439, G Loss: 16.432472229003906\n",
      "Epoch: 10, Batch: 171, D Loss: 0.09368641837933467, G Loss: 15.981658935546875\n",
      "Epoch: 10, Batch: 172, D Loss: 0.08922098810962353, G Loss: 15.4227933883667\n",
      "Epoch: 10, Batch: 173, D Loss: 0.10127679342049589, G Loss: 15.47497272491455\n",
      "Epoch: 10, Batch: 174, D Loss: 0.09385911780631062, G Loss: 15.839712142944336\n",
      "Epoch: 10, Batch: 175, D Loss: 0.09637650255689323, G Loss: 16.23627281188965\n",
      "Epoch: 10, Batch: 176, D Loss: 0.10047130741973831, G Loss: 15.753376960754395\n",
      "Epoch: 10, Batch: 177, D Loss: 0.09952104889049451, G Loss: 15.501091003417969\n",
      "Epoch: 10, Batch: 178, D Loss: 0.10219812416868024, G Loss: 15.145448684692383\n",
      "Epoch: 10, Batch: 179, D Loss: 0.09738241196060926, G Loss: 14.8245849609375\n",
      "Epoch: 10, Batch: 180, D Loss: 0.09731614182159376, G Loss: 14.756635665893555\n",
      "Epoch: 10, Batch: 181, D Loss: 0.09430211650229126, G Loss: 14.790494918823242\n",
      "Epoch: 10, Batch: 182, D Loss: 0.10021533678018102, G Loss: 14.993206024169922\n",
      "Epoch: 10, Batch: 183, D Loss: 0.1015550722974865, G Loss: 15.151573181152344\n",
      "Epoch: 10, Batch: 184, D Loss: 0.09155359389380635, G Loss: 14.98029613494873\n",
      "Epoch: 10, Batch: 185, D Loss: 0.09987504280493908, G Loss: 14.950450897216797\n",
      "Epoch: 10, Batch: 186, D Loss: 0.10115101906674795, G Loss: 15.102348327636719\n",
      "Epoch: 10, Batch: 187, D Loss: 0.09664977842650302, G Loss: 15.684371948242188\n",
      "Epoch: 10, Batch: 188, D Loss: 0.09989101015375468, G Loss: 16.07763671875\n",
      "Epoch: 10, Batch: 189, D Loss: 0.10076027513096619, G Loss: 16.30661964416504\n",
      "Epoch: 10, Batch: 190, D Loss: 0.1032944983817714, G Loss: 16.552249908447266\n",
      "Epoch: 10, Batch: 191, D Loss: 0.10021273056273827, G Loss: 16.705596923828125\n",
      "Epoch: 10, Batch: 192, D Loss: 0.09840303150159713, G Loss: 16.929588317871094\n",
      "Epoch: 10, Batch: 193, D Loss: 0.09957525330580097, G Loss: 17.453523635864258\n",
      "Epoch: 10, Batch: 194, D Loss: 0.09991152053467722, G Loss: 18.054100036621094\n",
      "Epoch: 10, Batch: 195, D Loss: 0.09779282676871315, G Loss: 17.948822021484375\n",
      "Epoch: 10, Batch: 196, D Loss: 0.09539514452341358, G Loss: 17.243335723876953\n",
      "Epoch: 10, Batch: 197, D Loss: 0.09826591389241468, G Loss: 17.71178436279297\n",
      "Epoch: 10, Batch: 198, D Loss: 0.09976830604422737, G Loss: 17.71192741394043\n",
      "Epoch: 10, Batch: 199, D Loss: 0.10370042463976148, G Loss: 17.67864990234375\n",
      "Epoch: 10, Batch: 200, D Loss: 0.10886855764025238, G Loss: 17.616069793701172\n",
      "Epoch: 10, Batch: 201, D Loss: 0.10857181291324736, G Loss: 17.02065658569336\n",
      "Epoch: 10, Batch: 202, D Loss: 0.09389366022064749, G Loss: 15.297796249389648\n",
      "Epoch: 10, Batch: 203, D Loss: 0.09878256943967756, G Loss: 14.081766128540039\n",
      "Epoch: 10, Batch: 204, D Loss: 0.1034051362628361, G Loss: 13.614169120788574\n",
      "Epoch: 10, Batch: 205, D Loss: 0.0964359064440714, G Loss: 13.418275833129883\n",
      "Epoch: 10, Batch: 206, D Loss: 0.09593939094509096, G Loss: 13.026193618774414\n",
      "Epoch: 10, Batch: 207, D Loss: 0.09792651761472371, G Loss: 12.634649276733398\n",
      "Epoch: 10, Batch: 208, D Loss: 0.09368167410684691, G Loss: 12.254213333129883\n",
      "Epoch: 10, Batch: 209, D Loss: 0.09318496016931022, G Loss: 12.159242630004883\n",
      "Epoch: 10, Batch: 210, D Loss: 0.09384996731660067, G Loss: 12.445541381835938\n",
      "Epoch: 10, Batch: 211, D Loss: 0.09258304563354613, G Loss: 12.968881607055664\n",
      "Epoch: 10, Batch: 212, D Loss: 0.10098463983683814, G Loss: 13.654233932495117\n",
      "Epoch: 10, Batch: 213, D Loss: 0.10373656767080774, G Loss: 14.209911346435547\n",
      "Epoch: 10, Batch: 214, D Loss: 0.10140436049346135, G Loss: 14.415083885192871\n",
      "Epoch: 10, Batch: 215, D Loss: 0.09522867349411968, G Loss: 14.261837005615234\n",
      "Epoch: 10, Batch: 216, D Loss: 0.10536791574435256, G Loss: 14.444694519042969\n",
      "Epoch: 10, Batch: 217, D Loss: 0.10040042697129081, G Loss: 14.839433670043945\n",
      "Epoch: 10, Batch: 218, D Loss: 0.0951895332227366, G Loss: 15.118967056274414\n",
      "Epoch: 10, Batch: 219, D Loss: 0.09619683104727983, G Loss: 15.245025634765625\n",
      "Epoch: 10, Batch: 220, D Loss: 0.10205828365089786, G Loss: 15.386002540588379\n",
      "Epoch: 10, Batch: 221, D Loss: 0.09538479934388278, G Loss: 15.376952171325684\n",
      "Epoch: 10, Batch: 222, D Loss: 0.10238956727093296, G Loss: 15.519804000854492\n",
      "Epoch: 10, Batch: 223, D Loss: 0.09556914083960777, G Loss: 15.563918113708496\n",
      "Epoch: 10, Batch: 224, D Loss: 0.09360176379354357, G Loss: 15.504838943481445\n",
      "Epoch: 10, Batch: 225, D Loss: 0.09116578865426561, G Loss: 15.41415786743164\n",
      "Epoch: 10, Batch: 226, D Loss: 0.09893858700724678, G Loss: 15.59520435333252\n",
      "Epoch: 10, Batch: 227, D Loss: 0.09888453541177, G Loss: 15.896389961242676\n",
      "Epoch: 10, Batch: 228, D Loss: 0.10619365454629914, G Loss: 16.228979110717773\n",
      "Epoch: 10, Batch: 229, D Loss: 0.10518406835674554, G Loss: 16.12098503112793\n",
      "Epoch: 10, Batch: 230, D Loss: 0.09827990751384874, G Loss: 15.451532363891602\n",
      "Epoch: 10, Batch: 231, D Loss: 0.09299707530274759, G Loss: 15.053690910339355\n",
      "Epoch: 10, Batch: 232, D Loss: 0.1000459274274732, G Loss: 15.097268104553223\n",
      "Epoch: 10, Batch: 233, D Loss: 0.10487383106971748, G Loss: 15.59964370727539\n",
      "Epoch: 10, Batch: 234, D Loss: 0.09863461578792965, G Loss: 15.5555419921875\n",
      "Epoch: 10, Batch: 235, D Loss: 0.10631964831719642, G Loss: 15.628430366516113\n",
      "Epoch: 10, Batch: 236, D Loss: 0.09546147903366631, G Loss: 15.186052322387695\n",
      "Epoch: 10, Batch: 237, D Loss: 0.09424521889840776, G Loss: 14.782295227050781\n",
      "Epoch: 10, Batch: 238, D Loss: 0.10449387299543389, G Loss: 15.052450180053711\n",
      "Epoch: 10, Batch: 239, D Loss: 0.09347559298910824, G Loss: 15.465839385986328\n",
      "Epoch: 10, Batch: 240, D Loss: 0.1023939970509673, G Loss: 16.016204833984375\n",
      "Epoch: 10, Batch: 241, D Loss: 0.10402585685820043, G Loss: 16.374765396118164\n",
      "Epoch: 10, Batch: 242, D Loss: 0.10587431847125117, G Loss: 16.274354934692383\n",
      "Epoch: 10, Batch: 243, D Loss: 0.10211028842922687, G Loss: 15.92203426361084\n",
      "Epoch: 10, Batch: 244, D Loss: 0.10060504904042489, G Loss: 15.71744155883789\n",
      "Epoch: 10, Batch: 245, D Loss: 0.09409229973677213, G Loss: 15.597095489501953\n",
      "Epoch: 10, Batch: 246, D Loss: 0.10099662781446739, G Loss: 15.847570419311523\n",
      "Epoch: 10, Batch: 247, D Loss: 0.09945416062229384, G Loss: 16.156082153320312\n",
      "Epoch: 10, Batch: 248, D Loss: 0.1041222033973348, G Loss: 16.438358306884766\n",
      "Epoch: 10, Batch: 249, D Loss: 0.0981432447836923, G Loss: 16.268096923828125\n",
      "Epoch: 10, Batch: 250, D Loss: 0.10524343191903895, G Loss: 16.09954261779785\n",
      "Epoch: 10, Batch: 251, D Loss: 0.09144508816125096, G Loss: 15.8107328414917\n",
      "Epoch: 10, Batch: 252, D Loss: 0.09460223882219765, G Loss: 15.725997924804688\n",
      "Epoch: 10, Batch: 253, D Loss: 0.09928801472359083, G Loss: 15.96902847290039\n",
      "Epoch: 10, Batch: 254, D Loss: 0.1021930880779287, G Loss: 16.43196678161621\n",
      "Epoch: 10, Batch: 255, D Loss: 0.10356770525601888, G Loss: 16.776124954223633\n",
      "Epoch: 10, Batch: 256, D Loss: 0.10050139407149672, G Loss: 16.62116813659668\n",
      "Epoch: 10, Batch: 257, D Loss: 0.10835700113771196, G Loss: 16.423755645751953\n",
      "Epoch: 10, Batch: 258, D Loss: 0.09775413358400442, G Loss: 16.148847579956055\n",
      "Epoch: 10, Batch: 259, D Loss: 0.10353337578231248, G Loss: 16.162139892578125\n",
      "Epoch: 10, Batch: 260, D Loss: 0.09885857911961082, G Loss: 16.329435348510742\n",
      "Epoch: 10, Batch: 261, D Loss: 0.09803344368615186, G Loss: 16.458778381347656\n",
      "Epoch: 10, Batch: 262, D Loss: 0.10111412813211373, G Loss: 16.552799224853516\n",
      "Epoch: 10, Batch: 263, D Loss: 0.10030353327435293, G Loss: 16.55359649658203\n",
      "Epoch: 10, Batch: 264, D Loss: 0.09597436915952073, G Loss: 16.374441146850586\n",
      "Epoch: 10, Batch: 265, D Loss: 0.09411479290513824, G Loss: 16.207324981689453\n",
      "Epoch: 10, Batch: 266, D Loss: 0.0972041489029607, G Loss: 16.246910095214844\n",
      "Epoch: 10, Batch: 267, D Loss: 0.10126570318345074, G Loss: 16.715925216674805\n",
      "Epoch: 10, Batch: 268, D Loss: 0.09619163791314733, G Loss: 17.052654266357422\n",
      "Epoch: 10, Batch: 269, D Loss: 0.10270584606641009, G Loss: 17.302997589111328\n",
      "Epoch: 10, Batch: 270, D Loss: 0.10137437302814156, G Loss: 17.328649520874023\n",
      "Epoch: 10, Batch: 271, D Loss: 0.09778507860057317, G Loss: 17.25296401977539\n",
      "Epoch: 10, Batch: 272, D Loss: 0.10408256972808161, G Loss: 17.366159439086914\n",
      "Epoch: 10, Batch: 273, D Loss: 0.09633791226124444, G Loss: 17.599933624267578\n",
      "Epoch: 10, Batch: 274, D Loss: 0.10211339721898138, G Loss: 18.098743438720703\n",
      "Epoch: 10, Batch: 275, D Loss: 0.09042080422136278, G Loss: 18.13938331604004\n",
      "Epoch: 10, Batch: 276, D Loss: 0.09920640954443627, G Loss: 18.13331413269043\n",
      "Epoch: 10, Batch: 277, D Loss: 0.09804239042383411, G Loss: 18.142417907714844\n",
      "Epoch: 10, Batch: 278, D Loss: 0.10006006656247379, G Loss: 18.343442916870117\n",
      "Epoch: 10, Batch: 279, D Loss: 0.09553056734075849, G Loss: 18.40210723876953\n",
      "Epoch: 10, Batch: 280, D Loss: 0.10565053377046985, G Loss: 18.635704040527344\n",
      "Epoch: 10, Batch: 281, D Loss: 0.09826893755692101, G Loss: 18.669143676757812\n",
      "Epoch: 10, Batch: 282, D Loss: 0.09778063419353566, G Loss: 18.52798843383789\n",
      "Epoch: 10, Batch: 283, D Loss: 0.09885776496715071, G Loss: 18.508678436279297\n",
      "Epoch: 10, Batch: 284, D Loss: 0.10468447597833741, G Loss: 18.81675148010254\n",
      "Epoch: 10, Batch: 285, D Loss: 0.09978252995982739, G Loss: 18.760326385498047\n",
      "Epoch: 10, Batch: 286, D Loss: 0.10305545084737, G Loss: 18.78884506225586\n",
      "Epoch: 10, Batch: 287, D Loss: 0.10130285840750686, G Loss: 18.666353225708008\n",
      "Epoch: 10, Batch: 288, D Loss: 0.09533046677327928, G Loss: 18.232933044433594\n",
      "Epoch: 10, Batch: 289, D Loss: 0.09998383188029702, G Loss: 18.374412536621094\n",
      "Epoch: 10, Batch: 290, D Loss: 0.09925570769797476, G Loss: 18.746326446533203\n",
      "Epoch: 10, Batch: 291, D Loss: 0.10298559387295181, G Loss: 18.989639282226562\n",
      "Epoch: 10, Batch: 292, D Loss: 0.10284886786709091, G Loss: 19.02720832824707\n",
      "Epoch: 10, Batch: 293, D Loss: 0.09767677207551473, G Loss: 18.736825942993164\n",
      "Epoch: 10, Batch: 294, D Loss: 0.10378937804033006, G Loss: 18.65373992919922\n",
      "Epoch: 10, Batch: 295, D Loss: 0.09445836131319796, G Loss: 18.283538818359375\n",
      "Epoch: 10, Batch: 296, D Loss: 0.09991154610997288, G Loss: 18.41110610961914\n",
      "Epoch: 10, Batch: 297, D Loss: 0.10312672355365216, G Loss: 18.874252319335938\n",
      "Epoch: 10, Batch: 298, D Loss: 0.09646354869829077, G Loss: 19.29861068725586\n",
      "Epoch: 10, Batch: 299, D Loss: 0.09697796612134568, G Loss: 19.299161911010742\n",
      "Epoch: 10, Batch: 300, D Loss: 0.10320981039171961, G Loss: 19.445819854736328\n",
      "Epoch: 10, Batch: 301, D Loss: 0.10044175569755165, G Loss: 19.40450668334961\n",
      "Epoch: 10, Batch: 302, D Loss: 0.09369818289482423, G Loss: 19.604331970214844\n",
      "Epoch: 10, Batch: 303, D Loss: 0.0975480094236858, G Loss: 19.696205139160156\n",
      "Epoch: 10, Batch: 304, D Loss: 0.09944161883680169, G Loss: 20.133434295654297\n",
      "Epoch: 10, Batch: 305, D Loss: 0.09486799045673333, G Loss: 19.870328903198242\n",
      "Epoch: 10, Batch: 306, D Loss: 0.09941189145208307, G Loss: 19.35224151611328\n",
      "Epoch: 10, Batch: 307, D Loss: 0.09582767160982186, G Loss: 18.750282287597656\n",
      "Epoch: 10, Batch: 308, D Loss: 0.09896382385770908, G Loss: 18.362472534179688\n",
      "Epoch: 10, Batch: 309, D Loss: 0.09784021950698207, G Loss: 17.775283813476562\n",
      "Epoch: 10, Batch: 310, D Loss: 0.09783915152635458, G Loss: 17.378602981567383\n",
      "Epoch: 10, Batch: 311, D Loss: 0.10495305220494977, G Loss: 17.179630279541016\n",
      "Epoch: 10, Batch: 312, D Loss: 0.10197312024294547, G Loss: 17.027660369873047\n",
      "Epoch: 10, Batch: 313, D Loss: 0.09979821442487058, G Loss: 16.48482894897461\n",
      "Epoch: 10, Batch: 314, D Loss: 0.09596120084477988, G Loss: 15.891754150390625\n",
      "Epoch: 10, Batch: 315, D Loss: 0.10034821848186937, G Loss: 15.587894439697266\n",
      "Epoch: 10, Batch: 316, D Loss: 0.09970936806797681, G Loss: 15.520490646362305\n",
      "Epoch: 10, Batch: 317, D Loss: 0.09656637891839637, G Loss: 15.368070602416992\n",
      "Epoch: 10, Batch: 318, D Loss: 0.09679193245630557, G Loss: 15.249811172485352\n",
      "Epoch: 10, Batch: 319, D Loss: 0.09125089081132387, G Loss: 14.904790878295898\n",
      "Epoch: 10, Batch: 320, D Loss: 0.10019352936542703, G Loss: 14.807256698608398\n",
      "Epoch: 10, Batch: 321, D Loss: 0.10071811718617596, G Loss: 14.89610481262207\n",
      "Epoch: 10, Batch: 322, D Loss: 0.09722701543950052, G Loss: 14.959997177124023\n",
      "Epoch: 10, Batch: 323, D Loss: 0.1049887109858787, G Loss: 15.068641662597656\n",
      "Epoch: 10, Batch: 324, D Loss: 0.09926843719482292, G Loss: 14.985076904296875\n",
      "Epoch: 10, Batch: 325, D Loss: 0.09670987045822699, G Loss: 14.798177719116211\n",
      "Epoch: 10, Batch: 326, D Loss: 0.09695212853824842, G Loss: 14.711729049682617\n",
      "Epoch: 10, Batch: 327, D Loss: 0.10025698701105057, G Loss: 14.818723678588867\n",
      "Epoch: 10, Batch: 328, D Loss: 0.09787296794218037, G Loss: 15.006020545959473\n",
      "Epoch: 10, Batch: 329, D Loss: 0.09588317872169227, G Loss: 15.108753204345703\n",
      "Epoch: 10, Batch: 330, D Loss: 0.10404383287902874, G Loss: 15.2820405960083\n",
      "Epoch: 10, Batch: 331, D Loss: 0.09530597960548448, G Loss: 15.21973705291748\n",
      "Epoch: 10, Batch: 332, D Loss: 0.10215700630068625, G Loss: 15.248053550720215\n",
      "Epoch: 10, Batch: 333, D Loss: 0.09879474087975382, G Loss: 15.296782493591309\n",
      "Epoch: 10, Batch: 334, D Loss: 0.09331378192412387, G Loss: 15.235843658447266\n",
      "Epoch: 10, Batch: 335, D Loss: 0.09633968676902782, G Loss: 15.281927108764648\n",
      "Epoch: 10, Batch: 336, D Loss: 0.10011849459333177, G Loss: 15.495590209960938\n",
      "Epoch: 10, Batch: 337, D Loss: 0.09712049798958589, G Loss: 15.645547866821289\n",
      "Epoch: 10, Batch: 338, D Loss: 0.09799850543085142, G Loss: 15.652664184570312\n",
      "Epoch: 10, Batch: 339, D Loss: 0.10404210604875175, G Loss: 15.765750885009766\n",
      "Epoch: 10, Batch: 340, D Loss: 0.10161804716469192, G Loss: 15.795452117919922\n",
      "Epoch: 10, Batch: 341, D Loss: 0.10248845414079, G Loss: 15.759322166442871\n",
      "Epoch: 10, Batch: 342, D Loss: 0.10372844029966188, G Loss: 15.766976356506348\n",
      "Epoch: 10, Batch: 343, D Loss: 0.10560365813878292, G Loss: 15.869050979614258\n",
      "Epoch: 10, Batch: 344, D Loss: 0.1080051990344515, G Loss: 15.851637840270996\n",
      "Epoch: 10, Batch: 345, D Loss: 0.1004789500879184, G Loss: 15.72256088256836\n",
      "Epoch: 10, Batch: 346, D Loss: 0.10178666586621432, G Loss: 15.532886505126953\n",
      "Epoch: 10, Batch: 347, D Loss: 0.09872987053806526, G Loss: 15.406970977783203\n",
      "Epoch: 10, Batch: 348, D Loss: 0.10044838789522714, G Loss: 15.17352294921875\n",
      "Epoch: 10, Batch: 349, D Loss: 0.10310926166332024, G Loss: 15.071921348571777\n",
      "Epoch: 10, Batch: 350, D Loss: 0.09813515477949863, G Loss: 15.138472557067871\n",
      "Epoch: 10, Batch: 351, D Loss: 0.10083408863107479, G Loss: 15.001348495483398\n",
      "Epoch: 10, Batch: 352, D Loss: 0.09438001296541643, G Loss: 14.717670440673828\n",
      "Epoch: 10, Batch: 353, D Loss: 0.08998135596274892, G Loss: 14.47118091583252\n",
      "Epoch: 10, Batch: 354, D Loss: 0.10261883196848487, G Loss: 14.73531436920166\n",
      "Epoch: 10, Batch: 355, D Loss: 0.10592653433069188, G Loss: 15.315674781799316\n",
      "Epoch: 10, Batch: 356, D Loss: 0.10045298417804815, G Loss: 15.549769401550293\n",
      "Epoch: 10, Batch: 357, D Loss: 0.10241672328666596, G Loss: 14.61526870727539\n",
      "Epoch: 10, Batch: 358, D Loss: 0.09127487698165737, G Loss: 14.076632499694824\n",
      "Epoch: 10, Batch: 359, D Loss: 0.1010644947621131, G Loss: 13.9832763671875\n",
      "Epoch: 10, Batch: 360, D Loss: 0.09368411514918762, G Loss: 14.201643943786621\n",
      "Epoch: 10, Batch: 361, D Loss: 0.10446172049046254, G Loss: 14.837112426757812\n",
      "Epoch: 10, Batch: 362, D Loss: 0.09654543165916607, G Loss: 15.257972717285156\n",
      "Epoch: 10, Batch: 363, D Loss: 0.0986429492485712, G Loss: 14.99141788482666\n",
      "Epoch: 10, Batch: 364, D Loss: 0.10059811784398676, G Loss: 14.814970970153809\n",
      "Epoch: 10, Batch: 365, D Loss: 0.09516674584966722, G Loss: 14.697644233703613\n",
      "Epoch: 10, Batch: 366, D Loss: 0.09751205187548351, G Loss: 14.828856468200684\n",
      "Epoch: 10, Batch: 367, D Loss: 0.11178648885022824, G Loss: 15.358940124511719\n",
      "Epoch: 10, Batch: 368, D Loss: 0.09050977279210315, G Loss: 15.28285026550293\n",
      "Epoch: 10, Batch: 369, D Loss: 0.09662249084777841, G Loss: 15.086729049682617\n",
      "Epoch: 10, Batch: 370, D Loss: 0.09754041227544974, G Loss: 14.930696487426758\n",
      "Epoch: 10, Batch: 371, D Loss: 0.09772173185191946, G Loss: 14.832024574279785\n",
      "Epoch: 10, Batch: 372, D Loss: 0.0997424941891154, G Loss: 15.120721817016602\n",
      "Epoch: 10, Batch: 373, D Loss: 0.09466728064857932, G Loss: 15.332923889160156\n",
      "Epoch: 10, Batch: 374, D Loss: 0.09659840814299514, G Loss: 15.4506196975708\n",
      "Epoch: 10, Batch: 375, D Loss: 0.09782884074921583, G Loss: 15.505979537963867\n",
      "Epoch: 10, Batch: 376, D Loss: 0.09886579884259561, G Loss: 15.585586547851562\n",
      "Epoch: 10, Batch: 377, D Loss: 0.1027514573253967, G Loss: 15.81501579284668\n",
      "Epoch: 10, Batch: 378, D Loss: 0.10022779818687866, G Loss: 15.97773551940918\n",
      "Epoch: 10, Batch: 379, D Loss: 0.09797863935622786, G Loss: 16.070072174072266\n",
      "Epoch: 10, Batch: 380, D Loss: 0.10057832830703006, G Loss: 16.16376495361328\n",
      "Epoch: 10, Batch: 381, D Loss: 0.09374213609470416, G Loss: 16.132999420166016\n",
      "Epoch: 10, Batch: 382, D Loss: 0.10086660328605035, G Loss: 16.219938278198242\n",
      "Epoch: 10, Batch: 383, D Loss: 0.10157536217926122, G Loss: 16.46540069580078\n",
      "Epoch: 10, Batch: 384, D Loss: 0.0972436699893322, G Loss: 16.588516235351562\n",
      "Epoch: 10, Batch: 385, D Loss: 0.09429819433531961, G Loss: 16.499553680419922\n",
      "Epoch: 10, Batch: 386, D Loss: 0.10358015871849346, G Loss: 16.528289794921875\n",
      "Epoch: 10, Batch: 387, D Loss: 0.09887763182072717, G Loss: 16.431795120239258\n",
      "Epoch: 10, Batch: 388, D Loss: 0.10302576869502644, G Loss: 16.555335998535156\n",
      "Epoch: 10, Batch: 389, D Loss: 0.09695598748263379, G Loss: 16.54747772216797\n",
      "Epoch: 10, Batch: 390, D Loss: 0.09744979127306408, G Loss: 16.459842681884766\n",
      "Epoch: 10, Batch: 391, D Loss: 0.10066614786828154, G Loss: 16.50803565979004\n",
      "Epoch: 10, Batch: 392, D Loss: 0.09109285977150705, G Loss: 16.455623626708984\n",
      "Epoch: 10, Batch: 393, D Loss: 0.10152335061030016, G Loss: 16.593338012695312\n",
      "Epoch: 10, Batch: 394, D Loss: 0.09711165647178888, G Loss: 16.726150512695312\n",
      "Epoch: 10, Batch: 395, D Loss: 0.10511066965011828, G Loss: 16.938766479492188\n",
      "Epoch: 10, Batch: 396, D Loss: 0.09819217787925183, G Loss: 16.89633560180664\n",
      "Epoch: 10, Batch: 397, D Loss: 0.09753939141312173, G Loss: 16.652652740478516\n",
      "Epoch: 10, Batch: 398, D Loss: 0.09790243423484668, G Loss: 16.489429473876953\n",
      "Epoch: 10, Batch: 399, D Loss: 0.09849693297301343, G Loss: 16.520511627197266\n",
      "Epoch: 10, Batch: 400, D Loss: 0.1061335346534964, G Loss: 16.795677185058594\n",
      "Epoch: 10, Batch: 401, D Loss: 0.09800155677740108, G Loss: 16.8633975982666\n",
      "Epoch: 10, Batch: 402, D Loss: 0.10088476840330429, G Loss: 16.741596221923828\n",
      "Epoch: 10, Batch: 403, D Loss: 0.09551849305441351, G Loss: 16.485591888427734\n",
      "Epoch: 10, Batch: 404, D Loss: 0.10047646404218114, G Loss: 16.457195281982422\n",
      "Epoch: 10, Batch: 405, D Loss: 0.10066969197139386, G Loss: 16.64475440979004\n",
      "Epoch: 10, Batch: 406, D Loss: 0.10171590315623646, G Loss: 16.924556732177734\n",
      "Epoch: 10, Batch: 407, D Loss: 0.1012871474373469, G Loss: 17.051118850708008\n",
      "Epoch: 10, Batch: 408, D Loss: 0.1011170799843022, G Loss: 16.983171463012695\n",
      "Epoch: 10, Batch: 409, D Loss: 0.09849508914945027, G Loss: 16.817420959472656\n",
      "Epoch: 10, Batch: 410, D Loss: 0.10556063969549712, G Loss: 16.88165855407715\n",
      "Epoch: 10, Batch: 411, D Loss: 0.0958825721181995, G Loss: 16.971677780151367\n",
      "Epoch: 10, Batch: 412, D Loss: 0.10137442270041142, G Loss: 17.086416244506836\n",
      "Epoch: 10, Batch: 413, D Loss: 0.0941616341260918, G Loss: 17.051342010498047\n",
      "Epoch: 10, Batch: 414, D Loss: 0.09632815955156815, G Loss: 16.996952056884766\n",
      "Epoch: 10, Batch: 415, D Loss: 0.09610522441979441, G Loss: 16.941822052001953\n",
      "Epoch: 10, Batch: 416, D Loss: 0.09766210512259477, G Loss: 16.997623443603516\n",
      "Epoch: 10, Batch: 417, D Loss: 0.10219839560855348, G Loss: 17.233936309814453\n",
      "Epoch: 10, Batch: 418, D Loss: 0.1011244653642116, G Loss: 17.427764892578125\n",
      "Epoch: 10, Batch: 419, D Loss: 0.09455819442537461, G Loss: 17.221771240234375\n",
      "Epoch: 10, Batch: 420, D Loss: 0.09771632783483497, G Loss: 16.993953704833984\n",
      "Epoch: 10, Batch: 421, D Loss: 0.09924477993740233, G Loss: 16.938945770263672\n",
      "Epoch: 10, Batch: 422, D Loss: 0.09758186962158533, G Loss: 17.017940521240234\n",
      "Epoch: 10, Batch: 423, D Loss: 0.09257710553652387, G Loss: 16.990718841552734\n",
      "Epoch: 10, Batch: 424, D Loss: 0.09543330124163418, G Loss: 16.94901466369629\n",
      "Epoch: 10, Batch: 425, D Loss: 0.10032581464123425, G Loss: 16.964984893798828\n",
      "Epoch: 10, Batch: 426, D Loss: 0.10272374606556056, G Loss: 17.012035369873047\n",
      "Epoch: 10, Batch: 427, D Loss: 0.10248253271359786, G Loss: 17.04422378540039\n",
      "Epoch: 10, Batch: 428, D Loss: 0.09513579291053986, G Loss: 16.830781936645508\n",
      "Epoch: 10, Batch: 429, D Loss: 0.09904568353330134, G Loss: 16.663787841796875\n",
      "Epoch: 10, Batch: 430, D Loss: 0.09860029717600582, G Loss: 16.680591583251953\n",
      "Epoch: 10, Batch: 431, D Loss: 0.09922712783016507, G Loss: 16.768478393554688\n",
      "Epoch: 10, Batch: 432, D Loss: 0.09943828865684523, G Loss: 16.953323364257812\n",
      "Epoch: 10, Batch: 433, D Loss: 0.09222941929982476, G Loss: 16.82701873779297\n",
      "Epoch: 10, Batch: 434, D Loss: 0.09392863207537516, G Loss: 16.668834686279297\n",
      "Epoch: 10, Batch: 435, D Loss: 0.09454277034396164, G Loss: 16.687488555908203\n",
      "Epoch: 10, Batch: 436, D Loss: 0.10041019407262652, G Loss: 17.063823699951172\n",
      "Epoch: 10, Batch: 437, D Loss: 0.08710131382877506, G Loss: 17.184162139892578\n",
      "Epoch: 10, Batch: 438, D Loss: 0.10082276236802379, G Loss: 17.370853424072266\n",
      "Epoch: 10, Batch: 439, D Loss: 0.10242186279825027, G Loss: 17.575462341308594\n",
      "Epoch: 10, Batch: 440, D Loss: 0.0973861339466442, G Loss: 17.48780059814453\n",
      "Epoch: 10, Batch: 441, D Loss: 0.10334062397437727, G Loss: 17.429161071777344\n",
      "Epoch: 10, Batch: 442, D Loss: 0.10593093739327486, G Loss: 17.501632690429688\n",
      "Epoch: 10, Batch: 443, D Loss: 0.10046298583982605, G Loss: 17.474164962768555\n",
      "Epoch: 10, Batch: 444, D Loss: 0.10386479435080886, G Loss: 17.488414764404297\n",
      "Epoch: 10, Batch: 445, D Loss: 0.10550157423179485, G Loss: 17.616987228393555\n",
      "Epoch: 10, Batch: 446, D Loss: 0.09933982459478408, G Loss: 17.545547485351562\n",
      "Epoch: 10, Batch: 447, D Loss: 0.09822825155986514, G Loss: 17.388099670410156\n",
      "Epoch: 10, Batch: 448, D Loss: 0.10349313812977456, G Loss: 17.410465240478516\n",
      "Epoch: 10, Batch: 449, D Loss: 0.09501399024587087, G Loss: 17.354312896728516\n",
      "Epoch: 10, Batch: 450, D Loss: 0.09907193450240648, G Loss: 17.347270965576172\n",
      "Epoch: 10, Batch: 451, D Loss: 0.09514233512140535, G Loss: 17.259784698486328\n",
      "Epoch: 10, Batch: 452, D Loss: 0.09760752478914014, G Loss: 17.199459075927734\n",
      "Epoch: 10, Batch: 453, D Loss: 0.09889604350141035, G Loss: 17.20792579650879\n",
      "Epoch: 10, Batch: 454, D Loss: 0.09521759551971165, G Loss: 17.143085479736328\n",
      "Epoch: 10, Batch: 455, D Loss: 0.09534579146396283, G Loss: 17.069272994995117\n",
      "Epoch: 10, Batch: 456, D Loss: 0.10200058238792664, G Loss: 17.19886016845703\n",
      "Epoch: 10, Batch: 457, D Loss: 0.09645925657201104, G Loss: 17.212913513183594\n",
      "Epoch: 10, Batch: 458, D Loss: 0.10426344047852609, G Loss: 17.346092224121094\n",
      "Epoch: 10, Batch: 459, D Loss: 0.09566814535397228, G Loss: 17.21094512939453\n",
      "Epoch: 10, Batch: 460, D Loss: 0.09457098376846673, G Loss: 16.974098205566406\n",
      "Epoch: 10, Batch: 461, D Loss: 0.10264051505515326, G Loss: 17.056819915771484\n",
      "Epoch: 10, Batch: 462, D Loss: 0.10429249871000223, G Loss: 17.372303009033203\n",
      "Epoch: 10, Batch: 463, D Loss: 0.10268641786305821, G Loss: 17.597900390625\n",
      "Epoch: 10, Batch: 464, D Loss: 0.09555975869669098, G Loss: 17.448331832885742\n",
      "Epoch: 10, Batch: 465, D Loss: 0.10243963157996916, G Loss: 17.00541114807129\n",
      "Epoch: 10, Batch: 466, D Loss: 0.10498705203748493, G Loss: 17.126758575439453\n",
      "Epoch: 10, Batch: 467, D Loss: 0.10104115435476047, G Loss: 17.35466766357422\n",
      "Epoch: 11, Batch: 0, D Loss: 0.09346406073886904, G Loss: 17.421703338623047\n",
      "Epoch: 11, Batch: 1, D Loss: 0.10090344913717608, G Loss: 17.565143585205078\n",
      "Epoch: 11, Batch: 2, D Loss: 0.10492769925610457, G Loss: 17.796348571777344\n",
      "Epoch: 11, Batch: 3, D Loss: 0.10133139192621332, G Loss: 17.87984848022461\n",
      "Epoch: 11, Batch: 4, D Loss: 0.09919002055670134, G Loss: 17.804636001586914\n",
      "Epoch: 11, Batch: 5, D Loss: 0.09878000842981205, G Loss: 17.718276977539062\n",
      "Epoch: 11, Batch: 6, D Loss: 0.0943175876303961, G Loss: 17.176284790039062\n",
      "Epoch: 11, Batch: 7, D Loss: 0.10271698980127919, G Loss: 17.469623565673828\n",
      "Epoch: 11, Batch: 8, D Loss: 0.09898089283988476, G Loss: 17.683876037597656\n",
      "Epoch: 11, Batch: 9, D Loss: 0.09973217810093082, G Loss: 17.75192642211914\n",
      "Epoch: 11, Batch: 10, D Loss: 0.09095818926488963, G Loss: 17.48708724975586\n",
      "Epoch: 11, Batch: 11, D Loss: 0.09571568571123024, G Loss: 17.313968658447266\n",
      "Epoch: 11, Batch: 12, D Loss: 0.09883664449549201, G Loss: 17.473243713378906\n",
      "Epoch: 11, Batch: 13, D Loss: 0.10209911593875365, G Loss: 17.93012809753418\n",
      "Epoch: 11, Batch: 14, D Loss: 0.09801677581193502, G Loss: 18.19183349609375\n",
      "Epoch: 11, Batch: 15, D Loss: 0.10182244258060891, G Loss: 18.063983917236328\n",
      "Epoch: 11, Batch: 16, D Loss: 0.09816444899414023, G Loss: 17.46558380126953\n",
      "Epoch: 11, Batch: 17, D Loss: 0.09747506977675613, G Loss: 16.870010375976562\n",
      "Epoch: 11, Batch: 18, D Loss: 0.09424270444870864, G Loss: 16.589473724365234\n",
      "Epoch: 11, Batch: 19, D Loss: 0.10084508313973828, G Loss: 16.708175659179688\n",
      "Epoch: 11, Batch: 20, D Loss: 0.0959506819921998, G Loss: 16.805458068847656\n",
      "Epoch: 11, Batch: 21, D Loss: 0.09281388362627219, G Loss: 16.691165924072266\n",
      "Epoch: 11, Batch: 22, D Loss: 0.09935673301622039, G Loss: 16.602954864501953\n",
      "Epoch: 11, Batch: 23, D Loss: 0.09423434310716772, G Loss: 16.47218894958496\n",
      "Epoch: 11, Batch: 24, D Loss: 0.09502760100100005, G Loss: 16.476736068725586\n",
      "Epoch: 11, Batch: 25, D Loss: 0.10292615047423226, G Loss: 16.74810791015625\n",
      "Epoch: 11, Batch: 26, D Loss: 0.0993580838076511, G Loss: 16.92020034790039\n",
      "Epoch: 11, Batch: 27, D Loss: 0.10023515685766071, G Loss: 16.929649353027344\n",
      "Epoch: 11, Batch: 28, D Loss: 0.10261843282493288, G Loss: 16.980060577392578\n",
      "Epoch: 11, Batch: 29, D Loss: 0.1082721379931062, G Loss: 17.323352813720703\n",
      "Epoch: 11, Batch: 30, D Loss: 0.09936080781314871, G Loss: 17.45505142211914\n",
      "Epoch: 11, Batch: 31, D Loss: 0.10542569050241735, G Loss: 17.578868865966797\n",
      "Epoch: 11, Batch: 32, D Loss: 0.1033388786607965, G Loss: 17.640974044799805\n",
      "Epoch: 11, Batch: 33, D Loss: 0.09920327753389557, G Loss: 17.568878173828125\n",
      "Epoch: 11, Batch: 34, D Loss: 0.101111744679792, G Loss: 17.484594345092773\n",
      "Epoch: 11, Batch: 35, D Loss: 0.10388015008713136, G Loss: 17.465797424316406\n",
      "Epoch: 11, Batch: 36, D Loss: 0.09574222408835364, G Loss: 17.415958404541016\n",
      "Epoch: 11, Batch: 37, D Loss: 0.10593423068321606, G Loss: 17.49411392211914\n",
      "Epoch: 11, Batch: 38, D Loss: 0.0982155939879803, G Loss: 17.29894256591797\n",
      "Epoch: 11, Batch: 39, D Loss: 0.09764500282421729, G Loss: 16.98674774169922\n",
      "Epoch: 11, Batch: 40, D Loss: 0.09580148985090986, G Loss: 16.682435989379883\n",
      "Epoch: 11, Batch: 41, D Loss: 0.09542914685166792, G Loss: 16.468692779541016\n",
      "Epoch: 11, Batch: 42, D Loss: 0.0957451442326871, G Loss: 16.47088623046875\n",
      "Epoch: 11, Batch: 43, D Loss: 0.10279506659111703, G Loss: 16.653186798095703\n",
      "Epoch: 11, Batch: 44, D Loss: 0.09265519906818298, G Loss: 16.48131561279297\n",
      "Epoch: 11, Batch: 45, D Loss: 0.0953840627570699, G Loss: 16.28148651123047\n",
      "Epoch: 11, Batch: 46, D Loss: 0.10063536256341266, G Loss: 16.277236938476562\n",
      "Epoch: 11, Batch: 47, D Loss: 0.09863002033720392, G Loss: 16.44649887084961\n",
      "Epoch: 11, Batch: 48, D Loss: 0.0995033545869255, G Loss: 16.72330093383789\n",
      "Epoch: 11, Batch: 49, D Loss: 0.09798520352913798, G Loss: 16.86951446533203\n",
      "Epoch: 11, Batch: 50, D Loss: 0.09440254654792568, G Loss: 16.783191680908203\n",
      "Epoch: 11, Batch: 51, D Loss: 0.10205761466796481, G Loss: 16.948518753051758\n",
      "Epoch: 11, Batch: 52, D Loss: 0.09838729806722313, G Loss: 17.16584014892578\n",
      "Epoch: 11, Batch: 53, D Loss: 0.09644828879242695, G Loss: 17.30279541015625\n",
      "Epoch: 11, Batch: 54, D Loss: 0.10120755361135814, G Loss: 17.448144912719727\n",
      "Epoch: 11, Batch: 55, D Loss: 0.09712096931819225, G Loss: 17.377443313598633\n",
      "Epoch: 11, Batch: 56, D Loss: 0.09853577638208577, G Loss: 17.259492874145508\n",
      "Epoch: 11, Batch: 57, D Loss: 0.09862121928923173, G Loss: 16.875093460083008\n",
      "Epoch: 11, Batch: 58, D Loss: 0.09869625560656559, G Loss: 16.851884841918945\n",
      "Epoch: 11, Batch: 59, D Loss: 0.09637592221564262, G Loss: 16.800060272216797\n",
      "Epoch: 11, Batch: 60, D Loss: 0.10309925089921457, G Loss: 16.90452766418457\n",
      "Epoch: 11, Batch: 61, D Loss: 0.10059220356072274, G Loss: 16.931047439575195\n",
      "Epoch: 11, Batch: 62, D Loss: 0.09608642972273529, G Loss: 16.742877960205078\n",
      "Epoch: 11, Batch: 63, D Loss: 0.09519717066885214, G Loss: 16.5600528717041\n",
      "Epoch: 11, Batch: 64, D Loss: 0.09699186059832954, G Loss: 16.63589096069336\n",
      "Epoch: 11, Batch: 65, D Loss: 0.10317559825925038, G Loss: 16.954444885253906\n",
      "Epoch: 11, Batch: 66, D Loss: 0.09714198599822765, G Loss: 17.14390754699707\n",
      "Epoch: 11, Batch: 67, D Loss: 0.10136597944985581, G Loss: 17.104177474975586\n",
      "Epoch: 11, Batch: 68, D Loss: 0.09769829319085943, G Loss: 16.79908561706543\n",
      "Epoch: 11, Batch: 69, D Loss: 0.1036554924130968, G Loss: 16.644990921020508\n",
      "Epoch: 11, Batch: 70, D Loss: 0.09808963595590114, G Loss: 16.592052459716797\n",
      "Epoch: 11, Batch: 71, D Loss: 0.09208923313829942, G Loss: 16.392810821533203\n",
      "Epoch: 11, Batch: 72, D Loss: 0.10104332106979186, G Loss: 16.438629150390625\n",
      "Epoch: 11, Batch: 73, D Loss: 0.09312918032629725, G Loss: 16.393489837646484\n",
      "Epoch: 11, Batch: 74, D Loss: 0.09780589620309854, G Loss: 16.36712646484375\n",
      "Epoch: 11, Batch: 75, D Loss: 0.10277009797211889, G Loss: 16.43407440185547\n",
      "Epoch: 11, Batch: 76, D Loss: 0.09016219356335853, G Loss: 16.122512817382812\n",
      "Epoch: 11, Batch: 77, D Loss: 0.09695821573051688, G Loss: 15.924817085266113\n",
      "Epoch: 11, Batch: 78, D Loss: 0.09927140198545459, G Loss: 15.954532623291016\n",
      "Epoch: 11, Batch: 79, D Loss: 0.09826905522430707, G Loss: 16.102415084838867\n",
      "Epoch: 11, Batch: 80, D Loss: 0.09820638883935118, G Loss: 16.229293823242188\n",
      "Epoch: 11, Batch: 81, D Loss: 0.1033164714588608, G Loss: 16.213354110717773\n",
      "Epoch: 11, Batch: 82, D Loss: 0.10085236466332503, G Loss: 15.909570693969727\n",
      "Epoch: 11, Batch: 83, D Loss: 0.0978866177408122, G Loss: 15.512311935424805\n",
      "Epoch: 11, Batch: 84, D Loss: 0.09682080743469612, G Loss: 15.299766540527344\n",
      "Epoch: 11, Batch: 85, D Loss: 0.09391159399783078, G Loss: 15.237733840942383\n",
      "Epoch: 11, Batch: 86, D Loss: 0.10305580940278247, G Loss: 15.438855171203613\n",
      "Epoch: 11, Batch: 87, D Loss: 0.09282917744705799, G Loss: 15.440553665161133\n",
      "Epoch: 11, Batch: 88, D Loss: 0.10472981063323772, G Loss: 15.443687438964844\n",
      "Epoch: 11, Batch: 89, D Loss: 0.10270727220404297, G Loss: 15.372237205505371\n",
      "Epoch: 11, Batch: 90, D Loss: 0.09675739592783827, G Loss: 15.140671730041504\n",
      "Epoch: 11, Batch: 91, D Loss: 0.10007419823881492, G Loss: 15.078076362609863\n",
      "Epoch: 11, Batch: 92, D Loss: 0.10160595179972631, G Loss: 15.267558097839355\n",
      "Epoch: 11, Batch: 93, D Loss: 0.10031004746045369, G Loss: 15.405214309692383\n",
      "Epoch: 11, Batch: 94, D Loss: 0.10260186802987192, G Loss: 15.424605369567871\n",
      "Epoch: 11, Batch: 95, D Loss: 0.10378198042235454, G Loss: 15.403926849365234\n",
      "Epoch: 11, Batch: 96, D Loss: 0.10167372367959615, G Loss: 15.344886779785156\n",
      "Epoch: 11, Batch: 97, D Loss: 0.09815299337143557, G Loss: 15.32252025604248\n",
      "Epoch: 11, Batch: 98, D Loss: 0.09925797127768732, G Loss: 15.391550064086914\n",
      "Epoch: 11, Batch: 99, D Loss: 0.09941201674177336, G Loss: 15.5184907913208\n",
      "Epoch: 11, Batch: 100, D Loss: 0.0931354613844988, G Loss: 15.555536270141602\n",
      "Epoch: 11, Batch: 101, D Loss: 0.097549212469211, G Loss: 15.57939338684082\n",
      "Epoch: 11, Batch: 102, D Loss: 0.0942608689686466, G Loss: 15.556882858276367\n",
      "Epoch: 11, Batch: 103, D Loss: 0.09914672411728276, G Loss: 15.681013107299805\n",
      "Epoch: 11, Batch: 104, D Loss: 0.09443673526172347, G Loss: 15.749643325805664\n",
      "Epoch: 11, Batch: 105, D Loss: 0.10098749376385996, G Loss: 15.902868270874023\n",
      "Epoch: 11, Batch: 106, D Loss: 0.10750713442993032, G Loss: 16.14773941040039\n",
      "Epoch: 11, Batch: 107, D Loss: 0.10236746408352815, G Loss: 16.169754028320312\n",
      "Epoch: 11, Batch: 108, D Loss: 0.10282677388630646, G Loss: 16.002986907958984\n",
      "Epoch: 11, Batch: 109, D Loss: 0.09187997161810557, G Loss: 15.656774520874023\n",
      "Epoch: 11, Batch: 110, D Loss: 0.10110793046455058, G Loss: 15.650468826293945\n",
      "Epoch: 11, Batch: 111, D Loss: 0.10313338849050524, G Loss: 15.964218139648438\n",
      "Epoch: 11, Batch: 112, D Loss: 0.1054034187156887, G Loss: 16.35369873046875\n",
      "Epoch: 11, Batch: 113, D Loss: 0.09248624574978592, G Loss: 16.19396209716797\n",
      "Epoch: 11, Batch: 114, D Loss: 0.09208999387161398, G Loss: 15.777106285095215\n",
      "Epoch: 11, Batch: 115, D Loss: 0.10796495332991185, G Loss: 15.76333999633789\n",
      "Epoch: 11, Batch: 116, D Loss: 0.08732716208341174, G Loss: 15.824515342712402\n",
      "Epoch: 11, Batch: 117, D Loss: 0.09877252464299247, G Loss: 16.088420867919922\n",
      "Epoch: 11, Batch: 118, D Loss: 0.10175849438463658, G Loss: 16.385009765625\n",
      "Epoch: 11, Batch: 119, D Loss: 0.10323419273176526, G Loss: 16.516761779785156\n",
      "Epoch: 11, Batch: 120, D Loss: 0.09874825930663889, G Loss: 16.317733764648438\n",
      "Epoch: 11, Batch: 121, D Loss: 0.09808901113663637, G Loss: 16.086467742919922\n",
      "Epoch: 11, Batch: 122, D Loss: 0.09482319870760136, G Loss: 15.991301536560059\n",
      "Epoch: 11, Batch: 123, D Loss: 0.09661867479367814, G Loss: 16.150846481323242\n",
      "Epoch: 11, Batch: 124, D Loss: 0.08941918923059688, G Loss: 16.250492095947266\n",
      "Epoch: 11, Batch: 125, D Loss: 0.0950605276659644, G Loss: 15.450352668762207\n",
      "Epoch: 11, Batch: 126, D Loss: 0.0995584208489646, G Loss: 15.61296272277832\n",
      "Epoch: 11, Batch: 127, D Loss: 0.09768042207606698, G Loss: 15.612151145935059\n",
      "Epoch: 11, Batch: 128, D Loss: 0.09869737686808122, G Loss: 15.468097686767578\n",
      "Epoch: 11, Batch: 129, D Loss: 0.09824062209385431, G Loss: 15.439308166503906\n",
      "Epoch: 11, Batch: 130, D Loss: 0.10490545001186291, G Loss: 15.61084270477295\n",
      "Epoch: 11, Batch: 131, D Loss: 0.09447350347374339, G Loss: 15.642379760742188\n",
      "Epoch: 11, Batch: 132, D Loss: 0.10767898205597248, G Loss: 15.925386428833008\n",
      "Epoch: 11, Batch: 133, D Loss: 0.0998949026324567, G Loss: 15.992685317993164\n",
      "Epoch: 11, Batch: 134, D Loss: 0.10243303158427608, G Loss: 15.956010818481445\n",
      "Epoch: 11, Batch: 135, D Loss: 0.09394751900807563, G Loss: 15.806853294372559\n",
      "Epoch: 11, Batch: 136, D Loss: 0.09819512814893727, G Loss: 15.84486198425293\n",
      "Epoch: 11, Batch: 137, D Loss: 0.1002765631803193, G Loss: 16.16096305847168\n",
      "Epoch: 11, Batch: 138, D Loss: 0.10806119188345775, G Loss: 16.774860382080078\n",
      "Epoch: 11, Batch: 139, D Loss: 0.09566422883782266, G Loss: 16.795400619506836\n",
      "Epoch: 11, Batch: 140, D Loss: 0.10189923497811826, G Loss: 16.589096069335938\n",
      "Epoch: 11, Batch: 141, D Loss: 0.10200354731772876, G Loss: 16.511859893798828\n",
      "Epoch: 11, Batch: 142, D Loss: 0.09823462645412562, G Loss: 16.579362869262695\n",
      "Epoch: 11, Batch: 143, D Loss: 0.09587135951786507, G Loss: 16.662443161010742\n",
      "Epoch: 11, Batch: 144, D Loss: 0.09928789334669652, G Loss: 16.886951446533203\n",
      "Epoch: 11, Batch: 145, D Loss: 0.09978677266467706, G Loss: 17.01425552368164\n",
      "Epoch: 11, Batch: 146, D Loss: 0.09887191516486915, G Loss: 16.9627628326416\n",
      "Epoch: 11, Batch: 147, D Loss: 0.09048321481695254, G Loss: 16.587989807128906\n",
      "Epoch: 11, Batch: 148, D Loss: 0.10319428319596824, G Loss: 16.57286262512207\n",
      "Epoch: 11, Batch: 149, D Loss: 0.10068221988830928, G Loss: 16.789443969726562\n",
      "Epoch: 11, Batch: 150, D Loss: 0.09667898975600764, G Loss: 16.835397720336914\n",
      "Epoch: 11, Batch: 151, D Loss: 0.1045328908713774, G Loss: 16.93290901184082\n",
      "Epoch: 11, Batch: 152, D Loss: 0.10177818822365658, G Loss: 16.80340576171875\n",
      "Epoch: 11, Batch: 153, D Loss: 0.0944440148745187, G Loss: 16.43962860107422\n",
      "Epoch: 11, Batch: 154, D Loss: 0.0965152338246753, G Loss: 16.243732452392578\n",
      "Epoch: 11, Batch: 155, D Loss: 0.10232162095697106, G Loss: 16.389158248901367\n",
      "Epoch: 11, Batch: 156, D Loss: 0.10039168930842735, G Loss: 16.657245635986328\n",
      "Epoch: 11, Batch: 157, D Loss: 0.10184804835253303, G Loss: 16.79121971130371\n",
      "Epoch: 11, Batch: 158, D Loss: 0.09835773608826415, G Loss: 16.560626983642578\n",
      "Epoch: 11, Batch: 159, D Loss: 0.10257726071142415, G Loss: 16.328702926635742\n",
      "Epoch: 11, Batch: 160, D Loss: 0.09733614358749065, G Loss: 16.130168914794922\n",
      "Epoch: 11, Batch: 161, D Loss: 0.10210334616158434, G Loss: 16.278291702270508\n",
      "Epoch: 11, Batch: 162, D Loss: 0.1006760458129996, G Loss: 16.485803604125977\n",
      "Epoch: 11, Batch: 163, D Loss: 0.09841071467741358, G Loss: 16.534175872802734\n",
      "Epoch: 11, Batch: 164, D Loss: 0.09949321759357233, G Loss: 16.456592559814453\n",
      "Epoch: 11, Batch: 165, D Loss: 0.09561948031430845, G Loss: 16.228971481323242\n",
      "Epoch: 11, Batch: 166, D Loss: 0.09658482962819903, G Loss: 16.11396598815918\n",
      "Epoch: 11, Batch: 167, D Loss: 0.09841893716927785, G Loss: 16.29401397705078\n",
      "Epoch: 11, Batch: 168, D Loss: 0.09756629861087518, G Loss: 16.54865264892578\n",
      "Epoch: 11, Batch: 169, D Loss: 0.09884452058349247, G Loss: 16.726240158081055\n",
      "Epoch: 11, Batch: 170, D Loss: 0.09817934651572102, G Loss: 16.640432357788086\n",
      "Epoch: 11, Batch: 171, D Loss: 0.10325098871942373, G Loss: 16.577260971069336\n",
      "Epoch: 11, Batch: 172, D Loss: 0.09421666546726115, G Loss: 16.352466583251953\n",
      "Epoch: 11, Batch: 173, D Loss: 0.09876562280793166, G Loss: 16.28876495361328\n",
      "Epoch: 11, Batch: 174, D Loss: 0.10357132552260495, G Loss: 16.527008056640625\n",
      "Epoch: 11, Batch: 175, D Loss: 0.10564195896527906, G Loss: 16.876127243041992\n",
      "Epoch: 11, Batch: 176, D Loss: 0.10013932947512139, G Loss: 16.794593811035156\n",
      "Epoch: 11, Batch: 177, D Loss: 0.10197193874883936, G Loss: 16.523792266845703\n",
      "Epoch: 11, Batch: 178, D Loss: 0.09024821242471148, G Loss: 15.957435607910156\n",
      "Epoch: 11, Batch: 179, D Loss: 0.09995722964098519, G Loss: 15.872598648071289\n",
      "Epoch: 11, Batch: 180, D Loss: 0.09915618043647356, G Loss: 16.193714141845703\n",
      "Epoch: 11, Batch: 181, D Loss: 0.10220285457672418, G Loss: 16.6356258392334\n",
      "Epoch: 11, Batch: 182, D Loss: 0.10051096782660807, G Loss: 16.76471519470215\n",
      "Epoch: 11, Batch: 183, D Loss: 0.09897739489965929, G Loss: 16.49028778076172\n",
      "Epoch: 11, Batch: 184, D Loss: 0.09751791816846023, G Loss: 16.1925048828125\n",
      "Epoch: 11, Batch: 185, D Loss: 0.10493758239069706, G Loss: 16.301761627197266\n",
      "Epoch: 11, Batch: 186, D Loss: 0.09738975004563599, G Loss: 16.52154541015625\n",
      "Epoch: 11, Batch: 187, D Loss: 0.10061430794209691, G Loss: 16.829265594482422\n",
      "Epoch: 11, Batch: 188, D Loss: 0.10179430222046015, G Loss: 17.030120849609375\n",
      "Epoch: 11, Batch: 189, D Loss: 0.10338745005156014, G Loss: 17.064409255981445\n",
      "Epoch: 11, Batch: 190, D Loss: 0.0997317644294693, G Loss: 16.90753936767578\n",
      "Epoch: 11, Batch: 191, D Loss: 0.10375975848968366, G Loss: 16.91243553161621\n",
      "Epoch: 11, Batch: 192, D Loss: 0.1034392473758512, G Loss: 17.086822509765625\n",
      "Epoch: 11, Batch: 193, D Loss: 0.10351486645452823, G Loss: 17.37534523010254\n",
      "Epoch: 11, Batch: 194, D Loss: 0.09701156623341056, G Loss: 17.278640747070312\n",
      "Epoch: 11, Batch: 195, D Loss: 0.09705002957527498, G Loss: 16.97231674194336\n",
      "Epoch: 11, Batch: 196, D Loss: 0.09603419289424764, G Loss: 16.769554138183594\n",
      "Epoch: 11, Batch: 197, D Loss: 0.09758092883819636, G Loss: 16.735605239868164\n",
      "Epoch: 11, Batch: 198, D Loss: 0.09948025869164034, G Loss: 16.91131019592285\n",
      "Epoch: 11, Batch: 199, D Loss: 0.09816881185176562, G Loss: 17.008281707763672\n",
      "Epoch: 11, Batch: 200, D Loss: 0.09486203649906777, G Loss: 16.84088897705078\n",
      "Epoch: 11, Batch: 201, D Loss: 0.10439006562144115, G Loss: 16.742694854736328\n",
      "Epoch: 11, Batch: 202, D Loss: 0.0989537221581216, G Loss: 16.655990600585938\n",
      "Epoch: 11, Batch: 203, D Loss: 0.1050195517250323, G Loss: 16.804489135742188\n",
      "Epoch: 11, Batch: 204, D Loss: 0.10024494912463666, G Loss: 16.842126846313477\n",
      "Epoch: 11, Batch: 205, D Loss: 0.10023741010694565, G Loss: 16.735107421875\n",
      "Epoch: 11, Batch: 206, D Loss: 0.10453213660770189, G Loss: 16.606538772583008\n",
      "Epoch: 11, Batch: 207, D Loss: 0.09722817997298705, G Loss: 16.47692108154297\n",
      "Epoch: 11, Batch: 208, D Loss: 0.10423829760525649, G Loss: 16.567420959472656\n",
      "Epoch: 11, Batch: 209, D Loss: 0.09641264742132805, G Loss: 16.480724334716797\n",
      "Epoch: 11, Batch: 210, D Loss: 0.0971616892997531, G Loss: 16.284027099609375\n",
      "Epoch: 11, Batch: 211, D Loss: 0.09691625911714397, G Loss: 16.151771545410156\n",
      "Epoch: 11, Batch: 212, D Loss: 0.09423304132195653, G Loss: 16.091903686523438\n",
      "Epoch: 11, Batch: 213, D Loss: 0.10398703969961787, G Loss: 16.29230499267578\n",
      "Epoch: 11, Batch: 214, D Loss: 0.0994985789560836, G Loss: 16.44621467590332\n",
      "Epoch: 11, Batch: 215, D Loss: 0.10262796916789085, G Loss: 16.442012786865234\n",
      "Epoch: 11, Batch: 216, D Loss: 0.09634466274557951, G Loss: 16.126846313476562\n",
      "Epoch: 11, Batch: 217, D Loss: 0.0954500792219477, G Loss: 15.833745956420898\n",
      "Epoch: 11, Batch: 218, D Loss: 0.10016837276479862, G Loss: 15.9495849609375\n",
      "Epoch: 11, Batch: 219, D Loss: 0.1077966562631012, G Loss: 16.394210815429688\n",
      "Epoch: 11, Batch: 220, D Loss: 0.09355453502980993, G Loss: 16.38055419921875\n",
      "Epoch: 11, Batch: 221, D Loss: 0.10426194774452568, G Loss: 16.1807861328125\n",
      "Epoch: 11, Batch: 222, D Loss: 0.10286339298016145, G Loss: 16.012468338012695\n",
      "Epoch: 11, Batch: 223, D Loss: 0.09676240591041108, G Loss: 15.81767463684082\n",
      "Epoch: 11, Batch: 224, D Loss: 0.09572436313860777, G Loss: 15.726154327392578\n",
      "Epoch: 11, Batch: 225, D Loss: 0.10168454147090955, G Loss: 15.890827178955078\n",
      "Epoch: 11, Batch: 226, D Loss: 0.09533518597491764, G Loss: 15.978570938110352\n",
      "Epoch: 11, Batch: 227, D Loss: 0.1029725163834101, G Loss: 16.115055084228516\n",
      "Epoch: 11, Batch: 228, D Loss: 0.09823378152117357, G Loss: 16.052947998046875\n",
      "Epoch: 11, Batch: 229, D Loss: 0.09409459069379267, G Loss: 15.831411361694336\n",
      "Epoch: 11, Batch: 230, D Loss: 0.0959620286582279, G Loss: 15.728507995605469\n",
      "Epoch: 11, Batch: 231, D Loss: 0.10362907344224226, G Loss: 15.963302612304688\n",
      "Epoch: 11, Batch: 232, D Loss: 0.09948770699736187, G Loss: 16.080249786376953\n",
      "Epoch: 11, Batch: 233, D Loss: 0.09978758328822579, G Loss: 16.155704498291016\n",
      "Epoch: 11, Batch: 234, D Loss: 0.09207385532223356, G Loss: 15.83260440826416\n",
      "Epoch: 11, Batch: 235, D Loss: 0.09519550272862176, G Loss: 15.623138427734375\n",
      "Epoch: 11, Batch: 236, D Loss: 0.0971459490581168, G Loss: 15.709480285644531\n",
      "Epoch: 11, Batch: 237, D Loss: 0.09194762310147553, G Loss: 15.918863296508789\n",
      "Epoch: 11, Batch: 238, D Loss: 0.10383289833195519, G Loss: 16.300783157348633\n",
      "Epoch: 11, Batch: 239, D Loss: 0.09815053858381262, G Loss: 16.40836524963379\n",
      "Epoch: 11, Batch: 240, D Loss: 0.10093079090276547, G Loss: 16.25855827331543\n",
      "Epoch: 11, Batch: 241, D Loss: 0.10056878302956918, G Loss: 16.03638458251953\n",
      "Epoch: 11, Batch: 242, D Loss: 0.0937457249725071, G Loss: 15.811676025390625\n",
      "Epoch: 11, Batch: 243, D Loss: 0.09928528790496927, G Loss: 15.891073226928711\n",
      "Epoch: 11, Batch: 244, D Loss: 0.09376841609343955, G Loss: 16.049062728881836\n",
      "Epoch: 11, Batch: 245, D Loss: 0.09976817916391667, G Loss: 16.293447494506836\n",
      "Epoch: 11, Batch: 246, D Loss: 0.09724520528221348, G Loss: 16.337276458740234\n",
      "Epoch: 11, Batch: 247, D Loss: 0.09941811615733442, G Loss: 16.243234634399414\n",
      "Epoch: 11, Batch: 248, D Loss: 0.10070700367415597, G Loss: 16.15106773376465\n",
      "Epoch: 11, Batch: 249, D Loss: 0.09489742794595202, G Loss: 15.96529769897461\n",
      "Epoch: 11, Batch: 250, D Loss: 0.09861425046892691, G Loss: 16.011276245117188\n",
      "Epoch: 11, Batch: 251, D Loss: 0.0987544786245671, G Loss: 16.206710815429688\n",
      "Epoch: 11, Batch: 252, D Loss: 0.09522966267486055, G Loss: 16.266347885131836\n",
      "Epoch: 11, Batch: 253, D Loss: 0.09276514646969503, G Loss: 16.139404296875\n",
      "Epoch: 11, Batch: 254, D Loss: 0.09912139650920082, G Loss: 16.12401580810547\n",
      "Epoch: 11, Batch: 255, D Loss: 0.0945813541449887, G Loss: 16.187458038330078\n",
      "Epoch: 11, Batch: 256, D Loss: 0.09982538665955332, G Loss: 16.404624938964844\n",
      "Epoch: 11, Batch: 257, D Loss: 0.09452749652896841, G Loss: 16.49269676208496\n",
      "Epoch: 11, Batch: 258, D Loss: 0.09889866662395264, G Loss: 16.61309814453125\n",
      "Epoch: 11, Batch: 259, D Loss: 0.10126690424597307, G Loss: 16.7506103515625\n",
      "Epoch: 11, Batch: 260, D Loss: 0.10523643543327665, G Loss: 16.918643951416016\n",
      "Epoch: 11, Batch: 261, D Loss: 0.10025505787869271, G Loss: 16.873497009277344\n",
      "Epoch: 11, Batch: 262, D Loss: 0.10184498411698506, G Loss: 16.745302200317383\n",
      "Epoch: 11, Batch: 263, D Loss: 0.09430626008409959, G Loss: 16.5557861328125\n",
      "Epoch: 11, Batch: 264, D Loss: 0.0986923151454846, G Loss: 16.567983627319336\n",
      "Epoch: 11, Batch: 265, D Loss: 0.09672446559957848, G Loss: 16.733882904052734\n",
      "Epoch: 11, Batch: 266, D Loss: 0.0911804374800731, G Loss: 16.48196029663086\n",
      "Epoch: 11, Batch: 267, D Loss: 0.10449621185029301, G Loss: 16.710357666015625\n",
      "Epoch: 11, Batch: 268, D Loss: 0.10271782518441164, G Loss: 17.04175567626953\n",
      "Epoch: 11, Batch: 269, D Loss: 0.09936121633011474, G Loss: 17.013803482055664\n",
      "Epoch: 11, Batch: 270, D Loss: 0.10557190184646537, G Loss: 16.97040557861328\n",
      "Epoch: 11, Batch: 271, D Loss: 0.09707822732589477, G Loss: 16.815773010253906\n",
      "Epoch: 11, Batch: 272, D Loss: 0.0966137687373898, G Loss: 16.71179962158203\n",
      "Epoch: 11, Batch: 273, D Loss: 0.09770539149148583, G Loss: 16.73812484741211\n",
      "Epoch: 11, Batch: 274, D Loss: 0.10079785614269099, G Loss: 16.94619369506836\n",
      "Epoch: 11, Batch: 275, D Loss: 0.10001843942441191, G Loss: 17.105838775634766\n",
      "Epoch: 11, Batch: 276, D Loss: 0.10315522149574718, G Loss: 17.13701057434082\n",
      "Epoch: 11, Batch: 277, D Loss: 0.10348803968110687, G Loss: 17.03302764892578\n",
      "Epoch: 11, Batch: 278, D Loss: 0.09653263601656015, G Loss: 16.775131225585938\n",
      "Epoch: 11, Batch: 279, D Loss: 0.09676735649077095, G Loss: 16.643381118774414\n",
      "Epoch: 11, Batch: 280, D Loss: 0.09965544725100806, G Loss: 16.77210807800293\n",
      "Epoch: 11, Batch: 281, D Loss: 0.0972175015746739, G Loss: 16.948368072509766\n",
      "Epoch: 11, Batch: 282, D Loss: 0.10363720826189748, G Loss: 17.152633666992188\n",
      "Epoch: 11, Batch: 283, D Loss: 0.1007722945665055, G Loss: 17.124717712402344\n",
      "Epoch: 11, Batch: 284, D Loss: 0.09655733275472222, G Loss: 16.858135223388672\n",
      "Epoch: 11, Batch: 285, D Loss: 0.10091882476202052, G Loss: 16.761615753173828\n",
      "Epoch: 11, Batch: 286, D Loss: 0.09996224418832611, G Loss: 16.889074325561523\n",
      "Epoch: 11, Batch: 287, D Loss: 0.09539030461278664, G Loss: 16.98224449157715\n",
      "Epoch: 11, Batch: 288, D Loss: 0.0992291771316598, G Loss: 17.067672729492188\n",
      "Epoch: 11, Batch: 289, D Loss: 0.09830936486508968, G Loss: 17.071500778198242\n",
      "Epoch: 11, Batch: 290, D Loss: 0.1068628385728072, G Loss: 17.214412689208984\n",
      "Epoch: 11, Batch: 291, D Loss: 0.09890702603130208, G Loss: 17.15319061279297\n",
      "Epoch: 11, Batch: 292, D Loss: 0.10047084528878614, G Loss: 17.000635147094727\n",
      "Epoch: 11, Batch: 293, D Loss: 0.10152115572311082, G Loss: 16.942638397216797\n",
      "Epoch: 11, Batch: 294, D Loss: 0.09744989828877237, G Loss: 16.94446563720703\n",
      "Epoch: 11, Batch: 295, D Loss: 0.09735223572134188, G Loss: 16.974000930786133\n",
      "Epoch: 11, Batch: 296, D Loss: 0.09624054915241054, G Loss: 16.977516174316406\n",
      "Epoch: 11, Batch: 297, D Loss: 0.09572159399241187, G Loss: 16.962722778320312\n",
      "Epoch: 11, Batch: 298, D Loss: 0.0984560466385922, G Loss: 16.961885452270508\n",
      "Epoch: 11, Batch: 299, D Loss: 0.09778036827776226, G Loss: 16.97214126586914\n",
      "Epoch: 11, Batch: 300, D Loss: 0.10237161595488686, G Loss: 17.087810516357422\n",
      "Epoch: 11, Batch: 301, D Loss: 0.10518259042905242, G Loss: 17.27096176147461\n",
      "Epoch: 11, Batch: 302, D Loss: 0.10611137760092682, G Loss: 17.366153717041016\n",
      "Epoch: 11, Batch: 303, D Loss: 0.10393710453258365, G Loss: 17.27225112915039\n",
      "Epoch: 11, Batch: 304, D Loss: 0.09655277755481961, G Loss: 17.006338119506836\n",
      "Epoch: 11, Batch: 305, D Loss: 0.10587522166745877, G Loss: 17.04750633239746\n",
      "Epoch: 11, Batch: 306, D Loss: 0.09744203484291347, G Loss: 17.137859344482422\n",
      "Epoch: 11, Batch: 307, D Loss: 0.09929743643998279, G Loss: 17.22368049621582\n",
      "Epoch: 11, Batch: 308, D Loss: 0.0913452086498232, G Loss: 17.103092193603516\n",
      "Epoch: 11, Batch: 309, D Loss: 0.09948638478702243, G Loss: 17.08429718017578\n",
      "Epoch: 11, Batch: 310, D Loss: 0.09824245767454975, G Loss: 17.155027389526367\n",
      "Epoch: 11, Batch: 311, D Loss: 0.09512956706583076, G Loss: 17.174121856689453\n",
      "Epoch: 11, Batch: 312, D Loss: 0.09763375902283933, G Loss: 17.193586349487305\n",
      "Epoch: 11, Batch: 313, D Loss: 0.10328354020945874, G Loss: 17.352725982666016\n",
      "Epoch: 11, Batch: 314, D Loss: 0.10238624995348555, G Loss: 17.45913314819336\n",
      "Epoch: 11, Batch: 315, D Loss: 0.10407976611235625, G Loss: 17.478710174560547\n",
      "Epoch: 11, Batch: 316, D Loss: 0.09711749045113738, G Loss: 17.274723052978516\n",
      "Epoch: 11, Batch: 317, D Loss: 0.09169019355550923, G Loss: 16.985904693603516\n",
      "Epoch: 11, Batch: 318, D Loss: 0.1023383788803045, G Loss: 17.06820297241211\n",
      "Epoch: 11, Batch: 319, D Loss: 0.10555710732792534, G Loss: 17.453304290771484\n",
      "Epoch: 11, Batch: 320, D Loss: 0.09711938815603638, G Loss: 17.614112854003906\n",
      "Epoch: 11, Batch: 321, D Loss: 0.10045823891749173, G Loss: 17.512939453125\n",
      "Epoch: 11, Batch: 322, D Loss: 0.10000036583047933, G Loss: 17.260366439819336\n",
      "Epoch: 11, Batch: 323, D Loss: 0.09985254204171135, G Loss: 17.10309600830078\n",
      "Epoch: 11, Batch: 324, D Loss: 0.09638242085017623, G Loss: 17.07489776611328\n",
      "Epoch: 11, Batch: 325, D Loss: 0.09987541565266511, G Loss: 17.234298706054688\n",
      "Epoch: 11, Batch: 326, D Loss: 0.09412844516548624, G Loss: 17.36760902404785\n",
      "Epoch: 11, Batch: 327, D Loss: 0.09589326304445578, G Loss: 17.395910263061523\n",
      "Epoch: 11, Batch: 328, D Loss: 0.09765569050624023, G Loss: 17.360795974731445\n",
      "Epoch: 11, Batch: 329, D Loss: 0.1023873676923186, G Loss: 17.431081771850586\n",
      "Epoch: 11, Batch: 330, D Loss: 0.09741440265610546, G Loss: 17.43886375427246\n",
      "Epoch: 11, Batch: 331, D Loss: 0.1019600982768889, G Loss: 17.49806785583496\n",
      "Epoch: 11, Batch: 332, D Loss: 0.10296586613766845, G Loss: 17.584014892578125\n",
      "Epoch: 11, Batch: 333, D Loss: 0.09876643558745979, G Loss: 17.539047241210938\n",
      "Epoch: 11, Batch: 334, D Loss: 0.09967894611670225, G Loss: 17.474733352661133\n",
      "Epoch: 11, Batch: 335, D Loss: 0.09633247396301492, G Loss: 17.411205291748047\n",
      "Epoch: 11, Batch: 336, D Loss: 0.09407830890698676, G Loss: 17.377521514892578\n",
      "Epoch: 11, Batch: 337, D Loss: 0.09590422247124941, G Loss: 17.438411712646484\n",
      "Epoch: 11, Batch: 338, D Loss: 0.10131836418719864, G Loss: 17.60114288330078\n",
      "Epoch: 11, Batch: 339, D Loss: 0.0999255882669603, G Loss: 17.72669219970703\n",
      "Epoch: 11, Batch: 340, D Loss: 0.10315137601316948, G Loss: 17.748476028442383\n",
      "Epoch: 11, Batch: 341, D Loss: 0.09746879693477073, G Loss: 17.52944564819336\n",
      "Epoch: 11, Batch: 342, D Loss: 0.09453133414135184, G Loss: 17.252897262573242\n",
      "Epoch: 11, Batch: 343, D Loss: 0.09854993331005879, G Loss: 17.2666015625\n",
      "Epoch: 11, Batch: 344, D Loss: 0.10022152851065247, G Loss: 17.53009033203125\n",
      "Epoch: 11, Batch: 345, D Loss: 0.10418988290815356, G Loss: 17.874303817749023\n",
      "Epoch: 11, Batch: 346, D Loss: 0.10465549746817793, G Loss: 17.98648452758789\n",
      "Epoch: 11, Batch: 347, D Loss: 0.09682362705808067, G Loss: 17.644466400146484\n",
      "Epoch: 11, Batch: 348, D Loss: 0.10071208087243289, G Loss: 17.380069732666016\n",
      "Epoch: 11, Batch: 349, D Loss: 0.10137249477201138, G Loss: 17.351322174072266\n",
      "Epoch: 11, Batch: 350, D Loss: 0.09536595534161574, G Loss: 17.45292854309082\n",
      "Epoch: 11, Batch: 351, D Loss: 0.09668383474416054, G Loss: 17.602209091186523\n",
      "Epoch: 11, Batch: 352, D Loss: 0.0949036146455784, G Loss: 17.58409881591797\n",
      "Epoch: 11, Batch: 353, D Loss: 0.09661984180811434, G Loss: 17.468488693237305\n",
      "Epoch: 11, Batch: 354, D Loss: 0.10130395569487849, G Loss: 17.435199737548828\n",
      "Epoch: 11, Batch: 355, D Loss: 0.09742865570367254, G Loss: 17.422910690307617\n",
      "Epoch: 11, Batch: 356, D Loss: 0.09615881615328536, G Loss: 17.412452697753906\n",
      "Epoch: 11, Batch: 357, D Loss: 0.1004338247842842, G Loss: 17.479114532470703\n",
      "Epoch: 11, Batch: 358, D Loss: 0.10708553747663263, G Loss: 17.688570022583008\n",
      "Epoch: 11, Batch: 359, D Loss: 0.10191276227625767, G Loss: 17.67395782470703\n",
      "Epoch: 11, Batch: 360, D Loss: 0.10343768830124844, G Loss: 17.548492431640625\n",
      "Epoch: 11, Batch: 361, D Loss: 0.09848466332500205, G Loss: 17.38077163696289\n",
      "Epoch: 11, Batch: 362, D Loss: 0.09518581627392475, G Loss: 17.284753799438477\n",
      "Epoch: 11, Batch: 363, D Loss: 0.09857480973685284, G Loss: 17.368576049804688\n",
      "Epoch: 11, Batch: 364, D Loss: 0.10508779908951027, G Loss: 17.67707061767578\n",
      "Epoch: 11, Batch: 365, D Loss: 0.09300528015173803, G Loss: 17.701866149902344\n",
      "Epoch: 11, Batch: 366, D Loss: 0.09722847848291938, G Loss: 17.567157745361328\n",
      "Epoch: 11, Batch: 367, D Loss: 0.09636296117457199, G Loss: 17.410202026367188\n",
      "Epoch: 11, Batch: 368, D Loss: 0.0920908300622223, G Loss: 17.274986267089844\n",
      "Epoch: 11, Batch: 369, D Loss: 0.09310191951275826, G Loss: 17.277103424072266\n",
      "Epoch: 11, Batch: 370, D Loss: 0.1010123626785413, G Loss: 17.556560516357422\n",
      "Epoch: 11, Batch: 371, D Loss: 0.10147095750265489, G Loss: 17.83739471435547\n",
      "Epoch: 11, Batch: 372, D Loss: 0.09707559092394735, G Loss: 17.752405166625977\n",
      "Epoch: 11, Batch: 373, D Loss: 0.10339432541013416, G Loss: 17.566200256347656\n",
      "Epoch: 11, Batch: 374, D Loss: 0.10100485159512385, G Loss: 17.426868438720703\n",
      "Epoch: 11, Batch: 375, D Loss: 0.10448361769946857, G Loss: 17.461944580078125\n",
      "Epoch: 11, Batch: 376, D Loss: 0.09628920052165846, G Loss: 17.49097442626953\n",
      "Epoch: 11, Batch: 377, D Loss: 0.10577974871590179, G Loss: 17.678808212280273\n",
      "Epoch: 11, Batch: 378, D Loss: 0.1087373066941053, G Loss: 17.902294158935547\n",
      "Epoch: 11, Batch: 379, D Loss: 0.10101775241115618, G Loss: 17.758522033691406\n",
      "Epoch: 11, Batch: 380, D Loss: 0.09995382683811371, G Loss: 17.467321395874023\n",
      "Epoch: 11, Batch: 381, D Loss: 0.10912955657792267, G Loss: 16.640594482421875\n",
      "Epoch: 11, Batch: 382, D Loss: 0.09655921174111626, G Loss: 16.626232147216797\n",
      "Epoch: 11, Batch: 383, D Loss: 0.09856219627492635, G Loss: 16.622541427612305\n",
      "Epoch: 11, Batch: 384, D Loss: 0.09470877191013827, G Loss: 16.562828063964844\n",
      "Epoch: 11, Batch: 385, D Loss: 0.09943273794076646, G Loss: 16.6221866607666\n",
      "Epoch: 11, Batch: 386, D Loss: 0.09274365796784778, G Loss: 16.62232780456543\n",
      "Epoch: 11, Batch: 387, D Loss: 0.10572603031693184, G Loss: 16.860633850097656\n",
      "Epoch: 11, Batch: 388, D Loss: 0.10266029011269495, G Loss: 17.049177169799805\n",
      "Epoch: 11, Batch: 389, D Loss: 0.0928956197228672, G Loss: 16.798507690429688\n",
      "Epoch: 11, Batch: 390, D Loss: 0.0970704849360633, G Loss: 16.51825523376465\n",
      "Epoch: 11, Batch: 391, D Loss: 0.09349421145016379, G Loss: 16.46120262145996\n",
      "Epoch: 11, Batch: 392, D Loss: 0.09583343029054703, G Loss: 16.666595458984375\n",
      "Epoch: 11, Batch: 393, D Loss: 0.10066140533024637, G Loss: 17.081039428710938\n",
      "Epoch: 11, Batch: 394, D Loss: 0.1016303837917576, G Loss: 17.364639282226562\n",
      "Epoch: 11, Batch: 395, D Loss: 0.10270684906874816, G Loss: 17.36322021484375\n",
      "Epoch: 11, Batch: 396, D Loss: 0.09574908284691475, G Loss: 16.985923767089844\n",
      "Epoch: 11, Batch: 397, D Loss: 0.10283900799274903, G Loss: 16.867023468017578\n",
      "Epoch: 11, Batch: 398, D Loss: 0.0971135799388545, G Loss: 16.939796447753906\n",
      "Epoch: 11, Batch: 399, D Loss: 0.1001548438057025, G Loss: 17.19361686706543\n",
      "Epoch: 11, Batch: 400, D Loss: 0.09549191677346158, G Loss: 17.348312377929688\n",
      "Epoch: 11, Batch: 401, D Loss: 0.09822247891837144, G Loss: 17.3516845703125\n",
      "Epoch: 11, Batch: 402, D Loss: 0.09733486218442522, G Loss: 17.25531005859375\n",
      "Epoch: 11, Batch: 403, D Loss: 0.10113152946408555, G Loss: 17.29093360900879\n",
      "Epoch: 11, Batch: 404, D Loss: 0.10435392626929829, G Loss: 17.469533920288086\n",
      "Epoch: 11, Batch: 405, D Loss: 0.10295954043416256, G Loss: 17.635204315185547\n",
      "Epoch: 11, Batch: 406, D Loss: 0.10583237851817362, G Loss: 17.74017333984375\n",
      "Epoch: 11, Batch: 407, D Loss: 0.0981096436959108, G Loss: 17.541873931884766\n",
      "Epoch: 11, Batch: 408, D Loss: 0.10428520125537233, G Loss: 17.36310386657715\n",
      "Epoch: 11, Batch: 409, D Loss: 0.095604867608575, G Loss: 17.19184112548828\n",
      "Epoch: 11, Batch: 410, D Loss: 0.09888504143244958, G Loss: 17.09699058532715\n",
      "Epoch: 11, Batch: 411, D Loss: 0.09363419137553919, G Loss: 17.172237396240234\n",
      "Epoch: 11, Batch: 412, D Loss: 0.09275272711138172, G Loss: 17.206531524658203\n",
      "Epoch: 11, Batch: 413, D Loss: 0.09653063256016203, G Loss: 17.272287368774414\n",
      "Epoch: 11, Batch: 414, D Loss: 0.0984674838418238, G Loss: 17.416101455688477\n",
      "Epoch: 11, Batch: 415, D Loss: 0.1013741617341708, G Loss: 17.598432540893555\n",
      "Epoch: 11, Batch: 416, D Loss: 0.10643482484834976, G Loss: 17.80392074584961\n",
      "Epoch: 11, Batch: 417, D Loss: 0.10237286429435066, G Loss: 17.788063049316406\n",
      "Epoch: 11, Batch: 418, D Loss: 0.09416444235826127, G Loss: 17.447673797607422\n",
      "Epoch: 11, Batch: 419, D Loss: 0.09689170138204695, G Loss: 17.202529907226562\n",
      "Epoch: 11, Batch: 420, D Loss: 0.10047173592214165, G Loss: 17.329557418823242\n",
      "Epoch: 11, Batch: 421, D Loss: 0.10073245044187118, G Loss: 17.71236801147461\n",
      "Epoch: 11, Batch: 422, D Loss: 0.09859319922450283, G Loss: 17.96072006225586\n",
      "Epoch: 11, Batch: 423, D Loss: 0.09620496012533675, G Loss: 17.778640747070312\n",
      "Epoch: 11, Batch: 424, D Loss: 0.09534853335310878, G Loss: 17.452415466308594\n",
      "Epoch: 11, Batch: 425, D Loss: 0.10252675987414772, G Loss: 17.45113754272461\n",
      "Epoch: 11, Batch: 426, D Loss: 0.10077923232446473, G Loss: 17.652660369873047\n",
      "Epoch: 11, Batch: 427, D Loss: 0.10278342099816484, G Loss: 17.942256927490234\n",
      "Epoch: 11, Batch: 428, D Loss: 0.09627112103042723, G Loss: 17.85072898864746\n",
      "Epoch: 11, Batch: 429, D Loss: 0.10099149704526678, G Loss: 17.706462860107422\n",
      "Epoch: 11, Batch: 430, D Loss: 0.09961622556970706, G Loss: 17.577320098876953\n",
      "Epoch: 11, Batch: 431, D Loss: 0.10369536661449708, G Loss: 17.638456344604492\n",
      "Epoch: 11, Batch: 432, D Loss: 0.10242870715399643, G Loss: 17.788818359375\n",
      "Epoch: 11, Batch: 433, D Loss: 0.09864062269159213, G Loss: 17.784011840820312\n",
      "Epoch: 11, Batch: 434, D Loss: 0.09848463092664872, G Loss: 17.589401245117188\n",
      "Epoch: 11, Batch: 435, D Loss: 0.09284807572758069, G Loss: 17.323455810546875\n",
      "Epoch: 11, Batch: 436, D Loss: 0.10714502489222966, G Loss: 17.526819229125977\n",
      "Epoch: 11, Batch: 437, D Loss: 0.09681748204395468, G Loss: 17.735490798950195\n",
      "Epoch: 11, Batch: 438, D Loss: 0.09632518364555942, G Loss: 17.784740447998047\n",
      "Epoch: 11, Batch: 439, D Loss: 0.10125235644843933, G Loss: 17.832101821899414\n",
      "Epoch: 11, Batch: 440, D Loss: 0.10364090950834459, G Loss: 17.731136322021484\n",
      "Epoch: 11, Batch: 441, D Loss: 0.10155817329556172, G Loss: 17.81780242919922\n",
      "Epoch: 11, Batch: 442, D Loss: 0.10130668582670488, G Loss: 17.8553466796875\n",
      "Epoch: 11, Batch: 443, D Loss: 0.10071829101198126, G Loss: 17.845657348632812\n",
      "Epoch: 11, Batch: 444, D Loss: 0.10056970442086666, G Loss: 17.78322982788086\n",
      "Epoch: 11, Batch: 445, D Loss: 0.09885069218271703, G Loss: 17.715694427490234\n",
      "Epoch: 11, Batch: 446, D Loss: 0.09539010703984196, G Loss: 17.604700088500977\n",
      "Epoch: 11, Batch: 447, D Loss: 0.09641419739593715, G Loss: 17.6009521484375\n",
      "Epoch: 11, Batch: 448, D Loss: 0.0996373550197518, G Loss: 17.74245834350586\n",
      "Epoch: 11, Batch: 449, D Loss: 0.09968985791069951, G Loss: 17.875452041625977\n",
      "Epoch: 11, Batch: 450, D Loss: 0.09564822353728175, G Loss: 17.729827880859375\n",
      "Epoch: 11, Batch: 451, D Loss: 0.09805529900534538, G Loss: 17.578523635864258\n",
      "Epoch: 11, Batch: 452, D Loss: 0.0953391614679937, G Loss: 17.48005485534668\n",
      "Epoch: 11, Batch: 453, D Loss: 0.10514656853140458, G Loss: 17.695762634277344\n",
      "Epoch: 11, Batch: 454, D Loss: 0.10219947426622156, G Loss: 17.909107208251953\n",
      "Epoch: 11, Batch: 455, D Loss: 0.1005267732913131, G Loss: 17.91836929321289\n",
      "Epoch: 11, Batch: 456, D Loss: 0.10137602103538157, G Loss: 17.742488861083984\n",
      "Epoch: 11, Batch: 457, D Loss: 0.1032451273299575, G Loss: 17.611589431762695\n",
      "Epoch: 11, Batch: 458, D Loss: 0.09606843922722508, G Loss: 17.445730209350586\n",
      "Epoch: 11, Batch: 459, D Loss: 0.10232656245290794, G Loss: 17.503944396972656\n",
      "Epoch: 11, Batch: 460, D Loss: 0.09802572118379782, G Loss: 17.61641502380371\n",
      "Epoch: 11, Batch: 461, D Loss: 0.09829815806105913, G Loss: 17.692853927612305\n",
      "Epoch: 11, Batch: 462, D Loss: 0.10192659745526811, G Loss: 17.772371292114258\n",
      "Epoch: 11, Batch: 463, D Loss: 0.089834581546274, G Loss: 17.56622314453125\n",
      "Epoch: 11, Batch: 464, D Loss: 0.10207263808871847, G Loss: 17.569576263427734\n",
      "Epoch: 11, Batch: 465, D Loss: 0.1002643365105369, G Loss: 17.729297637939453\n",
      "Epoch: 11, Batch: 466, D Loss: 0.09151136398253534, G Loss: 17.70193099975586\n",
      "Epoch: 11, Batch: 467, D Loss: 0.10599813789582502, G Loss: 17.900911331176758\n",
      "Epoch: 12, Batch: 0, D Loss: 0.10496316125332328, G Loss: 18.08041763305664\n",
      "Epoch: 12, Batch: 1, D Loss: 0.10194060195186205, G Loss: 17.998594284057617\n",
      "Epoch: 12, Batch: 2, D Loss: 0.10148377832290656, G Loss: 17.768997192382812\n",
      "Epoch: 12, Batch: 3, D Loss: 0.0939289294846013, G Loss: 17.468425750732422\n",
      "Epoch: 12, Batch: 4, D Loss: 0.100723517899171, G Loss: 17.481224060058594\n",
      "Epoch: 12, Batch: 5, D Loss: 0.0896724588479838, G Loss: 17.511749267578125\n",
      "Epoch: 12, Batch: 6, D Loss: 0.09549110767073987, G Loss: 17.691692352294922\n",
      "Epoch: 12, Batch: 7, D Loss: 0.0951696504962527, G Loss: 17.87445831298828\n",
      "Epoch: 12, Batch: 8, D Loss: 0.09621874339444414, G Loss: 17.92405128479004\n",
      "Epoch: 12, Batch: 9, D Loss: 0.09663554544051678, G Loss: 17.733732223510742\n",
      "Epoch: 12, Batch: 10, D Loss: 0.09815380981468103, G Loss: 17.731884002685547\n",
      "Epoch: 12, Batch: 11, D Loss: 0.09983841544622418, G Loss: 17.802383422851562\n",
      "Epoch: 12, Batch: 12, D Loss: 0.09587154732943493, G Loss: 17.777463912963867\n",
      "Epoch: 12, Batch: 13, D Loss: 0.10356998591635946, G Loss: 17.898283004760742\n",
      "Epoch: 12, Batch: 14, D Loss: 0.10099510188574712, G Loss: 17.928253173828125\n",
      "Epoch: 12, Batch: 15, D Loss: 0.09763416047254303, G Loss: 17.770343780517578\n",
      "Epoch: 12, Batch: 16, D Loss: 0.10708868705796526, G Loss: 17.792781829833984\n",
      "Epoch: 12, Batch: 17, D Loss: 0.09309021689922936, G Loss: 17.574399948120117\n",
      "Epoch: 12, Batch: 18, D Loss: 0.10290945048214173, G Loss: 17.517333984375\n",
      "Epoch: 12, Batch: 19, D Loss: 0.098569487269633, G Loss: 17.546987533569336\n",
      "Epoch: 12, Batch: 20, D Loss: 0.10129757648221283, G Loss: 17.596385955810547\n",
      "Epoch: 12, Batch: 21, D Loss: 0.10276899856664912, G Loss: 17.639854431152344\n",
      "Epoch: 12, Batch: 22, D Loss: 0.10288586890829432, G Loss: 17.511838912963867\n",
      "Epoch: 12, Batch: 23, D Loss: 0.10054893690187061, G Loss: 17.29908561706543\n",
      "Epoch: 12, Batch: 24, D Loss: 0.10056517478706795, G Loss: 17.11136245727539\n",
      "Epoch: 12, Batch: 25, D Loss: 0.09532629469826226, G Loss: 16.96080780029297\n",
      "Epoch: 12, Batch: 26, D Loss: 0.09805782821376141, G Loss: 16.94573974609375\n",
      "Epoch: 12, Batch: 27, D Loss: 0.10206793760634092, G Loss: 17.113903045654297\n",
      "Epoch: 12, Batch: 28, D Loss: 0.09625906800332729, G Loss: 17.171886444091797\n",
      "Epoch: 12, Batch: 29, D Loss: 0.10464639407734211, G Loss: 17.242158889770508\n",
      "Epoch: 12, Batch: 30, D Loss: 0.08994877732331474, G Loss: 16.96230697631836\n",
      "Epoch: 12, Batch: 31, D Loss: 0.09731690679154603, G Loss: 16.81224822998047\n",
      "Epoch: 12, Batch: 32, D Loss: 0.09893479340826872, G Loss: 16.907846450805664\n",
      "Epoch: 12, Batch: 33, D Loss: 0.097099086339826, G Loss: 17.097707748413086\n",
      "Epoch: 12, Batch: 34, D Loss: 0.09827762358606584, G Loss: 17.230998992919922\n",
      "Epoch: 12, Batch: 35, D Loss: 0.10203887625611863, G Loss: 17.290729522705078\n",
      "Epoch: 12, Batch: 36, D Loss: 0.09939862150938694, G Loss: 17.231075286865234\n",
      "Epoch: 12, Batch: 37, D Loss: 0.0968883012213766, G Loss: 16.67084312438965\n",
      "Epoch: 12, Batch: 38, D Loss: 0.10065877937375234, G Loss: 16.13454818725586\n",
      "Epoch: 12, Batch: 39, D Loss: 0.08920736473738344, G Loss: 16.078521728515625\n",
      "Epoch: 12, Batch: 40, D Loss: 0.09642859334651277, G Loss: 16.15777015686035\n",
      "Epoch: 12, Batch: 41, D Loss: 0.10002165847466671, G Loss: 16.379549026489258\n",
      "Epoch: 12, Batch: 42, D Loss: 0.09755321429382491, G Loss: 16.530216217041016\n",
      "Epoch: 12, Batch: 43, D Loss: 0.10294551578923716, G Loss: 16.623971939086914\n",
      "Epoch: 12, Batch: 44, D Loss: 0.09314724409626507, G Loss: 16.442813873291016\n",
      "Epoch: 12, Batch: 45, D Loss: 0.09884554949223201, G Loss: 16.355024337768555\n",
      "Epoch: 12, Batch: 46, D Loss: 0.09942886909558979, G Loss: 16.49856948852539\n",
      "Epoch: 12, Batch: 47, D Loss: 0.10083147834637352, G Loss: 16.79277992248535\n",
      "Epoch: 12, Batch: 48, D Loss: 0.09800741129823365, G Loss: 16.997957229614258\n",
      "Epoch: 12, Batch: 49, D Loss: 0.10054319166463443, G Loss: 17.02251434326172\n",
      "Epoch: 12, Batch: 50, D Loss: 0.10049791525098328, G Loss: 16.931550979614258\n",
      "Epoch: 12, Batch: 51, D Loss: 0.09545642266396825, G Loss: 16.81201934814453\n",
      "Epoch: 12, Batch: 52, D Loss: 0.09838601089638388, G Loss: 16.830293655395508\n",
      "Epoch: 12, Batch: 53, D Loss: 0.10185028247704864, G Loss: 16.785526275634766\n",
      "Epoch: 12, Batch: 54, D Loss: 0.10090932710964395, G Loss: 17.307323455810547\n",
      "Epoch: 12, Batch: 55, D Loss: 0.09549347326880842, G Loss: 16.566699981689453\n",
      "Epoch: 12, Batch: 56, D Loss: 0.10680876566651065, G Loss: 16.009586334228516\n",
      "Epoch: 12, Batch: 57, D Loss: 0.09707793734861525, G Loss: 14.68870735168457\n",
      "Epoch: 12, Batch: 58, D Loss: 0.09737010218537989, G Loss: 14.410189628601074\n",
      "Epoch: 12, Batch: 59, D Loss: 0.10233446891459153, G Loss: 14.44317626953125\n",
      "Epoch: 12, Batch: 60, D Loss: 0.09369036013779919, G Loss: 14.395362854003906\n",
      "Epoch: 12, Batch: 61, D Loss: 0.10112676712697066, G Loss: 14.456083297729492\n",
      "Epoch: 12, Batch: 62, D Loss: 0.09319572975579149, G Loss: 14.391977310180664\n",
      "Epoch: 12, Batch: 63, D Loss: 0.0946420754791859, G Loss: 14.388589859008789\n",
      "Epoch: 12, Batch: 64, D Loss: 0.10830625237937852, G Loss: 14.782746315002441\n",
      "Epoch: 12, Batch: 65, D Loss: 0.09926973350842161, G Loss: 15.0741605758667\n",
      "Epoch: 12, Batch: 66, D Loss: 0.09589324339202676, G Loss: 15.079174995422363\n",
      "Epoch: 12, Batch: 67, D Loss: 0.09910620902942924, G Loss: 14.873908042907715\n",
      "Epoch: 12, Batch: 68, D Loss: 0.09859237390574549, G Loss: 14.909111022949219\n",
      "Epoch: 12, Batch: 69, D Loss: 0.10271258341711587, G Loss: 15.185505867004395\n",
      "Epoch: 12, Batch: 70, D Loss: 0.09774721525712948, G Loss: 15.421663284301758\n",
      "Epoch: 12, Batch: 71, D Loss: 0.10554458051326066, G Loss: 15.681556701660156\n",
      "Epoch: 12, Batch: 72, D Loss: 0.10064543142399884, G Loss: 15.734513282775879\n",
      "Epoch: 12, Batch: 73, D Loss: 0.09535546415508378, G Loss: 15.57556438446045\n",
      "Epoch: 12, Batch: 74, D Loss: 0.10230308312621617, G Loss: 15.61081314086914\n",
      "Epoch: 12, Batch: 75, D Loss: 0.10677654771151879, G Loss: 15.894196510314941\n",
      "Epoch: 12, Batch: 76, D Loss: 0.09581974860599018, G Loss: 16.009475708007812\n",
      "Epoch: 12, Batch: 77, D Loss: 0.10110859202997347, G Loss: 15.924224853515625\n",
      "Epoch: 12, Batch: 78, D Loss: 0.10200164187289573, G Loss: 15.6646089553833\n",
      "Epoch: 12, Batch: 79, D Loss: 0.1059285254097162, G Loss: 15.774019241333008\n",
      "Epoch: 12, Batch: 80, D Loss: 0.10197391429024805, G Loss: 15.857894897460938\n",
      "Epoch: 12, Batch: 81, D Loss: 0.09770386485354265, G Loss: 15.853145599365234\n",
      "Epoch: 12, Batch: 82, D Loss: 0.10263697307942721, G Loss: 15.950919151306152\n",
      "Epoch: 12, Batch: 83, D Loss: 0.09619454802939487, G Loss: 16.01765251159668\n",
      "Epoch: 12, Batch: 84, D Loss: 0.10510323649016229, G Loss: 16.24344825744629\n",
      "Epoch: 12, Batch: 85, D Loss: 0.09732185079589684, G Loss: 16.346023559570312\n",
      "Epoch: 12, Batch: 86, D Loss: 0.09754636259067695, G Loss: 15.70319938659668\n",
      "Epoch: 12, Batch: 87, D Loss: 0.09790854743323507, G Loss: 15.294906616210938\n",
      "Epoch: 12, Batch: 88, D Loss: 0.10051646177088003, G Loss: 15.357085227966309\n",
      "Epoch: 12, Batch: 89, D Loss: 0.0955810423071739, G Loss: 14.359354019165039\n",
      "Epoch: 12, Batch: 90, D Loss: 0.0979913495568212, G Loss: 14.565179824829102\n",
      "Epoch: 12, Batch: 91, D Loss: 0.1015186469182936, G Loss: 13.880959510803223\n",
      "Epoch: 12, Batch: 92, D Loss: 0.10304880457346144, G Loss: 14.03382396697998\n",
      "Epoch: 12, Batch: 93, D Loss: 0.09903099888020961, G Loss: 14.304964065551758\n",
      "Epoch: 12, Batch: 94, D Loss: 0.09473496518262436, G Loss: 14.449979782104492\n",
      "Epoch: 12, Batch: 95, D Loss: 0.09418162030806343, G Loss: 14.525983810424805\n",
      "Epoch: 12, Batch: 96, D Loss: 0.09220421515504995, G Loss: 14.696574211120605\n",
      "Epoch: 12, Batch: 97, D Loss: 0.09788127671339453, G Loss: 15.046513557434082\n",
      "Epoch: 12, Batch: 98, D Loss: 0.10182763837639186, G Loss: 14.729362487792969\n",
      "Epoch: 12, Batch: 99, D Loss: 0.09968658607402858, G Loss: 14.799707412719727\n",
      "Epoch: 12, Batch: 100, D Loss: 0.09373030938536431, G Loss: 14.152188301086426\n",
      "Epoch: 12, Batch: 101, D Loss: 0.10203603315721921, G Loss: 13.81035327911377\n",
      "Epoch: 12, Batch: 102, D Loss: 0.10322639657348986, G Loss: 14.228038787841797\n",
      "Epoch: 12, Batch: 103, D Loss: 0.10464014466322169, G Loss: 14.847990036010742\n",
      "Epoch: 12, Batch: 104, D Loss: 0.10166982956857851, G Loss: 15.262615203857422\n",
      "Epoch: 12, Batch: 105, D Loss: 0.09781249229298794, G Loss: 15.33440113067627\n",
      "Epoch: 12, Batch: 106, D Loss: 0.09868041270161143, G Loss: 15.331564903259277\n",
      "Epoch: 12, Batch: 107, D Loss: 0.09525139358002832, G Loss: 15.492579460144043\n",
      "Epoch: 12, Batch: 108, D Loss: 0.09992477978698844, G Loss: 15.550005912780762\n",
      "Epoch: 12, Batch: 109, D Loss: 0.09636829500027488, G Loss: 15.383697509765625\n",
      "Epoch: 12, Batch: 110, D Loss: 0.10009545586737545, G Loss: 14.603915214538574\n",
      "Epoch: 12, Batch: 111, D Loss: 0.0971495930852484, G Loss: 14.573772430419922\n",
      "Epoch: 12, Batch: 112, D Loss: 0.104731306065446, G Loss: 14.754067420959473\n",
      "Epoch: 12, Batch: 113, D Loss: 0.09902711304201262, G Loss: 14.93809700012207\n",
      "Epoch: 12, Batch: 114, D Loss: 0.09620444223730829, G Loss: 15.008604049682617\n",
      "Epoch: 12, Batch: 115, D Loss: 0.09122007707591706, G Loss: 14.85232925415039\n",
      "Epoch: 12, Batch: 116, D Loss: 0.09829747464823413, G Loss: 14.602038383483887\n",
      "Epoch: 12, Batch: 117, D Loss: 0.10002874490146496, G Loss: 14.080801963806152\n",
      "Epoch: 12, Batch: 118, D Loss: 0.10032951814693547, G Loss: 14.492890357971191\n",
      "Epoch: 12, Batch: 119, D Loss: 0.1013274083527449, G Loss: 12.951123237609863\n",
      "Epoch: 12, Batch: 120, D Loss: 0.09742721356190032, G Loss: 12.647470474243164\n",
      "Epoch: 12, Batch: 121, D Loss: 0.10198497722967659, G Loss: 12.680027961730957\n",
      "Epoch: 12, Batch: 122, D Loss: 0.10147574614256882, G Loss: 13.104778289794922\n",
      "Epoch: 12, Batch: 123, D Loss: 0.09953725094010224, G Loss: 13.641797065734863\n",
      "Epoch: 12, Batch: 124, D Loss: 0.10229743706713634, G Loss: 13.35195541381836\n",
      "Epoch: 12, Batch: 125, D Loss: 0.09913936168265991, G Loss: 13.553424835205078\n",
      "Epoch: 12, Batch: 126, D Loss: 0.10219968615018615, G Loss: 14.49485969543457\n",
      "Epoch: 12, Batch: 127, D Loss: 0.1003054682303599, G Loss: 15.346725463867188\n",
      "Epoch: 12, Batch: 128, D Loss: 0.09799022567256088, G Loss: 16.022926330566406\n",
      "Epoch: 12, Batch: 129, D Loss: 0.10420025205164052, G Loss: 16.342853546142578\n",
      "Epoch: 12, Batch: 130, D Loss: 0.10057063618799589, G Loss: 16.245445251464844\n",
      "Epoch: 12, Batch: 131, D Loss: 0.0942049126830824, G Loss: 15.520200729370117\n",
      "Epoch: 12, Batch: 132, D Loss: 0.0997142416265433, G Loss: 13.401840209960938\n",
      "Epoch: 12, Batch: 133, D Loss: 0.0980404330177862, G Loss: 13.181243896484375\n",
      "Epoch: 12, Batch: 134, D Loss: 0.10249705492537942, G Loss: 13.587249755859375\n",
      "Epoch: 12, Batch: 135, D Loss: 0.10413860120462459, G Loss: 14.204680442810059\n",
      "Epoch: 12, Batch: 136, D Loss: 0.10457702422615966, G Loss: 13.848211288452148\n",
      "Epoch: 12, Batch: 137, D Loss: 0.10171922616018492, G Loss: 13.403788566589355\n",
      "Epoch: 12, Batch: 138, D Loss: 0.09762574176329508, G Loss: 12.983055114746094\n",
      "Epoch: 12, Batch: 139, D Loss: 0.10490436836118988, G Loss: 14.96023178100586\n",
      "Epoch: 12, Batch: 140, D Loss: 0.09650349894453214, G Loss: 18.258804321289062\n",
      "Epoch: 12, Batch: 141, D Loss: 0.09783055139195618, G Loss: 19.24767303466797\n",
      "Epoch: 12, Batch: 142, D Loss: 0.10007761062442455, G Loss: 17.347787857055664\n",
      "Epoch: 12, Batch: 143, D Loss: 0.10733954241428023, G Loss: 14.915919303894043\n",
      "Epoch: 12, Batch: 144, D Loss: 0.10256510112958495, G Loss: 10.865364074707031\n",
      "Epoch: 12, Batch: 145, D Loss: 0.10073268320411444, G Loss: 36.43258285522461\n",
      "Epoch: 12, Batch: 146, D Loss: 0.11095605800766659, G Loss: 20.778934478759766\n",
      "Epoch: 12, Batch: 147, D Loss: 0.09559402029844932, G Loss: 11.003989219665527\n",
      "Epoch: 12, Batch: 148, D Loss: 0.09754785499535501, G Loss: 13.857070922851562\n",
      "Epoch: 12, Batch: 149, D Loss: 0.09935149438342705, G Loss: 14.669425964355469\n",
      "Epoch: 12, Batch: 150, D Loss: 0.09954443026435911, G Loss: 7.663617134094238\n",
      "Epoch: 12, Batch: 151, D Loss: 0.09949821676127613, G Loss: 17.120433807373047\n",
      "Epoch: 12, Batch: 152, D Loss: 0.10116970540560387, G Loss: 34.74858856201172\n",
      "Epoch: 12, Batch: 153, D Loss: 0.8420836360310204, G Loss: 0.0004983624094165862\n",
      "Epoch: 12, Batch: 154, D Loss: 5.887353956699371, G Loss: 0.00042098455014638603\n",
      "Epoch: 12, Batch: 155, D Loss: 2.7312616407871246, G Loss: 0.3092237412929535\n",
      "Epoch: 12, Batch: 156, D Loss: 0.2430265098810196, G Loss: 3.0386393070220947\n",
      "Epoch: 12, Batch: 157, D Loss: 0.9715533778071404, G Loss: 5.7865400314331055\n",
      "Epoch: 12, Batch: 158, D Loss: 1.0973048112355173, G Loss: 7.129765510559082\n",
      "Epoch: 12, Batch: 159, D Loss: 0.5698710333090276, G Loss: 8.82928466796875\n",
      "Epoch: 12, Batch: 160, D Loss: 0.19365904838196002, G Loss: 12.019091606140137\n",
      "Epoch: 12, Batch: 161, D Loss: 0.10340725212563484, G Loss: 16.4449462890625\n",
      "Epoch: 12, Batch: 162, D Loss: 0.1064527514232605, G Loss: 23.928543090820312\n",
      "Epoch: 12, Batch: 163, D Loss: 0.11074042915302584, G Loss: 9.531632423400879\n",
      "Epoch: 12, Batch: 164, D Loss: 0.11898955737706274, G Loss: 8.166729927062988\n",
      "Epoch: 12, Batch: 165, D Loss: 0.11759954443550669, G Loss: 11.498185157775879\n",
      "Epoch: 12, Batch: 166, D Loss: 0.19032710697501898, G Loss: 8.272708892822266\n",
      "Epoch: 12, Batch: 167, D Loss: 0.12894066303761065, G Loss: 17.19180679321289\n",
      "Epoch: 12, Batch: 168, D Loss: 0.14589573442975426, G Loss: 38.792266845703125\n",
      "Epoch: 12, Batch: 169, D Loss: 0.16047311035070244, G Loss: 6.00360107421875\n",
      "Epoch: 12, Batch: 170, D Loss: 1.4594544768333435, G Loss: 30.646514892578125\n",
      "Epoch: 12, Batch: 171, D Loss: 0.12255264073610306, G Loss: 116.12986755371094\n",
      "Epoch: 12, Batch: 172, D Loss: 5.235002517700195, G Loss: 87.93779754638672\n",
      "Epoch: 12, Batch: 173, D Loss: 1.2281676530838013, G Loss: 46.49578857421875\n",
      "Epoch: 12, Batch: 174, D Loss: 0.09918726980687465, G Loss: 21.758312225341797\n",
      "Epoch: 12, Batch: 175, D Loss: 0.11859258180163579, G Loss: 7.956202030181885\n",
      "Epoch: 12, Batch: 176, D Loss: 0.1430139383301139, G Loss: 3.4401278495788574\n",
      "Epoch: 12, Batch: 177, D Loss: 0.19866015762090683, G Loss: 6.339552402496338\n",
      "Epoch: 12, Batch: 178, D Loss: 0.123545818580169, G Loss: 13.868209838867188\n",
      "Epoch: 12, Batch: 179, D Loss: 0.09763483676872653, G Loss: 19.54096031188965\n",
      "Epoch: 12, Batch: 180, D Loss: 0.10443988080870081, G Loss: 22.227670669555664\n",
      "Epoch: 12, Batch: 181, D Loss: 0.11410732651972988, G Loss: 22.4387264251709\n",
      "Epoch: 12, Batch: 182, D Loss: 0.10244730130299415, G Loss: 23.164947509765625\n",
      "Epoch: 12, Batch: 183, D Loss: 0.0995333494668953, G Loss: 23.97161102294922\n",
      "Epoch: 12, Batch: 184, D Loss: 0.10084867495777636, G Loss: 23.468332290649414\n",
      "Epoch: 12, Batch: 185, D Loss: 0.09848171482286702, G Loss: 23.170055389404297\n",
      "Epoch: 12, Batch: 186, D Loss: 0.09865606579733172, G Loss: 23.95838737487793\n",
      "Epoch: 12, Batch: 187, D Loss: 0.10449476542741112, G Loss: 24.38693618774414\n",
      "Epoch: 12, Batch: 188, D Loss: 0.10438261934611882, G Loss: 24.322275161743164\n",
      "Epoch: 12, Batch: 189, D Loss: 0.09962137146038597, G Loss: 22.293962478637695\n",
      "Epoch: 12, Batch: 190, D Loss: 0.09385516196357768, G Loss: 19.784404754638672\n",
      "Epoch: 12, Batch: 191, D Loss: 0.10169024823774464, G Loss: 18.08416748046875\n",
      "Epoch: 12, Batch: 192, D Loss: 0.10222263556128164, G Loss: 18.324878692626953\n",
      "Epoch: 12, Batch: 193, D Loss: 0.09612726285114359, G Loss: 18.40190315246582\n",
      "Epoch: 12, Batch: 194, D Loss: 0.10483980316539387, G Loss: 18.313091278076172\n",
      "Epoch: 12, Batch: 195, D Loss: 0.097094416133098, G Loss: 17.87908935546875\n",
      "Epoch: 12, Batch: 196, D Loss: 0.09750454925713115, G Loss: 16.442453384399414\n",
      "Epoch: 12, Batch: 197, D Loss: 0.10096394477628934, G Loss: 15.5195951461792\n",
      "Epoch: 12, Batch: 198, D Loss: 0.09849676240756366, G Loss: 15.23070240020752\n",
      "Epoch: 12, Batch: 199, D Loss: 0.10298094617618858, G Loss: 15.055758476257324\n",
      "Epoch: 12, Batch: 200, D Loss: 0.0913498577899361, G Loss: 14.98597240447998\n",
      "Epoch: 12, Batch: 201, D Loss: 0.0935714830129939, G Loss: 14.859991073608398\n",
      "Epoch: 12, Batch: 202, D Loss: 0.09556247857852895, G Loss: 14.437458038330078\n",
      "Epoch: 12, Batch: 203, D Loss: 0.10610908293170951, G Loss: 14.201271057128906\n",
      "Epoch: 12, Batch: 204, D Loss: 0.09984711170488936, G Loss: 13.100874900817871\n",
      "Epoch: 12, Batch: 205, D Loss: 0.09985597431784754, G Loss: 12.76593017578125\n",
      "Epoch: 12, Batch: 206, D Loss: 0.09346430882101231, G Loss: 12.084577560424805\n",
      "Epoch: 12, Batch: 207, D Loss: 0.09787844073480301, G Loss: 11.374937057495117\n",
      "Epoch: 12, Batch: 208, D Loss: 0.10878128521653707, G Loss: 10.668318748474121\n",
      "Epoch: 12, Batch: 209, D Loss: 0.09983236527477857, G Loss: 9.927700996398926\n",
      "Epoch: 12, Batch: 210, D Loss: 0.09630956232285826, G Loss: 9.3389892578125\n",
      "Epoch: 12, Batch: 211, D Loss: 0.09794849653553683, G Loss: 9.072147369384766\n",
      "Epoch: 12, Batch: 212, D Loss: 0.09964179682719987, G Loss: 9.136943817138672\n",
      "Epoch: 12, Batch: 213, D Loss: 0.09826893937133718, G Loss: 9.596966743469238\n",
      "Epoch: 12, Batch: 214, D Loss: 0.105118479084922, G Loss: 10.566329002380371\n",
      "Epoch: 12, Batch: 215, D Loss: 0.10117171998717822, G Loss: 10.570793151855469\n",
      "Epoch: 12, Batch: 216, D Loss: 0.10005594056565315, G Loss: 10.107620239257812\n",
      "Epoch: 12, Batch: 217, D Loss: 0.09593864041380584, G Loss: 10.36065673828125\n",
      "Epoch: 12, Batch: 218, D Loss: 0.09718501340830699, G Loss: 10.047954559326172\n",
      "Epoch: 12, Batch: 219, D Loss: 0.10211623692885041, G Loss: 11.821279525756836\n",
      "Epoch: 12, Batch: 220, D Loss: 0.09548055264167488, G Loss: 11.760009765625\n",
      "Epoch: 12, Batch: 221, D Loss: 0.10924538888502866, G Loss: 10.972644805908203\n",
      "Epoch: 12, Batch: 222, D Loss: 0.09935706073883921, G Loss: 10.688604354858398\n",
      "Epoch: 12, Batch: 223, D Loss: 0.09276340494398028, G Loss: 10.74835205078125\n",
      "Epoch: 12, Batch: 224, D Loss: 0.09537632280262187, G Loss: 11.776958465576172\n",
      "Epoch: 12, Batch: 225, D Loss: 0.09951287109288387, G Loss: 13.530608177185059\n",
      "Epoch: 12, Batch: 226, D Loss: 0.10702098277397454, G Loss: 8.121848106384277\n",
      "Epoch: 12, Batch: 227, D Loss: 0.09995104186236858, G Loss: 10.945358276367188\n",
      "Epoch: 12, Batch: 228, D Loss: 0.0979494254297606, G Loss: 16.80493927001953\n",
      "Epoch: 12, Batch: 229, D Loss: 0.11684610188240185, G Loss: 4.743216037750244\n",
      "Epoch: 12, Batch: 230, D Loss: 1.218527615070343, G Loss: 8.510665893554688\n",
      "Epoch: 12, Batch: 231, D Loss: 0.10213359140719547, G Loss: 25.295494079589844\n",
      "Epoch: 12, Batch: 232, D Loss: 1.6819488487262788, G Loss: 10.172599792480469\n",
      "Epoch: 12, Batch: 233, D Loss: 0.14760508947074413, G Loss: 1.525488018989563\n",
      "Epoch: 12, Batch: 234, D Loss: 0.6186226531863213, G Loss: 1.0277900695800781\n",
      "Epoch: 12, Batch: 235, D Loss: 0.30822912603616714, G Loss: 2.626790761947632\n",
      "Epoch: 12, Batch: 236, D Loss: 0.13986200839281082, G Loss: 5.229106426239014\n",
      "Epoch: 12, Batch: 237, D Loss: 0.15469526289962232, G Loss: 8.081585884094238\n",
      "Epoch: 12, Batch: 238, D Loss: 0.18247937432897743, G Loss: 10.524812698364258\n",
      "Epoch: 12, Batch: 239, D Loss: 0.18996766904547258, G Loss: 12.490743637084961\n",
      "Epoch: 12, Batch: 240, D Loss: 0.1682284876749236, G Loss: 13.384675979614258\n",
      "Epoch: 12, Batch: 241, D Loss: 0.13190302177144986, G Loss: 13.2907133102417\n",
      "Epoch: 12, Batch: 242, D Loss: 0.10753585411839595, G Loss: 11.624534606933594\n",
      "Epoch: 12, Batch: 243, D Loss: 0.09494945086771622, G Loss: 9.003843307495117\n",
      "Epoch: 12, Batch: 244, D Loss: 0.10102156811626628, G Loss: 7.406033039093018\n",
      "Epoch: 12, Batch: 245, D Loss: 0.10187551827402785, G Loss: 7.836086273193359\n",
      "Epoch: 12, Batch: 246, D Loss: 0.10372278233990073, G Loss: 7.815167427062988\n",
      "Epoch: 12, Batch: 247, D Loss: 0.1075307096762117, G Loss: 8.208643913269043\n",
      "Epoch: 12, Batch: 248, D Loss: 0.10314094938803464, G Loss: 8.832592964172363\n",
      "Epoch: 12, Batch: 249, D Loss: 0.09918011291301809, G Loss: 9.251845359802246\n",
      "Epoch: 12, Batch: 250, D Loss: 0.0976179325953126, G Loss: 7.856244087219238\n",
      "Epoch: 12, Batch: 251, D Loss: 0.10301498125772923, G Loss: 7.393967628479004\n",
      "Epoch: 12, Batch: 252, D Loss: 0.10313636844512075, G Loss: 7.830996990203857\n",
      "Epoch: 12, Batch: 253, D Loss: 0.1028498001396656, G Loss: 6.640724182128906\n",
      "Epoch: 12, Batch: 254, D Loss: 0.09779089596122503, G Loss: 7.510617256164551\n",
      "Epoch: 12, Batch: 255, D Loss: 0.09994790249038488, G Loss: 8.48051643371582\n",
      "Epoch: 12, Batch: 256, D Loss: 0.0935035915026674, G Loss: 9.467227935791016\n",
      "Epoch: 12, Batch: 257, D Loss: 0.10556197722326033, G Loss: 9.543704986572266\n",
      "Epoch: 12, Batch: 258, D Loss: 0.09619988026679493, G Loss: 9.614400863647461\n",
      "Epoch: 12, Batch: 259, D Loss: 0.09172430339094717, G Loss: 9.511947631835938\n",
      "Epoch: 12, Batch: 260, D Loss: 0.0983757002686616, G Loss: 9.344247817993164\n",
      "Epoch: 12, Batch: 261, D Loss: 0.10890535928774625, G Loss: 7.029427528381348\n",
      "Epoch: 12, Batch: 262, D Loss: 0.10135734151117504, G Loss: 8.084656715393066\n",
      "Epoch: 12, Batch: 263, D Loss: 0.1035673550068168, G Loss: 10.87024974822998\n",
      "Epoch: 12, Batch: 264, D Loss: 0.10978730706847273, G Loss: 6.159948348999023\n",
      "Epoch: 12, Batch: 265, D Loss: 0.11193559085950255, G Loss: 6.924074649810791\n",
      "Epoch: 12, Batch: 266, D Loss: 0.1034703979967162, G Loss: 11.39309310913086\n",
      "Epoch: 12, Batch: 267, D Loss: 0.09687902388486691, G Loss: 14.097843170166016\n",
      "Epoch: 12, Batch: 268, D Loss: 0.09895294715320802, G Loss: 15.844554901123047\n",
      "Epoch: 12, Batch: 269, D Loss: 0.10225837005549465, G Loss: 15.325705528259277\n",
      "Epoch: 12, Batch: 270, D Loss: 0.10272473799659565, G Loss: 12.824962615966797\n",
      "Epoch: 12, Batch: 271, D Loss: 0.09650631411932409, G Loss: 11.307117462158203\n",
      "Epoch: 12, Batch: 272, D Loss: 0.10222366300149588, G Loss: 9.472902297973633\n",
      "Epoch: 12, Batch: 273, D Loss: 0.10719859309028834, G Loss: 8.329338073730469\n",
      "Epoch: 12, Batch: 274, D Loss: 0.10462478874251246, G Loss: 8.588212966918945\n",
      "Epoch: 12, Batch: 275, D Loss: 0.10210723686031997, G Loss: 9.215031623840332\n",
      "Epoch: 12, Batch: 276, D Loss: 0.10357346606906503, G Loss: 8.43962287902832\n",
      "Epoch: 12, Batch: 277, D Loss: 0.10291094775311649, G Loss: 8.148815155029297\n",
      "Epoch: 12, Batch: 278, D Loss: 0.10439176252111793, G Loss: 8.001747131347656\n",
      "Epoch: 12, Batch: 279, D Loss: 0.10597907012561336, G Loss: 9.082645416259766\n",
      "Epoch: 12, Batch: 280, D Loss: 0.09346738080785144, G Loss: 8.787825584411621\n",
      "Epoch: 12, Batch: 281, D Loss: 0.09985275496728718, G Loss: 7.604756832122803\n",
      "Epoch: 12, Batch: 282, D Loss: 0.10116361160180531, G Loss: 7.338576316833496\n",
      "Epoch: 12, Batch: 283, D Loss: 0.09607471874915063, G Loss: 7.860963821411133\n",
      "Epoch: 12, Batch: 284, D Loss: 0.10950304561993107, G Loss: 8.947705268859863\n",
      "Epoch: 12, Batch: 285, D Loss: 0.09548432882002089, G Loss: 9.410785675048828\n",
      "Epoch: 12, Batch: 286, D Loss: 0.10174111647938844, G Loss: 9.029594421386719\n",
      "Epoch: 12, Batch: 287, D Loss: 0.09927730954950675, G Loss: 8.374025344848633\n",
      "Epoch: 12, Batch: 288, D Loss: 0.09421036002459005, G Loss: 7.393950462341309\n",
      "Epoch: 12, Batch: 289, D Loss: 0.09925417095655575, G Loss: 7.689461708068848\n",
      "Epoch: 12, Batch: 290, D Loss: 0.1031304596690461, G Loss: 9.244208335876465\n",
      "Epoch: 12, Batch: 291, D Loss: 0.09790763956698356, G Loss: 10.529561042785645\n",
      "Epoch: 12, Batch: 292, D Loss: 0.09894344134954736, G Loss: 10.521208763122559\n",
      "Epoch: 12, Batch: 293, D Loss: 0.10407399042742327, G Loss: 9.769281387329102\n",
      "Epoch: 12, Batch: 294, D Loss: 0.09804320233524777, G Loss: 8.23406982421875\n",
      "Epoch: 12, Batch: 295, D Loss: 0.09571685135597363, G Loss: 8.422760009765625\n",
      "Epoch: 12, Batch: 296, D Loss: 0.101753983515664, G Loss: 9.259845733642578\n",
      "Epoch: 12, Batch: 297, D Loss: 0.10150081001484068, G Loss: 8.514029502868652\n",
      "Epoch: 12, Batch: 298, D Loss: 0.095248770841863, G Loss: 8.4609375\n",
      "Epoch: 12, Batch: 299, D Loss: 0.10337159113259986, G Loss: 8.298778533935547\n",
      "Epoch: 12, Batch: 300, D Loss: 0.1009416178567335, G Loss: 8.601319313049316\n",
      "Epoch: 12, Batch: 301, D Loss: 0.10087184978328878, G Loss: 9.760663986206055\n",
      "Epoch: 12, Batch: 302, D Loss: 0.0974629041083972, G Loss: 8.513334274291992\n",
      "Epoch: 12, Batch: 303, D Loss: 0.09621823545603547, G Loss: 8.232795715332031\n",
      "Epoch: 12, Batch: 304, D Loss: 0.09897330612875521, G Loss: 8.41360855102539\n",
      "Epoch: 12, Batch: 305, D Loss: 0.10219108882301953, G Loss: 9.023398399353027\n",
      "Epoch: 12, Batch: 306, D Loss: 0.10107570642139763, G Loss: 10.137306213378906\n",
      "Epoch: 12, Batch: 307, D Loss: 0.10098369122715667, G Loss: 8.103256225585938\n",
      "Epoch: 12, Batch: 308, D Loss: 0.11123926332220435, G Loss: 12.622591018676758\n",
      "Epoch: 12, Batch: 309, D Loss: 0.10465929339261493, G Loss: 14.588772773742676\n",
      "Epoch: 12, Batch: 310, D Loss: 0.11891592293977737, G Loss: 7.675677299499512\n",
      "Epoch: 12, Batch: 311, D Loss: 0.14309235662221909, G Loss: 16.107755661010742\n",
      "Epoch: 12, Batch: 312, D Loss: 0.09873283001817157, G Loss: 32.02190399169922\n",
      "Epoch: 12, Batch: 313, D Loss: 0.8144786090940315, G Loss: 11.164759635925293\n",
      "Epoch: 12, Batch: 314, D Loss: 0.4267696440219879, G Loss: 4.8005523681640625\n",
      "Epoch: 12, Batch: 315, D Loss: 0.10184943384956568, G Loss: 11.688068389892578\n",
      "Epoch: 12, Batch: 316, D Loss: 0.10063498904358426, G Loss: 19.56243133544922\n",
      "Epoch: 12, Batch: 317, D Loss: 0.10846352610180518, G Loss: 25.54090118408203\n",
      "Epoch: 12, Batch: 318, D Loss: 0.09540112316850398, G Loss: 29.97555923461914\n",
      "Epoch: 12, Batch: 319, D Loss: 0.11804479360594546, G Loss: 30.816911697387695\n",
      "Epoch: 12, Batch: 320, D Loss: 0.1392616480589369, G Loss: 30.485599517822266\n",
      "Epoch: 12, Batch: 321, D Loss: 0.11800727248201004, G Loss: 29.08060073852539\n",
      "Epoch: 12, Batch: 322, D Loss: 0.11012720316720494, G Loss: 26.691652297973633\n",
      "Epoch: 12, Batch: 323, D Loss: 0.10736394674252288, G Loss: 24.568470001220703\n",
      "Epoch: 12, Batch: 324, D Loss: 0.09880409392753689, G Loss: 23.1090030670166\n",
      "Epoch: 12, Batch: 325, D Loss: 0.10721233497176565, G Loss: 22.108688354492188\n",
      "Epoch: 12, Batch: 326, D Loss: 0.10940451208949747, G Loss: 21.13397216796875\n",
      "Epoch: 12, Batch: 327, D Loss: 0.10075832264051088, G Loss: 20.008045196533203\n",
      "Epoch: 12, Batch: 328, D Loss: 0.10530105409479285, G Loss: 19.383956909179688\n",
      "Epoch: 12, Batch: 329, D Loss: 0.11068691581096468, G Loss: 19.15048599243164\n",
      "Epoch: 12, Batch: 330, D Loss: 0.10702784960739198, G Loss: 18.506336212158203\n",
      "Epoch: 12, Batch: 331, D Loss: 0.10078039068466271, G Loss: 18.122562408447266\n",
      "Epoch: 12, Batch: 332, D Loss: 0.0974857077494633, G Loss: 17.86377716064453\n",
      "Epoch: 12, Batch: 333, D Loss: 0.09975391729250216, G Loss: 17.932353973388672\n",
      "Epoch: 12, Batch: 334, D Loss: 0.0945794660229291, G Loss: 18.024009704589844\n",
      "Epoch: 12, Batch: 335, D Loss: 0.09617451821195289, G Loss: 17.835037231445312\n",
      "Epoch: 12, Batch: 336, D Loss: 0.09714327587124316, G Loss: 17.47806739807129\n",
      "Epoch: 12, Batch: 337, D Loss: 0.09946597897555698, G Loss: 17.505233764648438\n",
      "Epoch: 12, Batch: 338, D Loss: 0.09390362911541228, G Loss: 17.452178955078125\n",
      "Epoch: 12, Batch: 339, D Loss: 0.09412202093895417, G Loss: 17.41118621826172\n",
      "Epoch: 12, Batch: 340, D Loss: 0.09864851750818282, G Loss: 17.359378814697266\n",
      "Epoch: 12, Batch: 341, D Loss: 0.1018015073742049, G Loss: 17.28077507019043\n",
      "Epoch: 12, Batch: 342, D Loss: 0.10483842514919672, G Loss: 17.18168067932129\n",
      "Epoch: 12, Batch: 343, D Loss: 0.10701044302962615, G Loss: 17.072391510009766\n",
      "Epoch: 12, Batch: 344, D Loss: 0.09716389882605725, G Loss: 16.70038414001465\n",
      "Epoch: 12, Batch: 345, D Loss: 0.09908636365544865, G Loss: 16.465639114379883\n",
      "Epoch: 12, Batch: 346, D Loss: 0.09905756241236219, G Loss: 16.388221740722656\n",
      "Epoch: 12, Batch: 347, D Loss: 0.09470273061697299, G Loss: 16.310089111328125\n",
      "Epoch: 12, Batch: 348, D Loss: 0.10020226820955358, G Loss: 16.229768753051758\n",
      "Epoch: 12, Batch: 349, D Loss: 0.10214595648302449, G Loss: 16.167560577392578\n",
      "Epoch: 12, Batch: 350, D Loss: 0.09740732379584927, G Loss: 16.08005714416504\n",
      "Epoch: 12, Batch: 351, D Loss: 0.10368103750355218, G Loss: 15.99569034576416\n",
      "Epoch: 12, Batch: 352, D Loss: 0.09852579162525288, G Loss: 15.918647766113281\n",
      "Epoch: 12, Batch: 353, D Loss: 0.09872822826605443, G Loss: 15.852407455444336\n",
      "Epoch: 12, Batch: 354, D Loss: 0.10560562365662207, G Loss: 15.82918930053711\n",
      "Epoch: 12, Batch: 355, D Loss: 0.09804739269916496, G Loss: 15.774665832519531\n",
      "Epoch: 12, Batch: 356, D Loss: 0.09756728794003777, G Loss: 15.725330352783203\n",
      "Epoch: 12, Batch: 357, D Loss: 0.09949866068536295, G Loss: 15.68146800994873\n",
      "Epoch: 12, Batch: 358, D Loss: 0.09966632416526267, G Loss: 15.645743370056152\n",
      "Epoch: 12, Batch: 359, D Loss: 0.09640624378736362, G Loss: 15.60427474975586\n",
      "Epoch: 12, Batch: 360, D Loss: 0.09784705645338931, G Loss: 15.539652824401855\n",
      "Epoch: 12, Batch: 361, D Loss: 0.10103506079084923, G Loss: 15.487442970275879\n",
      "Epoch: 12, Batch: 362, D Loss: 0.09566775658191773, G Loss: 15.440600395202637\n",
      "Epoch: 12, Batch: 363, D Loss: 0.09527292524848008, G Loss: 15.391678810119629\n",
      "Epoch: 12, Batch: 364, D Loss: 0.10243876396391016, G Loss: 15.354663848876953\n",
      "Epoch: 12, Batch: 365, D Loss: 0.10438248847446374, G Loss: 15.349827766418457\n",
      "Epoch: 12, Batch: 366, D Loss: 0.09894062933559411, G Loss: 15.350181579589844\n",
      "Epoch: 12, Batch: 367, D Loss: 0.09181698084309176, G Loss: 15.338872909545898\n",
      "Epoch: 12, Batch: 368, D Loss: 0.09806782556644578, G Loss: 15.326093673706055\n",
      "Epoch: 12, Batch: 369, D Loss: 0.09483911137596834, G Loss: 15.29720687866211\n",
      "Epoch: 12, Batch: 370, D Loss: 0.10121632678946924, G Loss: 15.277873039245605\n",
      "Epoch: 12, Batch: 371, D Loss: 0.0999671795723387, G Loss: 15.258879661560059\n",
      "Epoch: 12, Batch: 372, D Loss: 0.09855532690232849, G Loss: 15.235090255737305\n",
      "Epoch: 12, Batch: 373, D Loss: 0.0993956663907909, G Loss: 15.203184127807617\n",
      "Epoch: 12, Batch: 374, D Loss: 0.09940131734724389, G Loss: 15.179890632629395\n",
      "Epoch: 12, Batch: 375, D Loss: 0.09901124548231621, G Loss: 15.152195930480957\n",
      "Epoch: 12, Batch: 376, D Loss: 0.09761171717796913, G Loss: 15.124398231506348\n",
      "Epoch: 12, Batch: 377, D Loss: 0.09501374184652889, G Loss: 15.08133602142334\n",
      "Epoch: 12, Batch: 378, D Loss: 0.10303276868380351, G Loss: 15.064067840576172\n",
      "Epoch: 12, Batch: 379, D Loss: 0.09444814635710941, G Loss: 15.029730796813965\n",
      "Epoch: 12, Batch: 380, D Loss: 0.10420926801982944, G Loss: 15.01087474822998\n",
      "Epoch: 12, Batch: 381, D Loss: 0.09211733188764981, G Loss: 14.964139938354492\n",
      "Epoch: 12, Batch: 382, D Loss: 0.10483195119945776, G Loss: 14.915760040283203\n",
      "Epoch: 12, Batch: 383, D Loss: 0.10150754269093909, G Loss: 14.90641975402832\n",
      "Epoch: 12, Batch: 384, D Loss: 0.09760345091238776, G Loss: 14.92151927947998\n",
      "Epoch: 12, Batch: 385, D Loss: 0.10083281913136943, G Loss: 14.950142860412598\n",
      "Epoch: 12, Batch: 386, D Loss: 0.08846825690089588, G Loss: 14.963587760925293\n",
      "Epoch: 12, Batch: 387, D Loss: 0.09641449951043057, G Loss: 14.984254837036133\n",
      "Epoch: 12, Batch: 388, D Loss: 0.09819413531309351, G Loss: 14.995471000671387\n",
      "Epoch: 12, Batch: 389, D Loss: 0.10284704700316638, G Loss: 14.964688301086426\n",
      "Epoch: 12, Batch: 390, D Loss: 0.09784039644395648, G Loss: 14.92690658569336\n",
      "Epoch: 12, Batch: 391, D Loss: 0.10320440403205566, G Loss: 14.882904052734375\n",
      "Epoch: 12, Batch: 392, D Loss: 0.0987856022548641, G Loss: 14.883559226989746\n",
      "Epoch: 12, Batch: 393, D Loss: 0.09942387748399995, G Loss: 14.895157814025879\n",
      "Epoch: 12, Batch: 394, D Loss: 0.09993395648726278, G Loss: 14.91434383392334\n",
      "Epoch: 12, Batch: 395, D Loss: 0.09426117664594358, G Loss: 14.950114250183105\n",
      "Epoch: 12, Batch: 396, D Loss: 0.0991881293027177, G Loss: 14.967638969421387\n",
      "Epoch: 12, Batch: 397, D Loss: 0.10023720027996319, G Loss: 14.960004806518555\n",
      "Epoch: 12, Batch: 398, D Loss: 0.1041604698612133, G Loss: 14.940338134765625\n",
      "Epoch: 12, Batch: 399, D Loss: 0.09289619315509867, G Loss: 14.925421714782715\n",
      "Epoch: 12, Batch: 400, D Loss: 0.09513414849919855, G Loss: 14.914999008178711\n",
      "Epoch: 12, Batch: 401, D Loss: 0.10001346016703394, G Loss: 14.912537574768066\n",
      "Epoch: 12, Batch: 402, D Loss: 0.09715226661261056, G Loss: 14.90707778930664\n",
      "Epoch: 12, Batch: 403, D Loss: 0.10062236819183568, G Loss: 14.898232460021973\n",
      "Epoch: 12, Batch: 404, D Loss: 0.10193284445072948, G Loss: 14.894091606140137\n",
      "Epoch: 12, Batch: 405, D Loss: 0.10435924529603824, G Loss: 14.897680282592773\n",
      "Epoch: 12, Batch: 406, D Loss: 0.10365564215764778, G Loss: 14.89574909210205\n",
      "Epoch: 12, Batch: 407, D Loss: 0.10227488600300205, G Loss: 14.893667221069336\n",
      "Epoch: 12, Batch: 408, D Loss: 0.09889219074497646, G Loss: 14.86855411529541\n",
      "Epoch: 12, Batch: 409, D Loss: 0.09826146002588132, G Loss: 14.830206871032715\n",
      "Epoch: 12, Batch: 410, D Loss: 0.0986009536546959, G Loss: 14.782088279724121\n",
      "Epoch: 12, Batch: 411, D Loss: 0.10158258791479113, G Loss: 14.738120079040527\n",
      "Epoch: 12, Batch: 412, D Loss: 0.10119950831628444, G Loss: 14.711670875549316\n",
      "Epoch: 12, Batch: 413, D Loss: 0.10325291517422386, G Loss: 14.6936674118042\n",
      "Epoch: 12, Batch: 414, D Loss: 0.10184762010429438, G Loss: 14.676680564880371\n",
      "Epoch: 12, Batch: 415, D Loss: 0.09969971107454967, G Loss: 14.656609535217285\n",
      "Epoch: 12, Batch: 416, D Loss: 0.10276145658467328, G Loss: 14.640238761901855\n",
      "Epoch: 12, Batch: 417, D Loss: 0.09308825297028989, G Loss: 14.617149353027344\n",
      "Epoch: 12, Batch: 418, D Loss: 0.09390011736216763, G Loss: 14.60051155090332\n",
      "Epoch: 12, Batch: 419, D Loss: 0.10185178342626955, G Loss: 14.581341743469238\n",
      "Epoch: 12, Batch: 420, D Loss: 0.09951686469518961, G Loss: 14.567422866821289\n",
      "Epoch: 12, Batch: 421, D Loss: 0.1035760085064652, G Loss: 14.576360702514648\n",
      "Epoch: 12, Batch: 422, D Loss: 0.10130434563696156, G Loss: 14.594365119934082\n",
      "Epoch: 12, Batch: 423, D Loss: 0.10010227183734344, G Loss: 14.616008758544922\n",
      "Epoch: 12, Batch: 424, D Loss: 0.10032624676523483, G Loss: 14.633862495422363\n",
      "Epoch: 12, Batch: 425, D Loss: 0.10389014557493681, G Loss: 14.656237602233887\n",
      "Epoch: 12, Batch: 426, D Loss: 0.1010057012182557, G Loss: 14.673267364501953\n",
      "Epoch: 12, Batch: 427, D Loss: 0.09947834584171744, G Loss: 14.669093132019043\n",
      "Epoch: 12, Batch: 428, D Loss: 0.09815248614071947, G Loss: 14.664695739746094\n",
      "Epoch: 12, Batch: 429, D Loss: 0.09784538169401458, G Loss: 14.65951156616211\n",
      "Epoch: 12, Batch: 430, D Loss: 0.10123958351066165, G Loss: 14.660542488098145\n",
      "Epoch: 12, Batch: 431, D Loss: 0.0998663888929201, G Loss: 14.663619995117188\n",
      "Epoch: 12, Batch: 432, D Loss: 0.10085842693410996, G Loss: 14.66122817993164\n",
      "Epoch: 12, Batch: 433, D Loss: 0.10044406609392809, G Loss: 14.518669128417969\n",
      "Epoch: 12, Batch: 434, D Loss: 0.09584867111061612, G Loss: 14.234428405761719\n",
      "Epoch: 12, Batch: 435, D Loss: 0.10239278631013349, G Loss: 14.175885200500488\n",
      "Epoch: 12, Batch: 436, D Loss: 0.1002159661551616, G Loss: 14.171133041381836\n",
      "Epoch: 12, Batch: 437, D Loss: 0.09871505183744489, G Loss: 14.177486419677734\n",
      "Epoch: 12, Batch: 438, D Loss: 0.09812374147469427, G Loss: 14.18532657623291\n",
      "Epoch: 12, Batch: 439, D Loss: 0.09580666126549886, G Loss: 14.188119888305664\n",
      "Epoch: 12, Batch: 440, D Loss: 0.09858835576335423, G Loss: 14.197312355041504\n",
      "Epoch: 12, Batch: 441, D Loss: 0.09908619053831558, G Loss: 14.220067977905273\n",
      "Epoch: 12, Batch: 442, D Loss: 0.10211045970544319, G Loss: 14.261909484863281\n",
      "Epoch: 12, Batch: 443, D Loss: 0.10086080481246995, G Loss: 14.305374145507812\n",
      "Epoch: 12, Batch: 444, D Loss: 0.09734139906521477, G Loss: 14.341461181640625\n",
      "Epoch: 12, Batch: 445, D Loss: 0.09337114796210244, G Loss: 14.36097526550293\n",
      "Epoch: 12, Batch: 446, D Loss: 0.10176080772347973, G Loss: 14.388723373413086\n",
      "Epoch: 12, Batch: 447, D Loss: 0.09713359425342105, G Loss: 14.417786598205566\n",
      "Epoch: 12, Batch: 448, D Loss: 0.1066902788313655, G Loss: 14.469939231872559\n",
      "Epoch: 12, Batch: 449, D Loss: 0.08819520145695492, G Loss: 14.49117374420166\n",
      "Epoch: 12, Batch: 450, D Loss: 0.10301974136888248, G Loss: 14.5240478515625\n",
      "Epoch: 12, Batch: 451, D Loss: 0.10051998892191705, G Loss: 14.557233810424805\n",
      "Epoch: 12, Batch: 452, D Loss: 0.09300243658319118, G Loss: 14.574291229248047\n",
      "Epoch: 12, Batch: 453, D Loss: 0.09729463032047647, G Loss: 14.589642524719238\n",
      "Epoch: 12, Batch: 454, D Loss: 0.10067374727721301, G Loss: 14.612622261047363\n",
      "Epoch: 12, Batch: 455, D Loss: 0.09942813279151608, G Loss: 14.626090049743652\n",
      "Epoch: 12, Batch: 456, D Loss: 0.10976611836366601, G Loss: 14.682318687438965\n",
      "Epoch: 12, Batch: 457, D Loss: 0.09263123439377807, G Loss: 14.711583137512207\n",
      "Epoch: 12, Batch: 458, D Loss: 0.0986038827663549, G Loss: 14.733964920043945\n",
      "Epoch: 12, Batch: 459, D Loss: 0.0988964176631697, G Loss: 14.758523941040039\n",
      "Epoch: 12, Batch: 460, D Loss: 0.10221063968832311, G Loss: 14.783544540405273\n",
      "Epoch: 12, Batch: 461, D Loss: 0.0929896726679118, G Loss: 14.778982162475586\n",
      "Epoch: 12, Batch: 462, D Loss: 0.09455641991249308, G Loss: 14.764272689819336\n",
      "Epoch: 12, Batch: 463, D Loss: 0.09797341669180071, G Loss: 14.737982749938965\n",
      "Epoch: 12, Batch: 464, D Loss: 0.10079722805184588, G Loss: 14.722949981689453\n",
      "Epoch: 12, Batch: 465, D Loss: 0.10018690827982368, G Loss: 14.717782020568848\n",
      "Epoch: 12, Batch: 466, D Loss: 0.09909676875338391, G Loss: 14.72597599029541\n",
      "Epoch: 12, Batch: 467, D Loss: 0.099381049978021, G Loss: 14.789679527282715\n",
      "Epoch: 13, Batch: 0, D Loss: 0.10050851570520081, G Loss: 15.011027336120605\n",
      "Epoch: 13, Batch: 1, D Loss: 0.10357586981831446, G Loss: 15.366299629211426\n",
      "Epoch: 13, Batch: 2, D Loss: 0.10168213431960993, G Loss: 15.263590812683105\n",
      "Epoch: 13, Batch: 3, D Loss: 0.1020045349530534, G Loss: 14.9295654296875\n",
      "Epoch: 13, Batch: 4, D Loss: 0.09612011034579382, G Loss: 14.65814208984375\n",
      "Epoch: 13, Batch: 5, D Loss: 0.09731922638823676, G Loss: 14.624776840209961\n",
      "Epoch: 13, Batch: 6, D Loss: 0.0985484060677635, G Loss: 14.610032081604004\n",
      "Epoch: 13, Batch: 7, D Loss: 0.08826999900765031, G Loss: 14.588613510131836\n",
      "Epoch: 13, Batch: 8, D Loss: 0.10539668543010805, G Loss: 14.549959182739258\n",
      "Epoch: 13, Batch: 9, D Loss: 0.10081435345395562, G Loss: 14.53661823272705\n",
      "Epoch: 13, Batch: 10, D Loss: 0.10049125273931736, G Loss: 14.539530754089355\n",
      "Epoch: 13, Batch: 11, D Loss: 0.10554945496139112, G Loss: 14.571496963500977\n",
      "Epoch: 13, Batch: 12, D Loss: 0.10752337154600866, G Loss: 14.627556800842285\n",
      "Epoch: 13, Batch: 13, D Loss: 0.10127258302762243, G Loss: 14.681084632873535\n",
      "Epoch: 13, Batch: 14, D Loss: 0.10469580802654832, G Loss: 14.734947204589844\n",
      "Epoch: 13, Batch: 15, D Loss: 0.10180443812700446, G Loss: 14.763915061950684\n",
      "Epoch: 13, Batch: 16, D Loss: 0.0950178875034311, G Loss: 14.767284393310547\n",
      "Epoch: 13, Batch: 17, D Loss: 0.095844031941823, G Loss: 14.747541427612305\n",
      "Epoch: 13, Batch: 18, D Loss: 0.09706154392890198, G Loss: 14.715805053710938\n",
      "Epoch: 13, Batch: 19, D Loss: 0.09998987466349263, G Loss: 14.68203067779541\n",
      "Epoch: 13, Batch: 20, D Loss: 0.10278363923941924, G Loss: 14.663009643554688\n",
      "Epoch: 13, Batch: 21, D Loss: 0.09768671656618721, G Loss: 14.639410972595215\n",
      "Epoch: 13, Batch: 22, D Loss: 0.09949198939960979, G Loss: 14.620842933654785\n",
      "Epoch: 13, Batch: 23, D Loss: 0.09222733604906352, G Loss: 14.591565132141113\n",
      "Epoch: 13, Batch: 24, D Loss: 0.0995100457689233, G Loss: 14.571612358093262\n",
      "Epoch: 13, Batch: 25, D Loss: 0.10077073834533223, G Loss: 14.571900367736816\n",
      "Epoch: 13, Batch: 26, D Loss: 0.09521501955855172, G Loss: 14.568625450134277\n",
      "Epoch: 13, Batch: 27, D Loss: 0.10670987556900968, G Loss: 14.603557586669922\n",
      "Epoch: 13, Batch: 28, D Loss: 0.09741103674984686, G Loss: 14.636555671691895\n",
      "Epoch: 13, Batch: 29, D Loss: 0.10860451033811103, G Loss: 14.697895050048828\n",
      "Epoch: 13, Batch: 30, D Loss: 0.10478232712871716, G Loss: 14.761947631835938\n",
      "Epoch: 13, Batch: 31, D Loss: 0.10204498726214695, G Loss: 14.816258430480957\n",
      "Epoch: 13, Batch: 32, D Loss: 0.10571756895275541, G Loss: 14.877551078796387\n",
      "Epoch: 13, Batch: 33, D Loss: 0.09717783251619494, G Loss: 14.905303001403809\n",
      "Epoch: 13, Batch: 34, D Loss: 0.09790370977832197, G Loss: 14.914051055908203\n",
      "Epoch: 13, Batch: 35, D Loss: 0.10231317818666241, G Loss: 14.920480728149414\n",
      "Epoch: 13, Batch: 36, D Loss: 0.10248676118575872, G Loss: 14.921865463256836\n",
      "Epoch: 13, Batch: 37, D Loss: 0.09756755323529376, G Loss: 14.913351058959961\n",
      "Epoch: 13, Batch: 38, D Loss: 0.09690529571700779, G Loss: 14.89563274383545\n",
      "Epoch: 13, Batch: 39, D Loss: 0.09732423803859547, G Loss: 14.871191024780273\n",
      "Epoch: 13, Batch: 40, D Loss: 0.10485060877067554, G Loss: 14.862288475036621\n",
      "Epoch: 13, Batch: 41, D Loss: 0.09710667853590849, G Loss: 14.847962379455566\n",
      "Epoch: 13, Batch: 42, D Loss: 0.10185526257876631, G Loss: 14.84804630279541\n",
      "Epoch: 13, Batch: 43, D Loss: 0.10236735440371092, G Loss: 14.865166664123535\n",
      "Epoch: 13, Batch: 44, D Loss: 0.09398863652158695, G Loss: 14.886978149414062\n",
      "Epoch: 13, Batch: 45, D Loss: 0.108332551779597, G Loss: 14.899503707885742\n",
      "Epoch: 13, Batch: 46, D Loss: 0.10252035635021173, G Loss: 14.935188293457031\n",
      "Epoch: 13, Batch: 47, D Loss: 0.10074779024307645, G Loss: 14.972023963928223\n",
      "Epoch: 13, Batch: 48, D Loss: 0.10427413638012695, G Loss: 15.013894081115723\n",
      "Epoch: 13, Batch: 49, D Loss: 0.09854029933123343, G Loss: 15.030348777770996\n",
      "Epoch: 13, Batch: 50, D Loss: 0.10440478992651947, G Loss: 15.05338191986084\n",
      "Epoch: 13, Batch: 51, D Loss: 0.09945444238282164, G Loss: 15.07159423828125\n",
      "Epoch: 13, Batch: 52, D Loss: 0.10319484719113348, G Loss: 15.091453552246094\n",
      "Epoch: 13, Batch: 53, D Loss: 0.0944462176451566, G Loss: 15.09177303314209\n",
      "Epoch: 13, Batch: 54, D Loss: 0.09866089239301346, G Loss: 15.084553718566895\n",
      "Epoch: 13, Batch: 55, D Loss: 0.09395147196860876, G Loss: 15.061991691589355\n",
      "Epoch: 13, Batch: 56, D Loss: 0.0973588717891829, G Loss: 15.036946296691895\n",
      "Epoch: 13, Batch: 57, D Loss: 0.10269413046520981, G Loss: 15.030823707580566\n",
      "Epoch: 13, Batch: 58, D Loss: 0.09661497192853119, G Loss: 15.0217924118042\n",
      "Epoch: 13, Batch: 59, D Loss: 0.09989686378413865, G Loss: 15.02344799041748\n",
      "Epoch: 13, Batch: 60, D Loss: 0.10681107487995689, G Loss: 15.05014705657959\n",
      "Epoch: 13, Batch: 61, D Loss: 0.1039978051314705, G Loss: 15.091886520385742\n",
      "Epoch: 13, Batch: 62, D Loss: 0.10626977859213582, G Loss: 15.144153594970703\n",
      "Epoch: 13, Batch: 63, D Loss: 0.1070856544662604, G Loss: 15.203462600708008\n",
      "Epoch: 13, Batch: 64, D Loss: 0.09772760788202106, G Loss: 15.234626770019531\n",
      "Epoch: 13, Batch: 65, D Loss: 0.10008810521223666, G Loss: 15.25454330444336\n",
      "Epoch: 13, Batch: 66, D Loss: 0.09641000603915728, G Loss: 15.250149726867676\n",
      "Epoch: 13, Batch: 67, D Loss: 0.11021049287261775, G Loss: 15.255569458007812\n",
      "Epoch: 13, Batch: 68, D Loss: 0.10372240047747283, G Loss: 15.253107070922852\n",
      "Epoch: 13, Batch: 69, D Loss: 0.09676498245852372, G Loss: 15.236255645751953\n",
      "Epoch: 13, Batch: 70, D Loss: 0.09761180323692997, G Loss: 15.209311485290527\n",
      "Epoch: 13, Batch: 71, D Loss: 0.10313696288240237, G Loss: 15.190898895263672\n",
      "Epoch: 13, Batch: 72, D Loss: 0.10060839464664184, G Loss: 15.172124862670898\n",
      "Epoch: 13, Batch: 73, D Loss: 0.09179436156834697, G Loss: 15.133827209472656\n",
      "Epoch: 13, Batch: 74, D Loss: 0.09389827687097352, G Loss: 15.091206550598145\n",
      "Epoch: 13, Batch: 75, D Loss: 0.09759277899978258, G Loss: 15.06049919128418\n",
      "Epoch: 13, Batch: 76, D Loss: 0.10264986296724032, G Loss: 15.056554794311523\n",
      "Epoch: 13, Batch: 77, D Loss: 0.09120175653794149, G Loss: 15.043986320495605\n",
      "Epoch: 13, Batch: 78, D Loss: 0.09621843522820939, G Loss: 15.034467697143555\n",
      "Epoch: 13, Batch: 79, D Loss: 0.09662178064581894, G Loss: 15.032943725585938\n",
      "Epoch: 13, Batch: 80, D Loss: 0.10262763964135502, G Loss: 15.05846881866455\n",
      "Epoch: 13, Batch: 81, D Loss: 0.09811842467203746, G Loss: 15.093265533447266\n",
      "Epoch: 13, Batch: 82, D Loss: 0.09773688289789106, G Loss: 15.129959106445312\n",
      "Epoch: 13, Batch: 83, D Loss: 0.10016224989610123, G Loss: 15.17630386352539\n",
      "Epoch: 13, Batch: 84, D Loss: 0.10068680932353402, G Loss: 15.2257080078125\n",
      "Epoch: 13, Batch: 85, D Loss: 0.09599283396055114, G Loss: 15.263092041015625\n",
      "Epoch: 13, Batch: 86, D Loss: 0.0974610415165813, G Loss: 15.291576385498047\n",
      "Epoch: 13, Batch: 87, D Loss: 0.10594724142880807, G Loss: 15.331522941589355\n",
      "Epoch: 13, Batch: 88, D Loss: 0.09774898386598352, G Loss: 15.360280990600586\n",
      "Epoch: 13, Batch: 89, D Loss: 0.10118913774621774, G Loss: 15.382316589355469\n",
      "Epoch: 13, Batch: 90, D Loss: 0.09671154567600126, G Loss: 15.394193649291992\n",
      "Epoch: 13, Batch: 91, D Loss: 0.10658069432603412, G Loss: 15.423563003540039\n",
      "Epoch: 13, Batch: 92, D Loss: 0.1008815422582856, G Loss: 15.431132316589355\n",
      "Epoch: 13, Batch: 93, D Loss: 0.10043729375033195, G Loss: 15.427901268005371\n",
      "Epoch: 13, Batch: 94, D Loss: 0.10069244666278365, G Loss: 15.424555778503418\n",
      "Epoch: 13, Batch: 95, D Loss: 0.09720360887459378, G Loss: 15.41085147857666\n",
      "Epoch: 13, Batch: 96, D Loss: 0.09554637086895923, G Loss: 15.384297370910645\n",
      "Epoch: 13, Batch: 97, D Loss: 0.10276819834979989, G Loss: 15.370584487915039\n",
      "Epoch: 13, Batch: 98, D Loss: 0.10084157600485355, G Loss: 15.366071701049805\n",
      "Epoch: 13, Batch: 99, D Loss: 0.10329360640628948, G Loss: 15.376921653747559\n",
      "Epoch: 13, Batch: 100, D Loss: 0.10357323218405412, G Loss: 15.402767181396484\n",
      "Epoch: 13, Batch: 101, D Loss: 0.09233901422346236, G Loss: 15.408459663391113\n",
      "Epoch: 13, Batch: 102, D Loss: 0.10026696033249749, G Loss: 15.415261268615723\n",
      "Epoch: 13, Batch: 103, D Loss: 0.10068799890728286, G Loss: 15.431428909301758\n",
      "Epoch: 13, Batch: 104, D Loss: 0.1045269774233546, G Loss: 15.420159339904785\n",
      "Epoch: 13, Batch: 105, D Loss: 0.09755100000982964, G Loss: 15.407676696777344\n",
      "Epoch: 13, Batch: 106, D Loss: 0.10473704050041022, G Loss: 15.415016174316406\n",
      "Epoch: 13, Batch: 107, D Loss: 0.09583096450835171, G Loss: 15.311059951782227\n",
      "Epoch: 13, Batch: 108, D Loss: 0.0990388677695293, G Loss: 15.217072486877441\n",
      "Epoch: 13, Batch: 109, D Loss: 0.09902887268754057, G Loss: 15.131484985351562\n",
      "Epoch: 13, Batch: 110, D Loss: 0.1053258297224886, G Loss: 15.074387550354004\n",
      "Epoch: 13, Batch: 111, D Loss: 0.09666182589855055, G Loss: 15.017280578613281\n",
      "Epoch: 13, Batch: 112, D Loss: 0.1004907166754947, G Loss: 14.972567558288574\n",
      "Epoch: 13, Batch: 113, D Loss: 0.09898991560321235, G Loss: 14.932809829711914\n",
      "Epoch: 13, Batch: 114, D Loss: 0.09725217818370879, G Loss: 14.896775245666504\n",
      "Epoch: 13, Batch: 115, D Loss: 0.10088797680134576, G Loss: 14.876556396484375\n",
      "Epoch: 13, Batch: 116, D Loss: 0.10305010759718414, G Loss: 14.87158203125\n",
      "Epoch: 13, Batch: 117, D Loss: 0.0979709284396364, G Loss: 14.866866111755371\n",
      "Epoch: 13, Batch: 118, D Loss: 0.09633679418119812, G Loss: 14.853951454162598\n",
      "Epoch: 13, Batch: 119, D Loss: 0.10258439038918254, G Loss: 14.852070808410645\n",
      "Epoch: 13, Batch: 120, D Loss: 0.10681248077465, G Loss: 14.879050254821777\n",
      "Epoch: 13, Batch: 121, D Loss: 0.10942305991729029, G Loss: 14.937233924865723\n",
      "Epoch: 13, Batch: 122, D Loss: 0.09542374718333235, G Loss: 14.966646194458008\n",
      "Epoch: 13, Batch: 123, D Loss: 0.10592839770448848, G Loss: 15.000482559204102\n",
      "Epoch: 13, Batch: 124, D Loss: 0.102411540425976, G Loss: 15.02484130859375\n",
      "Epoch: 13, Batch: 125, D Loss: 0.09529385860990658, G Loss: 15.010564804077148\n",
      "Epoch: 13, Batch: 126, D Loss: 0.10378460909862497, G Loss: 15.001058578491211\n",
      "Epoch: 13, Batch: 127, D Loss: 0.10325354803563869, G Loss: 14.991976737976074\n",
      "Epoch: 13, Batch: 128, D Loss: 0.10425292490597826, G Loss: 14.991606712341309\n",
      "Epoch: 13, Batch: 129, D Loss: 0.10213346528925626, G Loss: 14.996978759765625\n",
      "Epoch: 13, Batch: 130, D Loss: 0.10639710965448046, G Loss: 15.023658752441406\n",
      "Epoch: 13, Batch: 131, D Loss: 0.0989408935561471, G Loss: 15.035888671875\n",
      "Epoch: 13, Batch: 132, D Loss: 0.09904604236460557, G Loss: 15.040745735168457\n",
      "Epoch: 13, Batch: 133, D Loss: 0.099568574115807, G Loss: 15.034011840820312\n",
      "Epoch: 13, Batch: 134, D Loss: 0.09933510355665476, G Loss: 15.02936840057373\n",
      "Epoch: 13, Batch: 135, D Loss: 0.09628684943463384, G Loss: 15.009123802185059\n",
      "Epoch: 13, Batch: 136, D Loss: 0.09946622307968767, G Loss: 14.998697280883789\n",
      "Epoch: 13, Batch: 137, D Loss: 0.09915013317335308, G Loss: 14.996004104614258\n",
      "Epoch: 13, Batch: 138, D Loss: 0.10140862762943925, G Loss: 14.998919486999512\n",
      "Epoch: 13, Batch: 139, D Loss: 0.09492399228328452, G Loss: 14.998430252075195\n",
      "Epoch: 13, Batch: 140, D Loss: 0.10140328488432715, G Loss: 15.005142211914062\n",
      "Epoch: 13, Batch: 141, D Loss: 0.1043619081912226, G Loss: 15.0272855758667\n",
      "Epoch: 13, Batch: 142, D Loss: 0.1000642685159363, G Loss: 15.048479080200195\n",
      "Epoch: 13, Batch: 143, D Loss: 0.1008407495057213, G Loss: 15.07662582397461\n",
      "Epoch: 13, Batch: 144, D Loss: 0.09649728154266768, G Loss: 15.091216087341309\n",
      "Epoch: 13, Batch: 145, D Loss: 0.09934960786662828, G Loss: 15.102510452270508\n",
      "Epoch: 13, Batch: 146, D Loss: 0.10096582392699816, G Loss: 15.107918739318848\n",
      "Epoch: 13, Batch: 147, D Loss: 0.09646585986897094, G Loss: 15.09810733795166\n",
      "Epoch: 13, Batch: 148, D Loss: 0.10586049020628252, G Loss: 15.113201141357422\n",
      "Epoch: 13, Batch: 149, D Loss: 0.10468846592991099, G Loss: 15.144890785217285\n",
      "Epoch: 13, Batch: 150, D Loss: 0.10561153600012574, G Loss: 15.18405532836914\n",
      "Epoch: 13, Batch: 151, D Loss: 0.10150073279267247, G Loss: 15.222947120666504\n",
      "Epoch: 13, Batch: 152, D Loss: 0.09390114499238678, G Loss: 15.23483943939209\n",
      "Epoch: 13, Batch: 153, D Loss: 0.09582834201161461, G Loss: 15.223475456237793\n",
      "Epoch: 13, Batch: 154, D Loss: 0.1039090634953368, G Loss: 15.224674224853516\n",
      "Epoch: 13, Batch: 155, D Loss: 0.10220153147241717, G Loss: 15.231532096862793\n",
      "Epoch: 13, Batch: 156, D Loss: 0.10173744124574569, G Loss: 15.241188049316406\n",
      "Epoch: 13, Batch: 157, D Loss: 0.10035646016044097, G Loss: 15.249418258666992\n",
      "Epoch: 13, Batch: 158, D Loss: 0.0980001393508445, G Loss: 15.245039939880371\n",
      "Epoch: 13, Batch: 159, D Loss: 0.0957494840048696, G Loss: 15.230955123901367\n",
      "Epoch: 13, Batch: 160, D Loss: 0.09633908024395055, G Loss: 15.212535858154297\n",
      "Epoch: 13, Batch: 161, D Loss: 0.09742019132829682, G Loss: 15.197808265686035\n",
      "Epoch: 13, Batch: 162, D Loss: 0.10618569526707233, G Loss: 15.208475112915039\n",
      "Epoch: 13, Batch: 163, D Loss: 0.09762561013667437, G Loss: 15.219096183776855\n",
      "Epoch: 13, Batch: 164, D Loss: 0.10237079332816279, G Loss: 15.243398666381836\n",
      "Epoch: 13, Batch: 165, D Loss: 0.09940374587224454, G Loss: 15.264914512634277\n",
      "Epoch: 13, Batch: 166, D Loss: 0.09923482452474985, G Loss: 15.274331092834473\n",
      "Epoch: 13, Batch: 167, D Loss: 0.10075900320128994, G Loss: 15.290367126464844\n",
      "Epoch: 13, Batch: 168, D Loss: 0.09783026080326351, G Loss: 15.294454574584961\n",
      "Epoch: 13, Batch: 169, D Loss: 0.09994561448332462, G Loss: 15.295150756835938\n",
      "Epoch: 13, Batch: 170, D Loss: 0.10082087865246336, G Loss: 15.298494338989258\n",
      "Epoch: 13, Batch: 171, D Loss: 0.103323393329255, G Loss: 15.31620979309082\n",
      "Epoch: 13, Batch: 172, D Loss: 0.10291632064981115, G Loss: 15.34740161895752\n",
      "Epoch: 13, Batch: 173, D Loss: 0.1036814096767742, G Loss: 15.383418083190918\n",
      "Epoch: 13, Batch: 174, D Loss: 0.10178374336385332, G Loss: 15.413472175598145\n",
      "Epoch: 13, Batch: 175, D Loss: 0.09472132169556602, G Loss: 15.412837982177734\n",
      "Epoch: 13, Batch: 176, D Loss: 0.09768208639540887, G Loss: 15.397944450378418\n",
      "Epoch: 13, Batch: 177, D Loss: 0.10812088644090778, G Loss: 15.407901763916016\n",
      "Epoch: 13, Batch: 178, D Loss: 0.10190189350818457, G Loss: 15.413033485412598\n",
      "Epoch: 13, Batch: 179, D Loss: 0.09697332725981767, G Loss: 15.403436660766602\n",
      "Epoch: 13, Batch: 180, D Loss: 0.09707536463330513, G Loss: 15.381157875061035\n",
      "Epoch: 13, Batch: 181, D Loss: 0.10096316174537634, G Loss: 15.36125373840332\n",
      "Epoch: 13, Batch: 182, D Loss: 0.09870301510766666, G Loss: 15.345559120178223\n",
      "Epoch: 13, Batch: 183, D Loss: 0.09970410600163859, G Loss: 15.34066104888916\n",
      "Epoch: 13, Batch: 184, D Loss: 0.10623307856017306, G Loss: 15.363035202026367\n",
      "Epoch: 13, Batch: 185, D Loss: 0.09970006462430092, G Loss: 15.381083488464355\n",
      "Epoch: 13, Batch: 186, D Loss: 0.10430182366155805, G Loss: 15.413335800170898\n",
      "Epoch: 13, Batch: 187, D Loss: 0.1027526958537166, G Loss: 15.442270278930664\n",
      "Epoch: 13, Batch: 188, D Loss: 0.09948192570062986, G Loss: 15.464897155761719\n",
      "Epoch: 13, Batch: 189, D Loss: 0.10480097436368396, G Loss: 15.499663352966309\n",
      "Epoch: 13, Batch: 190, D Loss: 0.10291426050215335, G Loss: 15.536706924438477\n",
      "Epoch: 13, Batch: 191, D Loss: 0.09587351220211104, G Loss: 15.54103946685791\n",
      "Epoch: 13, Batch: 192, D Loss: 0.10005443527370517, G Loss: 15.53785228729248\n",
      "Epoch: 13, Batch: 193, D Loss: 0.10601445975666479, G Loss: 15.549482345581055\n",
      "Epoch: 13, Batch: 194, D Loss: 0.100812687053498, G Loss: 15.557242393493652\n",
      "Epoch: 13, Batch: 195, D Loss: 0.09581524013206177, G Loss: 15.545677185058594\n",
      "Epoch: 13, Batch: 196, D Loss: 0.10065286549599506, G Loss: 15.542473793029785\n",
      "Epoch: 13, Batch: 197, D Loss: 0.09972353250327615, G Loss: 15.539444923400879\n",
      "Epoch: 13, Batch: 198, D Loss: 0.10392311132918053, G Loss: 15.553525924682617\n",
      "Epoch: 13, Batch: 199, D Loss: 0.10348966486159128, G Loss: 15.573131561279297\n",
      "Epoch: 13, Batch: 200, D Loss: 0.10125964494204709, G Loss: 15.589399337768555\n",
      "Epoch: 13, Batch: 201, D Loss: 0.09936608607235797, G Loss: 15.602967262268066\n",
      "Epoch: 13, Batch: 202, D Loss: 0.10016838577343634, G Loss: 15.617270469665527\n",
      "Epoch: 13, Batch: 203, D Loss: 0.10068654255729825, G Loss: 15.634207725524902\n",
      "Epoch: 13, Batch: 204, D Loss: 0.09867042957640848, G Loss: 15.636951446533203\n",
      "Epoch: 13, Batch: 205, D Loss: 0.09511796338610168, G Loss: 15.624195098876953\n",
      "Epoch: 13, Batch: 206, D Loss: 0.10053330096988589, G Loss: 15.582406044006348\n",
      "Epoch: 13, Batch: 207, D Loss: 0.09637486766412451, G Loss: 15.53316879272461\n",
      "Epoch: 13, Batch: 208, D Loss: 0.09212596351292746, G Loss: 15.461893081665039\n",
      "Epoch: 13, Batch: 209, D Loss: 0.10025827001663856, G Loss: 15.421562194824219\n",
      "Epoch: 13, Batch: 210, D Loss: 0.10042175321585489, G Loss: 15.410327911376953\n",
      "Epoch: 13, Batch: 211, D Loss: 0.10933733803737766, G Loss: 15.484241485595703\n",
      "Epoch: 13, Batch: 212, D Loss: 0.10018146144294349, G Loss: 15.563058853149414\n",
      "Epoch: 13, Batch: 213, D Loss: 0.09954793975190057, G Loss: 15.628664016723633\n",
      "Epoch: 13, Batch: 214, D Loss: 0.10384608459369815, G Loss: 15.702706336975098\n",
      "Epoch: 13, Batch: 215, D Loss: 0.09817937047483838, G Loss: 15.725927352905273\n",
      "Epoch: 13, Batch: 216, D Loss: 0.10349349593263923, G Loss: 15.735967636108398\n",
      "Epoch: 13, Batch: 217, D Loss: 0.0956701931634214, G Loss: 15.712200164794922\n",
      "Epoch: 13, Batch: 218, D Loss: 0.09789053579928009, G Loss: 15.669133186340332\n",
      "Epoch: 13, Batch: 219, D Loss: 0.1015289780585249, G Loss: 15.626118659973145\n",
      "Epoch: 13, Batch: 220, D Loss: 0.10434052426113283, G Loss: 15.605229377746582\n",
      "Epoch: 13, Batch: 221, D Loss: 0.10194232586711394, G Loss: 15.579076766967773\n",
      "Epoch: 13, Batch: 222, D Loss: 0.10764219902670646, G Loss: 15.599372863769531\n",
      "Epoch: 13, Batch: 223, D Loss: 0.10216419512819641, G Loss: 15.621071815490723\n",
      "Epoch: 13, Batch: 224, D Loss: 0.09720549005803747, G Loss: 15.623509407043457\n",
      "Epoch: 13, Batch: 225, D Loss: 0.10152287002729565, G Loss: 15.6333589553833\n",
      "Epoch: 13, Batch: 226, D Loss: 0.0999927669277838, G Loss: 15.617835998535156\n",
      "Epoch: 13, Batch: 227, D Loss: 0.08854619715918233, G Loss: 15.561821937561035\n",
      "Epoch: 13, Batch: 228, D Loss: 0.0962796590000039, G Loss: 15.502622604370117\n",
      "Epoch: 13, Batch: 229, D Loss: 0.09781285992042399, G Loss: 15.44206428527832\n",
      "Epoch: 13, Batch: 230, D Loss: 0.10175278276110333, G Loss: 15.425570487976074\n",
      "Epoch: 13, Batch: 231, D Loss: 0.0968731153401663, G Loss: 15.422670364379883\n",
      "Epoch: 13, Batch: 232, D Loss: 0.09521175561890516, G Loss: 15.415043830871582\n",
      "Epoch: 13, Batch: 233, D Loss: 0.09988432675057624, G Loss: 15.438704490661621\n",
      "Epoch: 13, Batch: 234, D Loss: 0.09577278874518669, G Loss: 15.458858489990234\n",
      "Epoch: 13, Batch: 235, D Loss: 0.09827086905526272, G Loss: 15.489581108093262\n",
      "Epoch: 13, Batch: 236, D Loss: 0.09387472574179867, G Loss: 15.517812728881836\n",
      "Epoch: 13, Batch: 237, D Loss: 0.09231107799494964, G Loss: 15.530753135681152\n",
      "Epoch: 13, Batch: 238, D Loss: 0.09959369884690261, G Loss: 15.546693801879883\n",
      "Epoch: 13, Batch: 239, D Loss: 0.09985565215219339, G Loss: 15.567936897277832\n",
      "Epoch: 13, Batch: 240, D Loss: 0.10079367048756893, G Loss: 15.599583625793457\n",
      "Epoch: 13, Batch: 241, D Loss: 0.09991183383010593, G Loss: 15.581226348876953\n",
      "Epoch: 13, Batch: 242, D Loss: 0.10604051199261733, G Loss: 15.561079025268555\n",
      "Epoch: 13, Batch: 243, D Loss: 0.09805975655480381, G Loss: 15.559070587158203\n",
      "Epoch: 13, Batch: 244, D Loss: 0.10326951898521486, G Loss: 15.647317886352539\n",
      "Epoch: 13, Batch: 245, D Loss: 0.09839796069027074, G Loss: 15.653350830078125\n",
      "Epoch: 13, Batch: 246, D Loss: 0.10170349936805678, G Loss: 15.667516708374023\n",
      "Epoch: 13, Batch: 247, D Loss: 0.10274295827851176, G Loss: 15.687830924987793\n",
      "Epoch: 13, Batch: 248, D Loss: 0.10484433085613176, G Loss: 15.770065307617188\n",
      "Epoch: 13, Batch: 249, D Loss: 0.10572616152894909, G Loss: 15.834355354309082\n",
      "Epoch: 13, Batch: 250, D Loss: 0.09055645359517683, G Loss: 15.7210054397583\n",
      "Epoch: 13, Batch: 251, D Loss: 0.10598978610035914, G Loss: 15.666289329528809\n",
      "Epoch: 13, Batch: 252, D Loss: 0.09514929742876888, G Loss: 15.493021965026855\n",
      "Epoch: 13, Batch: 253, D Loss: 0.09311141961227065, G Loss: 15.25121021270752\n",
      "Epoch: 13, Batch: 254, D Loss: 0.1021378575336982, G Loss: 15.349509239196777\n",
      "Epoch: 13, Batch: 255, D Loss: 0.09677656901514098, G Loss: 15.519800186157227\n",
      "Epoch: 13, Batch: 256, D Loss: 0.10217477969259647, G Loss: 15.745579719543457\n",
      "Epoch: 13, Batch: 257, D Loss: 0.09709999801324187, G Loss: 15.867388725280762\n",
      "Epoch: 13, Batch: 258, D Loss: 0.10471958075576282, G Loss: 15.959506034851074\n",
      "Epoch: 13, Batch: 259, D Loss: 0.10426217076300404, G Loss: 16.00552749633789\n",
      "Epoch: 13, Batch: 260, D Loss: 0.10165142599809585, G Loss: 16.022672653198242\n",
      "Epoch: 13, Batch: 261, D Loss: 0.09832842265596398, G Loss: 15.997522354125977\n",
      "Epoch: 13, Batch: 262, D Loss: 0.1006515307451501, G Loss: 15.94802474975586\n",
      "Epoch: 13, Batch: 263, D Loss: 0.09588293972259265, G Loss: 15.862451553344727\n",
      "Epoch: 13, Batch: 264, D Loss: 0.09809807056659992, G Loss: 15.759440422058105\n",
      "Epoch: 13, Batch: 265, D Loss: 0.0975869378735581, G Loss: 15.665948867797852\n",
      "Epoch: 13, Batch: 266, D Loss: 0.09799508649221877, G Loss: 15.610501289367676\n",
      "Epoch: 13, Batch: 267, D Loss: 0.10268158343014022, G Loss: 15.66637897491455\n",
      "Epoch: 13, Batch: 268, D Loss: 0.09422607185361898, G Loss: 15.715415000915527\n",
      "Epoch: 13, Batch: 269, D Loss: 0.09540215822610065, G Loss: 15.739323616027832\n",
      "Epoch: 13, Batch: 270, D Loss: 0.10498387679570698, G Loss: 15.816378593444824\n",
      "Epoch: 13, Batch: 271, D Loss: 0.10322036315992733, G Loss: 15.913756370544434\n",
      "Epoch: 13, Batch: 272, D Loss: 0.09812120400995639, G Loss: 15.952735900878906\n",
      "Epoch: 13, Batch: 273, D Loss: 0.10482509329367318, G Loss: 15.968194961547852\n",
      "Epoch: 13, Batch: 274, D Loss: 0.09739889904773946, G Loss: 15.934127807617188\n",
      "Epoch: 13, Batch: 275, D Loss: 0.09540065685681043, G Loss: 15.853902816772461\n",
      "Epoch: 13, Batch: 276, D Loss: 0.10644295695000494, G Loss: 15.833076477050781\n",
      "Epoch: 13, Batch: 277, D Loss: 0.09934405299146931, G Loss: 15.800511360168457\n",
      "Epoch: 13, Batch: 278, D Loss: 0.10302461134638463, G Loss: 15.792851448059082\n",
      "Epoch: 13, Batch: 279, D Loss: 0.09548985585666969, G Loss: 15.75147533416748\n",
      "Epoch: 13, Batch: 280, D Loss: 0.09689204489752257, G Loss: 15.666730880737305\n",
      "Epoch: 13, Batch: 281, D Loss: 0.10408859368091328, G Loss: 15.665592193603516\n",
      "Epoch: 13, Batch: 282, D Loss: 0.10102524861366646, G Loss: 15.705850601196289\n",
      "Epoch: 13, Batch: 283, D Loss: 0.10605491326881378, G Loss: 15.829507827758789\n",
      "Epoch: 13, Batch: 284, D Loss: 0.09605122147624456, G Loss: 15.881573677062988\n",
      "Epoch: 13, Batch: 285, D Loss: 0.0967576254142557, G Loss: 15.849221229553223\n",
      "Epoch: 13, Batch: 286, D Loss: 0.10541037336442827, G Loss: 15.841864585876465\n",
      "Epoch: 13, Batch: 287, D Loss: 0.09714684614802138, G Loss: 15.81602954864502\n",
      "Epoch: 13, Batch: 288, D Loss: 0.08982522660194547, G Loss: 15.663798332214355\n",
      "Epoch: 13, Batch: 289, D Loss: 0.09829461054145128, G Loss: 15.536884307861328\n",
      "Epoch: 13, Batch: 290, D Loss: 0.0983658522499411, G Loss: 15.5078763961792\n",
      "Epoch: 13, Batch: 291, D Loss: 0.09435850663965084, G Loss: 15.506914138793945\n",
      "Epoch: 13, Batch: 292, D Loss: 0.09865112494490802, G Loss: 15.58918285369873\n",
      "Epoch: 13, Batch: 293, D Loss: 0.09733486847719774, G Loss: 15.674079895019531\n",
      "Epoch: 13, Batch: 294, D Loss: 0.10277954281912827, G Loss: 15.813833236694336\n",
      "Epoch: 13, Batch: 295, D Loss: 0.10070710215295975, G Loss: 15.955166816711426\n",
      "Epoch: 13, Batch: 296, D Loss: 0.10023694886184487, G Loss: 16.04399871826172\n",
      "Epoch: 13, Batch: 297, D Loss: 0.10062829495766223, G Loss: 16.07305145263672\n",
      "Epoch: 13, Batch: 298, D Loss: 0.09512793454499402, G Loss: 16.013174057006836\n",
      "Epoch: 13, Batch: 299, D Loss: 0.1006862795725958, G Loss: 15.956296920776367\n",
      "Epoch: 13, Batch: 300, D Loss: 0.10110639017349499, G Loss: 15.937368392944336\n",
      "Epoch: 13, Batch: 301, D Loss: 0.0988109340795873, G Loss: 15.93110179901123\n",
      "Epoch: 13, Batch: 302, D Loss: 0.10356993907204526, G Loss: 15.975105285644531\n",
      "Epoch: 13, Batch: 303, D Loss: 0.10166887638940736, G Loss: 16.012624740600586\n",
      "Epoch: 13, Batch: 304, D Loss: 0.10164626957431366, G Loss: 16.03856658935547\n",
      "Epoch: 13, Batch: 305, D Loss: 0.09717234526801732, G Loss: 16.003246307373047\n",
      "Epoch: 13, Batch: 306, D Loss: 0.09805331187760302, G Loss: 15.950305938720703\n",
      "Epoch: 13, Batch: 307, D Loss: 0.09779189593789539, G Loss: 15.91553020477295\n",
      "Epoch: 13, Batch: 308, D Loss: 0.10998785902229002, G Loss: 16.077167510986328\n",
      "Epoch: 13, Batch: 309, D Loss: 0.1017474564876153, G Loss: 16.23284149169922\n",
      "Epoch: 13, Batch: 310, D Loss: 0.09920555936837872, G Loss: 16.29802703857422\n",
      "Epoch: 13, Batch: 311, D Loss: 0.09752832783071952, G Loss: 16.30868148803711\n",
      "Epoch: 13, Batch: 312, D Loss: 0.09762619252097338, G Loss: 16.23988914489746\n",
      "Epoch: 13, Batch: 313, D Loss: 0.09805901605399114, G Loss: 16.11549186706543\n",
      "Epoch: 13, Batch: 314, D Loss: 0.09459502507667139, G Loss: 15.947592735290527\n",
      "Epoch: 13, Batch: 315, D Loss: 0.09345683967632112, G Loss: 15.781471252441406\n",
      "Epoch: 13, Batch: 316, D Loss: 0.09786465391242416, G Loss: 15.763310432434082\n",
      "Epoch: 13, Batch: 317, D Loss: 0.10092646539634131, G Loss: 15.904986381530762\n",
      "Epoch: 13, Batch: 318, D Loss: 0.10100142949689328, G Loss: 16.121984481811523\n",
      "Epoch: 13, Batch: 319, D Loss: 0.09811244267191555, G Loss: 16.279464721679688\n",
      "Epoch: 13, Batch: 320, D Loss: 0.09931613089706559, G Loss: 16.370038986206055\n",
      "Epoch: 13, Batch: 321, D Loss: 0.10220343661991649, G Loss: 16.429100036621094\n",
      "Epoch: 13, Batch: 322, D Loss: 0.1008785878779257, G Loss: 16.448434829711914\n",
      "Epoch: 13, Batch: 323, D Loss: 0.10481337290180903, G Loss: 16.46808624267578\n",
      "Epoch: 13, Batch: 324, D Loss: 0.09989232392819858, G Loss: 16.45530128479004\n",
      "Epoch: 13, Batch: 325, D Loss: 0.09492985137454468, G Loss: 16.385604858398438\n",
      "Epoch: 13, Batch: 326, D Loss: 0.0999888280562935, G Loss: 16.316789627075195\n",
      "Epoch: 13, Batch: 327, D Loss: 0.10252384536545378, G Loss: 16.287187576293945\n",
      "Epoch: 13, Batch: 328, D Loss: 0.09959485899195997, G Loss: 16.278953552246094\n",
      "Epoch: 13, Batch: 329, D Loss: 0.10200971806558812, G Loss: 16.32052230834961\n",
      "Epoch: 13, Batch: 330, D Loss: 0.0978625971008853, G Loss: 16.33607292175293\n",
      "Epoch: 13, Batch: 331, D Loss: 0.09492104822219716, G Loss: 16.324569702148438\n",
      "Epoch: 13, Batch: 332, D Loss: 0.09729925216326407, G Loss: 16.28953742980957\n",
      "Epoch: 13, Batch: 333, D Loss: 0.09564894249025357, G Loss: 16.259294509887695\n",
      "Epoch: 13, Batch: 334, D Loss: 0.10038418911507563, G Loss: 16.27252769470215\n",
      "Epoch: 13, Batch: 335, D Loss: 0.10087735642182949, G Loss: 16.328845977783203\n",
      "Epoch: 13, Batch: 336, D Loss: 0.0998981761437463, G Loss: 16.401575088500977\n",
      "Epoch: 13, Batch: 337, D Loss: 0.09464392130000476, G Loss: 16.390548706054688\n",
      "Epoch: 13, Batch: 338, D Loss: 0.09935145948158208, G Loss: 16.37115478515625\n",
      "Epoch: 13, Batch: 339, D Loss: 0.10129508546789978, G Loss: 16.36527442932129\n",
      "Epoch: 13, Batch: 340, D Loss: 0.10010525033376538, G Loss: 16.359130859375\n",
      "Epoch: 13, Batch: 341, D Loss: 0.08854568414222896, G Loss: 16.261512756347656\n",
      "Epoch: 13, Batch: 342, D Loss: 0.09449155775218898, G Loss: 16.140056610107422\n",
      "Epoch: 13, Batch: 343, D Loss: 0.0925049851665527, G Loss: 16.03567123413086\n",
      "Epoch: 13, Batch: 344, D Loss: 0.10003293424501791, G Loss: 16.071060180664062\n",
      "Epoch: 13, Batch: 345, D Loss: 0.10494452293489331, G Loss: 16.239730834960938\n",
      "Epoch: 13, Batch: 346, D Loss: 0.09908159396871596, G Loss: 16.409732818603516\n",
      "Epoch: 13, Batch: 347, D Loss: 0.09253857181332492, G Loss: 16.468931198120117\n",
      "Epoch: 13, Batch: 348, D Loss: 0.10711549593685987, G Loss: 16.562705993652344\n",
      "Epoch: 13, Batch: 349, D Loss: 0.09843985903980368, G Loss: 16.59775161743164\n",
      "Epoch: 13, Batch: 350, D Loss: 0.10188176610081001, G Loss: 16.590858459472656\n",
      "Epoch: 13, Batch: 351, D Loss: 0.10409063274332553, G Loss: 16.568769454956055\n",
      "Epoch: 13, Batch: 352, D Loss: 0.09924686276212213, G Loss: 16.501415252685547\n",
      "Epoch: 13, Batch: 353, D Loss: 0.09636215013091132, G Loss: 16.387014389038086\n",
      "Epoch: 13, Batch: 354, D Loss: 0.09972171011015973, G Loss: 16.30266571044922\n",
      "Epoch: 13, Batch: 355, D Loss: 0.09993134955544747, G Loss: 16.265743255615234\n",
      "Epoch: 13, Batch: 356, D Loss: 0.09887655629023939, G Loss: 16.28437042236328\n",
      "Epoch: 13, Batch: 357, D Loss: 0.09750920204033164, G Loss: 16.32821273803711\n",
      "Epoch: 13, Batch: 358, D Loss: 0.10212473708908476, G Loss: 16.419809341430664\n",
      "Epoch: 13, Batch: 359, D Loss: 0.10179837581838669, G Loss: 16.51704216003418\n",
      "Epoch: 13, Batch: 360, D Loss: 0.10359234576748833, G Loss: 16.610179901123047\n",
      "Epoch: 13, Batch: 361, D Loss: 0.10686577804365704, G Loss: 16.692136764526367\n",
      "Epoch: 13, Batch: 362, D Loss: 0.09794370654696571, G Loss: 16.700637817382812\n",
      "Epoch: 13, Batch: 363, D Loss: 0.10039770495516187, G Loss: 16.647480010986328\n",
      "Epoch: 13, Batch: 364, D Loss: 0.09708704178535044, G Loss: 16.547212600708008\n",
      "Epoch: 13, Batch: 365, D Loss: 0.0965143487919029, G Loss: 16.444425582885742\n",
      "Epoch: 13, Batch: 366, D Loss: 0.09959470500275103, G Loss: 16.37469482421875\n",
      "Epoch: 13, Batch: 367, D Loss: 0.09828296493733646, G Loss: 16.353364944458008\n",
      "Epoch: 13, Batch: 368, D Loss: 0.10777204469524548, G Loss: 16.47280502319336\n",
      "Epoch: 13, Batch: 369, D Loss: 0.09714457019765632, G Loss: 16.558956146240234\n",
      "Epoch: 13, Batch: 370, D Loss: 0.09176337975489446, G Loss: 16.548654556274414\n",
      "Epoch: 13, Batch: 371, D Loss: 0.10059438931854459, G Loss: 16.540771484375\n",
      "Epoch: 13, Batch: 372, D Loss: 0.09632036446220837, G Loss: 16.507312774658203\n",
      "Epoch: 13, Batch: 373, D Loss: 0.10082976185661252, G Loss: 16.506929397583008\n",
      "Epoch: 13, Batch: 374, D Loss: 0.10127419571981733, G Loss: 16.547948837280273\n",
      "Epoch: 13, Batch: 375, D Loss: 0.09637371707898623, G Loss: 16.55823516845703\n",
      "Epoch: 13, Batch: 376, D Loss: 0.09753145517492001, G Loss: 16.559106826782227\n",
      "Epoch: 13, Batch: 377, D Loss: 0.10135041388592825, G Loss: 16.575328826904297\n",
      "Epoch: 13, Batch: 378, D Loss: 0.09992108622222062, G Loss: 16.6107177734375\n",
      "Epoch: 13, Batch: 379, D Loss: 0.10282202822455133, G Loss: 16.650890350341797\n",
      "Epoch: 13, Batch: 380, D Loss: 0.09956149680091286, G Loss: 16.67234992980957\n",
      "Epoch: 13, Batch: 381, D Loss: 0.0967183476026321, G Loss: 16.665668487548828\n",
      "Epoch: 13, Batch: 382, D Loss: 0.08994509321409794, G Loss: 16.5825138092041\n",
      "Epoch: 13, Batch: 383, D Loss: 0.1038628611759691, G Loss: 16.569107055664062\n",
      "Epoch: 13, Batch: 384, D Loss: 0.10147203672733696, G Loss: 16.592529296875\n",
      "Epoch: 13, Batch: 385, D Loss: 0.10156823723309572, G Loss: 16.65685272216797\n",
      "Epoch: 13, Batch: 386, D Loss: 0.10657813950765771, G Loss: 16.744712829589844\n",
      "Epoch: 13, Batch: 387, D Loss: 0.09718455029703854, G Loss: 16.771617889404297\n",
      "Epoch: 13, Batch: 388, D Loss: 0.10048500806258431, G Loss: 16.778453826904297\n",
      "Epoch: 13, Batch: 389, D Loss: 0.09452271150379765, G Loss: 16.7169189453125\n",
      "Epoch: 13, Batch: 390, D Loss: 0.10094159667186098, G Loss: 16.677764892578125\n",
      "Epoch: 13, Batch: 391, D Loss: 0.09756838456388195, G Loss: 16.64636993408203\n",
      "Epoch: 13, Batch: 392, D Loss: 0.10185706555999374, G Loss: 16.665273666381836\n",
      "Epoch: 13, Batch: 393, D Loss: 0.10494192472099861, G Loss: 16.75310707092285\n",
      "Epoch: 13, Batch: 394, D Loss: 0.09867690098215753, G Loss: 16.808181762695312\n",
      "Epoch: 13, Batch: 395, D Loss: 0.10038268044578125, G Loss: 16.846479415893555\n",
      "Epoch: 13, Batch: 396, D Loss: 0.10261861376837977, G Loss: 16.876089096069336\n",
      "Epoch: 13, Batch: 397, D Loss: 0.10321316933681679, G Loss: 16.91133689880371\n",
      "Epoch: 13, Batch: 398, D Loss: 0.09637462401603791, G Loss: 16.889514923095703\n",
      "Epoch: 13, Batch: 399, D Loss: 0.09843776521219638, G Loss: 16.833717346191406\n",
      "Epoch: 13, Batch: 400, D Loss: 0.10966610341934846, G Loss: 16.858642578125\n",
      "Epoch: 13, Batch: 401, D Loss: 0.09355111608220135, G Loss: 16.8287353515625\n",
      "Epoch: 13, Batch: 402, D Loss: 0.10061080258775235, G Loss: 16.807750701904297\n",
      "Epoch: 13, Batch: 403, D Loss: 0.09631034316102571, G Loss: 16.76685905456543\n",
      "Epoch: 13, Batch: 404, D Loss: 0.10222678998190382, G Loss: 16.77646827697754\n",
      "Epoch: 13, Batch: 405, D Loss: 0.10172037328204553, G Loss: 16.822166442871094\n",
      "Epoch: 13, Batch: 406, D Loss: 0.09518327795354509, G Loss: 16.828035354614258\n",
      "Epoch: 13, Batch: 407, D Loss: 0.10296269688575599, G Loss: 16.860797882080078\n",
      "Epoch: 13, Batch: 408, D Loss: 0.10517774527782109, G Loss: 16.974403381347656\n",
      "Epoch: 13, Batch: 409, D Loss: 0.10225697391098265, G Loss: 17.06980323791504\n",
      "Epoch: 13, Batch: 410, D Loss: 0.09752379761565244, G Loss: 17.10676383972168\n",
      "Epoch: 13, Batch: 411, D Loss: 0.09970930597240191, G Loss: 17.09372329711914\n",
      "Epoch: 13, Batch: 412, D Loss: 0.09925011977193599, G Loss: 17.0567684173584\n",
      "Epoch: 13, Batch: 413, D Loss: 0.10652730340011907, G Loss: 17.05194091796875\n",
      "Epoch: 13, Batch: 414, D Loss: 0.09760451079822907, G Loss: 17.02083969116211\n",
      "Epoch: 13, Batch: 415, D Loss: 0.10056225017313736, G Loss: 17.00783920288086\n",
      "Epoch: 13, Batch: 416, D Loss: 0.09834690981212546, G Loss: 16.985071182250977\n",
      "Epoch: 13, Batch: 417, D Loss: 0.09560184083399292, G Loss: 16.952699661254883\n",
      "Epoch: 13, Batch: 418, D Loss: 0.09927383719965377, G Loss: 16.97586441040039\n",
      "Epoch: 13, Batch: 419, D Loss: 0.10372150480759501, G Loss: 17.061513900756836\n",
      "Epoch: 13, Batch: 420, D Loss: 0.100162725921356, G Loss: 17.142047882080078\n",
      "Epoch: 13, Batch: 421, D Loss: 0.09495213930881974, G Loss: 17.14548683166504\n",
      "Epoch: 13, Batch: 422, D Loss: 0.09844310158247183, G Loss: 17.122802734375\n",
      "Epoch: 13, Batch: 423, D Loss: 0.0918384015035194, G Loss: 17.020219802856445\n",
      "Epoch: 13, Batch: 424, D Loss: 0.1003494765815649, G Loss: 17.00041961669922\n",
      "Epoch: 13, Batch: 425, D Loss: 0.09947223746138789, G Loss: 17.04631805419922\n",
      "Epoch: 13, Batch: 426, D Loss: 0.10182900371896686, G Loss: 17.13905906677246\n",
      "Epoch: 13, Batch: 427, D Loss: 0.10341372558689699, G Loss: 17.238616943359375\n",
      "Epoch: 13, Batch: 428, D Loss: 0.09552584719588886, G Loss: 17.24916648864746\n",
      "Epoch: 13, Batch: 429, D Loss: 0.10186955457875868, G Loss: 17.24765396118164\n",
      "Epoch: 13, Batch: 430, D Loss: 0.09663582002648319, G Loss: 17.21446418762207\n",
      "Epoch: 13, Batch: 431, D Loss: 0.09238110735216232, G Loss: 17.13360023498535\n",
      "Epoch: 13, Batch: 432, D Loss: 0.09970166164480254, G Loss: 17.077598571777344\n",
      "Epoch: 13, Batch: 433, D Loss: 0.09649323379784214, G Loss: 17.051151275634766\n",
      "Epoch: 13, Batch: 434, D Loss: 0.10054779515827761, G Loss: 17.065025329589844\n",
      "Epoch: 13, Batch: 435, D Loss: 0.0929625601840538, G Loss: 17.055875778198242\n",
      "Epoch: 13, Batch: 436, D Loss: 0.09279887859382363, G Loss: 17.043344497680664\n",
      "Epoch: 13, Batch: 437, D Loss: 0.10973006880868574, G Loss: 17.139270782470703\n",
      "Epoch: 13, Batch: 438, D Loss: 0.09759493406799713, G Loss: 17.220844268798828\n",
      "Epoch: 13, Batch: 439, D Loss: 0.09623769063371057, G Loss: 17.258094787597656\n",
      "Epoch: 13, Batch: 440, D Loss: 0.09804329380484589, G Loss: 17.26410675048828\n",
      "Epoch: 13, Batch: 441, D Loss: 0.10058669098114414, G Loss: 17.267284393310547\n",
      "Epoch: 13, Batch: 442, D Loss: 0.09760511771221836, G Loss: 17.255451202392578\n",
      "Epoch: 13, Batch: 443, D Loss: 0.09478120659933964, G Loss: 17.207813262939453\n",
      "Epoch: 13, Batch: 444, D Loss: 0.09955106890620513, G Loss: 17.182016372680664\n",
      "Epoch: 13, Batch: 445, D Loss: 0.09906544775881798, G Loss: 17.178197860717773\n",
      "Epoch: 13, Batch: 446, D Loss: 0.09726642303653499, G Loss: 17.190488815307617\n",
      "Epoch: 13, Batch: 447, D Loss: 0.10110556519519598, G Loss: 17.23088264465332\n",
      "Epoch: 13, Batch: 448, D Loss: 0.09852375957658843, G Loss: 17.257661819458008\n",
      "Epoch: 13, Batch: 449, D Loss: 0.1000992293994436, G Loss: 17.262117385864258\n",
      "Epoch: 13, Batch: 450, D Loss: 0.09695533013644209, G Loss: 17.275543212890625\n",
      "Epoch: 13, Batch: 451, D Loss: 0.10398360404835749, G Loss: 17.299644470214844\n",
      "Epoch: 13, Batch: 452, D Loss: 0.09874121879752806, G Loss: 17.305564880371094\n",
      "Epoch: 13, Batch: 453, D Loss: 0.1032203215460541, G Loss: 17.311206817626953\n",
      "Epoch: 13, Batch: 454, D Loss: 0.09462916156867784, G Loss: 17.280921936035156\n",
      "Epoch: 13, Batch: 455, D Loss: 0.09471546236246375, G Loss: 17.221078872680664\n",
      "Epoch: 13, Batch: 456, D Loss: 0.09842716363534443, G Loss: 17.179664611816406\n",
      "Epoch: 13, Batch: 457, D Loss: 0.10237001103106813, G Loss: 17.201318740844727\n",
      "Epoch: 13, Batch: 458, D Loss: 0.10011214179482586, G Loss: 17.24819564819336\n",
      "Epoch: 13, Batch: 459, D Loss: 0.09365537878355568, G Loss: 17.259685516357422\n",
      "Epoch: 13, Batch: 460, D Loss: 0.10093524392961761, G Loss: 17.284826278686523\n",
      "Epoch: 13, Batch: 461, D Loss: 0.09405356724182568, G Loss: 17.271026611328125\n",
      "Epoch: 13, Batch: 462, D Loss: 0.09758053811276568, G Loss: 17.26827049255371\n",
      "Epoch: 13, Batch: 463, D Loss: 0.10183148914249252, G Loss: 17.280574798583984\n",
      "Epoch: 13, Batch: 464, D Loss: 0.10111615861947243, G Loss: 17.3035831451416\n",
      "Epoch: 13, Batch: 465, D Loss: 0.10263904933757395, G Loss: 17.345928192138672\n",
      "Epoch: 13, Batch: 466, D Loss: 0.10184487647292872, G Loss: 17.382633209228516\n",
      "Epoch: 13, Batch: 467, D Loss: 0.09602057869324909, G Loss: 17.364639282226562\n",
      "Epoch: 14, Batch: 0, D Loss: 0.10175515665039292, G Loss: 17.356786727905273\n",
      "Epoch: 14, Batch: 1, D Loss: 0.10134445094455025, G Loss: 17.35088539123535\n",
      "Epoch: 14, Batch: 2, D Loss: 0.0996841860682327, G Loss: 17.33641242980957\n",
      "Epoch: 14, Batch: 3, D Loss: 0.10442352270557542, G Loss: 17.353591918945312\n",
      "Epoch: 14, Batch: 4, D Loss: 0.09841463683442697, G Loss: 17.347259521484375\n",
      "Epoch: 14, Batch: 5, D Loss: 0.10138320902678366, G Loss: 17.33835792541504\n",
      "Epoch: 14, Batch: 6, D Loss: 0.09900571411097125, G Loss: 17.31378936767578\n",
      "Epoch: 14, Batch: 7, D Loss: 0.09399138460939582, G Loss: 17.25516700744629\n",
      "Epoch: 14, Batch: 8, D Loss: 0.10166832922201685, G Loss: 17.251317977905273\n",
      "Epoch: 14, Batch: 9, D Loss: 0.09226340205736783, G Loss: 17.21637535095215\n",
      "Epoch: 14, Batch: 10, D Loss: 0.09828964053317613, G Loss: 17.216638565063477\n",
      "Epoch: 14, Batch: 11, D Loss: 0.09509144890015087, G Loss: 17.228931427001953\n",
      "Epoch: 14, Batch: 12, D Loss: 0.09533853970322603, G Loss: 17.2469425201416\n",
      "Epoch: 14, Batch: 13, D Loss: 0.10242196987910823, G Loss: 17.31475830078125\n",
      "Epoch: 14, Batch: 14, D Loss: 0.10300699572820804, G Loss: 17.40385627746582\n",
      "Epoch: 14, Batch: 15, D Loss: 0.10105333325701693, G Loss: 17.464879989624023\n",
      "Epoch: 14, Batch: 16, D Loss: 0.09693725210205795, G Loss: 17.475828170776367\n",
      "Epoch: 14, Batch: 17, D Loss: 0.10271701760204177, G Loss: 17.472862243652344\n",
      "Epoch: 14, Batch: 18, D Loss: 0.09190628525281319, G Loss: 17.4036865234375\n",
      "Epoch: 14, Batch: 19, D Loss: 0.1039344287694286, G Loss: 17.36865234375\n",
      "Epoch: 14, Batch: 20, D Loss: 0.10238365775851577, G Loss: 17.3623046875\n",
      "Epoch: 14, Batch: 21, D Loss: 0.09834300682671504, G Loss: 17.3559513092041\n",
      "Epoch: 14, Batch: 22, D Loss: 0.09954713982878172, G Loss: 17.365798950195312\n",
      "Epoch: 14, Batch: 23, D Loss: 0.0986860686088713, G Loss: 17.379405975341797\n",
      "Epoch: 14, Batch: 24, D Loss: 0.09479805016657128, G Loss: 17.368911743164062\n",
      "Epoch: 14, Batch: 25, D Loss: 0.10000669888308167, G Loss: 17.38165855407715\n",
      "Epoch: 14, Batch: 26, D Loss: 0.09788253823953852, G Loss: 17.385658264160156\n",
      "Epoch: 14, Batch: 27, D Loss: 0.10475061716689371, G Loss: 17.43321990966797\n",
      "Epoch: 14, Batch: 28, D Loss: 0.1004277450064599, G Loss: 17.474632263183594\n",
      "Epoch: 14, Batch: 29, D Loss: 0.09786461087856768, G Loss: 17.48026466369629\n",
      "Epoch: 14, Batch: 30, D Loss: 0.09823216303646909, G Loss: 17.458112716674805\n",
      "Epoch: 14, Batch: 31, D Loss: 0.09730325480617186, G Loss: 17.42653465270996\n",
      "Epoch: 14, Batch: 32, D Loss: 0.10100022567710809, G Loss: 17.422578811645508\n",
      "Epoch: 14, Batch: 33, D Loss: 0.10406830743694062, G Loss: 17.464832305908203\n",
      "Epoch: 14, Batch: 34, D Loss: 0.09713753856607887, G Loss: 17.482322692871094\n",
      "Epoch: 14, Batch: 35, D Loss: 0.09567645732829533, G Loss: 17.47119140625\n",
      "Epoch: 14, Batch: 36, D Loss: 0.10231978993628399, G Loss: 17.471363067626953\n",
      "Epoch: 14, Batch: 37, D Loss: 0.09644117019522724, G Loss: 17.45529556274414\n",
      "Epoch: 14, Batch: 38, D Loss: 0.10103532488236944, G Loss: 17.465232849121094\n",
      "Epoch: 14, Batch: 39, D Loss: 0.09412160341474074, G Loss: 17.44259262084961\n",
      "Epoch: 14, Batch: 40, D Loss: 0.09952934676572589, G Loss: 17.435110092163086\n",
      "Epoch: 14, Batch: 41, D Loss: 0.09930103856208916, G Loss: 17.450780868530273\n",
      "Epoch: 14, Batch: 42, D Loss: 0.09968527213862455, G Loss: 17.482213973999023\n",
      "Epoch: 14, Batch: 43, D Loss: 0.0940777638109358, G Loss: 17.48418426513672\n",
      "Epoch: 14, Batch: 44, D Loss: 0.10582257555651431, G Loss: 17.540306091308594\n",
      "Epoch: 14, Batch: 45, D Loss: 0.09704183488918794, G Loss: 17.562881469726562\n",
      "Epoch: 14, Batch: 46, D Loss: 0.10138518036374489, G Loss: 17.58879280090332\n",
      "Epoch: 14, Batch: 47, D Loss: 0.09326012114690485, G Loss: 17.550771713256836\n",
      "Epoch: 14, Batch: 48, D Loss: 0.09611336620236433, G Loss: 17.503583908081055\n",
      "Epoch: 14, Batch: 49, D Loss: 0.09907679780772938, G Loss: 17.48138999938965\n",
      "Epoch: 14, Batch: 50, D Loss: 0.10400818052268956, G Loss: 17.519365310668945\n",
      "Epoch: 14, Batch: 51, D Loss: 0.10261015288606945, G Loss: 17.59280776977539\n",
      "Epoch: 14, Batch: 52, D Loss: 0.10411451362773594, G Loss: 17.674510955810547\n",
      "Epoch: 14, Batch: 53, D Loss: 0.09820471241562334, G Loss: 17.723623275756836\n",
      "Epoch: 14, Batch: 54, D Loss: 0.10046419748831958, G Loss: 17.745559692382812\n",
      "Epoch: 14, Batch: 55, D Loss: 0.09745305278225036, G Loss: 17.72734260559082\n",
      "Epoch: 14, Batch: 56, D Loss: 0.10212971538082893, G Loss: 17.70341682434082\n",
      "Epoch: 14, Batch: 57, D Loss: 0.09843229058936309, G Loss: 17.662961959838867\n",
      "Epoch: 14, Batch: 58, D Loss: 0.10325894089700682, G Loss: 17.648664474487305\n",
      "Epoch: 14, Batch: 59, D Loss: 0.10721910313840421, G Loss: 17.689821243286133\n",
      "Epoch: 14, Batch: 60, D Loss: 0.09697173073936849, G Loss: 17.708995819091797\n",
      "Epoch: 14, Batch: 61, D Loss: 0.09557310765598626, G Loss: 17.70916175842285\n",
      "Epoch: 14, Batch: 62, D Loss: 0.09535359131054477, G Loss: 17.688373565673828\n",
      "Epoch: 14, Batch: 63, D Loss: 0.10689302811196555, G Loss: 17.721054077148438\n",
      "Epoch: 14, Batch: 64, D Loss: 0.09799044834862247, G Loss: 17.732561111450195\n",
      "Epoch: 14, Batch: 65, D Loss: 0.09226466237824305, G Loss: 17.69955825805664\n",
      "Epoch: 14, Batch: 66, D Loss: 0.10088700346918333, G Loss: 17.68617057800293\n",
      "Epoch: 14, Batch: 67, D Loss: 0.10112162973202476, G Loss: 17.692899703979492\n",
      "Epoch: 14, Batch: 68, D Loss: 0.10305405681277868, G Loss: 17.72475814819336\n",
      "Epoch: 14, Batch: 69, D Loss: 0.09589690971532328, G Loss: 17.72758674621582\n",
      "Epoch: 14, Batch: 70, D Loss: 0.10205128291262167, G Loss: 17.74232292175293\n",
      "Epoch: 14, Batch: 71, D Loss: 0.1005734302886836, G Loss: 17.759994506835938\n",
      "Epoch: 14, Batch: 72, D Loss: 0.09673729765304628, G Loss: 17.753772735595703\n",
      "Epoch: 14, Batch: 73, D Loss: 0.09454525510921563, G Loss: 17.715871810913086\n",
      "Epoch: 14, Batch: 74, D Loss: 0.09396446046975804, G Loss: 17.662137985229492\n",
      "Epoch: 14, Batch: 75, D Loss: 0.09222482504537233, G Loss: 17.597049713134766\n",
      "Epoch: 14, Batch: 76, D Loss: 0.10346946506277632, G Loss: 17.61150360107422\n",
      "Epoch: 14, Batch: 77, D Loss: 0.10283554679671614, G Loss: 17.686630249023438\n",
      "Epoch: 14, Batch: 78, D Loss: 0.10076178120216639, G Loss: 17.76396369934082\n",
      "Epoch: 14, Batch: 79, D Loss: 0.0983340536035815, G Loss: 17.81522560119629\n",
      "Epoch: 14, Batch: 80, D Loss: 0.09043171433637376, G Loss: 17.803451538085938\n",
      "Epoch: 14, Batch: 81, D Loss: 0.10132780110922024, G Loss: 17.797693252563477\n",
      "Epoch: 14, Batch: 82, D Loss: 0.10678333964078579, G Loss: 17.82308578491211\n",
      "Epoch: 14, Batch: 83, D Loss: 0.10547391472886236, G Loss: 17.85734748840332\n",
      "Epoch: 14, Batch: 84, D Loss: 0.09784720228915411, G Loss: 17.851869583129883\n",
      "Epoch: 14, Batch: 85, D Loss: 0.09732576608972465, G Loss: 17.82803726196289\n",
      "Epoch: 14, Batch: 86, D Loss: 0.09749489452325744, G Loss: 17.79619026184082\n",
      "Epoch: 14, Batch: 87, D Loss: 0.09822789785816699, G Loss: 17.761009216308594\n",
      "Epoch: 14, Batch: 88, D Loss: 0.09488588067878201, G Loss: 17.72364044189453\n",
      "Epoch: 14, Batch: 89, D Loss: 0.09958783798041093, G Loss: 17.720272064208984\n",
      "Epoch: 14, Batch: 90, D Loss: 0.098155866092136, G Loss: 17.742202758789062\n",
      "Epoch: 14, Batch: 91, D Loss: 0.1033409482194072, G Loss: 17.80538558959961\n",
      "Epoch: 14, Batch: 92, D Loss: 0.09696885358943774, G Loss: 17.846038818359375\n",
      "Epoch: 14, Batch: 93, D Loss: 0.09483789791357466, G Loss: 17.85593032836914\n",
      "Epoch: 14, Batch: 94, D Loss: 0.09999844561892512, G Loss: 17.8659610748291\n",
      "Epoch: 14, Batch: 95, D Loss: 0.0990519983265461, G Loss: 17.86543846130371\n",
      "Epoch: 14, Batch: 96, D Loss: 0.09543067357023016, G Loss: 17.83528709411621\n",
      "Epoch: 14, Batch: 97, D Loss: 0.09824200882427103, G Loss: 17.81450843811035\n",
      "Epoch: 14, Batch: 98, D Loss: 0.09964780682468177, G Loss: 17.812149047851562\n",
      "Epoch: 14, Batch: 99, D Loss: 0.09655828948131706, G Loss: 17.81188201904297\n",
      "Epoch: 14, Batch: 100, D Loss: 0.10053053660231459, G Loss: 17.837474822998047\n",
      "Epoch: 14, Batch: 101, D Loss: 0.09607833021639411, G Loss: 17.8549861907959\n",
      "Epoch: 14, Batch: 102, D Loss: 0.09298058740015147, G Loss: 17.84355926513672\n",
      "Epoch: 14, Batch: 103, D Loss: 0.1026397435607942, G Loss: 17.863014221191406\n",
      "Epoch: 14, Batch: 104, D Loss: 0.09899591800140595, G Loss: 17.82626724243164\n",
      "Epoch: 14, Batch: 105, D Loss: 0.09749563961830265, G Loss: 17.79050064086914\n",
      "Epoch: 14, Batch: 106, D Loss: 0.09718059961735115, G Loss: 17.75209617614746\n",
      "Epoch: 14, Batch: 107, D Loss: 0.10493409149855815, G Loss: 17.694271087646484\n",
      "Epoch: 14, Batch: 108, D Loss: 0.09441370108318292, G Loss: 17.60906219482422\n",
      "Epoch: 14, Batch: 109, D Loss: 0.10336006099951245, G Loss: 17.557132720947266\n",
      "Epoch: 14, Batch: 110, D Loss: 0.09681775154953431, G Loss: 17.496967315673828\n",
      "Epoch: 14, Batch: 111, D Loss: 0.10024679995608654, G Loss: 17.453964233398438\n",
      "Epoch: 14, Batch: 112, D Loss: 0.10192650399753234, G Loss: 17.427770614624023\n",
      "Epoch: 14, Batch: 113, D Loss: 0.09622669114726268, G Loss: 17.379066467285156\n",
      "Epoch: 14, Batch: 114, D Loss: 0.09529464663844145, G Loss: 17.319717407226562\n",
      "Epoch: 14, Batch: 115, D Loss: 0.10139059310309051, G Loss: 17.293352127075195\n",
      "Epoch: 14, Batch: 116, D Loss: 0.09779754347336755, G Loss: 17.278390884399414\n",
      "Epoch: 14, Batch: 117, D Loss: 0.10061276022584842, G Loss: 17.295175552368164\n",
      "Epoch: 14, Batch: 118, D Loss: 0.09945599023996898, G Loss: 17.31620979309082\n",
      "Epoch: 14, Batch: 119, D Loss: 0.09296390454221992, G Loss: 17.290180206298828\n",
      "Epoch: 14, Batch: 120, D Loss: 0.09471963441212594, G Loss: 17.246179580688477\n",
      "Epoch: 14, Batch: 121, D Loss: 0.10278331604393998, G Loss: 17.26110076904297\n",
      "Epoch: 14, Batch: 122, D Loss: 0.10147263178814292, G Loss: 17.303802490234375\n",
      "Epoch: 14, Batch: 123, D Loss: 0.09585629438493903, G Loss: 17.30766487121582\n",
      "Epoch: 14, Batch: 124, D Loss: 0.10229602476521116, G Loss: 17.32225799560547\n",
      "Epoch: 14, Batch: 125, D Loss: 0.10308259715635693, G Loss: 17.34764289855957\n",
      "Epoch: 14, Batch: 126, D Loss: 0.10239724766609104, G Loss: 17.374605178833008\n",
      "Epoch: 14, Batch: 127, D Loss: 0.09781462649124961, G Loss: 17.352745056152344\n",
      "Epoch: 14, Batch: 128, D Loss: 0.10239613037572237, G Loss: 17.331392288208008\n",
      "Epoch: 14, Batch: 129, D Loss: 0.10161155471704397, G Loss: 17.314775466918945\n",
      "Epoch: 14, Batch: 130, D Loss: 0.10532660046672859, G Loss: 17.3298282623291\n",
      "Epoch: 14, Batch: 131, D Loss: 0.09649956244738611, G Loss: 17.304853439331055\n",
      "Epoch: 14, Batch: 132, D Loss: 0.09895463351939782, G Loss: 17.27060890197754\n",
      "Epoch: 14, Batch: 133, D Loss: 0.09374722990009587, G Loss: 17.19709587097168\n",
      "Epoch: 14, Batch: 134, D Loss: 0.09876288712891679, G Loss: 17.164819717407227\n",
      "Epoch: 14, Batch: 135, D Loss: 0.10515851747581273, G Loss: 17.214778900146484\n",
      "Epoch: 14, Batch: 136, D Loss: 0.10249032188790963, G Loss: 17.297420501708984\n",
      "Epoch: 14, Batch: 137, D Loss: 0.09649951026538162, G Loss: 17.337406158447266\n",
      "Epoch: 14, Batch: 138, D Loss: 0.09622891244735765, G Loss: 17.324596405029297\n",
      "Epoch: 14, Batch: 139, D Loss: 0.09828296330824315, G Loss: 17.298690795898438\n",
      "Epoch: 14, Batch: 140, D Loss: 0.09886600149098435, G Loss: 17.26662254333496\n",
      "Epoch: 14, Batch: 141, D Loss: 0.10233188516598268, G Loss: 17.266468048095703\n",
      "Epoch: 14, Batch: 142, D Loss: 0.0980670164170121, G Loss: 17.260969161987305\n",
      "Epoch: 14, Batch: 143, D Loss: 0.10358753869257775, G Loss: 17.304323196411133\n",
      "Epoch: 14, Batch: 144, D Loss: 0.09976635880031104, G Loss: 17.342620849609375\n",
      "Epoch: 14, Batch: 145, D Loss: 0.10059604754660789, G Loss: 17.367271423339844\n",
      "Epoch: 14, Batch: 146, D Loss: 0.1033440672316912, G Loss: 17.385860443115234\n",
      "Epoch: 14, Batch: 147, D Loss: 0.09799738907100419, G Loss: 17.364124298095703\n",
      "Epoch: 14, Batch: 148, D Loss: 0.09839453537239162, G Loss: 17.310951232910156\n",
      "Epoch: 14, Batch: 149, D Loss: 0.10120382955503615, G Loss: 17.281757354736328\n",
      "Epoch: 14, Batch: 150, D Loss: 0.10135814620367256, G Loss: 17.280887603759766\n",
      "Epoch: 14, Batch: 151, D Loss: 0.1002344494630858, G Loss: 17.30307960510254\n",
      "Epoch: 14, Batch: 152, D Loss: 0.10524498656794457, G Loss: 17.370729446411133\n",
      "Epoch: 14, Batch: 153, D Loss: 0.09692744095688877, G Loss: 17.38278579711914\n",
      "Epoch: 14, Batch: 154, D Loss: 0.10494059971820668, G Loss: 17.40907859802246\n",
      "Epoch: 14, Batch: 155, D Loss: 0.10329952715932578, G Loss: 17.416481018066406\n",
      "Epoch: 14, Batch: 156, D Loss: 0.103281884170082, G Loss: 17.411813735961914\n",
      "Epoch: 14, Batch: 157, D Loss: 0.10201400414943862, G Loss: 17.391075134277344\n",
      "Epoch: 14, Batch: 158, D Loss: 0.09729793623114968, G Loss: 17.330642700195312\n",
      "Epoch: 14, Batch: 159, D Loss: 0.10110069836796676, G Loss: 17.295330047607422\n",
      "Epoch: 14, Batch: 160, D Loss: 0.09153246989769315, G Loss: 17.223583221435547\n",
      "Epoch: 14, Batch: 161, D Loss: 0.09880421490517932, G Loss: 17.207500457763672\n",
      "Epoch: 14, Batch: 162, D Loss: 0.09623323563852892, G Loss: 17.21847152709961\n",
      "Epoch: 14, Batch: 163, D Loss: 0.10388217955077828, G Loss: 17.317853927612305\n",
      "Epoch: 14, Batch: 164, D Loss: 0.09596626421536669, G Loss: 17.388986587524414\n",
      "Epoch: 14, Batch: 165, D Loss: 0.09479774431990684, G Loss: 17.4106502532959\n",
      "Epoch: 14, Batch: 166, D Loss: 0.09961305432320433, G Loss: 17.423818588256836\n",
      "Epoch: 14, Batch: 167, D Loss: 0.09922321005762935, G Loss: 17.424060821533203\n",
      "Epoch: 14, Batch: 168, D Loss: 0.10284152480642472, G Loss: 17.439767837524414\n",
      "Epoch: 14, Batch: 169, D Loss: 0.09716118708478039, G Loss: 17.450443267822266\n",
      "Epoch: 14, Batch: 170, D Loss: 0.0973843021583134, G Loss: 17.442747116088867\n",
      "Epoch: 14, Batch: 171, D Loss: 0.10020078555865464, G Loss: 17.44645118713379\n",
      "Epoch: 14, Batch: 172, D Loss: 0.10278720967910981, G Loss: 17.47622299194336\n",
      "Epoch: 14, Batch: 173, D Loss: 0.09906183704469296, G Loss: 17.5054988861084\n",
      "Epoch: 14, Batch: 174, D Loss: 0.10342645371672177, G Loss: 17.55503273010254\n",
      "Epoch: 14, Batch: 175, D Loss: 0.1087638551648098, G Loss: 17.63543128967285\n",
      "Epoch: 14, Batch: 176, D Loss: 0.10203495203999591, G Loss: 17.67780303955078\n",
      "Epoch: 14, Batch: 177, D Loss: 0.09912582056045238, G Loss: 17.66324806213379\n",
      "Epoch: 14, Batch: 178, D Loss: 0.10125251459318996, G Loss: 17.62190818786621\n",
      "Epoch: 14, Batch: 179, D Loss: 0.09548019291660914, G Loss: 17.533845901489258\n",
      "Epoch: 14, Batch: 180, D Loss: 0.10038523144634759, G Loss: 17.464622497558594\n",
      "Epoch: 14, Batch: 181, D Loss: 0.09892182631281443, G Loss: 17.43110466003418\n",
      "Epoch: 14, Batch: 182, D Loss: 0.0987609162935108, G Loss: 17.437135696411133\n",
      "Epoch: 14, Batch: 183, D Loss: 0.08892507717022902, G Loss: 17.41083526611328\n",
      "Epoch: 14, Batch: 184, D Loss: 0.0983667806918298, G Loss: 17.439489364624023\n",
      "Epoch: 14, Batch: 185, D Loss: 0.0943589714279156, G Loss: 17.470664978027344\n",
      "Epoch: 14, Batch: 186, D Loss: 0.10401499016079185, G Loss: 17.557710647583008\n",
      "Epoch: 14, Batch: 187, D Loss: 0.09919399414967867, G Loss: 17.636219024658203\n",
      "Epoch: 14, Batch: 188, D Loss: 0.10025101473704012, G Loss: 17.69235610961914\n",
      "Epoch: 14, Batch: 189, D Loss: 0.09818484917963755, G Loss: 17.705528259277344\n",
      "Epoch: 14, Batch: 190, D Loss: 0.09737731062293609, G Loss: 17.680484771728516\n",
      "Epoch: 14, Batch: 191, D Loss: 0.10593711144426088, G Loss: 17.67807960510254\n",
      "Epoch: 14, Batch: 192, D Loss: 0.09934398845696712, G Loss: 17.663806915283203\n",
      "Epoch: 14, Batch: 193, D Loss: 0.0977002639335458, G Loss: 17.638219833374023\n",
      "Epoch: 14, Batch: 194, D Loss: 0.10340343013841125, G Loss: 17.64766502380371\n",
      "Epoch: 14, Batch: 195, D Loss: 0.10362208205401835, G Loss: 17.687332153320312\n",
      "Epoch: 14, Batch: 196, D Loss: 0.10126170788423927, G Loss: 17.730974197387695\n",
      "Epoch: 14, Batch: 197, D Loss: 0.09471377242237367, G Loss: 17.72103500366211\n",
      "Epoch: 14, Batch: 198, D Loss: 0.10374948643777859, G Loss: 17.721538543701172\n",
      "Epoch: 14, Batch: 199, D Loss: 0.09860202196130352, G Loss: 17.702821731567383\n",
      "Epoch: 14, Batch: 200, D Loss: 0.10755811151151828, G Loss: 17.731937408447266\n",
      "Epoch: 14, Batch: 201, D Loss: 0.09803287188576437, G Loss: 17.735830307006836\n",
      "Epoch: 14, Batch: 202, D Loss: 0.0994731436343077, G Loss: 17.729759216308594\n",
      "Epoch: 14, Batch: 203, D Loss: 0.10192584491730639, G Loss: 17.744258880615234\n",
      "Epoch: 14, Batch: 204, D Loss: 0.0986640105642822, G Loss: 17.725391387939453\n",
      "Epoch: 14, Batch: 205, D Loss: 0.09566462317257596, G Loss: 17.687610626220703\n",
      "Epoch: 14, Batch: 206, D Loss: 0.09838297530597728, G Loss: 17.657400131225586\n",
      "Epoch: 14, Batch: 207, D Loss: 0.10129928168980662, G Loss: 17.662168502807617\n",
      "Epoch: 14, Batch: 208, D Loss: 0.1006599769969263, G Loss: 17.689010620117188\n",
      "Epoch: 14, Batch: 209, D Loss: 0.09791051882980462, G Loss: 17.70351219177246\n",
      "Epoch: 14, Batch: 210, D Loss: 0.09961008552647943, G Loss: 17.717214584350586\n",
      "Epoch: 14, Batch: 211, D Loss: 0.09973537434392732, G Loss: 17.732236862182617\n",
      "Epoch: 14, Batch: 212, D Loss: 0.10061566031146274, G Loss: 17.74352264404297\n",
      "Epoch: 14, Batch: 213, D Loss: 0.0977681229102183, G Loss: 17.733959197998047\n",
      "Epoch: 14, Batch: 214, D Loss: 0.10428586100058368, G Loss: 17.74515724182129\n",
      "Epoch: 14, Batch: 215, D Loss: 0.09814461558994392, G Loss: 17.743867874145508\n",
      "Epoch: 14, Batch: 216, D Loss: 0.09929178153222917, G Loss: 17.73581886291504\n",
      "Epoch: 14, Batch: 217, D Loss: 0.09903741131897625, G Loss: 17.731761932373047\n",
      "Epoch: 14, Batch: 218, D Loss: 0.10133736079156996, G Loss: 17.745784759521484\n",
      "Epoch: 14, Batch: 219, D Loss: 0.10066677853383865, G Loss: 17.77227210998535\n",
      "Epoch: 14, Batch: 220, D Loss: 0.10090076374970991, G Loss: 17.801654815673828\n",
      "Epoch: 14, Batch: 221, D Loss: 0.10300219972017466, G Loss: 17.8339900970459\n",
      "Epoch: 14, Batch: 222, D Loss: 0.10180147882453383, G Loss: 17.852947235107422\n",
      "Epoch: 14, Batch: 223, D Loss: 0.10221307859358575, G Loss: 17.858591079711914\n",
      "Epoch: 14, Batch: 224, D Loss: 0.09983218602624522, G Loss: 17.8389949798584\n",
      "Epoch: 14, Batch: 225, D Loss: 0.09759403935615296, G Loss: 17.79515266418457\n",
      "Epoch: 14, Batch: 226, D Loss: 0.10494364216830743, G Loss: 17.848630905151367\n",
      "Epoch: 14, Batch: 227, D Loss: 0.10184584676731046, G Loss: 17.897127151489258\n",
      "Epoch: 14, Batch: 228, D Loss: 0.09479089920346695, G Loss: 17.90870475769043\n",
      "Epoch: 14, Batch: 229, D Loss: 0.10387542171983277, G Loss: 17.945823669433594\n",
      "Epoch: 14, Batch: 230, D Loss: 0.09862384990612405, G Loss: 17.978010177612305\n",
      "Epoch: 14, Batch: 231, D Loss: 0.09498111934844822, G Loss: 17.98369026184082\n",
      "Epoch: 14, Batch: 232, D Loss: 0.09858562077551092, G Loss: 17.993026733398438\n",
      "Epoch: 14, Batch: 233, D Loss: 0.09576449563941836, G Loss: 17.996028900146484\n",
      "Epoch: 14, Batch: 234, D Loss: 0.0955292808048922, G Loss: 17.994556427001953\n",
      "Epoch: 14, Batch: 235, D Loss: 0.09874292476365643, G Loss: 18.013057708740234\n",
      "Epoch: 14, Batch: 236, D Loss: 0.10197687880201922, G Loss: 18.065540313720703\n",
      "Epoch: 14, Batch: 237, D Loss: 0.09817951124001034, G Loss: 18.110740661621094\n",
      "Epoch: 14, Batch: 238, D Loss: 0.09265935359524091, G Loss: 18.10565185546875\n",
      "Epoch: 14, Batch: 239, D Loss: 0.09392075193882388, G Loss: 18.06949806213379\n",
      "Epoch: 14, Batch: 240, D Loss: 0.10267858172938249, G Loss: 18.068723678588867\n",
      "Epoch: 14, Batch: 241, D Loss: 0.09765034133952977, G Loss: 18.071365356445312\n",
      "Epoch: 14, Batch: 242, D Loss: 0.10144048883461876, G Loss: 18.097917556762695\n",
      "Epoch: 14, Batch: 243, D Loss: 0.0982136645684899, G Loss: 18.118343353271484\n",
      "Epoch: 14, Batch: 244, D Loss: 0.09666575422786217, G Loss: 18.1189022064209\n",
      "Epoch: 14, Batch: 245, D Loss: 0.10017724265202022, G Loss: 18.12217140197754\n",
      "Epoch: 14, Batch: 246, D Loss: 0.1054482750002359, G Loss: 18.148784637451172\n",
      "Epoch: 14, Batch: 247, D Loss: 0.09420125107243216, G Loss: 18.121234893798828\n",
      "Epoch: 14, Batch: 248, D Loss: 0.10329586202032459, G Loss: 18.107290267944336\n",
      "Epoch: 14, Batch: 249, D Loss: 0.0980733404394174, G Loss: 18.08064079284668\n",
      "Epoch: 14, Batch: 250, D Loss: 0.09452293785583654, G Loss: 18.040794372558594\n",
      "Epoch: 14, Batch: 251, D Loss: 0.10526713706994029, G Loss: 18.06170654296875\n",
      "Epoch: 14, Batch: 252, D Loss: 0.10515703953112299, G Loss: 18.12548828125\n",
      "Epoch: 14, Batch: 253, D Loss: 0.10239453521791209, G Loss: 18.178714752197266\n",
      "Epoch: 14, Batch: 254, D Loss: 0.09695523111381288, G Loss: 18.21710205078125\n",
      "Epoch: 14, Batch: 255, D Loss: 0.10120756044032442, G Loss: 18.2263240814209\n",
      "Epoch: 14, Batch: 256, D Loss: 0.10006938734378412, G Loss: 18.234622955322266\n",
      "Epoch: 14, Batch: 257, D Loss: 0.09882276363925246, G Loss: 18.229949951171875\n",
      "Epoch: 14, Batch: 258, D Loss: 0.10112961237518059, G Loss: 18.243396759033203\n",
      "Epoch: 14, Batch: 259, D Loss: 0.09911221855827312, G Loss: 18.26594352722168\n",
      "Epoch: 14, Batch: 260, D Loss: 0.10136946116617107, G Loss: 18.308032989501953\n",
      "Epoch: 14, Batch: 261, D Loss: 0.09041957373015563, G Loss: 18.304031372070312\n",
      "Epoch: 14, Batch: 262, D Loss: 0.0979338940737331, G Loss: 18.297603607177734\n",
      "Epoch: 14, Batch: 263, D Loss: 0.09538046837519154, G Loss: 18.293073654174805\n",
      "Epoch: 14, Batch: 264, D Loss: 0.10565642065416325, G Loss: 18.378433227539062\n",
      "Epoch: 14, Batch: 265, D Loss: 0.10604307542328151, G Loss: 18.5085391998291\n",
      "Epoch: 14, Batch: 266, D Loss: 0.09768784482095283, G Loss: 18.60200309753418\n",
      "Epoch: 14, Batch: 267, D Loss: 0.10154097185317346, G Loss: 18.666851043701172\n",
      "Epoch: 14, Batch: 268, D Loss: 0.09625269868995501, G Loss: 18.640399932861328\n",
      "Epoch: 14, Batch: 269, D Loss: 0.09762560992261093, G Loss: 18.571895599365234\n",
      "Epoch: 14, Batch: 270, D Loss: 0.10105934439701336, G Loss: 18.50316619873047\n",
      "Epoch: 14, Batch: 271, D Loss: 0.09061071025716316, G Loss: 18.368528366088867\n",
      "Epoch: 14, Batch: 272, D Loss: 0.09809956507664452, G Loss: 18.27599334716797\n",
      "Epoch: 14, Batch: 273, D Loss: 0.10240057692543658, G Loss: 18.26329803466797\n",
      "Epoch: 14, Batch: 274, D Loss: 0.09648774403360383, G Loss: 18.266809463500977\n",
      "Epoch: 14, Batch: 275, D Loss: 0.10284754459805479, G Loss: 18.30665397644043\n",
      "Epoch: 14, Batch: 276, D Loss: 0.10058414737267851, G Loss: 18.355003356933594\n",
      "Epoch: 14, Batch: 277, D Loss: 0.09716503853807446, G Loss: 18.363216400146484\n",
      "Epoch: 14, Batch: 278, D Loss: 0.10246511334948627, G Loss: 18.35743522644043\n",
      "Epoch: 14, Batch: 279, D Loss: 0.09738910000478684, G Loss: 18.305866241455078\n",
      "Epoch: 14, Batch: 280, D Loss: 0.0964618830661017, G Loss: 18.22899627685547\n",
      "Epoch: 14, Batch: 281, D Loss: 0.10722270476894957, G Loss: 18.203163146972656\n",
      "Epoch: 14, Batch: 282, D Loss: 0.10268521932012797, G Loss: 18.198488235473633\n",
      "Epoch: 14, Batch: 283, D Loss: 0.10191393513951263, G Loss: 18.226282119750977\n",
      "Epoch: 14, Batch: 284, D Loss: 0.09415512399173087, G Loss: 18.211027145385742\n",
      "Epoch: 14, Batch: 285, D Loss: 0.09983928378469642, G Loss: 18.194955825805664\n",
      "Epoch: 14, Batch: 286, D Loss: 0.09952560702828972, G Loss: 18.167940139770508\n",
      "Epoch: 14, Batch: 287, D Loss: 0.09911234577294348, G Loss: 18.163082122802734\n",
      "Epoch: 14, Batch: 288, D Loss: 0.10068979755754537, G Loss: 18.17936134338379\n",
      "Epoch: 14, Batch: 289, D Loss: 0.10787378869726538, G Loss: 18.234649658203125\n",
      "Epoch: 14, Batch: 290, D Loss: 0.10108240538503876, G Loss: 18.27448272705078\n",
      "Epoch: 14, Batch: 291, D Loss: 0.09570594712656177, G Loss: 18.268165588378906\n",
      "Epoch: 14, Batch: 292, D Loss: 0.10485615422354844, G Loss: 18.256147384643555\n",
      "Epoch: 14, Batch: 293, D Loss: 0.09952013795253611, G Loss: 18.22029685974121\n",
      "Epoch: 14, Batch: 294, D Loss: 0.10665332394780513, G Loss: 18.211416244506836\n",
      "Epoch: 14, Batch: 295, D Loss: 0.10080964003622661, G Loss: 18.168712615966797\n",
      "Epoch: 14, Batch: 296, D Loss: 0.10172494411826216, G Loss: 18.131614685058594\n",
      "Epoch: 14, Batch: 297, D Loss: 0.10744701249681965, G Loss: 18.128345489501953\n",
      "Epoch: 14, Batch: 298, D Loss: 0.09295439653567472, G Loss: 18.103984832763672\n",
      "Epoch: 14, Batch: 299, D Loss: 0.09383293202529996, G Loss: 18.049253463745117\n",
      "Epoch: 14, Batch: 300, D Loss: 0.09894506625122057, G Loss: 18.018230438232422\n",
      "Epoch: 14, Batch: 301, D Loss: 0.10622856009665282, G Loss: 18.05422592163086\n",
      "Epoch: 14, Batch: 302, D Loss: 0.09886661876551406, G Loss: 18.098804473876953\n",
      "Epoch: 14, Batch: 303, D Loss: 0.10186936627237841, G Loss: 18.165754318237305\n",
      "Epoch: 14, Batch: 304, D Loss: 0.09201241182912945, G Loss: 18.171369552612305\n",
      "Epoch: 14, Batch: 305, D Loss: 0.10731340082079566, G Loss: 18.213912963867188\n",
      "Epoch: 14, Batch: 306, D Loss: 0.09952106934515337, G Loss: 18.236392974853516\n",
      "Epoch: 14, Batch: 307, D Loss: 0.10175411999736284, G Loss: 18.25131607055664\n",
      "Epoch: 14, Batch: 308, D Loss: 0.09884667988814666, G Loss: 18.251558303833008\n",
      "Epoch: 14, Batch: 309, D Loss: 0.0991079345270851, G Loss: 18.24164390563965\n",
      "Epoch: 14, Batch: 310, D Loss: 0.09724557999505912, G Loss: 18.236421585083008\n",
      "Epoch: 14, Batch: 311, D Loss: 0.10048128521753785, G Loss: 18.233028411865234\n",
      "Epoch: 14, Batch: 312, D Loss: 0.09706742176561356, G Loss: 18.227184295654297\n",
      "Epoch: 14, Batch: 313, D Loss: 0.09916468575201787, G Loss: 18.215547561645508\n",
      "Epoch: 14, Batch: 314, D Loss: 0.09951063118916093, G Loss: 18.20167350769043\n",
      "Epoch: 14, Batch: 315, D Loss: 0.09154015673006999, G Loss: 18.15314483642578\n",
      "Epoch: 14, Batch: 316, D Loss: 0.10571088548200835, G Loss: 18.159229278564453\n",
      "Epoch: 14, Batch: 317, D Loss: 0.09557504113933213, G Loss: 18.1516170501709\n",
      "Epoch: 14, Batch: 318, D Loss: 0.09969914614530495, G Loss: 18.149944305419922\n",
      "Epoch: 14, Batch: 319, D Loss: 0.10020615071210814, G Loss: 18.149206161499023\n",
      "Epoch: 14, Batch: 320, D Loss: 0.10404609048696312, G Loss: 18.166675567626953\n",
      "Epoch: 14, Batch: 321, D Loss: 0.10446158687782203, G Loss: 18.191465377807617\n",
      "Epoch: 14, Batch: 322, D Loss: 0.09704912341261052, G Loss: 18.180816650390625\n",
      "Epoch: 14, Batch: 323, D Loss: 0.10479609558756753, G Loss: 18.18097496032715\n",
      "Epoch: 14, Batch: 324, D Loss: 0.09817275302900574, G Loss: 18.15859031677246\n",
      "Epoch: 14, Batch: 325, D Loss: 0.10305892583697407, G Loss: 18.15064239501953\n",
      "Epoch: 14, Batch: 326, D Loss: 0.10185917376297482, G Loss: 18.15250015258789\n",
      "Epoch: 14, Batch: 327, D Loss: 0.10396827657931951, G Loss: 18.176563262939453\n",
      "Epoch: 14, Batch: 328, D Loss: 0.10063043123746773, G Loss: 18.19523811340332\n",
      "Epoch: 14, Batch: 329, D Loss: 0.10329960904989344, G Loss: 18.220094680786133\n",
      "Epoch: 14, Batch: 330, D Loss: 0.09611852337768312, G Loss: 18.20571517944336\n",
      "Epoch: 14, Batch: 331, D Loss: 0.10085733861893509, G Loss: 18.184202194213867\n",
      "Epoch: 14, Batch: 332, D Loss: 0.09426312805681869, G Loss: 18.114171981811523\n",
      "Epoch: 14, Batch: 333, D Loss: 0.09698472126686841, G Loss: 18.05801010131836\n",
      "Epoch: 14, Batch: 334, D Loss: 0.09453121564094102, G Loss: 18.01157569885254\n",
      "Epoch: 14, Batch: 335, D Loss: 0.10102912785839369, G Loss: 18.025707244873047\n",
      "Epoch: 14, Batch: 336, D Loss: 0.09836190175502413, G Loss: 18.06599998474121\n",
      "Epoch: 14, Batch: 337, D Loss: 0.10029456708275086, G Loss: 18.131061553955078\n",
      "Epoch: 14, Batch: 338, D Loss: 0.10493787274876576, G Loss: 18.206668853759766\n",
      "Epoch: 14, Batch: 339, D Loss: 0.09423778078399891, G Loss: 18.212953567504883\n",
      "Epoch: 14, Batch: 340, D Loss: 0.09661798806224198, G Loss: 18.177452087402344\n",
      "Epoch: 14, Batch: 341, D Loss: 0.09992229100523664, G Loss: 18.13491439819336\n",
      "Epoch: 14, Batch: 342, D Loss: 0.09882026101825359, G Loss: 18.09050750732422\n",
      "Epoch: 14, Batch: 343, D Loss: 0.09710639677612365, G Loss: 18.058578491210938\n",
      "Epoch: 14, Batch: 344, D Loss: 0.10451758615425488, G Loss: 18.0871524810791\n",
      "Epoch: 14, Batch: 345, D Loss: 0.09825118571227609, G Loss: 18.122465133666992\n",
      "Epoch: 14, Batch: 346, D Loss: 0.09535014551993992, G Loss: 18.13985824584961\n",
      "Epoch: 14, Batch: 347, D Loss: 0.09517118998149865, G Loss: 18.13649559020996\n",
      "Epoch: 14, Batch: 348, D Loss: 0.10550267900335175, G Loss: 18.17522621154785\n",
      "Epoch: 14, Batch: 349, D Loss: 0.10110000403927044, G Loss: 18.208585739135742\n",
      "Epoch: 14, Batch: 350, D Loss: 0.09523189695881085, G Loss: 18.17852783203125\n",
      "Epoch: 14, Batch: 351, D Loss: 0.0972124850351257, G Loss: 18.135372161865234\n",
      "Epoch: 14, Batch: 352, D Loss: 0.10137297886229524, G Loss: 18.11269760131836\n",
      "Epoch: 14, Batch: 353, D Loss: 0.09676573369905483, G Loss: 18.08772850036621\n",
      "Epoch: 14, Batch: 354, D Loss: 0.09739722268735607, G Loss: 18.075115203857422\n",
      "Epoch: 14, Batch: 355, D Loss: 0.09812170971922107, G Loss: 18.079652786254883\n",
      "Epoch: 14, Batch: 356, D Loss: 0.0982779334257744, G Loss: 18.093828201293945\n",
      "Epoch: 14, Batch: 357, D Loss: 0.09833159983841488, G Loss: 18.113847732543945\n",
      "Epoch: 14, Batch: 358, D Loss: 0.10073444913667906, G Loss: 18.151195526123047\n",
      "Epoch: 14, Batch: 359, D Loss: 0.09777034719778355, G Loss: 18.177576065063477\n",
      "Epoch: 14, Batch: 360, D Loss: 0.09861817101125014, G Loss: 18.184791564941406\n",
      "Epoch: 14, Batch: 361, D Loss: 0.09680913280417736, G Loss: 18.173908233642578\n",
      "Epoch: 14, Batch: 362, D Loss: 0.10298488181643783, G Loss: 18.18120765686035\n",
      "Epoch: 14, Batch: 363, D Loss: 0.09766540569495774, G Loss: 18.172771453857422\n",
      "Epoch: 14, Batch: 364, D Loss: 0.10073448614885505, G Loss: 18.168107986450195\n",
      "Epoch: 14, Batch: 365, D Loss: 0.10108204826723766, G Loss: 18.176986694335938\n",
      "Epoch: 14, Batch: 366, D Loss: 0.09307371725144442, G Loss: 18.155759811401367\n",
      "Epoch: 14, Batch: 367, D Loss: 0.09645109543939823, G Loss: 18.116498947143555\n",
      "Epoch: 14, Batch: 368, D Loss: 0.10314498771122338, G Loss: 18.126188278198242\n",
      "Epoch: 14, Batch: 369, D Loss: 0.0967549972129671, G Loss: 18.131399154663086\n",
      "Epoch: 14, Batch: 370, D Loss: 0.09980227714506018, G Loss: 18.149951934814453\n",
      "Epoch: 14, Batch: 371, D Loss: 0.09446351141440656, G Loss: 18.14767074584961\n",
      "Epoch: 14, Batch: 372, D Loss: 0.10004836975032916, G Loss: 18.15609359741211\n",
      "Epoch: 14, Batch: 373, D Loss: 0.10317213734872865, G Loss: 18.17051124572754\n",
      "Epoch: 14, Batch: 374, D Loss: 0.09495471321069715, G Loss: 18.152830123901367\n",
      "Epoch: 14, Batch: 375, D Loss: 0.09911369448445129, G Loss: 18.131196975708008\n",
      "Epoch: 14, Batch: 376, D Loss: 0.10350356171462272, G Loss: 18.13817024230957\n",
      "Epoch: 14, Batch: 377, D Loss: 0.09192626856857977, G Loss: 18.09483528137207\n",
      "Epoch: 14, Batch: 378, D Loss: 0.1033951709598191, G Loss: 18.089401245117188\n",
      "Epoch: 14, Batch: 379, D Loss: 0.10309792999723655, G Loss: 18.10784149169922\n",
      "Epoch: 14, Batch: 380, D Loss: 0.10098902066211712, G Loss: 18.13174057006836\n",
      "Epoch: 14, Batch: 381, D Loss: 0.10031884080070963, G Loss: 18.149106979370117\n",
      "Epoch: 14, Batch: 382, D Loss: 0.10092690495687551, G Loss: 18.156116485595703\n",
      "Epoch: 14, Batch: 383, D Loss: 0.10097291974114597, G Loss: 18.15023422241211\n",
      "Epoch: 14, Batch: 384, D Loss: 0.10139832559216977, G Loss: 18.140878677368164\n",
      "Epoch: 14, Batch: 385, D Loss: 0.099445096378731, G Loss: 18.122150421142578\n",
      "Epoch: 14, Batch: 386, D Loss: 0.09978509632110955, G Loss: 18.097524642944336\n",
      "Epoch: 14, Batch: 387, D Loss: 0.09995001506042067, G Loss: 18.081722259521484\n",
      "Epoch: 14, Batch: 388, D Loss: 0.10018323318805811, G Loss: 18.081382751464844\n",
      "Epoch: 14, Batch: 389, D Loss: 0.1005423064186366, G Loss: 18.09544563293457\n",
      "Epoch: 14, Batch: 390, D Loss: 0.10211186791996596, G Loss: 18.126543045043945\n",
      "Epoch: 14, Batch: 391, D Loss: 0.10051571493984213, G Loss: 18.154491424560547\n",
      "Epoch: 14, Batch: 392, D Loss: 0.10243504392536451, G Loss: 18.182048797607422\n",
      "Epoch: 14, Batch: 393, D Loss: 0.10109224056081745, G Loss: 18.194520950317383\n",
      "Epoch: 14, Batch: 394, D Loss: 0.10135987284815728, G Loss: 18.188827514648438\n",
      "Epoch: 14, Batch: 395, D Loss: 0.10022794348463071, G Loss: 18.16577911376953\n",
      "Epoch: 14, Batch: 396, D Loss: 0.09711202149747455, G Loss: 18.12042999267578\n",
      "Epoch: 14, Batch: 397, D Loss: 0.09605462052315916, G Loss: 18.06999397277832\n",
      "Epoch: 14, Batch: 398, D Loss: 0.10001640739575413, G Loss: 18.049644470214844\n",
      "Epoch: 14, Batch: 399, D Loss: 0.09875235683823069, G Loss: 18.056045532226562\n",
      "Epoch: 14, Batch: 400, D Loss: 0.0940069479511263, G Loss: 18.0488338470459\n",
      "Epoch: 14, Batch: 401, D Loss: 0.09268186229533004, G Loss: 18.0283203125\n",
      "Epoch: 14, Batch: 402, D Loss: 0.09112200150826855, G Loss: 17.991212844848633\n",
      "Epoch: 14, Batch: 403, D Loss: 0.09665905710499789, G Loss: 17.983957290649414\n",
      "Epoch: 14, Batch: 404, D Loss: 0.106979235983375, G Loss: 18.061603546142578\n",
      "Epoch: 14, Batch: 405, D Loss: 0.09690872528832761, G Loss: 18.120691299438477\n",
      "Epoch: 14, Batch: 406, D Loss: 0.10178335669649563, G Loss: 18.167217254638672\n",
      "Epoch: 14, Batch: 407, D Loss: 0.10152011256139337, G Loss: 18.19040298461914\n",
      "Epoch: 14, Batch: 408, D Loss: 0.10132943722477616, G Loss: 18.193012237548828\n",
      "Epoch: 14, Batch: 409, D Loss: 0.0987771515539686, G Loss: 18.154634475708008\n",
      "Epoch: 14, Batch: 410, D Loss: 0.09773814607849163, G Loss: 18.090585708618164\n",
      "Epoch: 14, Batch: 411, D Loss: 0.0974133906344905, G Loss: 18.02200698852539\n",
      "Epoch: 14, Batch: 412, D Loss: 0.09894720479817298, G Loss: 17.98430633544922\n",
      "Epoch: 14, Batch: 413, D Loss: 0.09655673092276018, G Loss: 17.96765899658203\n",
      "Epoch: 14, Batch: 414, D Loss: 0.09528441769645823, G Loss: 17.965612411499023\n",
      "Epoch: 14, Batch: 415, D Loss: 0.10048695679324915, G Loss: 18.008434295654297\n",
      "Epoch: 14, Batch: 416, D Loss: 0.09827332934512567, G Loss: 18.057649612426758\n",
      "Epoch: 14, Batch: 417, D Loss: 0.09909393595351457, G Loss: 18.10272979736328\n",
      "Epoch: 14, Batch: 418, D Loss: 0.09926760128035905, G Loss: 18.1329288482666\n",
      "Epoch: 14, Batch: 419, D Loss: 0.09226430145217135, G Loss: 18.08785057067871\n",
      "Epoch: 14, Batch: 420, D Loss: 0.10226142367716351, G Loss: 18.064176559448242\n",
      "Epoch: 14, Batch: 421, D Loss: 0.10085146846626492, G Loss: 18.055686950683594\n",
      "Epoch: 14, Batch: 422, D Loss: 0.10424961865367166, G Loss: 18.068090438842773\n",
      "Epoch: 14, Batch: 423, D Loss: 0.10174803396507093, G Loss: 18.083412170410156\n",
      "Epoch: 14, Batch: 424, D Loss: 0.10114630265845515, G Loss: 18.08745765686035\n",
      "Epoch: 14, Batch: 425, D Loss: 0.10111138179365486, G Loss: 18.082111358642578\n",
      "Epoch: 14, Batch: 426, D Loss: 0.0970515531212599, G Loss: 18.04776382446289\n",
      "Epoch: 14, Batch: 427, D Loss: 0.10529457762469141, G Loss: 18.03816032409668\n",
      "Epoch: 14, Batch: 428, D Loss: 0.0983695462143066, G Loss: 18.01264190673828\n",
      "Epoch: 14, Batch: 429, D Loss: 0.10045915111098491, G Loss: 17.994821548461914\n",
      "Epoch: 14, Batch: 430, D Loss: 0.09746889054935703, G Loss: 17.97157096862793\n",
      "Epoch: 14, Batch: 431, D Loss: 0.09816315817340282, G Loss: 17.950687408447266\n",
      "Epoch: 14, Batch: 432, D Loss: 0.10354508505652227, G Loss: 17.972183227539062\n",
      "Epoch: 14, Batch: 433, D Loss: 0.10539567483290924, G Loss: 18.034330368041992\n",
      "Epoch: 14, Batch: 434, D Loss: 0.09933533497615077, G Loss: 18.06746482849121\n",
      "Epoch: 14, Batch: 435, D Loss: 0.08950054631724935, G Loss: 18.016447067260742\n",
      "Epoch: 14, Batch: 436, D Loss: 0.09620726140054092, G Loss: 17.9479923248291\n",
      "Epoch: 14, Batch: 437, D Loss: 0.10141684185613986, G Loss: 17.916370391845703\n",
      "Epoch: 14, Batch: 438, D Loss: 0.1032533280277006, G Loss: 17.94237518310547\n",
      "Epoch: 14, Batch: 439, D Loss: 0.1000858475302362, G Loss: 17.982030868530273\n",
      "Epoch: 14, Batch: 440, D Loss: 0.09938106700682603, G Loss: 18.020517349243164\n",
      "Epoch: 14, Batch: 441, D Loss: 0.09444198010833693, G Loss: 18.027250289916992\n",
      "Epoch: 14, Batch: 442, D Loss: 0.10117103148939899, G Loss: 18.044219970703125\n",
      "Epoch: 14, Batch: 443, D Loss: 0.09871333072599864, G Loss: 18.05332374572754\n",
      "Epoch: 14, Batch: 444, D Loss: 0.10197862206598751, G Loss: 18.074819564819336\n",
      "Epoch: 14, Batch: 445, D Loss: 0.09674278608906661, G Loss: 18.073345184326172\n",
      "Epoch: 14, Batch: 446, D Loss: 0.10453669679341493, G Loss: 18.100996017456055\n",
      "Epoch: 14, Batch: 447, D Loss: 0.10004877238819443, G Loss: 18.111120223999023\n",
      "Epoch: 14, Batch: 448, D Loss: 0.10135196827624249, G Loss: 18.1202449798584\n",
      "Epoch: 14, Batch: 449, D Loss: 0.09610813049445799, G Loss: 18.09750747680664\n",
      "Epoch: 14, Batch: 450, D Loss: 0.09558453375755249, G Loss: 18.045392990112305\n",
      "Epoch: 14, Batch: 451, D Loss: 0.09795845299687089, G Loss: 18.00146484375\n",
      "Epoch: 14, Batch: 452, D Loss: 0.10105088371548199, G Loss: 17.99420166015625\n",
      "Epoch: 14, Batch: 453, D Loss: 0.09578790538934445, G Loss: 17.988636016845703\n",
      "Epoch: 14, Batch: 454, D Loss: 0.09434302924230842, G Loss: 17.982074737548828\n",
      "Epoch: 14, Batch: 455, D Loss: 0.09609029478892772, G Loss: 17.966279983520508\n",
      "Epoch: 14, Batch: 456, D Loss: 0.09956737646590152, G Loss: 17.975610733032227\n",
      "Epoch: 14, Batch: 457, D Loss: 0.09593877973691178, G Loss: 17.983068466186523\n",
      "Epoch: 14, Batch: 458, D Loss: 0.09623892636111986, G Loss: 17.980056762695312\n",
      "Epoch: 14, Batch: 459, D Loss: 0.09791357102427867, G Loss: 17.979272842407227\n",
      "Epoch: 14, Batch: 460, D Loss: 0.10124820495081721, G Loss: 17.999502182006836\n",
      "Epoch: 14, Batch: 461, D Loss: 0.0888258744081094, G Loss: 17.948055267333984\n",
      "Epoch: 14, Batch: 462, D Loss: 0.09808599272976437, G Loss: 17.91982078552246\n",
      "Epoch: 14, Batch: 463, D Loss: 0.09900157977115054, G Loss: 17.923744201660156\n",
      "Epoch: 14, Batch: 464, D Loss: 0.10522890883962521, G Loss: 17.99161148071289\n",
      "Epoch: 14, Batch: 465, D Loss: 0.09821661563575024, G Loss: 18.044429779052734\n",
      "Epoch: 14, Batch: 466, D Loss: 0.10443570426057747, G Loss: 18.103153228759766\n",
      "Epoch: 14, Batch: 467, D Loss: 0.10405523259654625, G Loss: 18.137203216552734\n",
      "Epoch: 15, Batch: 0, D Loss: 0.09813935237747584, G Loss: 18.110990524291992\n",
      "Epoch: 15, Batch: 1, D Loss: 0.10374099707287199, G Loss: 18.084566116333008\n",
      "Epoch: 15, Batch: 2, D Loss: 0.09309291081849036, G Loss: 17.997766494750977\n",
      "Epoch: 15, Batch: 3, D Loss: 0.10523930969008255, G Loss: 17.963945388793945\n",
      "Epoch: 15, Batch: 4, D Loss: 0.1043605733535875, G Loss: 17.984594345092773\n",
      "Epoch: 15, Batch: 5, D Loss: 0.09970701502531121, G Loss: 18.013572692871094\n",
      "Epoch: 15, Batch: 6, D Loss: 0.09587167954188391, G Loss: 18.015056610107422\n",
      "Epoch: 15, Batch: 7, D Loss: 0.10557383287757327, G Loss: 18.056657791137695\n",
      "Epoch: 15, Batch: 8, D Loss: 0.09839308975037309, G Loss: 18.07383918762207\n",
      "Epoch: 15, Batch: 9, D Loss: 0.09894473070146192, G Loss: 18.06810760498047\n",
      "Epoch: 15, Batch: 10, D Loss: 0.09700980015635308, G Loss: 18.036806106567383\n",
      "Epoch: 15, Batch: 11, D Loss: 0.0963102058043539, G Loss: 17.996610641479492\n",
      "Epoch: 15, Batch: 12, D Loss: 0.10153776428359329, G Loss: 17.99170684814453\n",
      "Epoch: 15, Batch: 13, D Loss: 0.10072074098869432, G Loss: 18.015390396118164\n",
      "Epoch: 15, Batch: 14, D Loss: 0.09517342598627998, G Loss: 18.024425506591797\n",
      "Epoch: 15, Batch: 15, D Loss: 0.09917955091163311, G Loss: 18.04383087158203\n",
      "Epoch: 15, Batch: 16, D Loss: 0.0965935958383759, G Loss: 18.054807662963867\n",
      "Epoch: 15, Batch: 17, D Loss: 0.10835216143540727, G Loss: 18.12645721435547\n",
      "Epoch: 15, Batch: 18, D Loss: 0.09595324761622859, G Loss: 18.15083122253418\n",
      "Epoch: 15, Batch: 19, D Loss: 0.0922614850129917, G Loss: 18.105304718017578\n",
      "Epoch: 15, Batch: 20, D Loss: 0.09555522305687436, G Loss: 18.070125579833984\n",
      "Epoch: 15, Batch: 21, D Loss: 0.10191611163992054, G Loss: 18.07433319091797\n",
      "Epoch: 15, Batch: 22, D Loss: 0.09919794600629972, G Loss: 18.102062225341797\n",
      "Epoch: 15, Batch: 23, D Loss: 0.10139005553733993, G Loss: 18.158323287963867\n",
      "Epoch: 15, Batch: 24, D Loss: 0.0993795309195038, G Loss: 18.20848846435547\n",
      "Epoch: 15, Batch: 25, D Loss: 0.10440281630683224, G Loss: 18.27419662475586\n",
      "Epoch: 15, Batch: 26, D Loss: 0.09277360738908369, G Loss: 18.21369743347168\n",
      "Epoch: 15, Batch: 27, D Loss: 0.09956453631216355, G Loss: 18.150766372680664\n",
      "Epoch: 15, Batch: 28, D Loss: 0.1035706318581493, G Loss: 18.115623474121094\n",
      "Epoch: 15, Batch: 29, D Loss: 0.0964485848929546, G Loss: 18.068984985351562\n",
      "Epoch: 15, Batch: 30, D Loss: 0.10574514382948186, G Loss: 18.07349395751953\n",
      "Epoch: 15, Batch: 31, D Loss: 0.10647512173038542, G Loss: 18.11913299560547\n",
      "Epoch: 15, Batch: 32, D Loss: 0.09523398363106228, G Loss: 18.110864639282227\n",
      "Epoch: 15, Batch: 33, D Loss: 0.09754405123053589, G Loss: 18.067293167114258\n",
      "Epoch: 15, Batch: 34, D Loss: 0.10158623733110206, G Loss: 18.037717819213867\n",
      "Epoch: 15, Batch: 35, D Loss: 0.10217751553265808, G Loss: 18.031740188598633\n",
      "Epoch: 15, Batch: 36, D Loss: 0.10514093174246808, G Loss: 18.054853439331055\n",
      "Epoch: 15, Batch: 37, D Loss: 0.0969910768495752, G Loss: 18.048261642456055\n",
      "Epoch: 15, Batch: 38, D Loss: 0.10094312560634355, G Loss: 18.044260025024414\n",
      "Epoch: 15, Batch: 39, D Loss: 0.10168642533420513, G Loss: 18.046531677246094\n",
      "Epoch: 15, Batch: 40, D Loss: 0.09497853368122167, G Loss: 18.000783920288086\n",
      "Epoch: 15, Batch: 41, D Loss: 0.1054177583764968, G Loss: 18.003164291381836\n",
      "Epoch: 15, Batch: 42, D Loss: 0.09499240690933419, G Loss: 17.977874755859375\n",
      "Epoch: 15, Batch: 43, D Loss: 0.09716717198041991, G Loss: 17.95201301574707\n",
      "Epoch: 15, Batch: 44, D Loss: 0.09965960736830048, G Loss: 17.948705673217773\n",
      "Epoch: 15, Batch: 45, D Loss: 0.09369007563825171, G Loss: 17.92710304260254\n",
      "Epoch: 15, Batch: 46, D Loss: 0.10832787349330442, G Loss: 17.997610092163086\n",
      "Epoch: 15, Batch: 47, D Loss: 0.10168287891582972, G Loss: 18.073110580444336\n",
      "Epoch: 15, Batch: 48, D Loss: 0.09988322054252885, G Loss: 18.120769500732422\n",
      "Epoch: 15, Batch: 49, D Loss: 0.09896153885511261, G Loss: 18.12370491027832\n",
      "Epoch: 15, Batch: 50, D Loss: 0.10473523960596154, G Loss: 18.127513885498047\n",
      "Epoch: 15, Batch: 51, D Loss: 0.10168652909715048, G Loss: 18.11952018737793\n",
      "Epoch: 15, Batch: 52, D Loss: 0.09689385395345873, G Loss: 18.062074661254883\n",
      "Epoch: 15, Batch: 53, D Loss: 0.09898016594475179, G Loss: 18.00448226928711\n",
      "Epoch: 15, Batch: 54, D Loss: 0.0980054515740365, G Loss: 17.95965576171875\n",
      "Epoch: 15, Batch: 55, D Loss: 0.09722311106405446, G Loss: 17.938722610473633\n",
      "Epoch: 15, Batch: 56, D Loss: 0.09888600619709109, G Loss: 17.945838928222656\n",
      "Epoch: 15, Batch: 57, D Loss: 0.09621966682845784, G Loss: 17.960844039916992\n",
      "Epoch: 15, Batch: 58, D Loss: 0.09197221003217138, G Loss: 17.949058532714844\n",
      "Epoch: 15, Batch: 59, D Loss: 0.09942368464980511, G Loss: 17.971391677856445\n",
      "Epoch: 15, Batch: 60, D Loss: 0.10314761859326183, G Loss: 18.036794662475586\n",
      "Epoch: 15, Batch: 61, D Loss: 0.09589397882215334, G Loss: 18.07352066040039\n",
      "Epoch: 15, Batch: 62, D Loss: 0.10159433582359023, G Loss: 18.109487533569336\n",
      "Epoch: 15, Batch: 63, D Loss: 0.09551181587655488, G Loss: 18.09312629699707\n",
      "Epoch: 15, Batch: 64, D Loss: 0.09980941521484166, G Loss: 18.06915855407715\n",
      "Epoch: 15, Batch: 65, D Loss: 0.09704148005711177, G Loss: 18.027511596679688\n",
      "Epoch: 15, Batch: 66, D Loss: 0.10030058774588291, G Loss: 18.008840560913086\n",
      "Epoch: 15, Batch: 67, D Loss: 0.10097683228289256, G Loss: 18.015607833862305\n",
      "Epoch: 15, Batch: 68, D Loss: 0.09322955475338368, G Loss: 17.98740577697754\n",
      "Epoch: 15, Batch: 69, D Loss: 0.1010640489083654, G Loss: 18.002574920654297\n",
      "Epoch: 15, Batch: 70, D Loss: 0.10665032250180007, G Loss: 18.083877563476562\n",
      "Epoch: 15, Batch: 71, D Loss: 0.10465929578133748, G Loss: 18.17881202697754\n",
      "Epoch: 15, Batch: 72, D Loss: 0.10125487173141812, G Loss: 18.228435516357422\n",
      "Epoch: 15, Batch: 73, D Loss: 0.09195808199464528, G Loss: 18.175090789794922\n",
      "Epoch: 15, Batch: 74, D Loss: 0.09462325951324102, G Loss: 18.067283630371094\n",
      "Epoch: 15, Batch: 75, D Loss: 0.0956381709351648, G Loss: 17.956035614013672\n",
      "Epoch: 15, Batch: 76, D Loss: 0.09787223565759628, G Loss: 17.892799377441406\n",
      "Epoch: 15, Batch: 77, D Loss: 0.09792688592206211, G Loss: 17.891738891601562\n",
      "Epoch: 15, Batch: 78, D Loss: 0.10158202868001709, G Loss: 17.96636962890625\n",
      "Epoch: 15, Batch: 79, D Loss: 0.10490079214562664, G Loss: 18.095468521118164\n",
      "Epoch: 15, Batch: 80, D Loss: 0.10244187617903266, G Loss: 18.213424682617188\n",
      "Epoch: 15, Batch: 81, D Loss: 0.10382739297223154, G Loss: 18.29966163635254\n",
      "Epoch: 15, Batch: 82, D Loss: 0.10195471902334141, G Loss: 18.32822608947754\n",
      "Epoch: 15, Batch: 83, D Loss: 0.10336450295030275, G Loss: 18.313684463500977\n",
      "Epoch: 15, Batch: 84, D Loss: 0.09437539268218842, G Loss: 18.21910858154297\n",
      "Epoch: 15, Batch: 85, D Loss: 0.09704642647096051, G Loss: 18.105249404907227\n",
      "Epoch: 15, Batch: 86, D Loss: 0.09622350313729244, G Loss: 18.00176239013672\n",
      "Epoch: 15, Batch: 87, D Loss: 0.10037782815650864, G Loss: 17.97161293029785\n",
      "Epoch: 15, Batch: 88, D Loss: 0.09848248984109187, G Loss: 18.003286361694336\n",
      "Epoch: 15, Batch: 89, D Loss: 0.09413360801228476, G Loss: 18.04655647277832\n",
      "Epoch: 15, Batch: 90, D Loss: 0.10117728213771127, G Loss: 18.129619598388672\n",
      "Epoch: 15, Batch: 91, D Loss: 0.09916492447306036, G Loss: 18.211036682128906\n",
      "Epoch: 15, Batch: 92, D Loss: 0.10349687035663901, G Loss: 18.288726806640625\n",
      "Epoch: 15, Batch: 93, D Loss: 0.09593391994467293, G Loss: 18.270793914794922\n",
      "Epoch: 15, Batch: 94, D Loss: 0.1026303528946726, G Loss: 18.247371673583984\n",
      "Epoch: 15, Batch: 95, D Loss: 0.09695749600851311, G Loss: 18.180150985717773\n",
      "Epoch: 15, Batch: 96, D Loss: 0.09542359336452311, G Loss: 18.081361770629883\n",
      "Epoch: 15, Batch: 97, D Loss: 0.0954250022080596, G Loss: 17.985658645629883\n",
      "Epoch: 15, Batch: 98, D Loss: 0.1058095249191604, G Loss: 17.98859405517578\n",
      "Epoch: 15, Batch: 99, D Loss: 0.10436757652455997, G Loss: 18.05561065673828\n",
      "Epoch: 15, Batch: 100, D Loss: 0.09278256410848007, G Loss: 18.083812713623047\n",
      "Epoch: 15, Batch: 101, D Loss: 0.096775091710537, G Loss: 18.091232299804688\n",
      "Epoch: 15, Batch: 102, D Loss: 0.09913881817330417, G Loss: 18.093793869018555\n",
      "Epoch: 15, Batch: 103, D Loss: 0.10231181920243682, G Loss: 18.11391830444336\n",
      "Epoch: 15, Batch: 104, D Loss: 0.09468620210478784, G Loss: 18.098766326904297\n",
      "Epoch: 15, Batch: 105, D Loss: 0.10338363736450207, G Loss: 18.112451553344727\n",
      "Epoch: 15, Batch: 106, D Loss: 0.10356756223892738, G Loss: 18.14447784423828\n",
      "Epoch: 15, Batch: 107, D Loss: 0.1056025984340847, G Loss: 18.259191513061523\n",
      "Epoch: 15, Batch: 108, D Loss: 0.09533887932306984, G Loss: 18.298179626464844\n",
      "Epoch: 15, Batch: 109, D Loss: 0.10083124600327142, G Loss: 18.320117950439453\n",
      "Epoch: 15, Batch: 110, D Loss: 0.1018766964655482, G Loss: 18.336685180664062\n",
      "Epoch: 15, Batch: 111, D Loss: 0.09076770950500324, G Loss: 18.296539306640625\n",
      "Epoch: 15, Batch: 112, D Loss: 0.10547490231807632, G Loss: 18.3210506439209\n",
      "Epoch: 15, Batch: 113, D Loss: 0.09499882707994223, G Loss: 18.342092514038086\n",
      "Epoch: 15, Batch: 114, D Loss: 0.09210829233595774, G Loss: 18.3388729095459\n",
      "Epoch: 15, Batch: 115, D Loss: 0.10447805155636258, G Loss: 18.39865493774414\n",
      "Epoch: 15, Batch: 116, D Loss: 0.09637068709237173, G Loss: 18.451244354248047\n",
      "Epoch: 15, Batch: 117, D Loss: 0.09890796724952011, G Loss: 18.467700958251953\n",
      "Epoch: 15, Batch: 118, D Loss: 0.10392192474922535, G Loss: 18.500839233398438\n",
      "Epoch: 15, Batch: 119, D Loss: 0.10374242520867405, G Loss: 18.533960342407227\n",
      "Epoch: 15, Batch: 120, D Loss: 0.09010442075856506, G Loss: 18.41777992248535\n",
      "Epoch: 15, Batch: 121, D Loss: 0.10117622247767066, G Loss: 18.319984436035156\n",
      "Epoch: 15, Batch: 122, D Loss: 0.1033084151685224, G Loss: 18.257173538208008\n",
      "Epoch: 15, Batch: 123, D Loss: 0.10251373653564722, G Loss: 18.218584060668945\n",
      "Epoch: 15, Batch: 124, D Loss: 0.1043517427494085, G Loss: 18.211259841918945\n",
      "Epoch: 15, Batch: 125, D Loss: 0.09365390874922985, G Loss: 18.15882110595703\n",
      "Epoch: 15, Batch: 126, D Loss: 0.09600811379197616, G Loss: 18.09300994873047\n",
      "Epoch: 15, Batch: 127, D Loss: 0.09945863449844605, G Loss: 18.050697326660156\n",
      "Epoch: 15, Batch: 128, D Loss: 0.10262956448110083, G Loss: 18.053442001342773\n",
      "Epoch: 15, Batch: 129, D Loss: 0.09620629975239714, G Loss: 18.047504425048828\n",
      "Epoch: 15, Batch: 130, D Loss: 0.10038286423482345, G Loss: 18.061342239379883\n",
      "Epoch: 15, Batch: 131, D Loss: 0.10225657333101834, G Loss: 18.092857360839844\n",
      "Epoch: 15, Batch: 132, D Loss: 0.10397767209441122, G Loss: 18.134639739990234\n",
      "Epoch: 15, Batch: 133, D Loss: 0.09893827803428845, G Loss: 18.141986846923828\n",
      "Epoch: 15, Batch: 134, D Loss: 0.09895543678499452, G Loss: 18.117198944091797\n",
      "Epoch: 15, Batch: 135, D Loss: 0.10798295517781087, G Loss: 18.122358322143555\n",
      "Epoch: 15, Batch: 136, D Loss: 0.10217004197143487, G Loss: 18.125308990478516\n",
      "Epoch: 15, Batch: 137, D Loss: 0.10299750342753766, G Loss: 18.129749298095703\n",
      "Epoch: 15, Batch: 138, D Loss: 0.09048000671361356, G Loss: 18.06151580810547\n",
      "Epoch: 15, Batch: 139, D Loss: 0.09829347574445357, G Loss: 18.002185821533203\n",
      "Epoch: 15, Batch: 140, D Loss: 0.1000923889451748, G Loss: 17.975704193115234\n",
      "Epoch: 15, Batch: 141, D Loss: 0.09709334410699189, G Loss: 17.97098731994629\n",
      "Epoch: 15, Batch: 142, D Loss: 0.10687618712473501, G Loss: 18.04273796081543\n",
      "Epoch: 15, Batch: 143, D Loss: 0.09837878454202187, G Loss: 18.111278533935547\n",
      "Epoch: 15, Batch: 144, D Loss: 0.09821100454691756, G Loss: 18.152545928955078\n",
      "Epoch: 15, Batch: 145, D Loss: 0.10029659322871387, G Loss: 18.170551300048828\n",
      "Epoch: 15, Batch: 146, D Loss: 0.09334316017458244, G Loss: 18.124568939208984\n",
      "Epoch: 15, Batch: 147, D Loss: 0.09721451201410236, G Loss: 18.064908981323242\n",
      "Epoch: 15, Batch: 148, D Loss: 0.09832086401415951, G Loss: 18.015810012817383\n",
      "Epoch: 15, Batch: 149, D Loss: 0.09211986538973793, G Loss: 17.959644317626953\n",
      "Epoch: 15, Batch: 150, D Loss: 0.09913634560207107, G Loss: 17.95146942138672\n",
      "Epoch: 15, Batch: 151, D Loss: 0.10013001448965131, G Loss: 17.993745803833008\n",
      "Epoch: 15, Batch: 152, D Loss: 0.09449521459152166, G Loss: 18.029687881469727\n",
      "Epoch: 15, Batch: 153, D Loss: 0.10614086648991394, G Loss: 18.11566734313965\n",
      "Epoch: 15, Batch: 154, D Loss: 0.09726114488069948, G Loss: 18.162012100219727\n",
      "Epoch: 15, Batch: 155, D Loss: 0.09497884567484327, G Loss: 18.150604248046875\n",
      "Epoch: 15, Batch: 156, D Loss: 0.100058711249841, G Loss: 18.126323699951172\n",
      "Epoch: 15, Batch: 157, D Loss: 0.09568183815464915, G Loss: 18.06989097595215\n",
      "Epoch: 15, Batch: 158, D Loss: 0.09895230066566629, G Loss: 18.025463104248047\n",
      "Epoch: 15, Batch: 159, D Loss: 0.09317933040255433, G Loss: 17.975173950195312\n",
      "Epoch: 15, Batch: 160, D Loss: 0.10148989440123568, G Loss: 17.98688507080078\n",
      "Epoch: 15, Batch: 161, D Loss: 0.0989521444659065, G Loss: 18.032739639282227\n",
      "Epoch: 15, Batch: 162, D Loss: 0.10055079278436896, G Loss: 18.09724235534668\n",
      "Epoch: 15, Batch: 163, D Loss: 0.09453726496973625, G Loss: 18.12173080444336\n",
      "Epoch: 15, Batch: 164, D Loss: 0.09898506772646876, G Loss: 18.14039421081543\n",
      "Epoch: 15, Batch: 165, D Loss: 0.10577337345411308, G Loss: 18.18439483642578\n",
      "Epoch: 15, Batch: 166, D Loss: 0.10132092116464353, G Loss: 18.212448120117188\n",
      "Epoch: 15, Batch: 167, D Loss: 0.1041905940866692, G Loss: 18.233823776245117\n",
      "Epoch: 15, Batch: 168, D Loss: 0.09947735678507152, G Loss: 18.219587326049805\n",
      "Epoch: 15, Batch: 169, D Loss: 0.09288766131197601, G Loss: 18.128890991210938\n",
      "Epoch: 15, Batch: 170, D Loss: 0.10171106406434838, G Loss: 18.06088638305664\n",
      "Epoch: 15, Batch: 171, D Loss: 0.1027174813600098, G Loss: 18.036922454833984\n",
      "Epoch: 15, Batch: 172, D Loss: 0.0990469156669973, G Loss: 18.034860610961914\n",
      "Epoch: 15, Batch: 173, D Loss: 0.10427363935119738, G Loss: 18.079940795898438\n",
      "Epoch: 15, Batch: 174, D Loss: 0.09564841490182063, G Loss: 18.09764289855957\n",
      "Epoch: 15, Batch: 175, D Loss: 0.09534690480145613, G Loss: 18.08300018310547\n",
      "Epoch: 15, Batch: 176, D Loss: 0.09568888662282404, G Loss: 18.049753189086914\n",
      "Epoch: 15, Batch: 177, D Loss: 0.09261409195984438, G Loss: 17.98993492126465\n",
      "Epoch: 15, Batch: 178, D Loss: 0.1029004904213684, G Loss: 17.98650550842285\n",
      "Epoch: 15, Batch: 179, D Loss: 0.10071238144008632, G Loss: 18.019306182861328\n",
      "Epoch: 15, Batch: 180, D Loss: 0.09529764944489294, G Loss: 18.039199829101562\n",
      "Epoch: 15, Batch: 181, D Loss: 0.10003461662685886, G Loss: 18.07407569885254\n",
      "Epoch: 15, Batch: 182, D Loss: 0.09248163516542984, G Loss: 18.065277099609375\n",
      "Epoch: 15, Batch: 183, D Loss: 0.10443038448145225, G Loss: 18.101987838745117\n",
      "Epoch: 15, Batch: 184, D Loss: 0.10101168529353499, G Loss: 18.146804809570312\n",
      "Epoch: 15, Batch: 185, D Loss: 0.10290631549278739, G Loss: 18.1910343170166\n",
      "Epoch: 15, Batch: 186, D Loss: 0.09830545517402012, G Loss: 18.193279266357422\n",
      "Epoch: 15, Batch: 187, D Loss: 0.10006723441281684, G Loss: 18.17622947692871\n",
      "Epoch: 15, Batch: 188, D Loss: 0.09583140819154012, G Loss: 18.129104614257812\n",
      "Epoch: 15, Batch: 189, D Loss: 0.098474360403777, G Loss: 18.084596633911133\n",
      "Epoch: 15, Batch: 190, D Loss: 0.10109203267341282, G Loss: 18.07442283630371\n",
      "Epoch: 15, Batch: 191, D Loss: 0.09163663514279552, G Loss: 18.031715393066406\n",
      "Epoch: 15, Batch: 192, D Loss: 0.09289684902444773, G Loss: 17.9858341217041\n",
      "Epoch: 15, Batch: 193, D Loss: 0.09724658756446125, G Loss: 17.98248291015625\n",
      "Epoch: 15, Batch: 194, D Loss: 0.09732329861776456, G Loss: 18.016286849975586\n",
      "Epoch: 15, Batch: 195, D Loss: 0.09831755588545077, G Loss: 18.078046798706055\n",
      "Epoch: 15, Batch: 196, D Loss: 0.09393282922797663, G Loss: 18.122468948364258\n",
      "Epoch: 15, Batch: 197, D Loss: 0.09531745234885092, G Loss: 18.1464900970459\n",
      "Epoch: 15, Batch: 198, D Loss: 0.09599189369773509, G Loss: 18.15595817565918\n",
      "Epoch: 15, Batch: 199, D Loss: 0.101584336650276, G Loss: 18.175601959228516\n",
      "Epoch: 15, Batch: 200, D Loss: 0.1065947028441685, G Loss: 18.231748580932617\n",
      "Epoch: 15, Batch: 201, D Loss: 0.09820469321169112, G Loss: 18.25281524658203\n",
      "Epoch: 15, Batch: 202, D Loss: 0.10215331458412358, G Loss: 18.2592830657959\n",
      "Epoch: 15, Batch: 203, D Loss: 0.1001535489611336, G Loss: 18.249719619750977\n",
      "Epoch: 15, Batch: 204, D Loss: 0.09893082691096167, G Loss: 18.200471878051758\n",
      "Epoch: 15, Batch: 205, D Loss: 0.09783578561419448, G Loss: 18.142669677734375\n",
      "Epoch: 15, Batch: 206, D Loss: 0.0993603163262402, G Loss: 18.090923309326172\n",
      "Epoch: 15, Batch: 207, D Loss: 0.1064689600838995, G Loss: 18.108097076416016\n",
      "Epoch: 15, Batch: 208, D Loss: 0.09693237329117244, G Loss: 18.11787986755371\n",
      "Epoch: 15, Batch: 209, D Loss: 0.09254186541727005, G Loss: 18.091552734375\n",
      "Epoch: 15, Batch: 210, D Loss: 0.10332128350351555, G Loss: 18.10565757751465\n",
      "Epoch: 15, Batch: 211, D Loss: 0.09328024781753408, G Loss: 18.085832595825195\n",
      "Epoch: 15, Batch: 212, D Loss: 0.10270581344704555, G Loss: 18.09573745727539\n",
      "Epoch: 15, Batch: 213, D Loss: 0.10030893173691391, G Loss: 18.12263298034668\n",
      "Epoch: 15, Batch: 214, D Loss: 0.10117863033815677, G Loss: 18.161014556884766\n",
      "Epoch: 15, Batch: 215, D Loss: 0.10297965146867227, G Loss: 18.20474624633789\n",
      "Epoch: 15, Batch: 216, D Loss: 0.10314730420723706, G Loss: 18.23443031311035\n",
      "Epoch: 15, Batch: 217, D Loss: 0.09471981096631543, G Loss: 18.197343826293945\n",
      "Epoch: 15, Batch: 218, D Loss: 0.10524093990256667, G Loss: 18.18113136291504\n",
      "Epoch: 15, Batch: 219, D Loss: 0.10160812629840787, G Loss: 18.169450759887695\n",
      "Epoch: 15, Batch: 220, D Loss: 0.10664066563876506, G Loss: 18.18810272216797\n",
      "Epoch: 15, Batch: 221, D Loss: 0.09617150470274893, G Loss: 18.159969329833984\n",
      "Epoch: 15, Batch: 222, D Loss: 0.09488380625172521, G Loss: 18.099687576293945\n",
      "Epoch: 15, Batch: 223, D Loss: 0.10178159877796844, G Loss: 18.069194793701172\n",
      "Epoch: 15, Batch: 224, D Loss: 0.0930133832990081, G Loss: 18.017770767211914\n",
      "Epoch: 15, Batch: 225, D Loss: 0.09584290551429753, G Loss: 17.98244285583496\n",
      "Epoch: 15, Batch: 226, D Loss: 0.09904014333168831, G Loss: 18.02223014831543\n",
      "Epoch: 15, Batch: 227, D Loss: 0.09889002115514511, G Loss: 18.096559524536133\n",
      "Epoch: 15, Batch: 228, D Loss: 0.10400447156218595, G Loss: 18.20825958251953\n",
      "Epoch: 15, Batch: 229, D Loss: 0.0986172690736522, G Loss: 18.286090850830078\n",
      "Epoch: 15, Batch: 230, D Loss: 0.1030735801416709, G Loss: 18.347362518310547\n",
      "Epoch: 15, Batch: 231, D Loss: 0.10274877183524955, G Loss: 18.378393173217773\n",
      "Epoch: 15, Batch: 232, D Loss: 0.09837741188921978, G Loss: 18.351024627685547\n",
      "Epoch: 15, Batch: 233, D Loss: 0.0966687556106467, G Loss: 18.280527114868164\n",
      "Epoch: 15, Batch: 234, D Loss: 0.10012812761146828, G Loss: 18.220340728759766\n",
      "Epoch: 15, Batch: 235, D Loss: 0.09814999878432618, G Loss: 18.17448616027832\n",
      "Epoch: 15, Batch: 236, D Loss: 0.0994467128743044, G Loss: 18.173377990722656\n",
      "Epoch: 15, Batch: 237, D Loss: 0.09990195067040286, G Loss: 18.21294593811035\n",
      "Epoch: 15, Batch: 238, D Loss: 0.0994955882584434, G Loss: 18.269012451171875\n",
      "Epoch: 15, Batch: 239, D Loss: 0.10176107103149468, G Loss: 18.339160919189453\n",
      "Epoch: 15, Batch: 240, D Loss: 0.09760383305860998, G Loss: 18.367937088012695\n",
      "Epoch: 15, Batch: 241, D Loss: 0.09902625314167457, G Loss: 18.363866806030273\n",
      "Epoch: 15, Batch: 242, D Loss: 0.10073035743939496, G Loss: 18.34857749938965\n",
      "Epoch: 15, Batch: 243, D Loss: 0.09525538042261594, G Loss: 18.299680709838867\n",
      "Epoch: 15, Batch: 244, D Loss: 0.10451339751864896, G Loss: 18.292179107666016\n",
      "Epoch: 15, Batch: 245, D Loss: 0.10387652927423918, G Loss: 18.320972442626953\n",
      "Epoch: 15, Batch: 246, D Loss: 0.09925182711274338, G Loss: 18.338014602661133\n",
      "Epoch: 15, Batch: 247, D Loss: 0.09666206490603457, G Loss: 18.32124900817871\n",
      "Epoch: 15, Batch: 248, D Loss: 0.09634138461636121, G Loss: 18.285015106201172\n",
      "Epoch: 15, Batch: 249, D Loss: 0.10282372510063809, G Loss: 18.28799057006836\n",
      "Epoch: 15, Batch: 250, D Loss: 0.10088246879733154, G Loss: 18.311445236206055\n",
      "Epoch: 15, Batch: 251, D Loss: 0.10107070753956071, G Loss: 18.350723266601562\n",
      "Epoch: 15, Batch: 252, D Loss: 0.1018793933329527, G Loss: 18.39510154724121\n",
      "Epoch: 15, Batch: 253, D Loss: 0.10216129331160628, G Loss: 18.424875259399414\n",
      "Epoch: 15, Batch: 254, D Loss: 0.099418697270234, G Loss: 18.424888610839844\n",
      "Epoch: 15, Batch: 255, D Loss: 0.10215756051444336, G Loss: 18.419391632080078\n",
      "Epoch: 15, Batch: 256, D Loss: 0.09815825284524315, G Loss: 18.39321517944336\n",
      "Epoch: 15, Batch: 257, D Loss: 0.10049347353989813, G Loss: 18.372690200805664\n",
      "Epoch: 15, Batch: 258, D Loss: 0.09908320539231674, G Loss: 18.355093002319336\n",
      "Epoch: 15, Batch: 259, D Loss: 0.10297481499405547, G Loss: 18.373565673828125\n",
      "Epoch: 15, Batch: 260, D Loss: 0.10005682479630895, G Loss: 18.396608352661133\n",
      "Epoch: 15, Batch: 261, D Loss: 0.09998599202213176, G Loss: 18.41459083557129\n",
      "Epoch: 15, Batch: 262, D Loss: 0.09995005778275745, G Loss: 18.432113647460938\n",
      "Epoch: 15, Batch: 263, D Loss: 0.09411082919297709, G Loss: 18.400985717773438\n",
      "Epoch: 15, Batch: 264, D Loss: 0.09806017350321694, G Loss: 18.372377395629883\n",
      "Epoch: 15, Batch: 265, D Loss: 0.10304887368393345, G Loss: 18.387426376342773\n",
      "Epoch: 15, Batch: 266, D Loss: 0.09518474860674875, G Loss: 18.375442504882812\n",
      "Epoch: 15, Batch: 267, D Loss: 0.10548787329088771, G Loss: 18.423484802246094\n",
      "Epoch: 15, Batch: 268, D Loss: 0.0978258524815816, G Loss: 18.450756072998047\n",
      "Epoch: 15, Batch: 269, D Loss: 0.10246305645367393, G Loss: 18.480506896972656\n",
      "Epoch: 15, Batch: 270, D Loss: 0.10162835290574179, G Loss: 18.4949951171875\n",
      "Epoch: 15, Batch: 271, D Loss: 0.09813046924955371, G Loss: 18.47333526611328\n",
      "Epoch: 15, Batch: 272, D Loss: 0.09807970116110765, G Loss: 18.425996780395508\n",
      "Epoch: 15, Batch: 273, D Loss: 0.09758128734175253, G Loss: 18.384489059448242\n",
      "Epoch: 15, Batch: 274, D Loss: 0.10509010173706734, G Loss: 18.399465560913086\n",
      "Epoch: 15, Batch: 275, D Loss: 0.0971131971506658, G Loss: 18.413850784301758\n",
      "Epoch: 15, Batch: 276, D Loss: 0.09784700477571695, G Loss: 18.42279052734375\n",
      "Epoch: 15, Batch: 277, D Loss: 0.10269072396707779, G Loss: 18.45769691467285\n",
      "Epoch: 15, Batch: 278, D Loss: 0.09878176926524862, G Loss: 18.481813430786133\n",
      "Epoch: 15, Batch: 279, D Loss: 0.09607765551253777, G Loss: 18.472484588623047\n",
      "Epoch: 15, Batch: 280, D Loss: 0.10131866214063168, G Loss: 18.474754333496094\n",
      "Epoch: 15, Batch: 281, D Loss: 0.09780817954322396, G Loss: 18.46798324584961\n",
      "Epoch: 15, Batch: 282, D Loss: 0.09714987611321924, G Loss: 18.446577072143555\n",
      "Epoch: 15, Batch: 283, D Loss: 0.09639183927604655, G Loss: 18.413780212402344\n",
      "Epoch: 15, Batch: 284, D Loss: 0.10528003918860751, G Loss: 18.448266983032227\n",
      "Epoch: 15, Batch: 285, D Loss: 0.09639261399838883, G Loss: 18.46596908569336\n",
      "Epoch: 15, Batch: 286, D Loss: 0.09578886363142614, G Loss: 18.457509994506836\n",
      "Epoch: 15, Batch: 287, D Loss: 0.09592490385362451, G Loss: 18.437179565429688\n",
      "Epoch: 15, Batch: 288, D Loss: 0.10008117302072073, G Loss: 18.4422607421875\n",
      "Epoch: 15, Batch: 289, D Loss: 0.09902231880588142, G Loss: 18.457916259765625\n",
      "Epoch: 15, Batch: 290, D Loss: 0.10364874921053913, G Loss: 18.51002311706543\n",
      "Epoch: 15, Batch: 291, D Loss: 0.09957910778052481, G Loss: 18.545063018798828\n",
      "Epoch: 15, Batch: 292, D Loss: 0.09824854577486875, G Loss: 18.543338775634766\n",
      "Epoch: 15, Batch: 293, D Loss: 0.10123225745277775, G Loss: 18.537113189697266\n",
      "Epoch: 15, Batch: 294, D Loss: 0.09889009300000984, G Loss: 18.515594482421875\n",
      "Epoch: 15, Batch: 295, D Loss: 0.10452153240180717, G Loss: 18.529136657714844\n",
      "Epoch: 15, Batch: 296, D Loss: 0.10260672565453755, G Loss: 18.55231475830078\n",
      "Epoch: 15, Batch: 297, D Loss: 0.09846361421921479, G Loss: 18.543275833129883\n",
      "Epoch: 15, Batch: 298, D Loss: 0.09437233664628097, G Loss: 18.48941993713379\n",
      "Epoch: 15, Batch: 299, D Loss: 0.09779526771544411, G Loss: 18.443265914916992\n",
      "Epoch: 15, Batch: 300, D Loss: 0.09869360672328842, G Loss: 18.424917221069336\n",
      "Epoch: 15, Batch: 301, D Loss: 0.09430432822092216, G Loss: 18.40775489807129\n",
      "Epoch: 15, Batch: 302, D Loss: 0.10247067110335362, G Loss: 18.45804214477539\n",
      "Epoch: 15, Batch: 303, D Loss: 0.09689739815641163, G Loss: 18.508249282836914\n",
      "Epoch: 15, Batch: 304, D Loss: 0.09748179170714755, G Loss: 18.54122543334961\n",
      "Epoch: 15, Batch: 305, D Loss: 0.10065264690222886, G Loss: 18.575151443481445\n",
      "Epoch: 15, Batch: 306, D Loss: 0.09568560554659555, G Loss: 18.56304168701172\n",
      "Epoch: 15, Batch: 307, D Loss: 0.09364439247842515, G Loss: 18.51043128967285\n",
      "Epoch: 15, Batch: 308, D Loss: 0.09469302471269447, G Loss: 18.446762084960938\n",
      "Epoch: 15, Batch: 309, D Loss: 0.10005204870367557, G Loss: 18.432659149169922\n",
      "Epoch: 15, Batch: 310, D Loss: 0.10014085957028263, G Loss: 18.4664306640625\n",
      "Epoch: 15, Batch: 311, D Loss: 0.10198627870357901, G Loss: 18.54591941833496\n",
      "Epoch: 15, Batch: 312, D Loss: 0.10057649441820349, G Loss: 18.614715576171875\n",
      "Epoch: 15, Batch: 313, D Loss: 0.10039072142218242, G Loss: 18.653553009033203\n",
      "Epoch: 15, Batch: 314, D Loss: 0.0958080257467433, G Loss: 18.62457275390625\n",
      "Epoch: 15, Batch: 315, D Loss: 0.10114577083922205, G Loss: 18.585046768188477\n",
      "Epoch: 15, Batch: 316, D Loss: 0.09637260877879816, G Loss: 18.5118408203125\n",
      "Epoch: 15, Batch: 317, D Loss: 0.09942740670931371, G Loss: 18.460416793823242\n",
      "Epoch: 15, Batch: 318, D Loss: 0.09822045753127595, G Loss: 18.43714141845703\n",
      "Epoch: 15, Batch: 319, D Loss: 0.10106064865762798, G Loss: 18.457908630371094\n",
      "Epoch: 15, Batch: 320, D Loss: 0.09797863392876005, G Loss: 18.482080459594727\n",
      "Epoch: 15, Batch: 321, D Loss: 0.09817549305244677, G Loss: 18.507532119750977\n",
      "Epoch: 15, Batch: 322, D Loss: 0.10613903844869821, G Loss: 18.578519821166992\n",
      "Epoch: 15, Batch: 323, D Loss: 0.09876981052279499, G Loss: 18.611207962036133\n",
      "Epoch: 15, Batch: 324, D Loss: 0.09741867005402138, G Loss: 18.59516716003418\n",
      "Epoch: 15, Batch: 325, D Loss: 0.10159656830390196, G Loss: 18.5728702545166\n",
      "Epoch: 15, Batch: 326, D Loss: 0.09811076215688397, G Loss: 18.531572341918945\n",
      "Epoch: 15, Batch: 327, D Loss: 0.09713280660036894, G Loss: 18.483169555664062\n",
      "Epoch: 15, Batch: 328, D Loss: 0.10025480863538272, G Loss: 18.466352462768555\n",
      "Epoch: 15, Batch: 329, D Loss: 0.10104488307741155, G Loss: 18.49178123474121\n",
      "Epoch: 15, Batch: 330, D Loss: 0.10218011294870077, G Loss: 18.548246383666992\n",
      "Epoch: 15, Batch: 331, D Loss: 0.09894577843262553, G Loss: 18.594955444335938\n",
      "Epoch: 15, Batch: 332, D Loss: 0.09621428371727347, G Loss: 18.602188110351562\n",
      "Epoch: 15, Batch: 333, D Loss: 0.1027934294566002, G Loss: 18.618444442749023\n",
      "Epoch: 15, Batch: 334, D Loss: 0.10016659311175014, G Loss: 18.624561309814453\n",
      "Epoch: 15, Batch: 335, D Loss: 0.09784784579909145, G Loss: 18.60564422607422\n",
      "Epoch: 15, Batch: 336, D Loss: 0.09882713528838671, G Loss: 18.587568283081055\n",
      "Epoch: 15, Batch: 337, D Loss: 0.09851804805453757, G Loss: 18.55807113647461\n",
      "Epoch: 15, Batch: 338, D Loss: 0.09842254662044336, G Loss: 18.537490844726562\n",
      "Epoch: 15, Batch: 339, D Loss: 0.10338153382837811, G Loss: 18.5681209564209\n",
      "Epoch: 15, Batch: 340, D Loss: 0.09637500029093804, G Loss: 18.581600189208984\n",
      "Epoch: 15, Batch: 341, D Loss: 0.09803905017497971, G Loss: 18.58702850341797\n",
      "Epoch: 15, Batch: 342, D Loss: 0.10410209415986404, G Loss: 18.621109008789062\n",
      "Epoch: 15, Batch: 343, D Loss: 0.10066508160243792, G Loss: 18.64768409729004\n",
      "Epoch: 15, Batch: 344, D Loss: 0.10579251141691648, G Loss: 18.694581985473633\n",
      "Epoch: 15, Batch: 345, D Loss: 0.10272166508653724, G Loss: 18.717233657836914\n",
      "Epoch: 15, Batch: 346, D Loss: 0.10013392943104904, G Loss: 18.69815444946289\n",
      "Epoch: 15, Batch: 347, D Loss: 0.09686288631550122, G Loss: 18.623682022094727\n",
      "Epoch: 15, Batch: 348, D Loss: 0.09749804119342853, G Loss: 18.536670684814453\n",
      "Epoch: 15, Batch: 349, D Loss: 0.09475893247612222, G Loss: 18.452417373657227\n",
      "Epoch: 15, Batch: 350, D Loss: 0.09286848222290756, G Loss: 18.3480281829834\n",
      "Epoch: 15, Batch: 351, D Loss: 0.09621550691199898, G Loss: 18.31063461303711\n",
      "Epoch: 15, Batch: 352, D Loss: 0.09923966775119064, G Loss: 18.352161407470703\n",
      "Epoch: 15, Batch: 353, D Loss: 0.0999154797621582, G Loss: 18.441242218017578\n",
      "Epoch: 15, Batch: 354, D Loss: 0.10616153189530309, G Loss: 18.576690673828125\n",
      "Epoch: 15, Batch: 355, D Loss: 0.10232343932002452, G Loss: 18.669570922851562\n",
      "Epoch: 15, Batch: 356, D Loss: 0.10387857640998543, G Loss: 18.70488166809082\n",
      "Epoch: 15, Batch: 357, D Loss: 0.10058658210804117, G Loss: 18.657564163208008\n",
      "Epoch: 15, Batch: 358, D Loss: 0.10065062014859416, G Loss: 18.55756378173828\n",
      "Epoch: 15, Batch: 359, D Loss: 0.099302162405011, G Loss: 18.436996459960938\n",
      "Epoch: 15, Batch: 360, D Loss: 0.09806725158219054, G Loss: 18.32960319519043\n",
      "Epoch: 15, Batch: 361, D Loss: 0.0999409910570277, G Loss: 18.282197952270508\n",
      "Epoch: 15, Batch: 362, D Loss: 0.09390087265387059, G Loss: 18.24811553955078\n",
      "Epoch: 15, Batch: 363, D Loss: 0.10200103950664108, G Loss: 18.299623489379883\n",
      "Epoch: 15, Batch: 364, D Loss: 0.10123986542591545, G Loss: 18.394458770751953\n",
      "Epoch: 15, Batch: 365, D Loss: 0.08985288947301706, G Loss: 18.421350479125977\n",
      "Epoch: 15, Batch: 366, D Loss: 0.10284761825680455, G Loss: 18.473142623901367\n",
      "Epoch: 15, Batch: 367, D Loss: 0.09785910419899668, G Loss: 18.494592666625977\n",
      "Epoch: 15, Batch: 368, D Loss: 0.10317311149723851, G Loss: 18.517581939697266\n",
      "Epoch: 15, Batch: 369, D Loss: 0.09552236363214162, G Loss: 18.484405517578125\n",
      "Epoch: 15, Batch: 370, D Loss: 0.10054767609907955, G Loss: 18.448591232299805\n",
      "Epoch: 15, Batch: 371, D Loss: 0.10435111562865229, G Loss: 18.44499969482422\n",
      "Epoch: 15, Batch: 372, D Loss: 0.10041274618509366, G Loss: 18.444538116455078\n",
      "Epoch: 15, Batch: 373, D Loss: 0.09800202146429804, G Loss: 18.430076599121094\n",
      "Epoch: 15, Batch: 374, D Loss: 0.09055977083657041, G Loss: 18.359785079956055\n",
      "Epoch: 15, Batch: 375, D Loss: 0.10007829013705116, G Loss: 18.330665588378906\n",
      "Epoch: 15, Batch: 376, D Loss: 0.0942638944536065, G Loss: 18.300874710083008\n",
      "Epoch: 15, Batch: 377, D Loss: 0.09883634561705978, G Loss: 18.311115264892578\n",
      "Epoch: 15, Batch: 378, D Loss: 0.10290192602512205, G Loss: 18.39116668701172\n",
      "Epoch: 15, Batch: 379, D Loss: 0.09257863969252522, G Loss: 18.420005798339844\n",
      "Epoch: 15, Batch: 380, D Loss: 0.09881098316851578, G Loss: 18.446487426757812\n",
      "Epoch: 15, Batch: 381, D Loss: 0.10275759278068675, G Loss: 18.494346618652344\n",
      "Epoch: 15, Batch: 382, D Loss: 0.10066284696407513, G Loss: 18.524986267089844\n",
      "Epoch: 15, Batch: 383, D Loss: 0.09804022766866582, G Loss: 18.50745391845703\n",
      "Epoch: 15, Batch: 384, D Loss: 0.09999819566782575, G Loss: 18.472972869873047\n",
      "Epoch: 15, Batch: 385, D Loss: 0.09756520132959645, G Loss: 18.421810150146484\n",
      "Epoch: 15, Batch: 386, D Loss: 0.09478164238992726, G Loss: 18.345849990844727\n",
      "Epoch: 15, Batch: 387, D Loss: 0.0946133341748916, G Loss: 18.273162841796875\n",
      "Epoch: 15, Batch: 388, D Loss: 0.10178033092492766, G Loss: 18.2819766998291\n",
      "Epoch: 15, Batch: 389, D Loss: 0.09453405264485104, G Loss: 18.29865074157715\n",
      "Epoch: 15, Batch: 390, D Loss: 0.09609816784327974, G Loss: 18.31599998474121\n",
      "Epoch: 15, Batch: 391, D Loss: 0.09984455055158703, G Loss: 18.36675453186035\n",
      "Epoch: 15, Batch: 392, D Loss: 0.098117639968482, G Loss: 18.355478286743164\n",
      "Epoch: 15, Batch: 393, D Loss: 0.10164456604185101, G Loss: 18.353729248046875\n",
      "Epoch: 15, Batch: 394, D Loss: 0.09360220080746462, G Loss: 18.335695266723633\n",
      "Epoch: 15, Batch: 395, D Loss: 0.0916742514049802, G Loss: 18.2958984375\n",
      "Epoch: 15, Batch: 396, D Loss: 0.09891917380069071, G Loss: 18.288986206054688\n",
      "Epoch: 15, Batch: 397, D Loss: 0.09888339597185469, G Loss: 18.342735290527344\n",
      "Epoch: 15, Batch: 398, D Loss: 0.10064602412660806, G Loss: 18.436498641967773\n",
      "Epoch: 15, Batch: 399, D Loss: 0.09845450992677618, G Loss: 18.51525115966797\n",
      "Epoch: 15, Batch: 400, D Loss: 0.09778417349265389, G Loss: 18.546796798706055\n",
      "Epoch: 15, Batch: 401, D Loss: 0.10398905413733317, G Loss: 18.574127197265625\n",
      "Epoch: 15, Batch: 402, D Loss: 0.10679169420370505, G Loss: 18.608688354492188\n",
      "Epoch: 15, Batch: 403, D Loss: 0.10112173525672885, G Loss: 18.603744506835938\n",
      "Epoch: 15, Batch: 404, D Loss: 0.09335247120310708, G Loss: 18.506671905517578\n",
      "Epoch: 15, Batch: 405, D Loss: 0.09997367595599194, G Loss: 18.413738250732422\n",
      "Epoch: 15, Batch: 406, D Loss: 0.10540199044629395, G Loss: 18.3898983001709\n",
      "Epoch: 15, Batch: 407, D Loss: 0.1013394943473922, G Loss: 18.401409149169922\n",
      "Epoch: 15, Batch: 408, D Loss: 0.10053692557921279, G Loss: 18.27512550354004\n",
      "Epoch: 15, Batch: 409, D Loss: 0.10457362830533112, G Loss: 18.218652725219727\n",
      "Epoch: 15, Batch: 410, D Loss: 0.09621567917988205, G Loss: 18.137121200561523\n",
      "Epoch: 15, Batch: 411, D Loss: 0.09536787829842286, G Loss: 18.016836166381836\n",
      "Epoch: 15, Batch: 412, D Loss: 0.10471456528559475, G Loss: 17.950035095214844\n",
      "Epoch: 15, Batch: 413, D Loss: 0.09930532508816725, G Loss: 17.88565444946289\n",
      "Epoch: 15, Batch: 414, D Loss: 0.09511456047834521, G Loss: 17.786869049072266\n",
      "Epoch: 15, Batch: 415, D Loss: 0.1046970284391584, G Loss: 17.75660514831543\n",
      "Epoch: 15, Batch: 416, D Loss: 0.10214155394540203, G Loss: 17.75527000427246\n",
      "Epoch: 15, Batch: 417, D Loss: 0.09680779517527327, G Loss: 17.733043670654297\n",
      "Epoch: 15, Batch: 418, D Loss: 0.09508409627627223, G Loss: 17.6823787689209\n",
      "Epoch: 15, Batch: 419, D Loss: 0.1032578156351125, G Loss: 17.67120361328125\n",
      "Epoch: 15, Batch: 420, D Loss: 0.09873994010072895, G Loss: 17.667354583740234\n",
      "Epoch: 15, Batch: 421, D Loss: 0.09758220938143758, G Loss: 17.65324592590332\n",
      "Epoch: 15, Batch: 422, D Loss: 0.10143190947450265, G Loss: 17.66596221923828\n",
      "Epoch: 15, Batch: 423, D Loss: 0.10022717281182203, G Loss: 17.67808723449707\n",
      "Epoch: 15, Batch: 424, D Loss: 0.0965116354040072, G Loss: 17.652687072753906\n",
      "Epoch: 15, Batch: 425, D Loss: 0.09472801158919708, G Loss: 17.59224510192871\n",
      "Epoch: 15, Batch: 426, D Loss: 0.09851380863154802, G Loss: 17.550395965576172\n",
      "Epoch: 15, Batch: 427, D Loss: 0.10763587469404357, G Loss: 17.61048698425293\n",
      "Epoch: 15, Batch: 428, D Loss: 0.09438485277219932, G Loss: 17.626312255859375\n",
      "Epoch: 15, Batch: 429, D Loss: 0.1030031699581615, G Loss: 17.674091339111328\n",
      "Epoch: 15, Batch: 430, D Loss: 0.09636126022129776, G Loss: 17.676843643188477\n",
      "Epoch: 15, Batch: 431, D Loss: 0.09460164940589344, G Loss: 17.628877639770508\n",
      "Epoch: 15, Batch: 432, D Loss: 0.09895371281081289, G Loss: 17.592086791992188\n",
      "Epoch: 15, Batch: 433, D Loss: 0.09911030193157533, G Loss: 17.580495834350586\n",
      "Epoch: 15, Batch: 434, D Loss: 0.10386269180774388, G Loss: 17.62594223022461\n",
      "Epoch: 15, Batch: 435, D Loss: 0.09678749340407222, G Loss: 17.654991149902344\n",
      "Epoch: 15, Batch: 436, D Loss: 0.10054064104126326, G Loss: 17.696596145629883\n",
      "Epoch: 15, Batch: 437, D Loss: 0.10008784651504943, G Loss: 17.731204986572266\n",
      "Epoch: 15, Batch: 438, D Loss: 0.09400005159474478, G Loss: 17.703857421875\n",
      "Epoch: 15, Batch: 439, D Loss: 0.09935476179507852, G Loss: 17.677120208740234\n",
      "Epoch: 15, Batch: 440, D Loss: 0.09943941548808333, G Loss: 17.66563606262207\n",
      "Epoch: 15, Batch: 441, D Loss: 0.09288280805799065, G Loss: 17.613643646240234\n",
      "Epoch: 15, Batch: 442, D Loss: 0.09680139663122134, G Loss: 17.590299606323242\n",
      "Epoch: 15, Batch: 443, D Loss: 0.09516708217395298, G Loss: 17.578289031982422\n",
      "Epoch: 15, Batch: 444, D Loss: 0.0961199220089366, G Loss: 17.59177017211914\n",
      "Epoch: 15, Batch: 445, D Loss: 0.09939971186317909, G Loss: 17.651395797729492\n",
      "Epoch: 15, Batch: 446, D Loss: 0.09920486357306757, G Loss: 17.722553253173828\n",
      "Epoch: 15, Batch: 447, D Loss: 0.09898662056800411, G Loss: 17.771169662475586\n",
      "Epoch: 15, Batch: 448, D Loss: 0.10496799828105452, G Loss: 17.835895538330078\n",
      "Epoch: 15, Batch: 449, D Loss: 0.10329210146187773, G Loss: 17.877309799194336\n",
      "Epoch: 15, Batch: 450, D Loss: 0.10160343468721234, G Loss: 17.86904525756836\n",
      "Epoch: 15, Batch: 451, D Loss: 0.09379138229392403, G Loss: 17.75453758239746\n",
      "Epoch: 15, Batch: 452, D Loss: 0.10094848558394887, G Loss: 17.6503963470459\n",
      "Epoch: 15, Batch: 453, D Loss: 0.09717793403097819, G Loss: 17.56414794921875\n",
      "Epoch: 15, Batch: 454, D Loss: 0.1008772521322916, G Loss: 17.555461883544922\n",
      "Epoch: 15, Batch: 455, D Loss: 0.09098352951051059, G Loss: 17.529804229736328\n",
      "Epoch: 15, Batch: 456, D Loss: 0.09433004736041006, G Loss: 17.5266170501709\n",
      "Epoch: 15, Batch: 457, D Loss: 0.0995428232933353, G Loss: 17.59737205505371\n",
      "Epoch: 15, Batch: 458, D Loss: 0.09968813096540696, G Loss: 17.70218276977539\n",
      "Epoch: 15, Batch: 459, D Loss: 0.0956381137086817, G Loss: 17.764812469482422\n",
      "Epoch: 15, Batch: 460, D Loss: 0.10427435667077489, G Loss: 17.84308433532715\n",
      "Epoch: 15, Batch: 461, D Loss: 0.09705662124652115, G Loss: 17.850860595703125\n",
      "Epoch: 15, Batch: 462, D Loss: 0.09563823951729766, G Loss: 17.80137062072754\n",
      "Epoch: 15, Batch: 463, D Loss: 0.09867295095900097, G Loss: 17.732524871826172\n",
      "Epoch: 15, Batch: 464, D Loss: 0.09784368710018931, G Loss: 17.668121337890625\n",
      "Epoch: 15, Batch: 465, D Loss: 0.09741892261006768, G Loss: 17.625490188598633\n",
      "Epoch: 15, Batch: 466, D Loss: 0.09179156668292254, G Loss: 17.57122039794922\n",
      "Epoch: 15, Batch: 467, D Loss: 0.10393735415396055, G Loss: 17.621212005615234\n",
      "Epoch: 16, Batch: 0, D Loss: 0.0974828857386747, G Loss: 17.6862850189209\n",
      "Epoch: 16, Batch: 1, D Loss: 0.10514673820217091, G Loss: 17.813430786132812\n",
      "Epoch: 16, Batch: 2, D Loss: 0.09438727203630659, G Loss: 17.855634689331055\n",
      "Epoch: 16, Batch: 3, D Loss: 0.09825251391654533, G Loss: 17.844173431396484\n",
      "Epoch: 16, Batch: 4, D Loss: 0.10001808567678516, G Loss: 17.806676864624023\n",
      "Epoch: 16, Batch: 5, D Loss: 0.0979347846098193, G Loss: 17.74302864074707\n",
      "Epoch: 16, Batch: 6, D Loss: 0.09557818905927995, G Loss: 17.65843391418457\n",
      "Epoch: 16, Batch: 7, D Loss: 0.10116956724047288, G Loss: 17.633197784423828\n",
      "Epoch: 16, Batch: 8, D Loss: 0.09875392514765569, G Loss: 17.647348403930664\n",
      "Epoch: 16, Batch: 9, D Loss: 0.10301328004897936, G Loss: 17.717205047607422\n",
      "Epoch: 16, Batch: 10, D Loss: 0.09278917572760026, G Loss: 17.727434158325195\n",
      "Epoch: 16, Batch: 11, D Loss: 0.09841154766110627, G Loss: 17.73676872253418\n",
      "Epoch: 16, Batch: 12, D Loss: 0.09090224929015633, G Loss: 17.680822372436523\n",
      "Epoch: 16, Batch: 13, D Loss: 0.10067939321954533, G Loss: 17.670513153076172\n",
      "Epoch: 16, Batch: 14, D Loss: 0.09878258709203891, G Loss: 17.691781997680664\n",
      "Epoch: 16, Batch: 15, D Loss: 0.10237477976369558, G Loss: 17.75698471069336\n",
      "Epoch: 16, Batch: 16, D Loss: 0.10252995226477957, G Loss: 17.844181060791016\n",
      "Epoch: 16, Batch: 17, D Loss: 0.10434808687307484, G Loss: 17.930910110473633\n",
      "Epoch: 16, Batch: 18, D Loss: 0.09139841141205718, G Loss: 17.884296417236328\n",
      "Epoch: 16, Batch: 19, D Loss: 0.09603912539309967, G Loss: 17.78443145751953\n",
      "Epoch: 16, Batch: 20, D Loss: 0.08897314510497978, G Loss: 17.610620498657227\n",
      "Epoch: 16, Batch: 21, D Loss: 0.09788900309923765, G Loss: 17.508352279663086\n",
      "Epoch: 16, Batch: 22, D Loss: 0.09469470903365451, G Loss: 17.476165771484375\n",
      "Epoch: 16, Batch: 23, D Loss: 0.10022154189165633, G Loss: 17.562501907348633\n",
      "Epoch: 16, Batch: 24, D Loss: 0.10007631378434922, G Loss: 17.712392807006836\n",
      "Epoch: 16, Batch: 25, D Loss: 0.10219980959812691, G Loss: 17.881446838378906\n",
      "Epoch: 16, Batch: 26, D Loss: 0.09532976234031842, G Loss: 17.946504592895508\n",
      "Epoch: 16, Batch: 27, D Loss: 0.10753712834361906, G Loss: 18.011749267578125\n",
      "Epoch: 16, Batch: 28, D Loss: 0.09954605267580696, G Loss: 17.990772247314453\n",
      "Epoch: 16, Batch: 29, D Loss: 0.10282228190233322, G Loss: 17.930891036987305\n",
      "Epoch: 16, Batch: 30, D Loss: 0.09342561057195997, G Loss: 17.776063919067383\n",
      "Epoch: 16, Batch: 31, D Loss: 0.09404207317119173, G Loss: 17.606754302978516\n",
      "Epoch: 16, Batch: 32, D Loss: 0.10200084414366639, G Loss: 17.556964874267578\n",
      "Epoch: 16, Batch: 33, D Loss: 0.0993243572612208, G Loss: 17.58774185180664\n",
      "Epoch: 16, Batch: 34, D Loss: 0.09234891471068973, G Loss: 17.622812271118164\n",
      "Epoch: 16, Batch: 35, D Loss: 0.09635699873035275, G Loss: 17.68000030517578\n",
      "Epoch: 16, Batch: 36, D Loss: 0.10902659071149046, G Loss: 17.835372924804688\n",
      "Epoch: 16, Batch: 37, D Loss: 0.10474387635892057, G Loss: 17.996553421020508\n",
      "Epoch: 16, Batch: 38, D Loss: 0.10382548698885108, G Loss: 18.09829330444336\n",
      "Epoch: 16, Batch: 39, D Loss: 0.09966641615841354, G Loss: 18.081602096557617\n",
      "Epoch: 16, Batch: 40, D Loss: 0.09790239486394459, G Loss: 17.959590911865234\n",
      "Epoch: 16, Batch: 41, D Loss: 0.09467700999018991, G Loss: 17.771337509155273\n",
      "Epoch: 16, Batch: 42, D Loss: 0.10165524010166127, G Loss: 17.65514373779297\n",
      "Epoch: 16, Batch: 43, D Loss: 0.1019981686293896, G Loss: 17.641660690307617\n",
      "Epoch: 16, Batch: 44, D Loss: 0.09431454879911083, G Loss: 17.649150848388672\n",
      "Epoch: 16, Batch: 45, D Loss: 0.10096270883135983, G Loss: 17.729036331176758\n",
      "Epoch: 16, Batch: 46, D Loss: 0.09980870238617268, G Loss: 17.83298683166504\n",
      "Epoch: 16, Batch: 47, D Loss: 0.09673223769459405, G Loss: 17.897430419921875\n",
      "Epoch: 16, Batch: 48, D Loss: 0.09794518439897093, G Loss: 17.921234130859375\n",
      "Epoch: 16, Batch: 49, D Loss: 0.0998502307209792, G Loss: 17.918481826782227\n",
      "Epoch: 16, Batch: 50, D Loss: 0.09879440908419568, G Loss: 17.88906478881836\n",
      "Epoch: 16, Batch: 51, D Loss: 0.09095610083097228, G Loss: 17.793054580688477\n",
      "Epoch: 16, Batch: 52, D Loss: 0.10244890508858706, G Loss: 17.76339340209961\n",
      "Epoch: 16, Batch: 53, D Loss: 0.09395871544825685, G Loss: 17.737060546875\n",
      "Epoch: 16, Batch: 54, D Loss: 0.09778777749028489, G Loss: 17.749778747558594\n",
      "Epoch: 16, Batch: 55, D Loss: 0.10056438496727083, G Loss: 17.815814971923828\n",
      "Epoch: 16, Batch: 56, D Loss: 0.10291350755899575, G Loss: 17.917068481445312\n",
      "Epoch: 16, Batch: 57, D Loss: 0.09392403879599431, G Loss: 17.949604034423828\n",
      "Epoch: 16, Batch: 58, D Loss: 0.10104499057667393, G Loss: 17.97471809387207\n",
      "Epoch: 16, Batch: 59, D Loss: 0.098413385852691, G Loss: 17.96478271484375\n",
      "Epoch: 16, Batch: 60, D Loss: 0.10172010260312625, G Loss: 17.95686912536621\n",
      "Epoch: 16, Batch: 61, D Loss: 0.09178108060505341, G Loss: 17.878450393676758\n",
      "Epoch: 16, Batch: 62, D Loss: 0.09601546230395197, G Loss: 17.79941749572754\n",
      "Epoch: 16, Batch: 63, D Loss: 0.10000027164992975, G Loss: 17.782970428466797\n",
      "Epoch: 16, Batch: 64, D Loss: 0.09123016368009829, G Loss: 17.747161865234375\n",
      "Epoch: 16, Batch: 65, D Loss: 0.09665111683538985, G Loss: 17.755979537963867\n",
      "Epoch: 16, Batch: 66, D Loss: 0.0992425774216592, G Loss: 17.818714141845703\n",
      "Epoch: 16, Batch: 67, D Loss: 0.10237594811938244, G Loss: 17.925344467163086\n",
      "Epoch: 16, Batch: 68, D Loss: 0.09887223732009343, G Loss: 18.006513595581055\n",
      "Epoch: 16, Batch: 69, D Loss: 0.09522598987073039, G Loss: 18.02271270751953\n",
      "Epoch: 16, Batch: 70, D Loss: 0.10025054960432467, G Loss: 18.023929595947266\n",
      "Epoch: 16, Batch: 71, D Loss: 0.11089408367289888, G Loss: 18.099275588989258\n",
      "Epoch: 16, Batch: 72, D Loss: 0.09634622134483006, G Loss: 18.08970832824707\n",
      "Epoch: 16, Batch: 73, D Loss: 0.0967046690372384, G Loss: 18.028278350830078\n",
      "Epoch: 16, Batch: 74, D Loss: 0.09270461693484133, G Loss: 17.904951095581055\n",
      "Epoch: 16, Batch: 75, D Loss: 0.10110833613001002, G Loss: 17.849811553955078\n",
      "Epoch: 16, Batch: 76, D Loss: 0.09894242275645038, G Loss: 17.854228973388672\n",
      "Epoch: 16, Batch: 77, D Loss: 0.10005601603310765, G Loss: 17.91621971130371\n",
      "Epoch: 16, Batch: 78, D Loss: 0.09872456690513864, G Loss: 17.992473602294922\n",
      "Epoch: 16, Batch: 79, D Loss: 0.09873623396893771, G Loss: 18.058753967285156\n",
      "Epoch: 16, Batch: 80, D Loss: 0.09294503160051093, G Loss: 18.04619026184082\n",
      "Epoch: 16, Batch: 81, D Loss: 0.0953190028697648, G Loss: 17.999391555786133\n",
      "Epoch: 16, Batch: 82, D Loss: 0.10525712378618302, G Loss: 18.02269744873047\n",
      "Epoch: 16, Batch: 83, D Loss: 0.09706174578590465, G Loss: 18.03072166442871\n",
      "Epoch: 16, Batch: 84, D Loss: 0.09570594132285493, G Loss: 18.013307571411133\n",
      "Epoch: 16, Batch: 85, D Loss: 0.10149849203708694, G Loss: 18.03621482849121\n",
      "Epoch: 16, Batch: 86, D Loss: 0.09878363444099492, G Loss: 18.051006317138672\n",
      "Epoch: 16, Batch: 87, D Loss: 0.09409847100421498, G Loss: 18.021759033203125\n",
      "Epoch: 16, Batch: 88, D Loss: 0.10189937052677012, G Loss: 18.0284481048584\n",
      "Epoch: 16, Batch: 89, D Loss: 0.10545576334110063, G Loss: 18.093399047851562\n",
      "Epoch: 16, Batch: 90, D Loss: 0.09910502964546541, G Loss: 18.131893157958984\n",
      "Epoch: 16, Batch: 91, D Loss: 0.09592869807627968, G Loss: 18.111051559448242\n",
      "Epoch: 16, Batch: 92, D Loss: 0.10190845220428457, G Loss: 18.102643966674805\n",
      "Epoch: 16, Batch: 93, D Loss: 0.1025169709224949, G Loss: 18.110584259033203\n",
      "Epoch: 16, Batch: 94, D Loss: 0.10135296664402382, G Loss: 18.123483657836914\n",
      "Epoch: 16, Batch: 95, D Loss: 0.09485242460091037, G Loss: 18.078243255615234\n",
      "Epoch: 16, Batch: 96, D Loss: 0.10189706796607023, G Loss: 18.064298629760742\n",
      "Epoch: 16, Batch: 97, D Loss: 0.10305928398353092, G Loss: 18.09024429321289\n",
      "Epoch: 16, Batch: 98, D Loss: 0.10008302270734237, G Loss: 18.120698928833008\n",
      "Epoch: 16, Batch: 99, D Loss: 0.09946457222621907, G Loss: 18.13188362121582\n",
      "Epoch: 16, Batch: 100, D Loss: 0.09315659794236186, G Loss: 18.073101043701172\n",
      "Epoch: 16, Batch: 101, D Loss: 0.09734227490687086, G Loss: 18.021364212036133\n",
      "Epoch: 16, Batch: 102, D Loss: 0.10414447624178047, G Loss: 18.05145263671875\n",
      "Epoch: 16, Batch: 103, D Loss: 0.09514073999347561, G Loss: 18.068803787231445\n",
      "Epoch: 16, Batch: 104, D Loss: 0.1001088465160942, G Loss: 18.113462448120117\n",
      "Epoch: 16, Batch: 105, D Loss: 0.10448238156258771, G Loss: 18.205472946166992\n",
      "Epoch: 16, Batch: 106, D Loss: 0.09556991475343679, G Loss: 18.226116180419922\n",
      "Epoch: 16, Batch: 107, D Loss: 0.10310929120582513, G Loss: 18.259021759033203\n",
      "Epoch: 16, Batch: 108, D Loss: 0.0929140136516522, G Loss: 18.2049560546875\n",
      "Epoch: 16, Batch: 109, D Loss: 0.10103910302854713, G Loss: 18.171348571777344\n",
      "Epoch: 16, Batch: 110, D Loss: 0.10263160510659786, G Loss: 18.177640914916992\n",
      "Epoch: 16, Batch: 111, D Loss: 0.09915009025301025, G Loss: 18.202423095703125\n",
      "Epoch: 16, Batch: 112, D Loss: 0.10189871350101631, G Loss: 18.254676818847656\n",
      "Epoch: 16, Batch: 113, D Loss: 0.09633146067477982, G Loss: 18.26837921142578\n",
      "Epoch: 16, Batch: 114, D Loss: 0.10140261630976166, G Loss: 18.286109924316406\n",
      "Epoch: 16, Batch: 115, D Loss: 0.10150209637312857, G Loss: 18.299592971801758\n",
      "Epoch: 16, Batch: 116, D Loss: 0.09707873884446583, G Loss: 18.281572341918945\n",
      "Epoch: 16, Batch: 117, D Loss: 0.10141029037830585, G Loss: 18.283958435058594\n",
      "Epoch: 16, Batch: 118, D Loss: 0.10108621243661986, G Loss: 18.294240951538086\n",
      "Epoch: 16, Batch: 119, D Loss: 0.09812739314503416, G Loss: 18.29214859008789\n",
      "Epoch: 16, Batch: 120, D Loss: 0.09886188646751215, G Loss: 18.23282241821289\n",
      "Epoch: 16, Batch: 121, D Loss: 0.09346017873308021, G Loss: 18.145275115966797\n",
      "Epoch: 16, Batch: 122, D Loss: 0.09887517175926641, G Loss: 18.091999053955078\n",
      "Epoch: 16, Batch: 123, D Loss: 0.09869309472417864, G Loss: 18.07018280029297\n",
      "Epoch: 16, Batch: 124, D Loss: 0.09626086774038356, G Loss: 18.04945182800293\n",
      "Epoch: 16, Batch: 125, D Loss: 0.09743191283758001, G Loss: 18.04396629333496\n",
      "Epoch: 16, Batch: 126, D Loss: 0.09781727921962524, G Loss: 18.048450469970703\n",
      "Epoch: 16, Batch: 127, D Loss: 0.09896443759019391, G Loss: 18.063676834106445\n",
      "Epoch: 16, Batch: 128, D Loss: 0.09945655574417023, G Loss: 18.08858871459961\n",
      "Epoch: 16, Batch: 129, D Loss: 0.09785850297371645, G Loss: 18.090587615966797\n",
      "Epoch: 16, Batch: 130, D Loss: 0.09863000317453574, G Loss: 18.08042335510254\n",
      "Epoch: 16, Batch: 131, D Loss: 0.09870023244393922, G Loss: 18.06348419189453\n",
      "Epoch: 16, Batch: 132, D Loss: 0.09898582820505597, G Loss: 18.050640106201172\n",
      "Epoch: 16, Batch: 133, D Loss: 0.09941265712195957, G Loss: 18.047584533691406\n",
      "Epoch: 16, Batch: 134, D Loss: 0.09125347442191423, G Loss: 17.9818058013916\n",
      "Epoch: 16, Batch: 135, D Loss: 0.09457069693181896, G Loss: 17.916166305541992\n",
      "Epoch: 16, Batch: 136, D Loss: 0.09319610252483912, G Loss: 17.869373321533203\n",
      "Epoch: 16, Batch: 137, D Loss: 0.1025364184667783, G Loss: 17.937406539916992\n",
      "Epoch: 16, Batch: 138, D Loss: 0.10133498176667377, G Loss: 18.060760498046875\n",
      "Epoch: 16, Batch: 139, D Loss: 0.10017375576652476, G Loss: 18.178001403808594\n",
      "Epoch: 16, Batch: 140, D Loss: 0.0947496209221681, G Loss: 18.19251823425293\n",
      "Epoch: 16, Batch: 141, D Loss: 0.10014619569566285, G Loss: 18.1680965423584\n",
      "Epoch: 16, Batch: 142, D Loss: 0.100204757484053, G Loss: 18.124065399169922\n",
      "Epoch: 16, Batch: 143, D Loss: 0.0977536211227652, G Loss: 18.066158294677734\n",
      "Epoch: 16, Batch: 144, D Loss: 0.10546704341977042, G Loss: 18.08640480041504\n",
      "Epoch: 16, Batch: 145, D Loss: 0.09387641364121402, G Loss: 18.058069229125977\n",
      "Epoch: 16, Batch: 146, D Loss: 0.10383222214285093, G Loss: 18.08856964111328\n",
      "Epoch: 16, Batch: 147, D Loss: 0.09534753812702501, G Loss: 18.0841064453125\n",
      "Epoch: 16, Batch: 148, D Loss: 0.10033267688366587, G Loss: 18.09282875061035\n",
      "Epoch: 16, Batch: 149, D Loss: 0.09958315584449506, G Loss: 18.107385635375977\n",
      "Epoch: 16, Batch: 150, D Loss: 0.10159226432899082, G Loss: 18.144058227539062\n",
      "Epoch: 16, Batch: 151, D Loss: 0.09968725498027986, G Loss: 18.168012619018555\n",
      "Epoch: 16, Batch: 152, D Loss: 0.10138073456789165, G Loss: 18.18451690673828\n",
      "Epoch: 16, Batch: 153, D Loss: 0.09561628750309037, G Loss: 18.14364242553711\n",
      "Epoch: 16, Batch: 154, D Loss: 0.09392140004294758, G Loss: 18.06177520751953\n",
      "Epoch: 16, Batch: 155, D Loss: 0.0963310673663762, G Loss: 17.990421295166016\n",
      "Epoch: 16, Batch: 156, D Loss: 0.09802726688122387, G Loss: 17.970767974853516\n",
      "Epoch: 16, Batch: 157, D Loss: 0.09530909392421538, G Loss: 17.98592758178711\n",
      "Epoch: 16, Batch: 158, D Loss: 0.0989447310332432, G Loss: 18.06033706665039\n",
      "Epoch: 16, Batch: 159, D Loss: 0.09961819582663756, G Loss: 18.16364288330078\n",
      "Epoch: 16, Batch: 160, D Loss: 0.09506711246463473, G Loss: 18.220003128051758\n",
      "Epoch: 16, Batch: 161, D Loss: 0.10241523232426264, G Loss: 18.279186248779297\n",
      "Epoch: 16, Batch: 162, D Loss: 0.09976774281201672, G Loss: 18.29222869873047\n",
      "Epoch: 16, Batch: 163, D Loss: 0.099884784020837, G Loss: 18.267822265625\n",
      "Epoch: 16, Batch: 164, D Loss: 0.10146608798325296, G Loss: 18.229015350341797\n",
      "Epoch: 16, Batch: 165, D Loss: 0.09963378933006073, G Loss: 18.176097869873047\n",
      "Epoch: 16, Batch: 166, D Loss: 0.1047988448891699, G Loss: 18.174175262451172\n",
      "Epoch: 16, Batch: 167, D Loss: 0.1026056174149872, G Loss: 18.194978713989258\n",
      "Epoch: 16, Batch: 168, D Loss: 0.09926386802766807, G Loss: 18.199485778808594\n",
      "Epoch: 16, Batch: 169, D Loss: 0.09446786240909111, G Loss: 18.14527130126953\n",
      "Epoch: 16, Batch: 170, D Loss: 0.1040270394337548, G Loss: 18.146697998046875\n",
      "Epoch: 16, Batch: 171, D Loss: 0.10194594314819705, G Loss: 18.17836570739746\n",
      "Epoch: 16, Batch: 172, D Loss: 0.10049419736870968, G Loss: 18.19451904296875\n",
      "Epoch: 16, Batch: 173, D Loss: 0.09983540952249648, G Loss: 18.197858810424805\n",
      "Epoch: 16, Batch: 174, D Loss: 0.09575923425532817, G Loss: 18.15734100341797\n",
      "Epoch: 16, Batch: 175, D Loss: 0.1064413402850568, G Loss: 18.190431594848633\n",
      "Epoch: 16, Batch: 176, D Loss: 0.09858242302226294, G Loss: 18.204435348510742\n",
      "Epoch: 16, Batch: 177, D Loss: 0.09824634221990802, G Loss: 18.19573974609375\n",
      "Epoch: 16, Batch: 178, D Loss: 0.09821446128929479, G Loss: 18.17218589782715\n",
      "Epoch: 16, Batch: 179, D Loss: 0.10500223075556248, G Loss: 18.20240020751953\n",
      "Epoch: 16, Batch: 180, D Loss: 0.10034507381083602, G Loss: 18.229965209960938\n",
      "Epoch: 16, Batch: 181, D Loss: 0.0988570586764177, G Loss: 18.22970962524414\n",
      "Epoch: 16, Batch: 182, D Loss: 0.10070726882240955, G Loss: 18.225040435791016\n",
      "Epoch: 16, Batch: 183, D Loss: 0.09892110395386577, G Loss: 18.20718002319336\n",
      "Epoch: 16, Batch: 184, D Loss: 0.09816983968499393, G Loss: 18.185121536254883\n",
      "Epoch: 16, Batch: 185, D Loss: 0.09728850323081195, G Loss: 18.15253448486328\n",
      "Epoch: 16, Batch: 186, D Loss: 0.09379859198803775, G Loss: 18.091476440429688\n",
      "Epoch: 16, Batch: 187, D Loss: 0.09835858596585112, G Loss: 18.081836700439453\n",
      "Epoch: 16, Batch: 188, D Loss: 0.0914050560655233, G Loss: 18.059967041015625\n",
      "Epoch: 16, Batch: 189, D Loss: 0.09858978496499526, G Loss: 18.10134506225586\n",
      "Epoch: 16, Batch: 190, D Loss: 0.1018041884309171, G Loss: 18.210329055786133\n",
      "Epoch: 16, Batch: 191, D Loss: 0.10223294628811574, G Loss: 18.33013916015625\n",
      "Epoch: 16, Batch: 192, D Loss: 0.09990173361375865, G Loss: 18.39817237854004\n",
      "Epoch: 16, Batch: 193, D Loss: 0.10463282220600112, G Loss: 18.442174911499023\n",
      "Epoch: 16, Batch: 194, D Loss: 0.08813011425928163, G Loss: 18.309499740600586\n",
      "Epoch: 16, Batch: 195, D Loss: 0.10246326618374857, G Loss: 18.209304809570312\n",
      "Epoch: 16, Batch: 196, D Loss: 0.10315402478509705, G Loss: 18.18307876586914\n",
      "Epoch: 16, Batch: 197, D Loss: 0.1051045121698353, G Loss: 18.240192413330078\n",
      "Epoch: 16, Batch: 198, D Loss: 0.09871460336063587, G Loss: 18.289165496826172\n",
      "Epoch: 16, Batch: 199, D Loss: 0.09851859329141188, G Loss: 18.30962371826172\n",
      "Epoch: 16, Batch: 200, D Loss: 0.0955093485448133, G Loss: 18.273391723632812\n",
      "Epoch: 16, Batch: 201, D Loss: 0.0951472878981372, G Loss: 18.20282745361328\n",
      "Epoch: 16, Batch: 202, D Loss: 0.09668271139432871, G Loss: 18.145206451416016\n",
      "Epoch: 16, Batch: 203, D Loss: 0.1068190623280838, G Loss: 18.213651657104492\n",
      "Epoch: 16, Batch: 204, D Loss: 0.10196912872705477, G Loss: 18.311922073364258\n",
      "Epoch: 16, Batch: 205, D Loss: 0.10131037769046314, G Loss: 18.394424438476562\n",
      "Epoch: 16, Batch: 206, D Loss: 0.10510433216689785, G Loss: 18.457782745361328\n",
      "Epoch: 16, Batch: 207, D Loss: 0.09580901014052712, G Loss: 18.410533905029297\n",
      "Epoch: 16, Batch: 208, D Loss: 0.10386182885935336, G Loss: 18.36229133605957\n",
      "Epoch: 16, Batch: 209, D Loss: 0.10298690738845773, G Loss: 18.330774307250977\n",
      "Epoch: 16, Batch: 210, D Loss: 0.10321115506909884, G Loss: 18.322246551513672\n",
      "Epoch: 16, Batch: 211, D Loss: 0.09733115698742223, G Loss: 18.287023544311523\n",
      "Epoch: 16, Batch: 212, D Loss: 0.0984555988105571, G Loss: 18.25250244140625\n",
      "Epoch: 16, Batch: 213, D Loss: 0.0994148313682377, G Loss: 18.248634338378906\n",
      "Epoch: 16, Batch: 214, D Loss: 0.09892055980788106, G Loss: 18.266111373901367\n",
      "Epoch: 16, Batch: 215, D Loss: 0.09777775984327342, G Loss: 18.28635025024414\n",
      "Epoch: 16, Batch: 216, D Loss: 0.10272846927472656, G Loss: 18.33829116821289\n",
      "Epoch: 16, Batch: 217, D Loss: 0.09805250703761015, G Loss: 18.363351821899414\n",
      "Epoch: 16, Batch: 218, D Loss: 0.10406668999233126, G Loss: 18.416259765625\n",
      "Epoch: 16, Batch: 219, D Loss: 0.09633628784701376, G Loss: 18.40323257446289\n",
      "Epoch: 16, Batch: 220, D Loss: 0.10366188499505169, G Loss: 18.399789810180664\n",
      "Epoch: 16, Batch: 221, D Loss: 0.09562862447243337, G Loss: 18.33662986755371\n",
      "Epoch: 16, Batch: 222, D Loss: 0.10405080567207037, G Loss: 18.326688766479492\n",
      "Epoch: 16, Batch: 223, D Loss: 0.09412603643640916, G Loss: 18.278762817382812\n",
      "Epoch: 16, Batch: 224, D Loss: 0.09582625174782677, G Loss: 18.233074188232422\n",
      "Epoch: 16, Batch: 225, D Loss: 0.09761383248383604, G Loss: 18.215227127075195\n",
      "Epoch: 16, Batch: 226, D Loss: 0.09332037593329723, G Loss: 18.193246841430664\n",
      "Epoch: 16, Batch: 227, D Loss: 0.10241318355450169, G Loss: 18.2589054107666\n",
      "Epoch: 16, Batch: 228, D Loss: 0.09166682350009703, G Loss: 18.273143768310547\n",
      "Epoch: 16, Batch: 229, D Loss: 0.09587880804142213, G Loss: 18.271270751953125\n",
      "Epoch: 16, Batch: 230, D Loss: 0.09479201427215056, G Loss: 18.249914169311523\n",
      "Epoch: 16, Batch: 231, D Loss: 0.10128471093837543, G Loss: 18.28091812133789\n",
      "Epoch: 16, Batch: 232, D Loss: 0.10682747310267526, G Loss: 18.3922061920166\n",
      "Epoch: 16, Batch: 233, D Loss: 0.10030095773186964, G Loss: 18.4694766998291\n",
      "Epoch: 16, Batch: 234, D Loss: 0.10083230309542257, G Loss: 18.49561309814453\n",
      "Epoch: 16, Batch: 235, D Loss: 0.091658313994885, G Loss: 18.39434242248535\n",
      "Epoch: 16, Batch: 236, D Loss: 0.09904505106089667, G Loss: 18.302745819091797\n",
      "Epoch: 16, Batch: 237, D Loss: 0.10340752276922904, G Loss: 18.280254364013672\n",
      "Epoch: 16, Batch: 238, D Loss: 0.09839436983420224, G Loss: 18.293212890625\n",
      "Epoch: 16, Batch: 239, D Loss: 0.1002168710551814, G Loss: 18.349130630493164\n",
      "Epoch: 16, Batch: 240, D Loss: 0.10136308292125351, G Loss: 18.424835205078125\n",
      "Epoch: 16, Batch: 241, D Loss: 0.097819675933569, G Loss: 18.456035614013672\n",
      "Epoch: 16, Batch: 242, D Loss: 0.0944066245970645, G Loss: 18.416234970092773\n",
      "Epoch: 16, Batch: 243, D Loss: 0.10108843954105184, G Loss: 18.393569946289062\n",
      "Epoch: 16, Batch: 244, D Loss: 0.09854232293277754, G Loss: 18.376407623291016\n",
      "Epoch: 16, Batch: 245, D Loss: 0.09935282694564096, G Loss: 18.372501373291016\n",
      "Epoch: 16, Batch: 246, D Loss: 0.10432668539900858, G Loss: 18.427982330322266\n",
      "Epoch: 16, Batch: 247, D Loss: 0.10173833851831393, G Loss: 18.485429763793945\n",
      "Epoch: 16, Batch: 248, D Loss: 0.10101028247271504, G Loss: 18.51883316040039\n",
      "Epoch: 16, Batch: 249, D Loss: 0.09874365190475798, G Loss: 18.504322052001953\n",
      "Epoch: 16, Batch: 250, D Loss: 0.10279128416371952, G Loss: 18.500226974487305\n",
      "Epoch: 16, Batch: 251, D Loss: 0.10402439991032919, G Loss: 18.522830963134766\n",
      "Epoch: 16, Batch: 252, D Loss: 0.09607461552874019, G Loss: 18.495601654052734\n",
      "Epoch: 16, Batch: 253, D Loss: 0.09684162318437783, G Loss: 18.44458770751953\n",
      "Epoch: 16, Batch: 254, D Loss: 0.09404702247037999, G Loss: 18.37099266052246\n",
      "Epoch: 16, Batch: 255, D Loss: 0.10176305996031276, G Loss: 18.379581451416016\n",
      "Epoch: 16, Batch: 256, D Loss: 0.09648474072215318, G Loss: 18.415016174316406\n",
      "Epoch: 16, Batch: 257, D Loss: 0.09322277957926683, G Loss: 18.42069435119629\n",
      "Epoch: 16, Batch: 258, D Loss: 0.10013041388218502, G Loss: 18.467090606689453\n",
      "Epoch: 16, Batch: 259, D Loss: 0.1000126795344971, G Loss: 18.534683227539062\n",
      "Epoch: 16, Batch: 260, D Loss: 0.09440198984559434, G Loss: 18.544565200805664\n",
      "Epoch: 16, Batch: 261, D Loss: 0.10379776791061657, G Loss: 18.585132598876953\n",
      "Epoch: 16, Batch: 262, D Loss: 0.1015199762469714, G Loss: 18.62184715270996\n",
      "Epoch: 16, Batch: 263, D Loss: 0.09717883581347042, G Loss: 18.609045028686523\n",
      "Epoch: 16, Batch: 264, D Loss: 0.09492675644006887, G Loss: 18.54222297668457\n",
      "Epoch: 16, Batch: 265, D Loss: 0.10081936868682506, G Loss: 18.513118743896484\n",
      "Epoch: 16, Batch: 266, D Loss: 0.09584592746872556, G Loss: 18.479278564453125\n",
      "Epoch: 16, Batch: 267, D Loss: 0.09287932997073911, G Loss: 18.438093185424805\n",
      "Epoch: 16, Batch: 268, D Loss: 0.1040698262871782, G Loss: 18.50233268737793\n",
      "Epoch: 16, Batch: 269, D Loss: 0.09594285937152236, G Loss: 18.55165672302246\n",
      "Epoch: 16, Batch: 270, D Loss: 0.1049547758574052, G Loss: 18.652236938476562\n",
      "Epoch: 16, Batch: 271, D Loss: 0.09474017863206985, G Loss: 18.674232482910156\n",
      "Epoch: 16, Batch: 272, D Loss: 0.095403898774447, G Loss: 18.6202449798584\n",
      "Epoch: 16, Batch: 273, D Loss: 0.10158485591986022, G Loss: 18.582490921020508\n",
      "Epoch: 16, Batch: 274, D Loss: 0.10101168286442608, G Loss: 18.567169189453125\n",
      "Epoch: 16, Batch: 275, D Loss: 0.10416531984724342, G Loss: 18.611631393432617\n",
      "Epoch: 16, Batch: 276, D Loss: 0.10165507004325836, G Loss: 18.65883445739746\n",
      "Epoch: 16, Batch: 277, D Loss: 0.10182479410235556, G Loss: 18.696725845336914\n",
      "Epoch: 16, Batch: 278, D Loss: 0.10125280549123739, G Loss: 18.706449508666992\n",
      "Epoch: 16, Batch: 279, D Loss: 0.0984554701599123, G Loss: 18.670196533203125\n",
      "Epoch: 16, Batch: 280, D Loss: 0.09907789183576954, G Loss: 18.618911743164062\n",
      "Epoch: 16, Batch: 281, D Loss: 0.10531900485807011, G Loss: 18.630002975463867\n",
      "Epoch: 16, Batch: 282, D Loss: 0.0959180783562732, G Loss: 18.606698989868164\n",
      "Epoch: 16, Batch: 283, D Loss: 0.10173001553605854, G Loss: 18.61553955078125\n",
      "Epoch: 16, Batch: 284, D Loss: 0.09510954141354544, G Loss: 18.59052276611328\n",
      "Epoch: 16, Batch: 285, D Loss: 0.09869124418399045, G Loss: 18.585342407226562\n",
      "Epoch: 16, Batch: 286, D Loss: 0.09822503155781215, G Loss: 18.58816909790039\n",
      "Epoch: 16, Batch: 287, D Loss: 0.10071941135177287, G Loss: 18.623735427856445\n",
      "Epoch: 16, Batch: 288, D Loss: 0.1006441454202287, G Loss: 18.669391632080078\n",
      "Epoch: 16, Batch: 289, D Loss: 0.0987732151125904, G Loss: 18.68294334411621\n",
      "Epoch: 16, Batch: 290, D Loss: 0.09899162141105666, G Loss: 18.681102752685547\n",
      "Epoch: 16, Batch: 291, D Loss: 0.10055686921316243, G Loss: 18.669015884399414\n",
      "Epoch: 16, Batch: 292, D Loss: 0.09462473946378758, G Loss: 18.598161697387695\n",
      "Epoch: 16, Batch: 293, D Loss: 0.09861328137723646, G Loss: 18.54784393310547\n",
      "Epoch: 16, Batch: 294, D Loss: 0.10077956758575368, G Loss: 18.550561904907227\n",
      "Epoch: 16, Batch: 295, D Loss: 0.09660637068338707, G Loss: 18.569929122924805\n",
      "Epoch: 16, Batch: 296, D Loss: 0.09930593195502091, G Loss: 18.61709976196289\n",
      "Epoch: 16, Batch: 297, D Loss: 0.09580590239200859, G Loss: 18.628944396972656\n",
      "Epoch: 16, Batch: 298, D Loss: 0.10082431537718506, G Loss: 18.656646728515625\n",
      "Epoch: 16, Batch: 299, D Loss: 0.09954497609954416, G Loss: 18.67172622680664\n",
      "Epoch: 16, Batch: 300, D Loss: 0.09372544688225304, G Loss: 18.620824813842773\n",
      "Epoch: 16, Batch: 301, D Loss: 0.1039086173885777, G Loss: 18.634410858154297\n",
      "Epoch: 16, Batch: 302, D Loss: 0.09830569133723444, G Loss: 18.63884925842285\n",
      "Epoch: 16, Batch: 303, D Loss: 0.09787789391453083, G Loss: 18.628211975097656\n",
      "Epoch: 16, Batch: 304, D Loss: 0.09636404034315804, G Loss: 18.59236717224121\n",
      "Epoch: 16, Batch: 305, D Loss: 0.09673089962755688, G Loss: 18.558650970458984\n",
      "Epoch: 16, Batch: 306, D Loss: 0.10020377174114925, G Loss: 18.573469161987305\n",
      "Epoch: 16, Batch: 307, D Loss: 0.10034916224514845, G Loss: 18.616214752197266\n",
      "Epoch: 16, Batch: 308, D Loss: 0.10175805191166765, G Loss: 18.6815242767334\n",
      "Epoch: 16, Batch: 309, D Loss: 0.10445624959242927, G Loss: 18.76155662536621\n",
      "Epoch: 16, Batch: 310, D Loss: 0.10296839825182236, G Loss: 18.7941837310791\n",
      "Epoch: 16, Batch: 311, D Loss: 0.0952362752231053, G Loss: 18.70695686340332\n",
      "Epoch: 16, Batch: 312, D Loss: 0.10030584435600343, G Loss: 18.595012664794922\n",
      "Epoch: 16, Batch: 313, D Loss: 0.0936359733875185, G Loss: 18.453710556030273\n",
      "Epoch: 16, Batch: 314, D Loss: 0.09810160602859375, G Loss: 18.382017135620117\n",
      "Epoch: 16, Batch: 315, D Loss: 0.10000430558596429, G Loss: 18.41407012939453\n",
      "Epoch: 16, Batch: 316, D Loss: 0.09785489475659359, G Loss: 18.49346351623535\n",
      "Epoch: 16, Batch: 317, D Loss: 0.10317700043568356, G Loss: 18.63085174560547\n",
      "Epoch: 16, Batch: 318, D Loss: 0.09974348184168669, G Loss: 18.732147216796875\n",
      "Epoch: 16, Batch: 319, D Loss: 0.09899226193911792, G Loss: 18.749574661254883\n",
      "Epoch: 16, Batch: 320, D Loss: 0.09789026156262715, G Loss: 18.682950973510742\n",
      "Epoch: 16, Batch: 321, D Loss: 0.09575713835709987, G Loss: 18.56233787536621\n",
      "Epoch: 16, Batch: 322, D Loss: 0.09279676247991375, G Loss: 18.42572021484375\n",
      "Epoch: 16, Batch: 323, D Loss: 0.09733723617521495, G Loss: 18.365671157836914\n",
      "Epoch: 16, Batch: 324, D Loss: 0.10324369876798256, G Loss: 18.44814682006836\n",
      "Epoch: 16, Batch: 325, D Loss: 0.09978350703794225, G Loss: 18.587963104248047\n",
      "Epoch: 16, Batch: 326, D Loss: 0.09697816176080654, G Loss: 18.693078994750977\n",
      "Epoch: 16, Batch: 327, D Loss: 0.10426511231536773, G Loss: 18.79397964477539\n",
      "Epoch: 16, Batch: 328, D Loss: 0.10471128260558071, G Loss: 18.85566520690918\n",
      "Epoch: 16, Batch: 329, D Loss: 0.09928196999795547, G Loss: 18.81206512451172\n",
      "Epoch: 16, Batch: 330, D Loss: 0.09912119421137167, G Loss: 18.690387725830078\n",
      "Epoch: 16, Batch: 331, D Loss: 0.10364951595159777, G Loss: 18.593204498291016\n",
      "Epoch: 16, Batch: 332, D Loss: 0.10039714414009149, G Loss: 18.52908706665039\n",
      "Epoch: 16, Batch: 333, D Loss: 0.09777319888108238, G Loss: 18.49501609802246\n",
      "Epoch: 16, Batch: 334, D Loss: 0.10989299108247597, G Loss: 18.610645294189453\n",
      "Epoch: 16, Batch: 335, D Loss: 0.09999841098887785, G Loss: 18.710657119750977\n",
      "Epoch: 16, Batch: 336, D Loss: 0.10246508183151959, G Loss: 18.785640716552734\n",
      "Epoch: 16, Batch: 337, D Loss: 0.10143231944972086, G Loss: 18.80045509338379\n",
      "Epoch: 16, Batch: 338, D Loss: 0.10295132148144459, G Loss: 18.78083038330078\n",
      "Epoch: 16, Batch: 339, D Loss: 0.09921929600649682, G Loss: 18.718475341796875\n",
      "Epoch: 16, Batch: 340, D Loss: 0.10181938492459519, G Loss: 18.670812606811523\n",
      "Epoch: 16, Batch: 341, D Loss: 0.09658448798856556, G Loss: 18.616100311279297\n",
      "Epoch: 16, Batch: 342, D Loss: 0.09977011797271373, G Loss: 18.60044288635254\n",
      "Epoch: 16, Batch: 343, D Loss: 0.09309712475253029, G Loss: 18.577274322509766\n",
      "Epoch: 16, Batch: 344, D Loss: 0.0998170790430799, G Loss: 18.60771369934082\n",
      "Epoch: 16, Batch: 345, D Loss: 0.10231753088990203, G Loss: 18.698654174804688\n",
      "Epoch: 16, Batch: 346, D Loss: 0.09679961572035922, G Loss: 18.75554656982422\n",
      "Epoch: 16, Batch: 347, D Loss: 0.09508002909190627, G Loss: 18.744821548461914\n",
      "Epoch: 16, Batch: 348, D Loss: 0.10598529483319052, G Loss: 18.7900390625\n",
      "Epoch: 16, Batch: 349, D Loss: 0.10438265988191198, G Loss: 18.8394718170166\n",
      "Epoch: 16, Batch: 350, D Loss: 0.10396977830626253, G Loss: 18.912086486816406\n",
      "Epoch: 16, Batch: 351, D Loss: 0.10179844801186078, G Loss: 18.933027267456055\n",
      "Epoch: 16, Batch: 352, D Loss: 0.09513707025591134, G Loss: 18.85761260986328\n",
      "Epoch: 16, Batch: 353, D Loss: 0.09644385767386443, G Loss: 18.759443283081055\n",
      "Epoch: 16, Batch: 354, D Loss: 0.09571304543200032, G Loss: 18.68321418762207\n",
      "Epoch: 16, Batch: 355, D Loss: 0.10230863472646856, G Loss: 18.71450424194336\n",
      "Epoch: 16, Batch: 356, D Loss: 0.09537081781959955, G Loss: 18.772411346435547\n",
      "Epoch: 16, Batch: 357, D Loss: 0.09708214889715072, G Loss: 18.845317840576172\n",
      "Epoch: 16, Batch: 358, D Loss: 0.09331877105932462, G Loss: 18.878511428833008\n",
      "Epoch: 16, Batch: 359, D Loss: 0.0960445137446917, G Loss: 18.89166831970215\n",
      "Epoch: 16, Batch: 360, D Loss: 0.09752800627075464, G Loss: 18.8963623046875\n",
      "Epoch: 16, Batch: 361, D Loss: 0.10405531826626757, G Loss: 18.956790924072266\n",
      "Epoch: 16, Batch: 362, D Loss: 0.1013109488857189, G Loss: 19.013996124267578\n",
      "Epoch: 16, Batch: 363, D Loss: 0.09860691703597935, G Loss: 19.019865036010742\n",
      "Epoch: 16, Batch: 364, D Loss: 0.10075726637347682, G Loss: 19.001888275146484\n",
      "Epoch: 16, Batch: 365, D Loss: 0.097903492931801, G Loss: 18.955612182617188\n",
      "Epoch: 16, Batch: 366, D Loss: 0.09496581114382407, G Loss: 18.878278732299805\n",
      "Epoch: 16, Batch: 367, D Loss: 0.09444096269594637, G Loss: 18.79714012145996\n",
      "Epoch: 16, Batch: 368, D Loss: 0.0931194013121297, G Loss: 18.731218338012695\n",
      "Epoch: 16, Batch: 369, D Loss: 0.10115810096847389, G Loss: 18.774980545043945\n",
      "Epoch: 16, Batch: 370, D Loss: 0.10232688071468066, G Loss: 18.891429901123047\n",
      "Epoch: 16, Batch: 371, D Loss: 0.1005961328310152, G Loss: 19.00731086730957\n",
      "Epoch: 16, Batch: 372, D Loss: 0.1052138682636432, G Loss: 19.116374969482422\n",
      "Epoch: 16, Batch: 373, D Loss: 0.10163857288114775, G Loss: 19.147554397583008\n",
      "Epoch: 16, Batch: 374, D Loss: 0.09299059469786553, G Loss: 19.026453018188477\n",
      "Epoch: 16, Batch: 375, D Loss: 0.09634682833772756, G Loss: 18.860570907592773\n",
      "Epoch: 16, Batch: 376, D Loss: 0.10291269011774107, G Loss: 18.784076690673828\n",
      "Epoch: 16, Batch: 377, D Loss: 0.10319169954490803, G Loss: 18.805736541748047\n",
      "Epoch: 16, Batch: 378, D Loss: 0.09845912786512834, G Loss: 18.863676071166992\n",
      "Epoch: 16, Batch: 379, D Loss: 0.10677112937846678, G Loss: 18.99935531616211\n",
      "Epoch: 16, Batch: 380, D Loss: 0.09796119006360238, G Loss: 19.070018768310547\n",
      "Epoch: 16, Batch: 381, D Loss: 0.10222520191446316, G Loss: 19.09894561767578\n",
      "Epoch: 16, Batch: 382, D Loss: 0.09865302853581692, G Loss: 19.04503631591797\n",
      "Epoch: 16, Batch: 383, D Loss: 0.09699812071017777, G Loss: 18.929101943969727\n",
      "Epoch: 16, Batch: 384, D Loss: 0.09171014607100725, G Loss: 18.76351547241211\n",
      "Epoch: 16, Batch: 385, D Loss: 0.0913621821549806, G Loss: 18.618614196777344\n",
      "Epoch: 16, Batch: 386, D Loss: 0.10687771838444782, G Loss: 18.67188262939453\n",
      "Epoch: 16, Batch: 387, D Loss: 0.10458214936262267, G Loss: 18.84261131286621\n",
      "Epoch: 16, Batch: 388, D Loss: 0.09925004397252946, G Loss: 18.995765686035156\n",
      "Epoch: 16, Batch: 389, D Loss: 0.09293277839829583, G Loss: 19.017309188842773\n",
      "Epoch: 16, Batch: 390, D Loss: 0.10202391722713089, G Loss: 19.00546646118164\n",
      "Epoch: 16, Batch: 391, D Loss: 0.1011645151957834, G Loss: 18.95616912841797\n",
      "Epoch: 16, Batch: 392, D Loss: 0.10509338525367307, G Loss: 18.938438415527344\n",
      "Epoch: 16, Batch: 393, D Loss: 0.10348393321585059, G Loss: 18.93450355529785\n",
      "Epoch: 16, Batch: 394, D Loss: 0.09935302591081263, G Loss: 18.905418395996094\n",
      "Epoch: 16, Batch: 395, D Loss: 0.10726389591267105, G Loss: 18.940227508544922\n",
      "Epoch: 16, Batch: 396, D Loss: 0.09532697801245682, G Loss: 18.90833854675293\n",
      "Epoch: 16, Batch: 397, D Loss: 0.10014318240410791, G Loss: 18.886127471923828\n",
      "Epoch: 16, Batch: 398, D Loss: 0.09808752259978504, G Loss: 18.854331970214844\n",
      "Epoch: 16, Batch: 399, D Loss: 0.09608404668450876, G Loss: 18.81953239440918\n",
      "Epoch: 16, Batch: 400, D Loss: 0.0942690704782565, G Loss: 18.77838134765625\n",
      "Epoch: 16, Batch: 401, D Loss: 0.1053188924051387, G Loss: 18.840999603271484\n",
      "Epoch: 16, Batch: 402, D Loss: 0.09242818085970872, G Loss: 18.852584838867188\n",
      "Epoch: 16, Batch: 403, D Loss: 0.10339462326080429, G Loss: 18.91581153869629\n",
      "Epoch: 16, Batch: 404, D Loss: 0.10196303124836481, G Loss: 18.986295700073242\n",
      "Epoch: 16, Batch: 405, D Loss: 0.09814971967128994, G Loss: 19.001819610595703\n",
      "Epoch: 16, Batch: 406, D Loss: 0.107691707958125, G Loss: 19.04667091369629\n",
      "Epoch: 16, Batch: 407, D Loss: 0.09525144376318506, G Loss: 18.98543930053711\n",
      "Epoch: 16, Batch: 408, D Loss: 0.09799263175310213, G Loss: 18.92121696472168\n",
      "Epoch: 16, Batch: 409, D Loss: 0.10338183797744271, G Loss: 18.908315658569336\n",
      "Epoch: 16, Batch: 410, D Loss: 0.09881940789809107, G Loss: 18.916526794433594\n",
      "Epoch: 16, Batch: 411, D Loss: 0.09718908671805071, G Loss: 18.930910110473633\n",
      "Epoch: 16, Batch: 412, D Loss: 0.10363637199146236, G Loss: 19.008167266845703\n",
      "Epoch: 16, Batch: 413, D Loss: 0.09643037889830142, G Loss: 19.044504165649414\n",
      "Epoch: 16, Batch: 414, D Loss: 0.10219490789893948, G Loss: 19.088790893554688\n",
      "Epoch: 16, Batch: 415, D Loss: 0.10046890631528571, G Loss: 19.10991668701172\n",
      "Epoch: 16, Batch: 416, D Loss: 0.1013787413860181, G Loss: 19.11311912536621\n",
      "Epoch: 16, Batch: 417, D Loss: 0.09831471251662549, G Loss: 19.073137283325195\n",
      "Epoch: 16, Batch: 418, D Loss: 0.09916983065003038, G Loss: 19.038209915161133\n",
      "Epoch: 16, Batch: 419, D Loss: 0.09470777495071059, G Loss: 18.956424713134766\n",
      "Epoch: 16, Batch: 420, D Loss: 0.09918145387476351, G Loss: 18.927488327026367\n",
      "Epoch: 16, Batch: 421, D Loss: 0.10491779737178697, G Loss: 18.995826721191406\n",
      "Epoch: 16, Batch: 422, D Loss: 0.09954719515781574, G Loss: 19.0714054107666\n",
      "Epoch: 16, Batch: 423, D Loss: 0.09558622798097804, G Loss: 19.08458709716797\n",
      "Epoch: 16, Batch: 424, D Loss: 0.10427574322051436, G Loss: 19.112077713012695\n",
      "Epoch: 16, Batch: 425, D Loss: 0.09522863734290765, G Loss: 19.06435775756836\n",
      "Epoch: 16, Batch: 426, D Loss: 0.10012764007187869, G Loss: 19.022438049316406\n",
      "Epoch: 16, Batch: 427, D Loss: 0.10169551052094761, G Loss: 19.01093864440918\n",
      "Epoch: 16, Batch: 428, D Loss: 0.09558591528825056, G Loss: 18.976232528686523\n",
      "Epoch: 16, Batch: 429, D Loss: 0.09563380773019459, G Loss: 18.934932708740234\n",
      "Epoch: 16, Batch: 430, D Loss: 0.1079091607404199, G Loss: 19.013763427734375\n",
      "Epoch: 16, Batch: 431, D Loss: 0.10077046122903277, G Loss: 19.09318733215332\n",
      "Epoch: 16, Batch: 432, D Loss: 0.10229102024599324, G Loss: 19.15138053894043\n",
      "Epoch: 16, Batch: 433, D Loss: 0.1026318469581382, G Loss: 19.17525291442871\n",
      "Epoch: 16, Batch: 434, D Loss: 0.09645223862060104, G Loss: 19.10073471069336\n",
      "Epoch: 16, Batch: 435, D Loss: 0.09267682110332798, G Loss: 18.95616912841797\n",
      "Epoch: 16, Batch: 436, D Loss: 0.0988891453404317, G Loss: 18.86820411682129\n",
      "Epoch: 16, Batch: 437, D Loss: 0.10330009775260329, G Loss: 18.897127151489258\n",
      "Epoch: 16, Batch: 438, D Loss: 0.09619804773687402, G Loss: 18.950237274169922\n",
      "Epoch: 16, Batch: 439, D Loss: 0.10315050462444297, G Loss: 19.061141967773438\n",
      "Epoch: 16, Batch: 440, D Loss: 0.09861897931065178, G Loss: 19.132001876831055\n",
      "Epoch: 16, Batch: 441, D Loss: 0.09586245068259425, G Loss: 19.122756958007812\n",
      "Epoch: 16, Batch: 442, D Loss: 0.09750276314507, G Loss: 19.06377410888672\n",
      "Epoch: 16, Batch: 443, D Loss: 0.09768951957228489, G Loss: 18.991775512695312\n",
      "Epoch: 16, Batch: 444, D Loss: 0.10088108021583064, G Loss: 18.963817596435547\n",
      "Epoch: 16, Batch: 445, D Loss: 0.1047769664164806, G Loss: 19.01679229736328\n",
      "Epoch: 16, Batch: 446, D Loss: 0.09532799100051714, G Loss: 19.031625747680664\n",
      "Epoch: 16, Batch: 447, D Loss: 0.1016635623388733, G Loss: 19.067468643188477\n",
      "Epoch: 16, Batch: 448, D Loss: 0.09779124223318103, G Loss: 19.071083068847656\n",
      "Epoch: 16, Batch: 449, D Loss: 0.0989613410262089, G Loss: 19.059480667114258\n",
      "Epoch: 16, Batch: 450, D Loss: 0.10294222351472948, G Loss: 19.05360984802246\n",
      "Epoch: 16, Batch: 451, D Loss: 0.09493097936407047, G Loss: 18.99746322631836\n",
      "Epoch: 16, Batch: 452, D Loss: 0.09820083073157915, G Loss: 18.940128326416016\n",
      "Epoch: 16, Batch: 453, D Loss: 0.10167956649954135, G Loss: 18.93842315673828\n",
      "Epoch: 16, Batch: 454, D Loss: 0.09696294665755123, G Loss: 18.93536376953125\n",
      "Epoch: 16, Batch: 455, D Loss: 0.10305731289473341, G Loss: 18.986351013183594\n",
      "Epoch: 16, Batch: 456, D Loss: 0.10024718472718441, G Loss: 19.03031349182129\n",
      "Epoch: 16, Batch: 457, D Loss: 0.09593442357460513, G Loss: 19.00766944885254\n",
      "Epoch: 16, Batch: 458, D Loss: 0.09145206507532122, G Loss: 18.897708892822266\n",
      "Epoch: 16, Batch: 459, D Loss: 0.09758913841507222, G Loss: 18.81231689453125\n",
      "Epoch: 16, Batch: 460, D Loss: 0.10695766240328175, G Loss: 18.87057113647461\n",
      "Epoch: 16, Batch: 461, D Loss: 0.10868455761610218, G Loss: 19.03666877746582\n",
      "Epoch: 16, Batch: 462, D Loss: 0.10182848080297613, G Loss: 19.163116455078125\n",
      "Epoch: 16, Batch: 463, D Loss: 0.10680870194547842, G Loss: 19.24605369567871\n",
      "Epoch: 16, Batch: 464, D Loss: 0.09815547095655552, G Loss: 19.191503524780273\n",
      "Epoch: 16, Batch: 465, D Loss: 0.10088521490375868, G Loss: 19.057140350341797\n",
      "Epoch: 16, Batch: 466, D Loss: 0.10224354549565073, G Loss: 18.932411193847656\n",
      "Epoch: 16, Batch: 467, D Loss: 0.09093544215379801, G Loss: 18.75934600830078\n",
      "Epoch: 17, Batch: 0, D Loss: 0.09938998887922068, G Loss: 18.700790405273438\n",
      "Epoch: 17, Batch: 1, D Loss: 0.10222109022032733, G Loss: 18.793315887451172\n",
      "Epoch: 17, Batch: 2, D Loss: 0.09988310504777154, G Loss: 18.95254135131836\n",
      "Epoch: 17, Batch: 3, D Loss: 0.09577158370948724, G Loss: 19.060386657714844\n",
      "Epoch: 17, Batch: 4, D Loss: 0.10222820444824543, G Loss: 19.144935607910156\n",
      "Epoch: 17, Batch: 5, D Loss: 0.09756209199320942, G Loss: 19.13930320739746\n",
      "Epoch: 17, Batch: 6, D Loss: 0.10181395213732647, G Loss: 19.096534729003906\n",
      "Epoch: 17, Batch: 7, D Loss: 0.09315277909511122, G Loss: 18.958297729492188\n",
      "Epoch: 17, Batch: 8, D Loss: 0.09336491246324652, G Loss: 18.801193237304688\n",
      "Epoch: 17, Batch: 9, D Loss: 0.09879045540067866, G Loss: 18.747201919555664\n",
      "Epoch: 17, Batch: 10, D Loss: 0.09586555121369855, G Loss: 18.7741641998291\n",
      "Epoch: 17, Batch: 11, D Loss: 0.09719433971420544, G Loss: 18.84627914428711\n",
      "Epoch: 17, Batch: 12, D Loss: 0.10166482939434474, G Loss: 18.938663482666016\n",
      "Epoch: 17, Batch: 13, D Loss: 0.1003451599559666, G Loss: 19.009553909301758\n",
      "Epoch: 17, Batch: 14, D Loss: 0.10126713190385628, G Loss: 19.047258377075195\n",
      "Epoch: 17, Batch: 15, D Loss: 0.09986098376824115, G Loss: 19.058395385742188\n",
      "Epoch: 17, Batch: 16, D Loss: 0.09893237325942383, G Loss: 18.99917984008789\n",
      "Epoch: 17, Batch: 17, D Loss: 0.09932363322997695, G Loss: 18.937053680419922\n",
      "Epoch: 17, Batch: 18, D Loss: 0.10437276511451787, G Loss: 18.9451904296875\n",
      "Epoch: 17, Batch: 19, D Loss: 0.09634930194193014, G Loss: 18.927005767822266\n",
      "Epoch: 17, Batch: 20, D Loss: 0.10162768063351812, G Loss: 18.964797973632812\n",
      "Epoch: 17, Batch: 21, D Loss: 0.10271883289047823, G Loss: 19.045114517211914\n",
      "Epoch: 17, Batch: 22, D Loss: 0.10206201185883645, G Loss: 19.113086700439453\n",
      "Epoch: 17, Batch: 23, D Loss: 0.09538326666233732, G Loss: 19.08596420288086\n",
      "Epoch: 17, Batch: 24, D Loss: 0.09842300679675375, G Loss: 19.030851364135742\n",
      "Epoch: 17, Batch: 25, D Loss: 0.09858545939024088, G Loss: 18.986576080322266\n",
      "Epoch: 17, Batch: 26, D Loss: 0.10350913833624054, G Loss: 19.018665313720703\n",
      "Epoch: 17, Batch: 27, D Loss: 0.10287678506186393, G Loss: 19.092710494995117\n",
      "Epoch: 17, Batch: 28, D Loss: 0.10344566648099196, G Loss: 19.184633255004883\n",
      "Epoch: 17, Batch: 29, D Loss: 0.09778595201884754, G Loss: 19.198942184448242\n",
      "Epoch: 17, Batch: 30, D Loss: 0.10809394941652806, G Loss: 19.242271423339844\n",
      "Epoch: 17, Batch: 31, D Loss: 0.09383695056238883, G Loss: 19.167551040649414\n",
      "Epoch: 17, Batch: 32, D Loss: 0.09793031464880575, G Loss: 19.071380615234375\n",
      "Epoch: 17, Batch: 33, D Loss: 0.09630883013163749, G Loss: 18.983774185180664\n",
      "Epoch: 17, Batch: 34, D Loss: 0.09437090452994967, G Loss: 18.91951560974121\n",
      "Epoch: 17, Batch: 35, D Loss: 0.0935749293227377, G Loss: 18.9013729095459\n",
      "Epoch: 17, Batch: 36, D Loss: 0.10898731187611532, G Loss: 19.064002990722656\n",
      "Epoch: 17, Batch: 37, D Loss: 0.09728594368103627, G Loss: 19.206195831298828\n",
      "Epoch: 17, Batch: 38, D Loss: 0.09686029177385458, G Loss: 19.273441314697266\n",
      "Epoch: 17, Batch: 39, D Loss: 0.10416537732097342, G Loss: 19.312135696411133\n",
      "Epoch: 17, Batch: 40, D Loss: 0.0955612680800717, G Loss: 19.23554801940918\n",
      "Epoch: 17, Batch: 41, D Loss: 0.10073508554046207, G Loss: 19.14779281616211\n",
      "Epoch: 17, Batch: 42, D Loss: 0.10491945093874899, G Loss: 19.126585006713867\n",
      "Epoch: 17, Batch: 43, D Loss: 0.0935315664346843, G Loss: 19.059831619262695\n",
      "Epoch: 17, Batch: 44, D Loss: 0.09728685292638128, G Loss: 19.007600784301758\n",
      "Epoch: 17, Batch: 45, D Loss: 0.10235023771396468, G Loss: 19.043331146240234\n",
      "Epoch: 17, Batch: 46, D Loss: 0.09703269863032249, G Loss: 19.087182998657227\n",
      "Epoch: 17, Batch: 47, D Loss: 0.10015914837605888, G Loss: 19.14983367919922\n",
      "Epoch: 17, Batch: 48, D Loss: 0.0956810066174032, G Loss: 19.166114807128906\n",
      "Epoch: 17, Batch: 49, D Loss: 0.10292244190463662, G Loss: 19.201168060302734\n",
      "Epoch: 17, Batch: 50, D Loss: 0.09169397740040863, G Loss: 19.137493133544922\n",
      "Epoch: 17, Batch: 51, D Loss: 0.10161324092832635, G Loss: 19.112138748168945\n",
      "Epoch: 17, Batch: 52, D Loss: 0.10006065918149809, G Loss: 19.104354858398438\n",
      "Epoch: 17, Batch: 53, D Loss: 0.09362594296910909, G Loss: 19.057727813720703\n",
      "Epoch: 17, Batch: 54, D Loss: 0.09620324046402184, G Loss: 19.023855209350586\n",
      "Epoch: 17, Batch: 55, D Loss: 0.10473133887929587, G Loss: 19.088993072509766\n",
      "Epoch: 17, Batch: 56, D Loss: 0.10044589885958488, G Loss: 19.15730094909668\n",
      "Epoch: 17, Batch: 57, D Loss: 0.10271272294993627, G Loss: 19.218900680541992\n",
      "Epoch: 17, Batch: 58, D Loss: 0.10239391250498797, G Loss: 19.24835968017578\n",
      "Epoch: 17, Batch: 59, D Loss: 0.10277392190459178, G Loss: 19.233169555664062\n",
      "Epoch: 17, Batch: 60, D Loss: 0.0999466799938371, G Loss: 19.157426834106445\n",
      "Epoch: 17, Batch: 61, D Loss: 0.10556453710649127, G Loss: 19.119060516357422\n",
      "Epoch: 17, Batch: 62, D Loss: 0.10343659921175274, G Loss: 19.09405517578125\n",
      "Epoch: 17, Batch: 63, D Loss: 0.10368134337157864, G Loss: 19.088336944580078\n",
      "Epoch: 17, Batch: 64, D Loss: 0.09980365895112953, G Loss: 19.05402374267578\n",
      "Epoch: 17, Batch: 65, D Loss: 0.09810497139895014, G Loss: 18.999170303344727\n",
      "Epoch: 17, Batch: 66, D Loss: 0.10059790597081908, G Loss: 18.976016998291016\n",
      "Epoch: 17, Batch: 67, D Loss: 0.09868605723367962, G Loss: 18.9660701751709\n",
      "Epoch: 17, Batch: 68, D Loss: 0.10352305607168377, G Loss: 19.002777099609375\n",
      "Epoch: 17, Batch: 69, D Loss: 0.09399053736198093, G Loss: 18.986482620239258\n",
      "Epoch: 17, Batch: 70, D Loss: 0.10266731960662412, G Loss: 19.0050106048584\n",
      "Epoch: 17, Batch: 71, D Loss: 0.0926389275870092, G Loss: 18.950252532958984\n",
      "Epoch: 17, Batch: 72, D Loss: 0.09729984705011563, G Loss: 18.89993667602539\n",
      "Epoch: 17, Batch: 73, D Loss: 0.1056826740724206, G Loss: 18.958595275878906\n",
      "Epoch: 17, Batch: 74, D Loss: 0.10452343799223263, G Loss: 19.067440032958984\n",
      "Epoch: 17, Batch: 75, D Loss: 0.09689085444251333, G Loss: 19.09052848815918\n",
      "Epoch: 17, Batch: 76, D Loss: 0.09840706251995535, G Loss: 19.051620483398438\n",
      "Epoch: 17, Batch: 77, D Loss: 0.09661919158467058, G Loss: 18.95509147644043\n",
      "Epoch: 17, Batch: 78, D Loss: 0.10329909176659169, G Loss: 18.91653823852539\n",
      "Epoch: 17, Batch: 79, D Loss: 0.10902970576987814, G Loss: 18.991369247436523\n",
      "Epoch: 17, Batch: 80, D Loss: 0.09452210650417836, G Loss: 18.984004974365234\n",
      "Epoch: 17, Batch: 81, D Loss: 0.0980517893273285, G Loss: 18.945798873901367\n",
      "Epoch: 17, Batch: 82, D Loss: 0.09708122469190528, G Loss: 18.88622283935547\n",
      "Epoch: 17, Batch: 83, D Loss: 0.09965109398826755, G Loss: 18.857271194458008\n",
      "Epoch: 17, Batch: 84, D Loss: 0.09686734109061779, G Loss: 18.83614158630371\n",
      "Epoch: 17, Batch: 85, D Loss: 0.10174981826679508, G Loss: 18.883075714111328\n",
      "Epoch: 17, Batch: 86, D Loss: 0.09497715846708754, G Loss: 18.88908576965332\n",
      "Epoch: 17, Batch: 87, D Loss: 0.09651118832147088, G Loss: 18.875829696655273\n",
      "Epoch: 17, Batch: 88, D Loss: 0.09817864318449243, G Loss: 18.873197555541992\n",
      "Epoch: 17, Batch: 89, D Loss: 0.09563792074144373, G Loss: 18.84807586669922\n",
      "Epoch: 17, Batch: 90, D Loss: 0.09721115561512494, G Loss: 18.825727462768555\n",
      "Epoch: 17, Batch: 91, D Loss: 0.0904958655320467, G Loss: 18.752853393554688\n",
      "Epoch: 17, Batch: 92, D Loss: 0.10093720613961676, G Loss: 18.763700485229492\n",
      "Epoch: 17, Batch: 93, D Loss: 0.10053329515034015, G Loss: 18.815540313720703\n",
      "Epoch: 17, Batch: 94, D Loss: 0.10621440724528108, G Loss: 18.94950294494629\n",
      "Epoch: 17, Batch: 95, D Loss: 0.09891642915784415, G Loss: 19.00827980041504\n",
      "Epoch: 17, Batch: 96, D Loss: 0.10064611118069755, G Loss: 18.99925994873047\n",
      "Epoch: 17, Batch: 97, D Loss: 0.09207275813413207, G Loss: 18.8477783203125\n",
      "Epoch: 17, Batch: 98, D Loss: 0.10522388261860804, G Loss: 18.768903732299805\n",
      "Epoch: 17, Batch: 99, D Loss: 0.09405626728168648, G Loss: 18.671432495117188\n",
      "Epoch: 17, Batch: 100, D Loss: 0.10104286316377431, G Loss: 18.663686752319336\n",
      "Epoch: 17, Batch: 101, D Loss: 0.10018927239000419, G Loss: 18.72306251525879\n",
      "Epoch: 17, Batch: 102, D Loss: 0.09578627708357446, G Loss: 18.770692825317383\n",
      "Epoch: 17, Batch: 103, D Loss: 0.09093952538253758, G Loss: 18.73373031616211\n",
      "Epoch: 17, Batch: 104, D Loss: 0.09650662166197788, G Loss: 18.711946487426758\n",
      "Epoch: 17, Batch: 105, D Loss: 0.10578165560574027, G Loss: 18.79751205444336\n",
      "Epoch: 17, Batch: 106, D Loss: 0.09574011304874053, G Loss: 18.83323097229004\n",
      "Epoch: 17, Batch: 107, D Loss: 0.10344773852915412, G Loss: 18.88596534729004\n",
      "Epoch: 17, Batch: 108, D Loss: 0.09968921854488388, G Loss: 18.8962345123291\n",
      "Epoch: 17, Batch: 109, D Loss: 0.098203453620614, G Loss: 18.853147506713867\n",
      "Epoch: 17, Batch: 110, D Loss: 0.09584711833284998, G Loss: 18.75743865966797\n",
      "Epoch: 17, Batch: 111, D Loss: 0.09762551262074304, G Loss: 18.681489944458008\n",
      "Epoch: 17, Batch: 112, D Loss: 0.09456085068033593, G Loss: 18.612960815429688\n",
      "Epoch: 17, Batch: 113, D Loss: 0.10046925057365419, G Loss: 18.64036750793457\n",
      "Epoch: 17, Batch: 114, D Loss: 0.10203025124955456, G Loss: 18.744630813598633\n",
      "Epoch: 17, Batch: 115, D Loss: 0.09957033738337184, G Loss: 18.847644805908203\n",
      "Epoch: 17, Batch: 116, D Loss: 0.09253656447298297, G Loss: 18.836563110351562\n",
      "Epoch: 17, Batch: 117, D Loss: 0.09671203390037975, G Loss: 18.76255226135254\n",
      "Epoch: 17, Batch: 118, D Loss: 0.09658556803186746, G Loss: 18.676652908325195\n",
      "Epoch: 17, Batch: 119, D Loss: 0.1005449855777516, G Loss: 18.653223037719727\n",
      "Epoch: 17, Batch: 120, D Loss: 0.10685883089433634, G Loss: 18.77295684814453\n",
      "Epoch: 17, Batch: 121, D Loss: 0.09406012639194361, G Loss: 18.822599411010742\n",
      "Epoch: 17, Batch: 122, D Loss: 0.0986905578087316, G Loss: 18.843399047851562\n",
      "Epoch: 17, Batch: 123, D Loss: 0.09576543010167171, G Loss: 18.80317497253418\n",
      "Epoch: 17, Batch: 124, D Loss: 0.09964708584753423, G Loss: 18.77663230895996\n",
      "Epoch: 17, Batch: 125, D Loss: 0.09714874232857507, G Loss: 18.76357650756836\n",
      "Epoch: 17, Batch: 126, D Loss: 0.10422350063559493, G Loss: 18.83184242248535\n",
      "Epoch: 17, Batch: 127, D Loss: 0.09608771232685576, G Loss: 18.864910125732422\n",
      "Epoch: 17, Batch: 128, D Loss: 0.09960953463563604, G Loss: 18.884845733642578\n",
      "Epoch: 17, Batch: 129, D Loss: 0.09102467028662464, G Loss: 18.81450653076172\n",
      "Epoch: 17, Batch: 130, D Loss: 0.09804515887417531, G Loss: 18.761423110961914\n",
      "Epoch: 17, Batch: 131, D Loss: 0.09745808297536263, G Loss: 18.78216552734375\n",
      "Epoch: 17, Batch: 132, D Loss: 0.10736165518633611, G Loss: 18.925878524780273\n",
      "Epoch: 17, Batch: 133, D Loss: 0.09742009179517308, G Loss: 19.035131454467773\n",
      "Epoch: 17, Batch: 134, D Loss: 0.09554557023373689, G Loss: 19.06578254699707\n",
      "Epoch: 17, Batch: 135, D Loss: 0.10150737578134494, G Loss: 19.062969207763672\n",
      "Epoch: 17, Batch: 136, D Loss: 0.0993327152479977, G Loss: 19.04387092590332\n",
      "Epoch: 17, Batch: 137, D Loss: 0.10039343954616209, G Loss: 19.03284454345703\n",
      "Epoch: 17, Batch: 138, D Loss: 0.09851108764592942, G Loss: 19.01845932006836\n",
      "Epoch: 17, Batch: 139, D Loss: 0.10332276942510776, G Loss: 19.050912857055664\n",
      "Epoch: 17, Batch: 140, D Loss: 0.10015251749491072, G Loss: 19.08159828186035\n",
      "Epoch: 17, Batch: 141, D Loss: 0.09953893230079247, G Loss: 19.11256980895996\n",
      "Epoch: 17, Batch: 142, D Loss: 0.09611027197129651, G Loss: 19.0819149017334\n",
      "Epoch: 17, Batch: 143, D Loss: 0.09904221706137939, G Loss: 19.062246322631836\n",
      "Epoch: 17, Batch: 144, D Loss: 0.10421444731459606, G Loss: 19.116777420043945\n",
      "Epoch: 17, Batch: 145, D Loss: 0.09660254665638579, G Loss: 19.13591194152832\n",
      "Epoch: 17, Batch: 146, D Loss: 0.10098558164311822, G Loss: 19.13214683532715\n",
      "Epoch: 17, Batch: 147, D Loss: 0.09676279377916375, G Loss: 19.0952091217041\n",
      "Epoch: 17, Batch: 148, D Loss: 0.09603701795181085, G Loss: 19.032222747802734\n",
      "Epoch: 17, Batch: 149, D Loss: 0.1003140089404857, G Loss: 19.019453048706055\n",
      "Epoch: 17, Batch: 150, D Loss: 0.0937081007278886, G Loss: 18.98827362060547\n",
      "Epoch: 17, Batch: 151, D Loss: 0.0964577077479909, G Loss: 18.98055076599121\n",
      "Epoch: 17, Batch: 152, D Loss: 0.10043373983015957, G Loss: 19.024961471557617\n",
      "Epoch: 17, Batch: 153, D Loss: 0.09952091686840059, G Loss: 19.110740661621094\n",
      "Epoch: 17, Batch: 154, D Loss: 0.09724270051214945, G Loss: 19.163904190063477\n",
      "Epoch: 17, Batch: 155, D Loss: 0.09532564374484376, G Loss: 19.137939453125\n",
      "Epoch: 17, Batch: 156, D Loss: 0.0988351131431513, G Loss: 19.108434677124023\n",
      "Epoch: 17, Batch: 157, D Loss: 0.09813759730236993, G Loss: 19.086490631103516\n",
      "Epoch: 17, Batch: 158, D Loss: 0.1040361921119366, G Loss: 19.14141082763672\n",
      "Epoch: 17, Batch: 159, D Loss: 0.09510134401822734, G Loss: 19.15643310546875\n",
      "Epoch: 17, Batch: 160, D Loss: 0.09670326354340353, G Loss: 19.14815902709961\n",
      "Epoch: 17, Batch: 161, D Loss: 0.1023900830596518, G Loss: 19.185138702392578\n",
      "Epoch: 17, Batch: 162, D Loss: 0.10310891497435448, G Loss: 19.234825134277344\n",
      "Epoch: 17, Batch: 163, D Loss: 0.09832000953916209, G Loss: 19.235122680664062\n",
      "Epoch: 17, Batch: 164, D Loss: 0.09945012854825697, G Loss: 19.198293685913086\n",
      "Epoch: 17, Batch: 165, D Loss: 0.09616050364580797, G Loss: 19.112085342407227\n",
      "Epoch: 17, Batch: 166, D Loss: 0.10004358997595131, G Loss: 19.048736572265625\n",
      "Epoch: 17, Batch: 167, D Loss: 0.10213169721292559, G Loss: 19.056413650512695\n",
      "Epoch: 17, Batch: 168, D Loss: 0.10144955173847725, G Loss: 19.135223388671875\n",
      "Epoch: 17, Batch: 169, D Loss: 0.1029255115223977, G Loss: 19.24643898010254\n",
      "Epoch: 17, Batch: 170, D Loss: 0.10060240539034937, G Loss: 19.319303512573242\n",
      "Epoch: 17, Batch: 171, D Loss: 0.09538167924993735, G Loss: 19.260934829711914\n",
      "Epoch: 17, Batch: 172, D Loss: 0.09507663778575859, G Loss: 19.134849548339844\n",
      "Epoch: 17, Batch: 173, D Loss: 0.09726382303833225, G Loss: 19.043188095092773\n",
      "Epoch: 17, Batch: 174, D Loss: 0.09622495152848165, G Loss: 18.986360549926758\n",
      "Epoch: 17, Batch: 175, D Loss: 0.0980796469399563, G Loss: 19.015872955322266\n",
      "Epoch: 17, Batch: 176, D Loss: 0.09975496945107065, G Loss: 19.087255477905273\n",
      "Epoch: 17, Batch: 177, D Loss: 0.10250529143323006, G Loss: 19.20323944091797\n",
      "Epoch: 17, Batch: 178, D Loss: 0.0974561892484842, G Loss: 19.243228912353516\n",
      "Epoch: 17, Batch: 179, D Loss: 0.09935433641202729, G Loss: 19.209186553955078\n",
      "Epoch: 17, Batch: 180, D Loss: 0.09971675513683076, G Loss: 19.13016128540039\n",
      "Epoch: 17, Batch: 181, D Loss: 0.1068409557175829, G Loss: 19.10942840576172\n",
      "Epoch: 17, Batch: 182, D Loss: 0.10117719577182616, G Loss: 19.08226203918457\n",
      "Epoch: 17, Batch: 183, D Loss: 0.10528022305873264, G Loss: 19.10465431213379\n",
      "Epoch: 17, Batch: 184, D Loss: 0.10275636863316828, G Loss: 19.12264633178711\n",
      "Epoch: 17, Batch: 185, D Loss: 0.09217949472476517, G Loss: 19.02495574951172\n",
      "Epoch: 17, Batch: 186, D Loss: 0.09861712441057491, G Loss: 18.956035614013672\n",
      "Epoch: 17, Batch: 187, D Loss: 0.10148774377393543, G Loss: 18.974227905273438\n",
      "Epoch: 17, Batch: 188, D Loss: 0.1004095030354264, G Loss: 19.069231033325195\n",
      "Epoch: 17, Batch: 189, D Loss: 0.0953566606268128, G Loss: 19.134641647338867\n",
      "Epoch: 17, Batch: 190, D Loss: 0.10698171935030198, G Loss: 19.25318717956543\n",
      "Epoch: 17, Batch: 191, D Loss: 0.09821335438607925, G Loss: 19.29893684387207\n",
      "Epoch: 17, Batch: 192, D Loss: 0.09797689529916775, G Loss: 19.267271041870117\n",
      "Epoch: 17, Batch: 193, D Loss: 0.10418340779145652, G Loss: 19.259174346923828\n",
      "Epoch: 17, Batch: 194, D Loss: 0.10652470801389824, G Loss: 19.290103912353516\n",
      "Epoch: 17, Batch: 195, D Loss: 0.09636623628732854, G Loss: 19.2298583984375\n",
      "Epoch: 17, Batch: 196, D Loss: 0.09929073831667234, G Loss: 19.170312881469727\n",
      "Epoch: 17, Batch: 197, D Loss: 0.10398324069203047, G Loss: 19.178611755371094\n",
      "Epoch: 17, Batch: 198, D Loss: 0.09949077898066272, G Loss: 19.195545196533203\n",
      "Epoch: 17, Batch: 199, D Loss: 0.09526967491226435, G Loss: 19.166336059570312\n",
      "Epoch: 17, Batch: 200, D Loss: 0.09034355980172237, G Loss: 19.063777923583984\n",
      "Epoch: 17, Batch: 201, D Loss: 0.10198752843183767, G Loss: 19.076459884643555\n",
      "Epoch: 17, Batch: 202, D Loss: 0.09707208230688114, G Loss: 19.125581741333008\n",
      "Epoch: 17, Batch: 203, D Loss: 0.0946783373047817, G Loss: 19.170696258544922\n",
      "Epoch: 17, Batch: 204, D Loss: 0.10267931448409229, G Loss: 19.258699417114258\n",
      "Epoch: 17, Batch: 205, D Loss: 0.09711531017412045, G Loss: 19.289875030517578\n",
      "Epoch: 17, Batch: 206, D Loss: 0.10421639885639311, G Loss: 19.334623336791992\n",
      "Epoch: 17, Batch: 207, D Loss: 0.09673107620173171, G Loss: 19.29470443725586\n",
      "Epoch: 17, Batch: 208, D Loss: 0.0967134110180643, G Loss: 19.202280044555664\n",
      "Epoch: 17, Batch: 209, D Loss: 0.09849824995904233, G Loss: 19.115602493286133\n",
      "Epoch: 17, Batch: 210, D Loss: 0.10102813943155198, G Loss: 19.09534454345703\n",
      "Epoch: 17, Batch: 211, D Loss: 0.09466120856521387, G Loss: 19.08690071105957\n",
      "Epoch: 17, Batch: 212, D Loss: 0.09874822448839038, G Loss: 19.142091751098633\n",
      "Epoch: 17, Batch: 213, D Loss: 0.10012021147292782, G Loss: 19.234159469604492\n",
      "Epoch: 17, Batch: 214, D Loss: 0.09743161714001491, G Loss: 19.29659652709961\n",
      "Epoch: 17, Batch: 215, D Loss: 0.09841984717744912, G Loss: 19.30511474609375\n",
      "Epoch: 17, Batch: 216, D Loss: 0.09673804258245866, G Loss: 19.241477966308594\n",
      "Epoch: 17, Batch: 217, D Loss: 0.10785431627681041, G Loss: 19.30473518371582\n",
      "Epoch: 17, Batch: 218, D Loss: 0.09563778547585211, G Loss: 19.302894592285156\n",
      "Epoch: 17, Batch: 219, D Loss: 0.09745099607399688, G Loss: 19.257999420166016\n",
      "Epoch: 17, Batch: 220, D Loss: 0.09503685908921433, G Loss: 19.176652908325195\n",
      "Epoch: 17, Batch: 221, D Loss: 0.10382925949685529, G Loss: 19.210411071777344\n",
      "Epoch: 17, Batch: 222, D Loss: 0.09905368310146834, G Loss: 19.265804290771484\n",
      "Epoch: 17, Batch: 223, D Loss: 0.09803145590014584, G Loss: 19.2977294921875\n",
      "Epoch: 17, Batch: 224, D Loss: 0.10059873962189458, G Loss: 19.34933853149414\n",
      "Epoch: 17, Batch: 225, D Loss: 0.10507941435645907, G Loss: 19.427204132080078\n",
      "Epoch: 17, Batch: 226, D Loss: 0.1046892794494817, G Loss: 19.519390106201172\n",
      "Epoch: 17, Batch: 227, D Loss: 0.10099506543600623, G Loss: 19.533527374267578\n",
      "Epoch: 17, Batch: 228, D Loss: 0.09868991545556038, G Loss: 19.46225357055664\n",
      "Epoch: 17, Batch: 229, D Loss: 0.1066357213437682, G Loss: 19.418109893798828\n",
      "Epoch: 17, Batch: 230, D Loss: 0.0924669076857021, G Loss: 19.289867401123047\n",
      "Epoch: 17, Batch: 231, D Loss: 0.09479446934996116, G Loss: 19.148357391357422\n",
      "Epoch: 17, Batch: 232, D Loss: 0.09734559302887225, G Loss: 19.131040573120117\n",
      "Epoch: 17, Batch: 233, D Loss: 0.1024079047728439, G Loss: 19.26177406311035\n",
      "Epoch: 17, Batch: 234, D Loss: 0.09530196542562996, G Loss: 19.37002182006836\n",
      "Epoch: 17, Batch: 235, D Loss: 0.10276137475268299, G Loss: 19.477060317993164\n",
      "Epoch: 17, Batch: 236, D Loss: 0.10100859572499055, G Loss: 19.53218650817871\n",
      "Epoch: 17, Batch: 237, D Loss: 0.10109676587210448, G Loss: 19.50949478149414\n",
      "Epoch: 17, Batch: 238, D Loss: 0.09619751756288131, G Loss: 19.343242645263672\n",
      "Epoch: 17, Batch: 239, D Loss: 0.09934675163521267, G Loss: 19.193092346191406\n",
      "Epoch: 17, Batch: 240, D Loss: 0.09682107961993092, G Loss: 19.07928466796875\n",
      "Epoch: 17, Batch: 241, D Loss: 0.0982976582020787, G Loss: 19.056289672851562\n",
      "Epoch: 17, Batch: 242, D Loss: 0.09010228041024826, G Loss: 19.00959014892578\n",
      "Epoch: 17, Batch: 243, D Loss: 0.09375975559902527, G Loss: 18.999961853027344\n",
      "Epoch: 17, Batch: 244, D Loss: 0.09720360013910168, G Loss: 19.06109046936035\n",
      "Epoch: 17, Batch: 245, D Loss: 0.10134374597899032, G Loss: 19.179733276367188\n",
      "Epoch: 17, Batch: 246, D Loss: 0.09560004105988584, G Loss: 19.218862533569336\n",
      "Epoch: 17, Batch: 247, D Loss: 0.10214399770454996, G Loss: 19.227497100830078\n",
      "Epoch: 17, Batch: 248, D Loss: 0.10055478145201135, G Loss: 19.186616897583008\n",
      "Epoch: 17, Batch: 249, D Loss: 0.10440905627057107, G Loss: 19.16692543029785\n",
      "Epoch: 17, Batch: 250, D Loss: 0.10006426519730027, G Loss: 19.10489273071289\n",
      "Epoch: 17, Batch: 251, D Loss: 0.09754143921388048, G Loss: 19.003374099731445\n",
      "Epoch: 17, Batch: 252, D Loss: 0.10140297106351559, G Loss: 18.934511184692383\n",
      "Epoch: 17, Batch: 253, D Loss: 0.09743500064250754, G Loss: 18.876585006713867\n",
      "Epoch: 17, Batch: 254, D Loss: 0.09227552597048971, G Loss: 18.787771224975586\n",
      "Epoch: 17, Batch: 255, D Loss: 0.10140530365445732, G Loss: 18.79308319091797\n",
      "Epoch: 17, Batch: 256, D Loss: 0.09794065691649978, G Loss: 18.844396591186523\n",
      "Epoch: 17, Batch: 257, D Loss: 0.09687712365521484, G Loss: 18.875680923461914\n",
      "Epoch: 17, Batch: 258, D Loss: 0.09900147035986429, G Loss: 18.90017318725586\n",
      "Epoch: 17, Batch: 259, D Loss: 0.09857322584181727, G Loss: 18.906564712524414\n",
      "Epoch: 17, Batch: 260, D Loss: 0.09650485532133879, G Loss: 18.86410140991211\n",
      "Epoch: 17, Batch: 261, D Loss: 0.1035952450791493, G Loss: 18.884740829467773\n",
      "Epoch: 17, Batch: 262, D Loss: 0.09705382153316999, G Loss: 18.894140243530273\n",
      "Epoch: 17, Batch: 263, D Loss: 0.09803129296583313, G Loss: 18.908998489379883\n",
      "Epoch: 17, Batch: 264, D Loss: 0.10345718558586303, G Loss: 18.990264892578125\n",
      "Epoch: 17, Batch: 265, D Loss: 0.09469248635253669, G Loss: 19.004352569580078\n",
      "Epoch: 17, Batch: 266, D Loss: 0.09233007869690191, G Loss: 18.93268585205078\n",
      "Epoch: 17, Batch: 267, D Loss: 0.09781345286484688, G Loss: 18.889978408813477\n",
      "Epoch: 17, Batch: 268, D Loss: 0.09771921052975174, G Loss: 18.89235496520996\n",
      "Epoch: 17, Batch: 269, D Loss: 0.10385145545432284, G Loss: 18.976608276367188\n",
      "Epoch: 17, Batch: 270, D Loss: 0.09668658208315484, G Loss: 19.0247859954834\n",
      "Epoch: 17, Batch: 271, D Loss: 0.09894407065921174, G Loss: 19.044952392578125\n",
      "Epoch: 17, Batch: 272, D Loss: 0.10012877257563302, G Loss: 19.029020309448242\n",
      "Epoch: 17, Batch: 273, D Loss: 0.09789002222019572, G Loss: 18.97265625\n",
      "Epoch: 17, Batch: 274, D Loss: 0.10221951001138008, G Loss: 18.95046615600586\n",
      "Epoch: 17, Batch: 275, D Loss: 0.10639626070992714, G Loss: 19.023664474487305\n",
      "Epoch: 17, Batch: 276, D Loss: 0.0993878719264445, G Loss: 19.057689666748047\n",
      "Epoch: 17, Batch: 277, D Loss: 0.09443800426223636, G Loss: 18.9842586517334\n",
      "Epoch: 17, Batch: 278, D Loss: 0.10579967037689775, G Loss: 18.988563537597656\n",
      "Epoch: 17, Batch: 279, D Loss: 0.10146361126204928, G Loss: 18.99901008605957\n",
      "Epoch: 17, Batch: 280, D Loss: 0.09958253337318745, G Loss: 18.99180793762207\n",
      "Epoch: 17, Batch: 281, D Loss: 0.09932677733399942, G Loss: 18.970863342285156\n",
      "Epoch: 17, Batch: 282, D Loss: 0.10411390944737686, G Loss: 19.010141372680664\n",
      "Epoch: 17, Batch: 283, D Loss: 0.09930801668620304, G Loss: 19.012372970581055\n",
      "Epoch: 17, Batch: 284, D Loss: 0.09615963983330755, G Loss: 18.95035171508789\n",
      "Epoch: 17, Batch: 285, D Loss: 0.10123722553156389, G Loss: 18.92791748046875\n",
      "Epoch: 17, Batch: 286, D Loss: 0.09911006990463966, G Loss: 18.926122665405273\n",
      "Epoch: 17, Batch: 287, D Loss: 0.09440171279530785, G Loss: 18.899019241333008\n",
      "Epoch: 17, Batch: 288, D Loss: 0.09726924015083749, G Loss: 18.89296531677246\n",
      "Epoch: 17, Batch: 289, D Loss: 0.10065074567633436, G Loss: 18.949771881103516\n",
      "Epoch: 17, Batch: 290, D Loss: 0.09942862673898789, G Loss: 19.02985191345215\n",
      "Epoch: 17, Batch: 291, D Loss: 0.10247497519490034, G Loss: 19.12287139892578\n",
      "Epoch: 17, Batch: 292, D Loss: 0.10245546193792099, G Loss: 19.18115997314453\n",
      "Epoch: 17, Batch: 293, D Loss: 0.09757512304610882, G Loss: 19.11652946472168\n",
      "Epoch: 17, Batch: 294, D Loss: 0.10269823183830273, G Loss: 19.048002243041992\n",
      "Epoch: 17, Batch: 295, D Loss: 0.09930077471689502, G Loss: 18.98163604736328\n",
      "Epoch: 17, Batch: 296, D Loss: 0.09508395494273292, G Loss: 18.891096115112305\n",
      "Epoch: 17, Batch: 297, D Loss: 0.09984506237659962, G Loss: 18.86905288696289\n",
      "Epoch: 17, Batch: 298, D Loss: 0.10128834408853904, G Loss: 18.923904418945312\n",
      "Epoch: 17, Batch: 299, D Loss: 0.10454234016509778, G Loss: 19.064443588256836\n",
      "Epoch: 17, Batch: 300, D Loss: 0.0974446858513911, G Loss: 19.129695892333984\n",
      "Epoch: 17, Batch: 301, D Loss: 0.10303126516723848, G Loss: 19.167911529541016\n",
      "Epoch: 17, Batch: 302, D Loss: 0.10011843092965722, G Loss: 19.095151901245117\n",
      "Epoch: 17, Batch: 303, D Loss: 0.09541827717380436, G Loss: 18.934707641601562\n",
      "Epoch: 17, Batch: 304, D Loss: 0.0915624830811348, G Loss: 18.719417572021484\n",
      "Epoch: 17, Batch: 305, D Loss: 0.10231896123196949, G Loss: 18.681602478027344\n",
      "Epoch: 17, Batch: 306, D Loss: 0.10078172007375619, G Loss: 18.77480125427246\n",
      "Epoch: 17, Batch: 307, D Loss: 0.10324250480306518, G Loss: 18.957195281982422\n",
      "Epoch: 17, Batch: 308, D Loss: 0.09076457759921164, G Loss: 18.977800369262695\n",
      "Epoch: 17, Batch: 309, D Loss: 0.1041915593931515, G Loss: 19.007408142089844\n",
      "Epoch: 17, Batch: 310, D Loss: 0.09551835351250104, G Loss: 18.92031478881836\n",
      "Epoch: 17, Batch: 311, D Loss: 0.10267892792164846, G Loss: 18.865568161010742\n",
      "Epoch: 17, Batch: 312, D Loss: 0.1030562403398736, G Loss: 18.845857620239258\n",
      "Epoch: 17, Batch: 313, D Loss: 0.10484922995974322, G Loss: 18.8939266204834\n",
      "Epoch: 17, Batch: 314, D Loss: 0.0959876360272991, G Loss: 18.86882209777832\n",
      "Epoch: 17, Batch: 315, D Loss: 0.10324997027671956, G Loss: 18.87835121154785\n",
      "Epoch: 17, Batch: 316, D Loss: 0.10232515945797704, G Loss: 18.900850296020508\n",
      "Epoch: 17, Batch: 317, D Loss: 0.10019892761110327, G Loss: 18.915729522705078\n",
      "Epoch: 17, Batch: 318, D Loss: 0.0959396020960408, G Loss: 18.87230110168457\n",
      "Epoch: 17, Batch: 319, D Loss: 0.0975885125943372, G Loss: 18.81941032409668\n",
      "Epoch: 17, Batch: 320, D Loss: 0.09372592322942563, G Loss: 18.736122131347656\n",
      "Epoch: 17, Batch: 321, D Loss: 0.09718680751187958, G Loss: 18.712169647216797\n",
      "Epoch: 17, Batch: 322, D Loss: 0.09992496286143937, G Loss: 18.77267074584961\n",
      "Epoch: 17, Batch: 323, D Loss: 0.1026051002810322, G Loss: 18.90160369873047\n",
      "Epoch: 17, Batch: 324, D Loss: 0.10146595827530769, G Loss: 19.023712158203125\n",
      "Epoch: 17, Batch: 325, D Loss: 0.0980029729346541, G Loss: 19.037675857543945\n",
      "Epoch: 17, Batch: 326, D Loss: 0.0973141519860985, G Loss: 18.936925888061523\n",
      "Epoch: 17, Batch: 327, D Loss: 0.09605765671954591, G Loss: 18.749305725097656\n",
      "Epoch: 17, Batch: 328, D Loss: 0.09852055101049251, G Loss: 18.61716651916504\n",
      "Epoch: 17, Batch: 329, D Loss: 0.10405576633941305, G Loss: 18.64522361755371\n",
      "Epoch: 17, Batch: 330, D Loss: 0.0996260531877593, G Loss: 18.743745803833008\n",
      "Epoch: 17, Batch: 331, D Loss: 0.10113269431229521, G Loss: 18.8591365814209\n",
      "Epoch: 17, Batch: 332, D Loss: 0.0989572139354058, G Loss: 18.900062561035156\n",
      "Epoch: 17, Batch: 333, D Loss: 0.09663609733730905, G Loss: 18.85213279724121\n",
      "Epoch: 17, Batch: 334, D Loss: 0.10078401452634034, G Loss: 18.799373626708984\n",
      "Epoch: 17, Batch: 335, D Loss: 0.09757365637623816, G Loss: 18.75067138671875\n",
      "Epoch: 17, Batch: 336, D Loss: 0.10478477527997354, G Loss: 18.812395095825195\n",
      "Epoch: 17, Batch: 337, D Loss: 0.10521365275255512, G Loss: 18.926631927490234\n",
      "Epoch: 17, Batch: 338, D Loss: 0.10100428308695863, G Loss: 18.976282119750977\n",
      "Epoch: 17, Batch: 339, D Loss: 0.09657786340650021, G Loss: 18.896764755249023\n",
      "Epoch: 17, Batch: 340, D Loss: 0.09967582256396157, G Loss: 18.789613723754883\n",
      "Epoch: 17, Batch: 341, D Loss: 0.09122702112682068, G Loss: 18.617652893066406\n",
      "Epoch: 17, Batch: 342, D Loss: 0.09670366774954298, G Loss: 18.539039611816406\n",
      "Epoch: 17, Batch: 343, D Loss: 0.10026497820897129, G Loss: 18.613994598388672\n",
      "Epoch: 17, Batch: 344, D Loss: 0.10131279756783851, G Loss: 18.779281616210938\n",
      "Epoch: 17, Batch: 345, D Loss: 0.09718163639145572, G Loss: 18.9007511138916\n",
      "Epoch: 17, Batch: 346, D Loss: 0.09705381402667013, G Loss: 18.91397476196289\n",
      "Epoch: 17, Batch: 347, D Loss: 0.1025828228354122, G Loss: 18.900318145751953\n",
      "Epoch: 17, Batch: 348, D Loss: 0.09698010560210224, G Loss: 18.81238555908203\n",
      "Epoch: 17, Batch: 349, D Loss: 0.0979038214548027, G Loss: 18.71217918395996\n",
      "Epoch: 17, Batch: 350, D Loss: 0.10076661792371722, G Loss: 18.65806007385254\n",
      "Epoch: 17, Batch: 351, D Loss: 0.10085018368534238, G Loss: 18.68262481689453\n",
      "Epoch: 17, Batch: 352, D Loss: 0.10332419344560329, G Loss: 18.77605628967285\n",
      "Epoch: 17, Batch: 353, D Loss: 0.09095773458562517, G Loss: 18.737436294555664\n",
      "Epoch: 17, Batch: 354, D Loss: 0.09999315811164378, G Loss: 18.705406188964844\n",
      "Epoch: 17, Batch: 355, D Loss: 0.10091280571631778, G Loss: 18.688884735107422\n",
      "Epoch: 17, Batch: 356, D Loss: 0.10487296059641871, G Loss: 18.739137649536133\n",
      "Epoch: 17, Batch: 357, D Loss: 0.09627245735180523, G Loss: 18.713638305664062\n",
      "Epoch: 17, Batch: 358, D Loss: 0.10698492443319307, G Loss: 18.763853073120117\n",
      "Epoch: 17, Batch: 359, D Loss: 0.09296954049090478, G Loss: 18.679161071777344\n",
      "Epoch: 17, Batch: 360, D Loss: 0.09851304098470948, G Loss: 18.603530883789062\n",
      "Epoch: 17, Batch: 361, D Loss: 0.1064206923959965, G Loss: 18.649824142456055\n",
      "Epoch: 17, Batch: 362, D Loss: 0.10163613791864545, G Loss: 18.720823287963867\n",
      "Epoch: 17, Batch: 363, D Loss: 0.10108314816960995, G Loss: 18.762310028076172\n",
      "Epoch: 17, Batch: 364, D Loss: 0.10480372953784278, G Loss: 18.812536239624023\n",
      "Epoch: 17, Batch: 365, D Loss: 0.10638933213661206, G Loss: 18.858156204223633\n",
      "Epoch: 17, Batch: 366, D Loss: 0.09600669487041857, G Loss: 18.75172996520996\n",
      "Epoch: 17, Batch: 367, D Loss: 0.09570096086186908, G Loss: 18.555662155151367\n",
      "Epoch: 17, Batch: 368, D Loss: 0.10573390573921237, G Loss: 18.50950050354004\n",
      "Epoch: 17, Batch: 369, D Loss: 0.10407560759406698, G Loss: 18.58088493347168\n",
      "Epoch: 17, Batch: 370, D Loss: 0.09378993940187819, G Loss: 18.567916870117188\n",
      "Epoch: 17, Batch: 371, D Loss: 0.10022738261073805, G Loss: 18.574228286743164\n",
      "Epoch: 17, Batch: 372, D Loss: 0.09580565682238484, G Loss: 18.53318977355957\n",
      "Epoch: 17, Batch: 373, D Loss: 0.09968264102775715, G Loss: 18.53325653076172\n",
      "Epoch: 17, Batch: 374, D Loss: 0.09929963642528561, G Loss: 18.55726432800293\n",
      "Epoch: 17, Batch: 375, D Loss: 0.0970921858122038, G Loss: 18.554882049560547\n",
      "Epoch: 17, Batch: 376, D Loss: 0.1049477350822614, G Loss: 18.6389217376709\n",
      "Epoch: 17, Batch: 377, D Loss: 0.09145670798773198, G Loss: 18.58039665222168\n",
      "Epoch: 17, Batch: 378, D Loss: 0.09478977023867818, G Loss: 18.492828369140625\n",
      "Epoch: 17, Batch: 379, D Loss: 0.09810682117394931, G Loss: 18.448410034179688\n",
      "Epoch: 17, Batch: 380, D Loss: 0.09473974750571967, G Loss: 18.423423767089844\n",
      "Epoch: 17, Batch: 381, D Loss: 0.1005220758825307, G Loss: 18.512130737304688\n",
      "Epoch: 17, Batch: 382, D Loss: 0.10438666162780441, G Loss: 18.69159507751465\n",
      "Epoch: 17, Batch: 383, D Loss: 0.09496807679460217, G Loss: 18.736656188964844\n",
      "Epoch: 17, Batch: 384, D Loss: 0.10979371862349674, G Loss: 18.84443473815918\n",
      "Epoch: 17, Batch: 385, D Loss: 0.09972891544159879, G Loss: 18.813831329345703\n",
      "Epoch: 17, Batch: 386, D Loss: 0.10237513836501355, G Loss: 18.72349739074707\n",
      "Epoch: 17, Batch: 387, D Loss: 0.09800853980076507, G Loss: 18.57278823852539\n",
      "Epoch: 17, Batch: 388, D Loss: 0.10634744598626922, G Loss: 18.564958572387695\n",
      "Epoch: 17, Batch: 389, D Loss: 0.10443710205623713, G Loss: 18.645540237426758\n",
      "Epoch: 17, Batch: 390, D Loss: 0.09434119268216001, G Loss: 18.6364688873291\n",
      "Epoch: 17, Batch: 391, D Loss: 0.10587642727609481, G Loss: 18.71959686279297\n",
      "Epoch: 17, Batch: 392, D Loss: 0.10251701234726118, G Loss: 18.79420280456543\n",
      "Epoch: 17, Batch: 393, D Loss: 0.10205039721629006, G Loss: 18.81951141357422\n",
      "Epoch: 17, Batch: 394, D Loss: 0.0976594349286053, G Loss: 18.722957611083984\n",
      "Epoch: 17, Batch: 395, D Loss: 0.10662450270506918, G Loss: 18.699724197387695\n",
      "Epoch: 17, Batch: 396, D Loss: 0.10075371351830675, G Loss: 18.669219970703125\n",
      "Epoch: 17, Batch: 397, D Loss: 0.09963237145965831, G Loss: 18.636629104614258\n",
      "Epoch: 17, Batch: 398, D Loss: 0.10385474213392554, G Loss: 18.67069435119629\n",
      "Epoch: 17, Batch: 399, D Loss: 0.10286220540301372, G Loss: 18.7314395904541\n",
      "Epoch: 17, Batch: 400, D Loss: 0.0990393496371329, G Loss: 18.735370635986328\n",
      "Epoch: 17, Batch: 401, D Loss: 0.09705464920407358, G Loss: 18.6666316986084\n",
      "Epoch: 17, Batch: 402, D Loss: 0.09888475050585877, G Loss: 18.58885383605957\n",
      "Epoch: 17, Batch: 403, D Loss: 0.09870684578595768, G Loss: 18.548625946044922\n",
      "Epoch: 17, Batch: 404, D Loss: 0.09941499372254547, G Loss: 18.561689376831055\n",
      "Epoch: 17, Batch: 405, D Loss: 0.09823076854348001, G Loss: 18.592355728149414\n",
      "Epoch: 17, Batch: 406, D Loss: 0.09819842546047619, G Loss: 18.615501403808594\n",
      "Epoch: 17, Batch: 407, D Loss: 0.09799881689283474, G Loss: 18.62360954284668\n",
      "Epoch: 17, Batch: 408, D Loss: 0.09636673749905267, G Loss: 18.575740814208984\n",
      "Epoch: 17, Batch: 409, D Loss: 0.10042527751082853, G Loss: 18.554481506347656\n",
      "Epoch: 17, Batch: 410, D Loss: 0.10018571903349471, G Loss: 18.555912017822266\n",
      "Epoch: 17, Batch: 411, D Loss: 0.09719872169647914, G Loss: 18.54207420349121\n",
      "Epoch: 17, Batch: 412, D Loss: 0.09682526144523163, G Loss: 18.5113468170166\n",
      "Epoch: 17, Batch: 413, D Loss: 0.0969668375156969, G Loss: 18.481626510620117\n",
      "Epoch: 17, Batch: 414, D Loss: 0.0984262423869171, G Loss: 18.490039825439453\n",
      "Epoch: 17, Batch: 415, D Loss: 0.09626057463291726, G Loss: 18.499317169189453\n",
      "Epoch: 17, Batch: 416, D Loss: 0.099189002866789, G Loss: 18.539888381958008\n",
      "Epoch: 17, Batch: 417, D Loss: 0.0946754708618811, G Loss: 18.537931442260742\n",
      "Epoch: 17, Batch: 418, D Loss: 0.10105477707368138, G Loss: 18.58487892150879\n",
      "Epoch: 17, Batch: 419, D Loss: 0.10172275116512974, G Loss: 18.6606388092041\n",
      "Epoch: 17, Batch: 420, D Loss: 0.09664325061774015, G Loss: 18.673494338989258\n",
      "Epoch: 17, Batch: 421, D Loss: 0.10416385907798498, G Loss: 18.7331485748291\n",
      "Epoch: 17, Batch: 422, D Loss: 0.09623150901227051, G Loss: 18.6926212310791\n",
      "Epoch: 17, Batch: 423, D Loss: 0.10178222146401472, G Loss: 18.676647186279297\n",
      "Epoch: 17, Batch: 424, D Loss: 0.10303433617559099, G Loss: 18.721601486206055\n",
      "Epoch: 17, Batch: 425, D Loss: 0.09901258713055228, G Loss: 18.755229949951172\n",
      "Epoch: 17, Batch: 426, D Loss: 0.10705456474199626, G Loss: 18.87192726135254\n",
      "Epoch: 17, Batch: 427, D Loss: 0.10158631512404681, G Loss: 18.942472457885742\n",
      "Epoch: 17, Batch: 428, D Loss: 0.10706843721481185, G Loss: 19.0145263671875\n",
      "Epoch: 17, Batch: 429, D Loss: 0.1007843343456023, G Loss: 18.998001098632812\n",
      "Epoch: 17, Batch: 430, D Loss: 0.09396563774480948, G Loss: 18.84547996520996\n",
      "Epoch: 17, Batch: 431, D Loss: 0.0995089297256253, G Loss: 18.741670608520508\n",
      "Epoch: 17, Batch: 432, D Loss: 0.10270353016564582, G Loss: 18.783058166503906\n",
      "Epoch: 17, Batch: 433, D Loss: 0.08947085193574922, G Loss: 18.77554702758789\n",
      "Epoch: 17, Batch: 434, D Loss: 0.09587869392604453, G Loss: 18.80950164794922\n",
      "Epoch: 17, Batch: 435, D Loss: 0.09938565216871065, G Loss: 18.91706085205078\n",
      "Epoch: 17, Batch: 436, D Loss: 0.09894804196700457, G Loss: 19.040189743041992\n",
      "Epoch: 17, Batch: 437, D Loss: 0.10240853833079155, G Loss: 19.140758514404297\n",
      "Epoch: 17, Batch: 438, D Loss: 0.09670943267747112, G Loss: 19.12069320678711\n",
      "Epoch: 17, Batch: 439, D Loss: 0.09524997591486772, G Loss: 18.977426528930664\n",
      "Epoch: 17, Batch: 440, D Loss: 0.09484294370445667, G Loss: 18.806068420410156\n",
      "Epoch: 17, Batch: 441, D Loss: 0.10293448311815845, G Loss: 18.804317474365234\n",
      "Epoch: 17, Batch: 442, D Loss: 0.10329985932279784, G Loss: 18.96111488342285\n",
      "Epoch: 17, Batch: 443, D Loss: 0.09598193591931281, G Loss: 19.075204849243164\n",
      "Epoch: 17, Batch: 444, D Loss: 0.10072710612310654, G Loss: 19.169706344604492\n",
      "Epoch: 17, Batch: 445, D Loss: 0.10523393975640039, G Loss: 19.260055541992188\n",
      "Epoch: 17, Batch: 446, D Loss: 0.0952672608395384, G Loss: 19.178266525268555\n",
      "Epoch: 17, Batch: 447, D Loss: 0.0979921619535673, G Loss: 19.035070419311523\n",
      "Epoch: 17, Batch: 448, D Loss: 0.09648031285953818, G Loss: 18.905136108398438\n",
      "Epoch: 17, Batch: 449, D Loss: 0.10312882369244258, G Loss: 18.93368911743164\n",
      "Epoch: 17, Batch: 450, D Loss: 0.09778446244288075, G Loss: 19.025800704956055\n",
      "Epoch: 17, Batch: 451, D Loss: 0.09790893902031605, G Loss: 19.13375473022461\n",
      "Epoch: 17, Batch: 452, D Loss: 0.09973959859339687, G Loss: 19.217060089111328\n",
      "Epoch: 17, Batch: 453, D Loss: 0.09583454060965568, G Loss: 19.205245971679688\n",
      "Epoch: 17, Batch: 454, D Loss: 0.09607001630234668, G Loss: 19.139549255371094\n",
      "Epoch: 17, Batch: 455, D Loss: 0.09613710892773208, G Loss: 19.083913803100586\n",
      "Epoch: 17, Batch: 456, D Loss: 0.10255900277221186, G Loss: 19.126861572265625\n",
      "Epoch: 17, Batch: 457, D Loss: 0.0960728103338262, G Loss: 19.159530639648438\n",
      "Epoch: 17, Batch: 458, D Loss: 0.10289281832421238, G Loss: 19.266544342041016\n",
      "Epoch: 17, Batch: 459, D Loss: 0.09695386351040525, G Loss: 19.31235122680664\n",
      "Epoch: 17, Batch: 460, D Loss: 0.10234228722087768, G Loss: 19.35452651977539\n",
      "Epoch: 17, Batch: 461, D Loss: 0.10579075107680325, G Loss: 19.434202194213867\n",
      "Epoch: 17, Batch: 462, D Loss: 0.10217511087492537, G Loss: 19.46409034729004\n",
      "Epoch: 17, Batch: 463, D Loss: 0.10227998524007964, G Loss: 19.445024490356445\n",
      "Epoch: 17, Batch: 464, D Loss: 0.09861686270083303, G Loss: 19.343273162841797\n",
      "Epoch: 17, Batch: 465, D Loss: 0.09610289551259643, G Loss: 19.184778213500977\n",
      "Epoch: 17, Batch: 466, D Loss: 0.09780384099107242, G Loss: 19.09615707397461\n",
      "Epoch: 17, Batch: 467, D Loss: 0.09817864254659425, G Loss: 19.100831985473633\n",
      "Epoch: 18, Batch: 0, D Loss: 0.10173843293558238, G Loss: 19.222169876098633\n",
      "Epoch: 18, Batch: 1, D Loss: 0.10302460397792368, G Loss: 19.400785446166992\n",
      "Epoch: 18, Batch: 2, D Loss: 0.0988907682961725, G Loss: 19.485288619995117\n",
      "Epoch: 18, Batch: 3, D Loss: 0.09389548187128316, G Loss: 19.367551803588867\n",
      "Epoch: 18, Batch: 4, D Loss: 0.09902755381231665, G Loss: 19.215139389038086\n",
      "Epoch: 18, Batch: 5, D Loss: 0.09951324999445332, G Loss: 19.111961364746094\n",
      "Epoch: 18, Batch: 6, D Loss: 0.09957364454738138, G Loss: 19.091623306274414\n",
      "Epoch: 18, Batch: 7, D Loss: 0.10560021787273821, G Loss: 19.22875213623047\n",
      "Epoch: 18, Batch: 8, D Loss: 0.0999792536890669, G Loss: 19.372716903686523\n",
      "Epoch: 18, Batch: 9, D Loss: 0.10623328565705836, G Loss: 19.52640724182129\n",
      "Epoch: 18, Batch: 10, D Loss: 0.0972465964121082, G Loss: 19.49219512939453\n",
      "Epoch: 18, Batch: 11, D Loss: 0.10352106570198427, G Loss: 19.420753479003906\n",
      "Epoch: 18, Batch: 12, D Loss: 0.09856732387649036, G Loss: 19.28069496154785\n",
      "Epoch: 18, Batch: 13, D Loss: 0.10203866880799439, G Loss: 19.20492172241211\n",
      "Epoch: 18, Batch: 14, D Loss: 0.09766706312070594, G Loss: 19.167268753051758\n",
      "Epoch: 18, Batch: 15, D Loss: 0.10380687044796777, G Loss: 19.263994216918945\n",
      "Epoch: 18, Batch: 16, D Loss: 0.09723488447685624, G Loss: 19.344310760498047\n",
      "Epoch: 18, Batch: 17, D Loss: 0.09274168513751824, G Loss: 19.31914710998535\n",
      "Epoch: 18, Batch: 18, D Loss: 0.09881928767166559, G Loss: 19.315086364746094\n",
      "Epoch: 18, Batch: 19, D Loss: 0.10095672510021836, G Loss: 19.35094451904297\n",
      "Epoch: 18, Batch: 20, D Loss: 0.10063255772009372, G Loss: 19.385066986083984\n",
      "Epoch: 18, Batch: 21, D Loss: 0.10154512712692187, G Loss: 19.41053009033203\n",
      "Epoch: 18, Batch: 22, D Loss: 0.10690601348950457, G Loss: 19.48284339904785\n",
      "Epoch: 18, Batch: 23, D Loss: 0.10160122240579494, G Loss: 19.47215461730957\n",
      "Epoch: 18, Batch: 24, D Loss: 0.10473963797127728, G Loss: 19.42781639099121\n",
      "Epoch: 18, Batch: 25, D Loss: 0.09837904770267358, G Loss: 19.27630043029785\n",
      "Epoch: 18, Batch: 26, D Loss: 0.09865569557708698, G Loss: 19.089752197265625\n",
      "Epoch: 18, Batch: 27, D Loss: 0.1051282610883808, G Loss: 19.045421600341797\n",
      "Epoch: 18, Batch: 28, D Loss: 0.10524675506946224, G Loss: 19.12390899658203\n",
      "Epoch: 18, Batch: 29, D Loss: 0.09385709715944168, G Loss: 19.094396591186523\n",
      "Epoch: 18, Batch: 30, D Loss: 0.09714918103047276, G Loss: 19.02454948425293\n",
      "Epoch: 18, Batch: 31, D Loss: 0.09959591460183748, G Loss: 18.978445053100586\n",
      "Epoch: 18, Batch: 32, D Loss: 0.10444177218967665, G Loss: 19.04195213317871\n",
      "Epoch: 18, Batch: 33, D Loss: 0.10058815293443946, G Loss: 19.09540367126465\n",
      "Epoch: 18, Batch: 34, D Loss: 0.09135794908170247, G Loss: 18.994287490844727\n",
      "Epoch: 18, Batch: 35, D Loss: 0.09898297037150994, G Loss: 18.916677474975586\n",
      "Epoch: 18, Batch: 36, D Loss: 0.09720896499403886, G Loss: 18.852617263793945\n",
      "Epoch: 18, Batch: 37, D Loss: 0.10459706497778054, G Loss: 18.93720245361328\n",
      "Epoch: 18, Batch: 38, D Loss: 0.1006581960487638, G Loss: 19.045333862304688\n",
      "Epoch: 18, Batch: 39, D Loss: 0.10216993348407133, G Loss: 19.13860321044922\n",
      "Epoch: 18, Batch: 40, D Loss: 0.10765954336964367, G Loss: 19.25069236755371\n",
      "Epoch: 18, Batch: 41, D Loss: 0.09804098532524863, G Loss: 19.195695877075195\n",
      "Epoch: 18, Batch: 42, D Loss: 0.09551421061865284, G Loss: 19.009374618530273\n",
      "Epoch: 18, Batch: 43, D Loss: 0.1024508952561829, G Loss: 18.908273696899414\n",
      "Epoch: 18, Batch: 44, D Loss: 0.09543495200163932, G Loss: 18.830097198486328\n",
      "Epoch: 18, Batch: 45, D Loss: 0.09753762516151654, G Loss: 18.838653564453125\n",
      "Epoch: 18, Batch: 46, D Loss: 0.10614036322484055, G Loss: 19.02216339111328\n",
      "Epoch: 18, Batch: 47, D Loss: 0.09665917862616147, G Loss: 19.14055824279785\n",
      "Epoch: 18, Batch: 48, D Loss: 0.10107130791660413, G Loss: 19.21263885498047\n",
      "Epoch: 18, Batch: 49, D Loss: 0.09558166799368628, G Loss: 19.13563346862793\n",
      "Epoch: 18, Batch: 50, D Loss: 0.09505458441964199, G Loss: 18.977529525756836\n",
      "Epoch: 18, Batch: 51, D Loss: 0.08803281512334449, G Loss: 18.741455078125\n",
      "Epoch: 18, Batch: 52, D Loss: 0.09478393578773847, G Loss: 18.645061492919922\n",
      "Epoch: 18, Batch: 53, D Loss: 0.09872432432446665, G Loss: 18.743623733520508\n",
      "Epoch: 18, Batch: 54, D Loss: 0.09768762019493415, G Loss: 18.94791603088379\n",
      "Epoch: 18, Batch: 55, D Loss: 0.09269558913424314, G Loss: 19.081438064575195\n",
      "Epoch: 18, Batch: 56, D Loss: 0.09282046069347416, G Loss: 19.08387565612793\n",
      "Epoch: 18, Batch: 57, D Loss: 0.10241365687358872, G Loss: 19.106231689453125\n",
      "Epoch: 18, Batch: 58, D Loss: 0.10333171731011914, G Loss: 19.165815353393555\n",
      "Epoch: 18, Batch: 59, D Loss: 0.09855971724990376, G Loss: 19.14788246154785\n",
      "Epoch: 18, Batch: 60, D Loss: 0.10315591339015717, G Loss: 19.14411735534668\n",
      "Epoch: 18, Batch: 61, D Loss: 0.09735272330301337, G Loss: 19.082191467285156\n",
      "Epoch: 18, Batch: 62, D Loss: 0.09675331684661992, G Loss: 18.989704132080078\n",
      "Epoch: 18, Batch: 63, D Loss: 0.107255401967846, G Loss: 19.05107879638672\n",
      "Epoch: 18, Batch: 64, D Loss: 0.10390922676687553, G Loss: 19.174070358276367\n",
      "Epoch: 18, Batch: 65, D Loss: 0.10452422722155785, G Loss: 19.28109359741211\n",
      "Epoch: 18, Batch: 66, D Loss: 0.09300112947168149, G Loss: 19.181684494018555\n",
      "Epoch: 18, Batch: 67, D Loss: 0.09797369198832984, G Loss: 19.013948440551758\n",
      "Epoch: 18, Batch: 68, D Loss: 0.09919485001211559, G Loss: 18.8797664642334\n",
      "Epoch: 18, Batch: 69, D Loss: 0.0945391688209114, G Loss: 18.783414840698242\n",
      "Epoch: 18, Batch: 70, D Loss: 0.09665849407463778, G Loss: 18.78509521484375\n",
      "Epoch: 18, Batch: 71, D Loss: 0.09357515317155718, G Loss: 18.82744789123535\n",
      "Epoch: 18, Batch: 72, D Loss: 0.09689341799591134, G Loss: 18.938085556030273\n",
      "Epoch: 18, Batch: 73, D Loss: 0.09675789161342974, G Loss: 19.04365348815918\n",
      "Epoch: 18, Batch: 74, D Loss: 0.10333838561165964, G Loss: 19.197315216064453\n",
      "Epoch: 18, Batch: 75, D Loss: 0.094996193827809, G Loss: 19.22517204284668\n",
      "Epoch: 18, Batch: 76, D Loss: 0.1014359764612407, G Loss: 19.23874282836914\n",
      "Epoch: 18, Batch: 77, D Loss: 0.10725540134867306, G Loss: 19.313434600830078\n",
      "Epoch: 18, Batch: 78, D Loss: 0.09945076912582285, G Loss: 19.27878761291504\n",
      "Epoch: 18, Batch: 79, D Loss: 0.09794742835154135, G Loss: 19.198659896850586\n",
      "Epoch: 18, Batch: 80, D Loss: 0.10210664806732916, G Loss: 19.14389991760254\n",
      "Epoch: 18, Batch: 81, D Loss: 0.10134665166464463, G Loss: 19.136972427368164\n",
      "Epoch: 18, Batch: 82, D Loss: 0.0995805138978143, G Loss: 19.133913040161133\n",
      "Epoch: 18, Batch: 83, D Loss: 0.10249640287663353, G Loss: 19.17264175415039\n",
      "Epoch: 18, Batch: 84, D Loss: 0.09960969773087691, G Loss: 19.17391586303711\n",
      "Epoch: 18, Batch: 85, D Loss: 0.09621510153205293, G Loss: 19.10939598083496\n",
      "Epoch: 18, Batch: 86, D Loss: 0.09854188823099985, G Loss: 19.031408309936523\n",
      "Epoch: 18, Batch: 87, D Loss: 0.09941354671889657, G Loss: 18.987028121948242\n",
      "Epoch: 18, Batch: 88, D Loss: 0.09562884561328455, G Loss: 18.94501304626465\n",
      "Epoch: 18, Batch: 89, D Loss: 0.09748551548907658, G Loss: 18.923416137695312\n",
      "Epoch: 18, Batch: 90, D Loss: 0.09722705489290617, G Loss: 18.914691925048828\n",
      "Epoch: 18, Batch: 91, D Loss: 0.09148427415060478, G Loss: 18.8477840423584\n",
      "Epoch: 18, Batch: 92, D Loss: 0.10239467343861475, G Loss: 18.89007568359375\n",
      "Epoch: 18, Batch: 93, D Loss: 0.10468234412016275, G Loss: 19.031770706176758\n",
      "Epoch: 18, Batch: 94, D Loss: 0.09526778280529946, G Loss: 19.05570411682129\n",
      "Epoch: 18, Batch: 95, D Loss: 0.10358667635901764, G Loss: 19.07551383972168\n",
      "Epoch: 18, Batch: 96, D Loss: 0.09826080770698176, G Loss: 19.004966735839844\n",
      "Epoch: 18, Batch: 97, D Loss: 0.10612650494800113, G Loss: 19.002370834350586\n",
      "Epoch: 18, Batch: 98, D Loss: 0.09768182328705954, G Loss: 18.936010360717773\n",
      "Epoch: 18, Batch: 99, D Loss: 0.10057881034431926, G Loss: 18.896326065063477\n",
      "Epoch: 18, Batch: 100, D Loss: 0.09764578511635413, G Loss: 18.851478576660156\n",
      "Epoch: 18, Batch: 101, D Loss: 0.10468098835632667, G Loss: 18.914709091186523\n",
      "Epoch: 18, Batch: 102, D Loss: 0.10066833639960326, G Loss: 18.99252700805664\n",
      "Epoch: 18, Batch: 103, D Loss: 0.08961086270957441, G Loss: 18.90363883972168\n",
      "Epoch: 18, Batch: 104, D Loss: 0.10140250189934119, G Loss: 18.883798599243164\n",
      "Epoch: 18, Batch: 105, D Loss: 0.10102328219871892, G Loss: 18.931995391845703\n",
      "Epoch: 18, Batch: 106, D Loss: 0.10156207074011436, G Loss: 19.012950897216797\n",
      "Epoch: 18, Batch: 107, D Loss: 0.10062609159710756, G Loss: 18.91110610961914\n",
      "Epoch: 18, Batch: 108, D Loss: 0.09794437472321826, G Loss: 18.756988525390625\n",
      "Epoch: 18, Batch: 109, D Loss: 0.09216736667709657, G Loss: 18.49188995361328\n",
      "Epoch: 18, Batch: 110, D Loss: 0.10628626982252198, G Loss: 18.408470153808594\n",
      "Epoch: 18, Batch: 111, D Loss: 0.09907629856174482, G Loss: 18.374948501586914\n",
      "Epoch: 18, Batch: 112, D Loss: 0.09755713282009104, G Loss: 18.335784912109375\n",
      "Epoch: 18, Batch: 113, D Loss: 0.09971435920590732, G Loss: 18.307788848876953\n",
      "Epoch: 18, Batch: 114, D Loss: 0.10037105350886089, G Loss: 18.289108276367188\n",
      "Epoch: 18, Batch: 115, D Loss: 0.09967510986041805, G Loss: 18.24510955810547\n",
      "Epoch: 18, Batch: 116, D Loss: 0.10199402874201002, G Loss: 18.22810173034668\n",
      "Epoch: 18, Batch: 117, D Loss: 0.09814883651694295, G Loss: 18.160877227783203\n",
      "Epoch: 18, Batch: 118, D Loss: 0.10243860548712291, G Loss: 18.123098373413086\n",
      "Epoch: 18, Batch: 119, D Loss: 0.09581390730322736, G Loss: 18.03057861328125\n",
      "Epoch: 18, Batch: 120, D Loss: 0.10065083953689058, G Loss: 18.007150650024414\n",
      "Epoch: 18, Batch: 121, D Loss: 0.10340364260934809, G Loss: 18.077970504760742\n",
      "Epoch: 18, Batch: 122, D Loss: 0.10164569996643325, G Loss: 18.1502685546875\n",
      "Epoch: 18, Batch: 123, D Loss: 0.09087675021398356, G Loss: 18.020856857299805\n",
      "Epoch: 18, Batch: 124, D Loss: 0.09746906217462126, G Loss: 17.885269165039062\n",
      "Epoch: 18, Batch: 125, D Loss: 0.10000727460790415, G Loss: 17.828777313232422\n",
      "Epoch: 18, Batch: 126, D Loss: 0.09978205854918443, G Loss: 17.860074996948242\n",
      "Epoch: 18, Batch: 127, D Loss: 0.10259553119226794, G Loss: 17.98775863647461\n",
      "Epoch: 18, Batch: 128, D Loss: 0.09821756916312996, G Loss: 18.086397171020508\n",
      "Epoch: 18, Batch: 129, D Loss: 0.10376898115174926, G Loss: 18.19195556640625\n",
      "Epoch: 18, Batch: 130, D Loss: 0.10683161615577719, G Loss: 18.29557991027832\n",
      "Epoch: 18, Batch: 131, D Loss: 0.09706599105978597, G Loss: 18.233135223388672\n",
      "Epoch: 18, Batch: 132, D Loss: 0.09355664925509233, G Loss: 18.026906967163086\n",
      "Epoch: 18, Batch: 133, D Loss: 0.10190167321950572, G Loss: 17.909046173095703\n",
      "Epoch: 18, Batch: 134, D Loss: 0.10425397075764664, G Loss: 17.960229873657227\n",
      "Epoch: 18, Batch: 135, D Loss: 0.09691423194559512, G Loss: 18.03546905517578\n",
      "Epoch: 18, Batch: 136, D Loss: 0.0961657684837216, G Loss: 18.093212127685547\n",
      "Epoch: 18, Batch: 137, D Loss: 0.0953530514680101, G Loss: 18.104501724243164\n",
      "Epoch: 18, Batch: 138, D Loss: 0.09986007887007764, G Loss: 18.140134811401367\n",
      "Epoch: 18, Batch: 139, D Loss: 0.09378484563548639, G Loss: 18.11183738708496\n",
      "Epoch: 18, Batch: 140, D Loss: 0.10342379579146943, G Loss: 18.158044815063477\n",
      "Epoch: 18, Batch: 141, D Loss: 0.1002205077320184, G Loss: 18.21580696105957\n",
      "Epoch: 18, Batch: 142, D Loss: 0.09821265053469297, G Loss: 18.23502540588379\n",
      "Epoch: 18, Batch: 143, D Loss: 0.09764457356758971, G Loss: 18.217388153076172\n",
      "Epoch: 18, Batch: 144, D Loss: 0.102207562402155, G Loss: 18.246688842773438\n",
      "Epoch: 18, Batch: 145, D Loss: 0.10039172909189054, G Loss: 18.2709903717041\n",
      "Epoch: 18, Batch: 146, D Loss: 0.10401204788642593, G Loss: 18.339752197265625\n",
      "Epoch: 18, Batch: 147, D Loss: 0.09491675158420376, G Loss: 18.29096794128418\n",
      "Epoch: 18, Batch: 148, D Loss: 0.0963095561219931, G Loss: 18.186504364013672\n",
      "Epoch: 18, Batch: 149, D Loss: 0.10454099502280334, G Loss: 18.21721076965332\n",
      "Epoch: 18, Batch: 150, D Loss: 0.09692074965715225, G Loss: 18.2351131439209\n",
      "Epoch: 18, Batch: 151, D Loss: 0.09383366128673698, G Loss: 18.189430236816406\n",
      "Epoch: 18, Batch: 152, D Loss: 0.09337027281541488, G Loss: 18.11431884765625\n",
      "Epoch: 18, Batch: 153, D Loss: 0.09899362101953635, G Loss: 18.139970779418945\n",
      "Epoch: 18, Batch: 154, D Loss: 0.0975402210235985, G Loss: 18.215023040771484\n",
      "Epoch: 18, Batch: 155, D Loss: 0.1010445637298587, G Loss: 18.34349250793457\n",
      "Epoch: 18, Batch: 156, D Loss: 0.09219909267605564, G Loss: 18.298179626464844\n",
      "Epoch: 18, Batch: 157, D Loss: 0.1097822466166054, G Loss: 18.4091739654541\n",
      "Epoch: 18, Batch: 158, D Loss: 0.09829987341031243, G Loss: 18.429418563842773\n",
      "Epoch: 18, Batch: 159, D Loss: 0.10278615849669137, G Loss: 18.435596466064453\n",
      "Epoch: 18, Batch: 160, D Loss: 0.09518901038833016, G Loss: 18.314186096191406\n",
      "Epoch: 18, Batch: 161, D Loss: 0.09990414066238973, G Loss: 18.23734474182129\n",
      "Epoch: 18, Batch: 162, D Loss: 0.10142440203065428, G Loss: 18.242170333862305\n",
      "Epoch: 18, Batch: 163, D Loss: 0.09583946167596746, G Loss: 18.250661849975586\n",
      "Epoch: 18, Batch: 164, D Loss: 0.09929365494350373, G Loss: 18.309797286987305\n",
      "Epoch: 18, Batch: 165, D Loss: 0.1077241128532247, G Loss: 18.501134872436523\n",
      "Epoch: 18, Batch: 166, D Loss: 0.0951039240684377, G Loss: 18.522727966308594\n",
      "Epoch: 18, Batch: 167, D Loss: 0.0918320914596027, G Loss: 18.32328987121582\n",
      "Epoch: 18, Batch: 168, D Loss: 0.10192542356346834, G Loss: 18.23246955871582\n",
      "Epoch: 18, Batch: 169, D Loss: 0.1003054663922831, G Loss: 18.244579315185547\n",
      "Epoch: 18, Batch: 170, D Loss: 0.10631485084228043, G Loss: 18.41254997253418\n",
      "Epoch: 18, Batch: 171, D Loss: 0.101518479194731, G Loss: 18.555702209472656\n",
      "Epoch: 18, Batch: 172, D Loss: 0.09657731354119159, G Loss: 18.51279067993164\n",
      "Epoch: 18, Batch: 173, D Loss: 0.10175395490522599, G Loss: 18.421178817749023\n",
      "Epoch: 18, Batch: 174, D Loss: 0.09636203739401683, G Loss: 18.27532196044922\n",
      "Epoch: 18, Batch: 175, D Loss: 0.10455111249837934, G Loss: 18.267763137817383\n",
      "Epoch: 18, Batch: 176, D Loss: 0.0951442628763095, G Loss: 18.235698699951172\n",
      "Epoch: 18, Batch: 177, D Loss: 0.10525767329406044, G Loss: 18.34095573425293\n",
      "Epoch: 18, Batch: 178, D Loss: 0.1021805754469125, G Loss: 18.46150016784668\n",
      "Epoch: 18, Batch: 179, D Loss: 0.10869422994703282, G Loss: 18.628488540649414\n",
      "Epoch: 18, Batch: 180, D Loss: 0.09361730941045687, G Loss: 18.542322158813477\n",
      "Epoch: 18, Batch: 181, D Loss: 0.1050964789021398, G Loss: 18.464933395385742\n",
      "Epoch: 18, Batch: 182, D Loss: 0.0973688191838975, G Loss: 18.331296920776367\n",
      "Epoch: 18, Batch: 183, D Loss: 0.11011875939235072, G Loss: 18.432796478271484\n",
      "Epoch: 18, Batch: 184, D Loss: 0.10074913964465537, G Loss: 18.557334899902344\n",
      "Epoch: 18, Batch: 185, D Loss: 0.0988733736194578, G Loss: 18.61865997314453\n",
      "Epoch: 18, Batch: 186, D Loss: 0.09550366233129637, G Loss: 18.5404052734375\n",
      "Epoch: 18, Batch: 187, D Loss: 0.09715619408020659, G Loss: 18.431568145751953\n",
      "Epoch: 18, Batch: 188, D Loss: 0.10006616767162146, G Loss: 18.401594161987305\n",
      "Epoch: 18, Batch: 189, D Loss: 0.10142330570403413, G Loss: 18.47613525390625\n",
      "Epoch: 18, Batch: 190, D Loss: 0.10249683699542089, G Loss: 18.619848251342773\n",
      "Epoch: 18, Batch: 191, D Loss: 0.10070620870128089, G Loss: 18.699604034423828\n",
      "Epoch: 18, Batch: 192, D Loss: 0.10503408678371606, G Loss: 18.764963150024414\n",
      "Epoch: 18, Batch: 193, D Loss: 0.0983114130356304, G Loss: 18.69276237487793\n",
      "Epoch: 18, Batch: 194, D Loss: 0.10516080647836512, G Loss: 18.6601619720459\n",
      "Epoch: 18, Batch: 195, D Loss: 0.09425981019231333, G Loss: 18.529766082763672\n",
      "Epoch: 18, Batch: 196, D Loss: 0.100318294905823, G Loss: 18.4760799407959\n",
      "Epoch: 18, Batch: 197, D Loss: 0.10010201204887759, G Loss: 18.505128860473633\n",
      "Epoch: 18, Batch: 198, D Loss: 0.09827262608124165, G Loss: 18.56667137145996\n",
      "Epoch: 18, Batch: 199, D Loss: 0.1054985637485859, G Loss: 18.724946975708008\n",
      "Epoch: 18, Batch: 200, D Loss: 0.0972205436599245, G Loss: 18.76435089111328\n",
      "Epoch: 18, Batch: 201, D Loss: 0.10027981909941541, G Loss: 18.733535766601562\n",
      "Epoch: 18, Batch: 202, D Loss: 0.09858835128213661, G Loss: 18.637331008911133\n",
      "Epoch: 18, Batch: 203, D Loss: 0.10276437959626072, G Loss: 18.60851287841797\n",
      "Epoch: 18, Batch: 204, D Loss: 0.10377270385917337, G Loss: 18.663532257080078\n",
      "Epoch: 18, Batch: 205, D Loss: 0.10093364498599344, G Loss: 18.72853660583496\n",
      "Epoch: 18, Batch: 206, D Loss: 0.0982816107270803, G Loss: 18.718505859375\n",
      "Epoch: 18, Batch: 207, D Loss: 0.10079110040837636, G Loss: 18.714340209960938\n",
      "Epoch: 18, Batch: 208, D Loss: 0.09659708672610545, G Loss: 18.671533584594727\n",
      "Epoch: 18, Batch: 209, D Loss: 0.09616460312154995, G Loss: 18.5905818939209\n",
      "Epoch: 18, Batch: 210, D Loss: 0.10230347927341654, G Loss: 18.63050651550293\n",
      "Epoch: 18, Batch: 211, D Loss: 0.09838065897736792, G Loss: 18.69112205505371\n",
      "Epoch: 18, Batch: 212, D Loss: 0.09692290798959835, G Loss: 18.73103904724121\n",
      "Epoch: 18, Batch: 213, D Loss: 0.10014286249707371, G Loss: 18.779314041137695\n",
      "Epoch: 18, Batch: 214, D Loss: 0.09615743514108299, G Loss: 18.755077362060547\n",
      "Epoch: 18, Batch: 215, D Loss: 0.0972643754661533, G Loss: 18.716022491455078\n",
      "Epoch: 18, Batch: 216, D Loss: 0.10211865968302591, G Loss: 18.756433486938477\n",
      "Epoch: 18, Batch: 217, D Loss: 0.10046976404250474, G Loss: 18.826183319091797\n",
      "Epoch: 18, Batch: 218, D Loss: 0.09755270511824676, G Loss: 18.852815628051758\n",
      "Epoch: 18, Batch: 219, D Loss: 0.10745754399100105, G Loss: 18.96383285522461\n",
      "Epoch: 18, Batch: 220, D Loss: 0.10006388565638424, G Loss: 18.974849700927734\n",
      "Epoch: 18, Batch: 221, D Loss: 0.09136814194726739, G Loss: 18.795257568359375\n",
      "Epoch: 18, Batch: 222, D Loss: 0.09313588971761977, G Loss: 18.59317970275879\n",
      "Epoch: 18, Batch: 223, D Loss: 0.0988715036336747, G Loss: 18.537628173828125\n",
      "Epoch: 18, Batch: 224, D Loss: 0.10475556212602743, G Loss: 18.714406967163086\n",
      "Epoch: 18, Batch: 225, D Loss: 0.0974228341594292, G Loss: 18.889345169067383\n",
      "Epoch: 18, Batch: 226, D Loss: 0.09922467472223451, G Loss: 18.968894958496094\n",
      "Epoch: 18, Batch: 227, D Loss: 0.10072254681587078, G Loss: 18.948965072631836\n",
      "Epoch: 18, Batch: 228, D Loss: 0.09995101706083265, G Loss: 18.83043098449707\n",
      "Epoch: 18, Batch: 229, D Loss: 0.10490228583317451, G Loss: 18.742961883544922\n",
      "Epoch: 18, Batch: 230, D Loss: 0.10280092431886323, G Loss: 18.696277618408203\n",
      "Epoch: 18, Batch: 231, D Loss: 0.09506734114859094, G Loss: 18.600149154663086\n",
      "Epoch: 18, Batch: 232, D Loss: 0.1008700248995753, G Loss: 18.585430145263672\n",
      "Epoch: 18, Batch: 233, D Loss: 0.09229676863248981, G Loss: 18.525253295898438\n",
      "Epoch: 18, Batch: 234, D Loss: 0.09197691548595888, G Loss: 18.462291717529297\n",
      "Epoch: 18, Batch: 235, D Loss: 0.09482601018648484, G Loss: 18.466337203979492\n",
      "Epoch: 18, Batch: 236, D Loss: 0.10003000192580691, G Loss: 18.62349510192871\n",
      "Epoch: 18, Batch: 237, D Loss: 0.10251918796720605, G Loss: 18.85366439819336\n",
      "Epoch: 18, Batch: 238, D Loss: 0.09243224880748402, G Loss: 18.882076263427734\n",
      "Epoch: 18, Batch: 239, D Loss: 0.1031598927103714, G Loss: 18.894773483276367\n",
      "Epoch: 18, Batch: 240, D Loss: 0.10119501070590653, G Loss: 18.876256942749023\n",
      "Epoch: 18, Batch: 241, D Loss: 0.10603361143706369, G Loss: 18.907196044921875\n",
      "Epoch: 18, Batch: 242, D Loss: 0.09987770332140822, G Loss: 18.884178161621094\n",
      "Epoch: 18, Batch: 243, D Loss: 0.10028503413050527, G Loss: 18.834556579589844\n",
      "Epoch: 18, Batch: 244, D Loss: 0.09640521903941113, G Loss: 18.738019943237305\n",
      "Epoch: 18, Batch: 245, D Loss: 0.09849234304404941, G Loss: 18.6614933013916\n",
      "Epoch: 18, Batch: 246, D Loss: 0.09969931486141537, G Loss: 18.674976348876953\n",
      "Epoch: 18, Batch: 247, D Loss: 0.09817346564216933, G Loss: 18.71978187561035\n",
      "Epoch: 18, Batch: 248, D Loss: 0.09104402744811502, G Loss: 18.665756225585938\n",
      "Epoch: 18, Batch: 249, D Loss: 0.0987250247764937, G Loss: 18.676979064941406\n",
      "Epoch: 18, Batch: 250, D Loss: 0.09735633812347144, G Loss: 18.71445083618164\n",
      "Epoch: 18, Batch: 251, D Loss: 0.0964840761741883, G Loss: 18.745389938354492\n",
      "Epoch: 18, Batch: 252, D Loss: 0.09873393533543462, G Loss: 18.776561737060547\n",
      "Epoch: 18, Batch: 253, D Loss: 0.10105237709247605, G Loss: 18.808635711669922\n",
      "Epoch: 18, Batch: 254, D Loss: 0.09578754352178032, G Loss: 18.780393600463867\n",
      "Epoch: 18, Batch: 255, D Loss: 0.09994644276293041, G Loss: 18.776737213134766\n",
      "Epoch: 18, Batch: 256, D Loss: 0.09840886647683922, G Loss: 18.76290512084961\n",
      "Epoch: 18, Batch: 257, D Loss: 0.0965314990997761, G Loss: 18.712059020996094\n",
      "Epoch: 18, Batch: 258, D Loss: 0.09545413792620083, G Loss: 18.64103889465332\n",
      "Epoch: 18, Batch: 259, D Loss: 0.09335829734441381, G Loss: 18.568214416503906\n",
      "Epoch: 18, Batch: 260, D Loss: 0.10269200469858264, G Loss: 18.651151657104492\n",
      "Epoch: 18, Batch: 261, D Loss: 0.09662013132527525, G Loss: 18.75178337097168\n",
      "Epoch: 18, Batch: 262, D Loss: 0.09292379380696625, G Loss: 18.75223159790039\n",
      "Epoch: 18, Batch: 263, D Loss: 0.10004257021679908, G Loss: 18.768190383911133\n",
      "Epoch: 18, Batch: 264, D Loss: 0.09578159063327196, G Loss: 18.748916625976562\n",
      "Epoch: 18, Batch: 265, D Loss: 0.10194196906664255, G Loss: 18.77838897705078\n",
      "Epoch: 18, Batch: 266, D Loss: 0.0989796107020875, G Loss: 18.788986206054688\n",
      "Epoch: 18, Batch: 267, D Loss: 0.09862494812924605, G Loss: 18.798803329467773\n",
      "Epoch: 18, Batch: 268, D Loss: 0.10046137463174842, G Loss: 18.819799423217773\n",
      "Epoch: 18, Batch: 269, D Loss: 0.09828180409748932, G Loss: 18.822410583496094\n",
      "Epoch: 18, Batch: 270, D Loss: 0.1020546513937517, G Loss: 18.85333251953125\n",
      "Epoch: 18, Batch: 271, D Loss: 0.09838227507094777, G Loss: 18.853200912475586\n",
      "Epoch: 18, Batch: 272, D Loss: 0.09882349102001386, G Loss: 18.843551635742188\n",
      "Epoch: 18, Batch: 273, D Loss: 0.09542955797616726, G Loss: 18.776229858398438\n",
      "Epoch: 18, Batch: 274, D Loss: 0.10057987620131126, G Loss: 18.792993545532227\n",
      "Epoch: 18, Batch: 275, D Loss: 0.0965754721669645, G Loss: 18.82526206970215\n",
      "Epoch: 18, Batch: 276, D Loss: 0.09187612276772161, G Loss: 18.793838500976562\n",
      "Epoch: 18, Batch: 277, D Loss: 0.09877650033315644, G Loss: 18.825613021850586\n",
      "Epoch: 18, Batch: 278, D Loss: 0.10904985962014391, G Loss: 19.053794860839844\n",
      "Epoch: 18, Batch: 279, D Loss: 0.09360962620946456, G Loss: 19.094688415527344\n",
      "Epoch: 18, Batch: 280, D Loss: 0.10033783573840926, G Loss: 19.077144622802734\n",
      "Epoch: 18, Batch: 281, D Loss: 0.10210258778155801, G Loss: 19.040191650390625\n",
      "Epoch: 18, Batch: 282, D Loss: 0.10271431775942252, G Loss: 19.032318115234375\n",
      "Epoch: 18, Batch: 283, D Loss: 0.09890206435833182, G Loss: 18.987987518310547\n",
      "Epoch: 18, Batch: 284, D Loss: 0.09662094264982035, G Loss: 18.89497947692871\n",
      "Epoch: 18, Batch: 285, D Loss: 0.10739716443332714, G Loss: 18.958818435668945\n",
      "Epoch: 18, Batch: 286, D Loss: 0.09500848798700923, G Loss: 18.927717208862305\n",
      "Epoch: 18, Batch: 287, D Loss: 0.09757064594590581, G Loss: 18.86252784729004\n",
      "Epoch: 18, Batch: 288, D Loss: 0.08929592727166669, G Loss: 18.667491912841797\n",
      "Epoch: 18, Batch: 289, D Loss: 0.09976269709094288, G Loss: 18.602420806884766\n",
      "Epoch: 18, Batch: 290, D Loss: 0.1003601591026726, G Loss: 18.682796478271484\n",
      "Epoch: 18, Batch: 291, D Loss: 0.09905692550806777, G Loss: 18.804475784301758\n",
      "Epoch: 18, Batch: 292, D Loss: 0.10092543383259311, G Loss: 18.936988830566406\n",
      "Epoch: 18, Batch: 293, D Loss: 0.09811850186938287, G Loss: 18.960115432739258\n",
      "Epoch: 18, Batch: 294, D Loss: 0.09702673113894167, G Loss: 18.87747573852539\n",
      "Epoch: 18, Batch: 295, D Loss: 0.09565770968005549, G Loss: 18.731605529785156\n",
      "Epoch: 18, Batch: 296, D Loss: 0.09925969322318684, G Loss: 18.676223754882812\n",
      "Epoch: 18, Batch: 297, D Loss: 0.10175001997290023, G Loss: 18.732362747192383\n",
      "Epoch: 18, Batch: 298, D Loss: 0.1049186769641477, G Loss: 18.912691116333008\n",
      "Epoch: 18, Batch: 299, D Loss: 0.09732161009947848, G Loss: 18.995502471923828\n",
      "Epoch: 18, Batch: 300, D Loss: 0.0992751447781528, G Loss: 18.9892635345459\n",
      "Epoch: 18, Batch: 301, D Loss: 0.0956771850957705, G Loss: 18.8686466217041\n",
      "Epoch: 18, Batch: 302, D Loss: 0.09757566796090011, G Loss: 18.727819442749023\n",
      "Epoch: 18, Batch: 303, D Loss: 0.09877191864462409, G Loss: 18.66360092163086\n",
      "Epoch: 18, Batch: 304, D Loss: 0.09427763921552534, G Loss: 18.626998901367188\n",
      "Epoch: 18, Batch: 305, D Loss: 0.10107712088525789, G Loss: 18.727262496948242\n",
      "Epoch: 18, Batch: 306, D Loss: 0.10159445891915686, G Loss: 18.88938331604004\n",
      "Epoch: 18, Batch: 307, D Loss: 0.0976230755709464, G Loss: 18.965660095214844\n",
      "Epoch: 18, Batch: 308, D Loss: 0.09842306670085987, G Loss: 18.935657501220703\n",
      "Epoch: 18, Batch: 309, D Loss: 0.10087953070816202, G Loss: 18.878211975097656\n",
      "Epoch: 18, Batch: 310, D Loss: 0.0991525757321261, G Loss: 18.810705184936523\n",
      "Epoch: 18, Batch: 311, D Loss: 0.09071311724303954, G Loss: 18.643451690673828\n",
      "Epoch: 18, Batch: 312, D Loss: 0.09718200979376723, G Loss: 18.57463264465332\n",
      "Epoch: 18, Batch: 313, D Loss: 0.105409387692319, G Loss: 18.745380401611328\n",
      "Epoch: 18, Batch: 314, D Loss: 0.09938022820720827, G Loss: 18.938791275024414\n",
      "Epoch: 18, Batch: 315, D Loss: 0.10268861329308132, G Loss: 19.097675323486328\n",
      "Epoch: 18, Batch: 316, D Loss: 0.09647371881720579, G Loss: 19.04111671447754\n",
      "Epoch: 18, Batch: 317, D Loss: 0.10319686215738022, G Loss: 18.965740203857422\n",
      "Epoch: 18, Batch: 318, D Loss: 0.10319609491736825, G Loss: 18.921737670898438\n",
      "Epoch: 18, Batch: 319, D Loss: 0.098397377300534, G Loss: 18.849430084228516\n",
      "Epoch: 18, Batch: 320, D Loss: 0.10174876776834796, G Loss: 18.85161018371582\n",
      "Epoch: 18, Batch: 321, D Loss: 0.09681789904293492, G Loss: 18.8383731842041\n",
      "Epoch: 18, Batch: 322, D Loss: 0.09483208841788304, G Loss: 18.808923721313477\n",
      "Epoch: 18, Batch: 323, D Loss: 0.10269484993131983, G Loss: 18.895030975341797\n",
      "Epoch: 18, Batch: 324, D Loss: 0.09649110143497563, G Loss: 18.945112228393555\n",
      "Epoch: 18, Batch: 325, D Loss: 0.10274270457721757, G Loss: 19.044931411743164\n",
      "Epoch: 18, Batch: 326, D Loss: 0.09805884476335613, G Loss: 19.072023391723633\n",
      "Epoch: 18, Batch: 327, D Loss: 0.09759810090804222, G Loss: 19.01275634765625\n",
      "Epoch: 18, Batch: 328, D Loss: 0.09681023946205536, G Loss: 18.930326461791992\n",
      "Epoch: 18, Batch: 329, D Loss: 0.10059740696358466, G Loss: 18.92028045654297\n",
      "Epoch: 18, Batch: 330, D Loss: 0.10894824093639177, G Loss: 19.112146377563477\n",
      "Epoch: 18, Batch: 331, D Loss: 0.10139267378394656, G Loss: 19.25895118713379\n",
      "Epoch: 18, Batch: 332, D Loss: 0.09741470435748911, G Loss: 19.243288040161133\n",
      "Epoch: 18, Batch: 333, D Loss: 0.10111035635002397, G Loss: 19.1690616607666\n",
      "Epoch: 18, Batch: 334, D Loss: 0.10004927467140878, G Loss: 19.070512771606445\n",
      "Epoch: 18, Batch: 335, D Loss: 0.09523417335173368, G Loss: 18.94057273864746\n",
      "Epoch: 18, Batch: 336, D Loss: 0.10419222254610783, G Loss: 19.00680923461914\n",
      "Epoch: 18, Batch: 337, D Loss: 0.10335618512969136, G Loss: 19.169170379638672\n",
      "Epoch: 18, Batch: 338, D Loss: 0.10250160317362056, G Loss: 19.313146591186523\n",
      "Epoch: 18, Batch: 339, D Loss: 0.1003831347217008, G Loss: 19.334522247314453\n",
      "Epoch: 18, Batch: 340, D Loss: 0.10784516681469936, G Loss: 19.35920524597168\n",
      "Epoch: 18, Batch: 341, D Loss: 0.09714532855833125, G Loss: 19.203760147094727\n",
      "Epoch: 18, Batch: 342, D Loss: 0.09792669374329344, G Loss: 18.981046676635742\n",
      "Epoch: 18, Batch: 343, D Loss: 0.10067479613807051, G Loss: 18.87836456298828\n",
      "Epoch: 18, Batch: 344, D Loss: 0.1023024798143215, G Loss: 18.947847366333008\n",
      "Epoch: 18, Batch: 345, D Loss: 0.09941499213123017, G Loss: 19.062353134155273\n",
      "Epoch: 18, Batch: 346, D Loss: 0.0939381074499328, G Loss: 19.05576515197754\n",
      "Epoch: 18, Batch: 347, D Loss: 0.10150631034520452, G Loss: 19.0743465423584\n",
      "Epoch: 18, Batch: 348, D Loss: 0.0980119806023807, G Loss: 19.05206871032715\n",
      "Epoch: 18, Batch: 349, D Loss: 0.09833759345099513, G Loss: 18.98404884338379\n",
      "Epoch: 18, Batch: 350, D Loss: 0.09804102329511166, G Loss: 18.90912628173828\n",
      "Epoch: 18, Batch: 351, D Loss: 0.102755370807877, G Loss: 18.919334411621094\n",
      "Epoch: 18, Batch: 352, D Loss: 0.09559769497274284, G Loss: 18.856887817382812\n",
      "Epoch: 18, Batch: 353, D Loss: 0.10074794617827787, G Loss: 18.84471893310547\n",
      "Epoch: 18, Batch: 354, D Loss: 0.09767151212925906, G Loss: 18.805879592895508\n",
      "Epoch: 18, Batch: 355, D Loss: 0.09711189918889773, G Loss: 18.747447967529297\n",
      "Epoch: 18, Batch: 356, D Loss: 0.09377210225274446, G Loss: 18.63302230834961\n",
      "Epoch: 18, Batch: 357, D Loss: 0.10074823010931588, G Loss: 18.62440299987793\n",
      "Epoch: 18, Batch: 358, D Loss: 0.10194086669723923, G Loss: 18.727951049804688\n",
      "Epoch: 18, Batch: 359, D Loss: 0.10001210477442624, G Loss: 18.799728393554688\n",
      "Epoch: 18, Batch: 360, D Loss: 0.10366081030202334, G Loss: 18.87590217590332\n",
      "Epoch: 18, Batch: 361, D Loss: 0.10236662942194608, G Loss: 18.883625030517578\n",
      "Epoch: 18, Batch: 362, D Loss: 0.09265109504760405, G Loss: 18.66446876525879\n",
      "Epoch: 18, Batch: 363, D Loss: 0.10426570892074105, G Loss: 18.546594619750977\n",
      "Epoch: 18, Batch: 364, D Loss: 0.10164258329665277, G Loss: 18.52655792236328\n",
      "Epoch: 18, Batch: 365, D Loss: 0.09668519799427955, G Loss: 18.519668579101562\n",
      "Epoch: 18, Batch: 366, D Loss: 0.09896835382240932, G Loss: 18.564043045043945\n",
      "Epoch: 18, Batch: 367, D Loss: 0.10130098873438964, G Loss: 18.66293716430664\n",
      "Epoch: 18, Batch: 368, D Loss: 0.10296796633621486, G Loss: 18.768125534057617\n",
      "Epoch: 18, Batch: 369, D Loss: 0.10219135481823338, G Loss: 18.805654525756836\n",
      "Epoch: 18, Batch: 370, D Loss: 0.09792916836072507, G Loss: 18.70211410522461\n",
      "Epoch: 18, Batch: 371, D Loss: 0.10500255613525944, G Loss: 18.65729522705078\n",
      "Epoch: 18, Batch: 372, D Loss: 0.10607782399042387, G Loss: 18.666698455810547\n",
      "Epoch: 18, Batch: 373, D Loss: 0.10243562252368532, G Loss: 18.679241180419922\n",
      "Epoch: 18, Batch: 374, D Loss: 0.09451616223309234, G Loss: 18.551944732666016\n",
      "Epoch: 18, Batch: 375, D Loss: 0.09596293152656754, G Loss: 18.387836456298828\n",
      "Epoch: 18, Batch: 376, D Loss: 0.09902389135085565, G Loss: 18.330854415893555\n",
      "Epoch: 18, Batch: 377, D Loss: 0.10041138313975129, G Loss: 18.394102096557617\n",
      "Epoch: 18, Batch: 378, D Loss: 0.09806819750745044, G Loss: 18.481060028076172\n",
      "Epoch: 18, Batch: 379, D Loss: 0.10648958813667786, G Loss: 18.658855438232422\n",
      "Epoch: 18, Batch: 380, D Loss: 0.09613644729588389, G Loss: 18.640792846679688\n",
      "Epoch: 18, Batch: 381, D Loss: 0.09628153280260632, G Loss: 18.496307373046875\n",
      "Epoch: 18, Batch: 382, D Loss: 0.10118265194462461, G Loss: 18.393293380737305\n",
      "Epoch: 18, Batch: 383, D Loss: 0.1028335145692405, G Loss: 18.399370193481445\n",
      "Epoch: 18, Batch: 384, D Loss: 0.10322278479374036, G Loss: 18.4926815032959\n",
      "Epoch: 18, Batch: 385, D Loss: 0.09578267202528945, G Loss: 18.503795623779297\n",
      "Epoch: 18, Batch: 386, D Loss: 0.09124804042402612, G Loss: 18.348773956298828\n",
      "Epoch: 18, Batch: 387, D Loss: 0.10400229478262224, G Loss: 18.372255325317383\n",
      "Epoch: 18, Batch: 388, D Loss: 0.09903388231264332, G Loss: 18.44253158569336\n",
      "Epoch: 18, Batch: 389, D Loss: 0.10465798236001733, G Loss: 18.584449768066406\n",
      "Epoch: 18, Batch: 390, D Loss: 0.09414963106889651, G Loss: 18.57034683227539\n",
      "Epoch: 18, Batch: 391, D Loss: 0.09590606100729948, G Loss: 18.468231201171875\n",
      "Epoch: 18, Batch: 392, D Loss: 0.10010512662744109, G Loss: 18.418493270874023\n",
      "Epoch: 18, Batch: 393, D Loss: 0.09374827668794339, G Loss: 18.340360641479492\n",
      "Epoch: 18, Batch: 394, D Loss: 0.10393907644848577, G Loss: 18.437034606933594\n",
      "Epoch: 18, Batch: 395, D Loss: 0.10125823772628806, G Loss: 18.591049194335938\n",
      "Epoch: 18, Batch: 396, D Loss: 0.09823376350657176, G Loss: 18.643280029296875\n",
      "Epoch: 18, Batch: 397, D Loss: 0.10179230967059594, G Loss: 18.662578582763672\n",
      "Epoch: 18, Batch: 398, D Loss: 0.09876828307742702, G Loss: 18.5706787109375\n",
      "Epoch: 18, Batch: 399, D Loss: 0.10394556511580255, G Loss: 18.545310974121094\n",
      "Epoch: 18, Batch: 400, D Loss: 0.10109097209900009, G Loss: 18.53308868408203\n",
      "Epoch: 18, Batch: 401, D Loss: 0.09725582310647773, G Loss: 18.494749069213867\n",
      "Epoch: 18, Batch: 402, D Loss: 0.10226042280664194, G Loss: 18.525239944458008\n",
      "Epoch: 18, Batch: 403, D Loss: 0.08956986404677192, G Loss: 18.388700485229492\n",
      "Epoch: 18, Batch: 404, D Loss: 0.10315464951750153, G Loss: 18.39487075805664\n",
      "Epoch: 18, Batch: 405, D Loss: 0.10024543600748537, G Loss: 18.466617584228516\n",
      "Epoch: 18, Batch: 406, D Loss: 0.0990825043819461, G Loss: 18.522035598754883\n",
      "Epoch: 18, Batch: 407, D Loss: 0.09458069972706573, G Loss: 18.449932098388672\n",
      "Epoch: 18, Batch: 408, D Loss: 0.10388308505238575, G Loss: 18.445768356323242\n",
      "Epoch: 18, Batch: 409, D Loss: 0.09896149235754681, G Loss: 18.41963768005371\n",
      "Epoch: 18, Batch: 410, D Loss: 0.10690827404317238, G Loss: 18.493064880371094\n",
      "Epoch: 18, Batch: 411, D Loss: 0.09283327062025482, G Loss: 18.371976852416992\n",
      "Epoch: 18, Batch: 412, D Loss: 0.1018828803773717, G Loss: 18.314748764038086\n",
      "Epoch: 18, Batch: 413, D Loss: 0.09825629558668636, G Loss: 18.291973114013672\n",
      "Epoch: 18, Batch: 414, D Loss: 0.08951359103950152, G Loss: 18.169111251831055\n",
      "Epoch: 18, Batch: 415, D Loss: 0.09499603420197156, G Loss: 18.133787155151367\n",
      "Epoch: 18, Batch: 416, D Loss: 0.1049439892650037, G Loss: 18.33017349243164\n",
      "Epoch: 18, Batch: 417, D Loss: 0.10132109112996757, G Loss: 18.562963485717773\n",
      "Epoch: 18, Batch: 418, D Loss: 0.10640598475093244, G Loss: 18.781343460083008\n",
      "Epoch: 18, Batch: 419, D Loss: 0.09518042582019026, G Loss: 18.64166259765625\n",
      "Epoch: 18, Batch: 420, D Loss: 0.09679670355763159, G Loss: 18.343339920043945\n",
      "Epoch: 18, Batch: 421, D Loss: 0.09982012815277574, G Loss: 18.134662628173828\n",
      "Epoch: 18, Batch: 422, D Loss: 0.09456340938565067, G Loss: 17.99920654296875\n",
      "Epoch: 18, Batch: 423, D Loss: 0.09686454388431454, G Loss: 18.03564453125\n",
      "Epoch: 18, Batch: 424, D Loss: 0.1016833400410686, G Loss: 18.261577606201172\n",
      "Epoch: 18, Batch: 425, D Loss: 0.09622787473683392, G Loss: 18.43721580505371\n",
      "Epoch: 18, Batch: 426, D Loss: 0.09882282192648306, G Loss: 18.515716552734375\n",
      "Epoch: 18, Batch: 427, D Loss: 0.10169054278526124, G Loss: 18.51167869567871\n",
      "Epoch: 18, Batch: 428, D Loss: 0.0964369972203234, G Loss: 18.36489486694336\n",
      "Epoch: 18, Batch: 429, D Loss: 0.09547842883249702, G Loss: 18.15907859802246\n",
      "Epoch: 18, Batch: 430, D Loss: 0.09934344067378031, G Loss: 18.10148048400879\n",
      "Epoch: 18, Batch: 431, D Loss: 0.0928818206363764, G Loss: 18.071958541870117\n",
      "Epoch: 18, Batch: 432, D Loss: 0.09678358521122155, G Loss: 18.146825790405273\n",
      "Epoch: 18, Batch: 433, D Loss: 0.09782539915236255, G Loss: 18.298742294311523\n",
      "Epoch: 18, Batch: 434, D Loss: 0.09935378803119344, G Loss: 18.45691680908203\n",
      "Epoch: 18, Batch: 435, D Loss: 0.09430905164113224, G Loss: 18.475502014160156\n",
      "Epoch: 18, Batch: 436, D Loss: 0.10307591124212712, G Loss: 18.527097702026367\n",
      "Epoch: 18, Batch: 437, D Loss: 0.09712534110968818, G Loss: 18.491371154785156\n",
      "Epoch: 18, Batch: 438, D Loss: 0.09771455558139674, G Loss: 18.439800262451172\n",
      "Epoch: 18, Batch: 439, D Loss: 0.09692943602479343, G Loss: 18.38014793395996\n",
      "Epoch: 18, Batch: 440, D Loss: 0.10695085416360994, G Loss: 18.508073806762695\n",
      "Epoch: 18, Batch: 441, D Loss: 0.09619396628374854, G Loss: 18.54927635192871\n",
      "Epoch: 18, Batch: 442, D Loss: 0.09747124164989884, G Loss: 18.519550323486328\n",
      "Epoch: 18, Batch: 443, D Loss: 0.10327037871123812, G Loss: 18.5439453125\n",
      "Epoch: 18, Batch: 444, D Loss: 0.10236774818814842, G Loss: 18.579925537109375\n",
      "Epoch: 18, Batch: 445, D Loss: 0.1007346926048398, G Loss: 18.580759048461914\n",
      "Epoch: 18, Batch: 446, D Loss: 0.09883404967738185, G Loss: 18.50019073486328\n",
      "Epoch: 18, Batch: 447, D Loss: 0.10142257536534238, G Loss: 18.4593448638916\n",
      "Epoch: 18, Batch: 448, D Loss: 0.09543724121968022, G Loss: 18.35271644592285\n",
      "Epoch: 18, Batch: 449, D Loss: 0.09606200274755405, G Loss: 18.256328582763672\n",
      "Epoch: 18, Batch: 450, D Loss: 0.10551570910934682, G Loss: 18.370689392089844\n",
      "Epoch: 18, Batch: 451, D Loss: 0.1005006928311376, G Loss: 18.5144100189209\n",
      "Epoch: 18, Batch: 452, D Loss: 0.10042897303541176, G Loss: 18.59379768371582\n",
      "Epoch: 18, Batch: 453, D Loss: 0.10064667889112044, G Loss: 18.5705509185791\n",
      "Epoch: 18, Batch: 454, D Loss: 0.10008861578657058, G Loss: 18.469017028808594\n",
      "Epoch: 18, Batch: 455, D Loss: 0.09681682810025061, G Loss: 18.297992706298828\n",
      "Epoch: 18, Batch: 456, D Loss: 0.10288112438819086, G Loss: 18.271865844726562\n",
      "Epoch: 18, Batch: 457, D Loss: 0.0992142615045064, G Loss: 18.308115005493164\n",
      "Epoch: 18, Batch: 458, D Loss: 0.09443265766236397, G Loss: 18.285173416137695\n",
      "Epoch: 18, Batch: 459, D Loss: 0.10297939730884131, G Loss: 18.363733291625977\n",
      "Epoch: 18, Batch: 460, D Loss: 0.09614155226277754, G Loss: 18.3625431060791\n",
      "Epoch: 18, Batch: 461, D Loss: 0.09723946991167454, G Loss: 18.33087158203125\n",
      "Epoch: 18, Batch: 462, D Loss: 0.09916432009277054, G Loss: 18.312606811523438\n",
      "Epoch: 18, Batch: 463, D Loss: 0.10149299903842746, G Loss: 18.335813522338867\n",
      "Epoch: 18, Batch: 464, D Loss: 0.09792353764858497, G Loss: 18.30963897705078\n",
      "Epoch: 18, Batch: 465, D Loss: 0.09067375085155271, G Loss: 18.12061309814453\n",
      "Epoch: 18, Batch: 466, D Loss: 0.09859084290783349, G Loss: 18.05814552307129\n",
      "Epoch: 18, Batch: 467, D Loss: 0.10509664477058012, G Loss: 18.22954559326172\n",
      "Epoch: 19, Batch: 0, D Loss: 0.10239561435995626, G Loss: 18.46827507019043\n",
      "Epoch: 19, Batch: 1, D Loss: 0.0971629516806547, G Loss: 18.527727127075195\n",
      "Epoch: 19, Batch: 2, D Loss: 0.10035190448057385, G Loss: 18.475740432739258\n",
      "Epoch: 19, Batch: 3, D Loss: 0.0975854150328046, G Loss: 18.314233779907227\n",
      "Epoch: 19, Batch: 4, D Loss: 0.10677409723505482, G Loss: 18.33106803894043\n",
      "Epoch: 19, Batch: 5, D Loss: 0.09375164481531106, G Loss: 18.25712776184082\n",
      "Epoch: 19, Batch: 6, D Loss: 0.1007873474009946, G Loss: 18.284542083740234\n",
      "Epoch: 19, Batch: 7, D Loss: 0.0993486324981423, G Loss: 18.374080657958984\n",
      "Epoch: 19, Batch: 8, D Loss: 0.09081358996745426, G Loss: 18.337631225585938\n",
      "Epoch: 19, Batch: 9, D Loss: 0.09646723225669929, G Loss: 18.310497283935547\n",
      "Epoch: 19, Batch: 10, D Loss: 0.09766393699064846, G Loss: 18.359540939331055\n",
      "Epoch: 19, Batch: 11, D Loss: 0.09998375670420812, G Loss: 18.50286865234375\n",
      "Epoch: 19, Batch: 12, D Loss: 0.09922095814467813, G Loss: 18.650184631347656\n",
      "Epoch: 19, Batch: 13, D Loss: 0.10877956800180022, G Loss: 18.89081382751465\n",
      "Epoch: 19, Batch: 14, D Loss: 0.10280458928368197, G Loss: 18.973331451416016\n",
      "Epoch: 19, Batch: 15, D Loss: 0.09854665713662336, G Loss: 18.800840377807617\n",
      "Epoch: 19, Batch: 16, D Loss: 0.09984471291996888, G Loss: 18.559656143188477\n",
      "Epoch: 19, Batch: 17, D Loss: 0.10010602052026085, G Loss: 18.405887603759766\n",
      "Epoch: 19, Batch: 18, D Loss: 0.09229870679747831, G Loss: 18.29109764099121\n",
      "Epoch: 19, Batch: 19, D Loss: 0.0930062887999652, G Loss: 18.270767211914062\n",
      "Epoch: 19, Batch: 20, D Loss: 0.09396669077843534, G Loss: 18.360429763793945\n",
      "Epoch: 19, Batch: 21, D Loss: 0.09791979671126594, G Loss: 18.562896728515625\n",
      "Epoch: 19, Batch: 22, D Loss: 0.09155536111685247, G Loss: 18.652936935424805\n",
      "Epoch: 19, Batch: 23, D Loss: 0.09857470174881788, G Loss: 18.744831085205078\n",
      "Epoch: 19, Batch: 24, D Loss: 0.09694400787631063, G Loss: 18.764657974243164\n",
      "Epoch: 19, Batch: 25, D Loss: 0.10105099131785944, G Loss: 18.801111221313477\n",
      "Epoch: 19, Batch: 26, D Loss: 0.09680553873485742, G Loss: 18.760398864746094\n",
      "Epoch: 19, Batch: 27, D Loss: 0.09526159248317345, G Loss: 18.63905143737793\n",
      "Epoch: 19, Batch: 28, D Loss: 0.09457567011667578, G Loss: 18.545085906982422\n",
      "Epoch: 19, Batch: 29, D Loss: 0.09474751791461822, G Loss: 18.5589542388916\n",
      "Epoch: 19, Batch: 30, D Loss: 0.09728049153773499, G Loss: 18.661943435668945\n",
      "Epoch: 19, Batch: 31, D Loss: 0.0982369519417845, G Loss: 18.777860641479492\n",
      "Epoch: 19, Batch: 32, D Loss: 0.09854029456836355, G Loss: 18.84463119506836\n",
      "Epoch: 19, Batch: 33, D Loss: 0.10429514515150595, G Loss: 18.913358688354492\n",
      "Epoch: 19, Batch: 34, D Loss: 0.10005040778222773, G Loss: 18.87712860107422\n",
      "Epoch: 19, Batch: 35, D Loss: 0.09609867979696007, G Loss: 18.70229721069336\n",
      "Epoch: 19, Batch: 36, D Loss: 0.10025554556908967, G Loss: 18.560588836669922\n",
      "Epoch: 19, Batch: 37, D Loss: 0.09881535617195292, G Loss: 18.517921447753906\n",
      "Epoch: 19, Batch: 38, D Loss: 0.0955293819546652, G Loss: 18.536407470703125\n",
      "Epoch: 19, Batch: 39, D Loss: 0.0978491572428557, G Loss: 18.6212100982666\n",
      "Epoch: 19, Batch: 40, D Loss: 0.100231323443988, G Loss: 18.772911071777344\n",
      "Epoch: 19, Batch: 41, D Loss: 0.10222795929420947, G Loss: 18.929607391357422\n",
      "Epoch: 19, Batch: 42, D Loss: 0.09950132963986813, G Loss: 18.959266662597656\n",
      "Epoch: 19, Batch: 43, D Loss: 0.09890120779254241, G Loss: 18.889320373535156\n",
      "Epoch: 19, Batch: 44, D Loss: 0.10259692693260458, G Loss: 18.833173751831055\n",
      "Epoch: 19, Batch: 45, D Loss: 0.10378501141051655, G Loss: 18.886859893798828\n",
      "Epoch: 19, Batch: 46, D Loss: 0.0981003225796826, G Loss: 18.925212860107422\n",
      "Epoch: 19, Batch: 47, D Loss: 0.10251927667520899, G Loss: 18.990703582763672\n",
      "Epoch: 19, Batch: 48, D Loss: 0.09885780049662274, G Loss: 19.00005531311035\n",
      "Epoch: 19, Batch: 49, D Loss: 0.09603722683135629, G Loss: 18.937023162841797\n",
      "Epoch: 19, Batch: 50, D Loss: 0.10520939820264186, G Loss: 18.982662200927734\n",
      "Epoch: 19, Batch: 51, D Loss: 0.0984309046066465, G Loss: 18.989418029785156\n",
      "Epoch: 19, Batch: 52, D Loss: 0.09761230940532628, G Loss: 18.924819946289062\n",
      "Epoch: 19, Batch: 53, D Loss: 0.10391619353579329, G Loss: 18.95626449584961\n",
      "Epoch: 19, Batch: 54, D Loss: 0.09963716858025928, G Loss: 18.964494705200195\n",
      "Epoch: 19, Batch: 55, D Loss: 0.10132453878448122, G Loss: 18.98097038269043\n",
      "Epoch: 19, Batch: 56, D Loss: 0.09740732905499483, G Loss: 18.917491912841797\n",
      "Epoch: 19, Batch: 57, D Loss: 0.10205284809712434, G Loss: 18.921646118164062\n",
      "Epoch: 19, Batch: 58, D Loss: 0.1041615485194769, G Loss: 19.014829635620117\n",
      "Epoch: 19, Batch: 59, D Loss: 0.09879428420941583, G Loss: 19.038354873657227\n",
      "Epoch: 19, Batch: 60, D Loss: 0.10748218255972897, G Loss: 19.13665771484375\n",
      "Epoch: 19, Batch: 61, D Loss: 0.10330093891487357, G Loss: 19.175312042236328\n",
      "Epoch: 19, Batch: 62, D Loss: 0.10339837014353481, G Loss: 19.151437759399414\n",
      "Epoch: 19, Batch: 63, D Loss: 0.1008169080320036, G Loss: 19.05483627319336\n",
      "Epoch: 19, Batch: 64, D Loss: 0.10242922877507965, G Loss: 18.997047424316406\n",
      "Epoch: 19, Batch: 65, D Loss: 0.09749806215496482, G Loss: 18.948986053466797\n",
      "Epoch: 19, Batch: 66, D Loss: 0.10366021383357737, G Loss: 19.002609252929688\n",
      "Epoch: 19, Batch: 67, D Loss: 0.10158820718909256, G Loss: 19.077802658081055\n",
      "Epoch: 19, Batch: 68, D Loss: 0.09994658340514673, G Loss: 19.08828353881836\n",
      "Epoch: 19, Batch: 69, D Loss: 0.09741711883954407, G Loss: 19.008995056152344\n",
      "Epoch: 19, Batch: 70, D Loss: 0.09595240953614526, G Loss: 18.855257034301758\n",
      "Epoch: 19, Batch: 71, D Loss: 0.09784210063984555, G Loss: 18.7866268157959\n",
      "Epoch: 19, Batch: 72, D Loss: 0.09651507784393032, G Loss: 18.784971237182617\n",
      "Epoch: 19, Batch: 73, D Loss: 0.09693183342304224, G Loss: 18.84030532836914\n",
      "Epoch: 19, Batch: 74, D Loss: 0.10367305876555699, G Loss: 19.01519203186035\n",
      "Epoch: 19, Batch: 75, D Loss: 0.09950129952006304, G Loss: 19.0977783203125\n",
      "Epoch: 19, Batch: 76, D Loss: 0.10101148742606236, G Loss: 19.0800724029541\n",
      "Epoch: 19, Batch: 77, D Loss: 0.10430411510577486, G Loss: 19.06142807006836\n",
      "Epoch: 19, Batch: 78, D Loss: 0.10170044278820822, G Loss: 18.98778533935547\n",
      "Epoch: 19, Batch: 79, D Loss: 0.09679954803435242, G Loss: 18.853160858154297\n",
      "Epoch: 19, Batch: 80, D Loss: 0.09724331988230062, G Loss: 18.758634567260742\n",
      "Epoch: 19, Batch: 81, D Loss: 0.09853037802705122, G Loss: 18.762550354003906\n",
      "Epoch: 19, Batch: 82, D Loss: 0.09824714401030143, G Loss: 18.8660945892334\n",
      "Epoch: 19, Batch: 83, D Loss: 0.10302857597939385, G Loss: 19.065397262573242\n",
      "Epoch: 19, Batch: 84, D Loss: 0.1036166721737859, G Loss: 19.23505401611328\n",
      "Epoch: 19, Batch: 85, D Loss: 0.10034488362697114, G Loss: 19.237943649291992\n",
      "Epoch: 19, Batch: 86, D Loss: 0.09725035227299283, G Loss: 19.03782844543457\n",
      "Epoch: 19, Batch: 87, D Loss: 0.0968430147282513, G Loss: 18.8035888671875\n",
      "Epoch: 19, Batch: 88, D Loss: 0.0959552265017245, G Loss: 18.67085075378418\n",
      "Epoch: 19, Batch: 89, D Loss: 0.10138715423665356, G Loss: 18.79323387145996\n",
      "Epoch: 19, Batch: 90, D Loss: 0.09140441894567353, G Loss: 18.887479782104492\n",
      "Epoch: 19, Batch: 91, D Loss: 0.09640556872116623, G Loss: 18.98247718811035\n",
      "Epoch: 19, Batch: 92, D Loss: 0.1022628274353019, G Loss: 19.113187789916992\n",
      "Epoch: 19, Batch: 93, D Loss: 0.09903776894151317, G Loss: 19.126178741455078\n",
      "Epoch: 19, Batch: 94, D Loss: 0.0908698616730641, G Loss: 18.87904167175293\n",
      "Epoch: 19, Batch: 95, D Loss: 0.09454391513359472, G Loss: 18.623308181762695\n",
      "Epoch: 19, Batch: 96, D Loss: 0.09937318086801117, G Loss: 18.581863403320312\n",
      "Epoch: 19, Batch: 97, D Loss: 0.10038111004242856, G Loss: 18.74578285217285\n",
      "Epoch: 19, Batch: 98, D Loss: 0.09133190266877378, G Loss: 18.804737091064453\n",
      "Epoch: 19, Batch: 99, D Loss: 0.10741998558148702, G Loss: 19.02717399597168\n",
      "Epoch: 19, Batch: 100, D Loss: 0.09921119625957853, G Loss: 19.08974266052246\n",
      "Epoch: 19, Batch: 101, D Loss: 0.09664605833075246, G Loss: 18.9534912109375\n",
      "Epoch: 19, Batch: 102, D Loss: 0.10212142332838292, G Loss: 18.835126876831055\n",
      "Epoch: 19, Batch: 103, D Loss: 0.10012176976008291, G Loss: 18.763429641723633\n",
      "Epoch: 19, Batch: 104, D Loss: 0.1043804992310986, G Loss: 18.853927612304688\n",
      "Epoch: 19, Batch: 105, D Loss: 0.10717317002917426, G Loss: 19.092182159423828\n",
      "Epoch: 19, Batch: 106, D Loss: 0.10215039048147467, G Loss: 19.195829391479492\n",
      "Epoch: 19, Batch: 107, D Loss: 0.10751089681816217, G Loss: 19.214336395263672\n",
      "Epoch: 19, Batch: 108, D Loss: 0.10043822474578001, G Loss: 19.056427001953125\n",
      "Epoch: 19, Batch: 109, D Loss: 0.09649898418522174, G Loss: 18.77639389038086\n",
      "Epoch: 19, Batch: 110, D Loss: 0.09589149455048673, G Loss: 18.537738800048828\n",
      "Epoch: 19, Batch: 111, D Loss: 0.10886785799854604, G Loss: 18.68413543701172\n",
      "Epoch: 19, Batch: 112, D Loss: 0.10130548813764095, G Loss: 18.935304641723633\n",
      "Epoch: 19, Batch: 113, D Loss: 0.09475593559840245, G Loss: 18.986507415771484\n",
      "Epoch: 19, Batch: 114, D Loss: 0.10412703738036, G Loss: 18.989538192749023\n",
      "Epoch: 19, Batch: 115, D Loss: 0.10030139534368154, G Loss: 18.900367736816406\n",
      "Epoch: 19, Batch: 116, D Loss: 0.1090054169881407, G Loss: 18.935604095458984\n",
      "Epoch: 19, Batch: 117, D Loss: 0.10455956604429217, G Loss: 18.964031219482422\n",
      "Epoch: 19, Batch: 118, D Loss: 0.09625485856400195, G Loss: 18.797893524169922\n",
      "Epoch: 19, Batch: 119, D Loss: 0.09712319455707563, G Loss: 18.604494094848633\n",
      "Epoch: 19, Batch: 120, D Loss: 0.10090952777383722, G Loss: 18.629236221313477\n",
      "Epoch: 19, Batch: 121, D Loss: 0.09869369502022396, G Loss: 18.741769790649414\n",
      "Epoch: 19, Batch: 122, D Loss: 0.09756064758145078, G Loss: 18.847461700439453\n",
      "Epoch: 19, Batch: 123, D Loss: 0.09924096927115778, G Loss: 18.927003860473633\n",
      "Epoch: 19, Batch: 124, D Loss: 0.09749104387896668, G Loss: 18.90271759033203\n",
      "Epoch: 19, Batch: 125, D Loss: 0.09785750082917177, G Loss: 18.837282180786133\n",
      "Epoch: 19, Batch: 126, D Loss: 0.09367673452767211, G Loss: 18.703672409057617\n",
      "Epoch: 19, Batch: 127, D Loss: 0.100302640364482, G Loss: 18.717735290527344\n",
      "Epoch: 19, Batch: 128, D Loss: 0.09144997231539032, G Loss: 18.67605972290039\n",
      "Epoch: 19, Batch: 129, D Loss: 0.09640442215186784, G Loss: 18.71156883239746\n",
      "Epoch: 19, Batch: 130, D Loss: 0.10082677351816982, G Loss: 18.863666534423828\n",
      "Epoch: 19, Batch: 131, D Loss: 0.10577127617645266, G Loss: 19.122053146362305\n",
      "Epoch: 19, Batch: 132, D Loss: 0.10311579937122195, G Loss: 19.241741180419922\n",
      "Epoch: 19, Batch: 133, D Loss: 0.09804478529695526, G Loss: 19.060630798339844\n",
      "Epoch: 19, Batch: 134, D Loss: 0.09293517050618161, G Loss: 18.66042137145996\n",
      "Epoch: 19, Batch: 135, D Loss: 0.10069224676440758, G Loss: 18.456558227539062\n",
      "Epoch: 19, Batch: 136, D Loss: 0.09597369767607056, G Loss: 18.450284957885742\n",
      "Epoch: 19, Batch: 137, D Loss: 0.09857690768845995, G Loss: 18.6610164642334\n",
      "Epoch: 19, Batch: 138, D Loss: 0.09844801168390127, G Loss: 18.94538116455078\n",
      "Epoch: 19, Batch: 139, D Loss: 0.09655764970037373, G Loss: 19.11198616027832\n",
      "Epoch: 19, Batch: 140, D Loss: 0.1050458499298601, G Loss: 19.245384216308594\n",
      "Epoch: 19, Batch: 141, D Loss: 0.10186643375095361, G Loss: 19.224336624145508\n",
      "Epoch: 19, Batch: 142, D Loss: 0.10543423375257266, G Loss: 19.179359436035156\n",
      "Epoch: 19, Batch: 143, D Loss: 0.09589517377638757, G Loss: 18.97233009338379\n",
      "Epoch: 19, Batch: 144, D Loss: 0.09378082633440643, G Loss: 18.723678588867188\n",
      "Epoch: 19, Batch: 145, D Loss: 0.10143434627448689, G Loss: 18.714902877807617\n",
      "Epoch: 19, Batch: 146, D Loss: 0.10335472553289304, G Loss: 18.961971282958984\n",
      "Epoch: 19, Batch: 147, D Loss: 0.10195504381143095, G Loss: 19.234634399414062\n",
      "Epoch: 19, Batch: 148, D Loss: 0.09538367609618703, G Loss: 19.257118225097656\n",
      "Epoch: 19, Batch: 149, D Loss: 0.10147759543132917, G Loss: 19.18724250793457\n",
      "Epoch: 19, Batch: 150, D Loss: 0.0959566261333551, G Loss: 18.988609313964844\n",
      "Epoch: 19, Batch: 151, D Loss: 0.0941551359541124, G Loss: 18.76727867126465\n",
      "Epoch: 19, Batch: 152, D Loss: 0.10173069288865766, G Loss: 18.796653747558594\n",
      "Epoch: 19, Batch: 153, D Loss: 0.0964087428360334, G Loss: 18.96053695678711\n",
      "Epoch: 19, Batch: 154, D Loss: 0.09435830537284917, G Loss: 19.092144012451172\n",
      "Epoch: 19, Batch: 155, D Loss: 0.10558647138684996, G Loss: 19.364564895629883\n",
      "Epoch: 19, Batch: 156, D Loss: 0.09848868285492374, G Loss: 19.474369049072266\n",
      "Epoch: 19, Batch: 157, D Loss: 0.09835395396357549, G Loss: 19.419893264770508\n",
      "Epoch: 19, Batch: 158, D Loss: 0.1022826526498064, G Loss: 19.379114151000977\n",
      "Epoch: 19, Batch: 159, D Loss: 0.09890647428017707, G Loss: 19.342700958251953\n",
      "Epoch: 19, Batch: 160, D Loss: 0.09335554599188622, G Loss: 19.257259368896484\n",
      "Epoch: 19, Batch: 161, D Loss: 0.0960702321991429, G Loss: 19.235000610351562\n",
      "Epoch: 19, Batch: 162, D Loss: 0.10567847091603433, G Loss: 19.454029083251953\n",
      "Epoch: 19, Batch: 163, D Loss: 0.09434929659146152, G Loss: 19.551239013671875\n",
      "Epoch: 19, Batch: 164, D Loss: 0.0950031446252031, G Loss: 19.4843807220459\n",
      "Epoch: 19, Batch: 165, D Loss: 0.09505189396627567, G Loss: 19.33767318725586\n",
      "Epoch: 19, Batch: 166, D Loss: 0.10452842163834686, G Loss: 19.3702392578125\n",
      "Epoch: 19, Batch: 167, D Loss: 0.10317331738504454, G Loss: 19.445459365844727\n",
      "Epoch: 19, Batch: 168, D Loss: 0.09715186238636919, G Loss: 19.448707580566406\n",
      "Epoch: 19, Batch: 169, D Loss: 0.10715765675932165, G Loss: 19.546476364135742\n",
      "Epoch: 19, Batch: 170, D Loss: 0.09673477877114811, G Loss: 19.481918334960938\n",
      "Epoch: 19, Batch: 171, D Loss: 0.09683555553656786, G Loss: 19.313552856445312\n",
      "Epoch: 19, Batch: 172, D Loss: 0.10156607842855214, G Loss: 19.221084594726562\n",
      "Epoch: 19, Batch: 173, D Loss: 0.09635381632131268, G Loss: 19.163314819335938\n",
      "Epoch: 19, Batch: 174, D Loss: 0.09916839233419772, G Loss: 19.22928810119629\n",
      "Epoch: 19, Batch: 175, D Loss: 0.1050633360578972, G Loss: 19.481372833251953\n",
      "Epoch: 19, Batch: 176, D Loss: 0.10213416224041649, G Loss: 19.699832916259766\n",
      "Epoch: 19, Batch: 177, D Loss: 0.0972149982080055, G Loss: 19.69745635986328\n",
      "Epoch: 19, Batch: 178, D Loss: 0.09499015816471712, G Loss: 19.46750259399414\n",
      "Epoch: 19, Batch: 179, D Loss: 0.10306260176097148, G Loss: 19.353864669799805\n",
      "Epoch: 19, Batch: 180, D Loss: 0.10191773815422844, G Loss: 19.397714614868164\n",
      "Epoch: 19, Batch: 181, D Loss: 0.09573911317619177, G Loss: 19.40835952758789\n",
      "Epoch: 19, Batch: 182, D Loss: 0.09600664862971886, G Loss: 19.393274307250977\n",
      "Epoch: 19, Batch: 183, D Loss: 0.10591968319768719, G Loss: 19.586034774780273\n",
      "Epoch: 19, Batch: 184, D Loss: 0.09966756548566158, G Loss: 19.72245979309082\n",
      "Epoch: 19, Batch: 185, D Loss: 0.09459445023476387, G Loss: 19.627683639526367\n",
      "Epoch: 19, Batch: 186, D Loss: 0.09599743947538597, G Loss: 19.451465606689453\n",
      "Epoch: 19, Batch: 187, D Loss: 0.10654394500995157, G Loss: 19.516326904296875\n",
      "Epoch: 19, Batch: 188, D Loss: 0.10072696362816902, G Loss: 19.673938751220703\n",
      "Epoch: 19, Batch: 189, D Loss: 0.10480833181355209, G Loss: 19.885028839111328\n",
      "Epoch: 19, Batch: 190, D Loss: 0.10852346673949154, G Loss: 20.07382583618164\n",
      "Epoch: 19, Batch: 191, D Loss: 0.09071578197007568, G Loss: 19.78152084350586\n",
      "Epoch: 19, Batch: 192, D Loss: 0.09694221770416933, G Loss: 19.424604415893555\n",
      "Epoch: 19, Batch: 193, D Loss: 0.1009404604289399, G Loss: 19.304033279418945\n",
      "Epoch: 19, Batch: 194, D Loss: 0.09803799739232355, G Loss: 19.372325897216797\n",
      "Epoch: 19, Batch: 195, D Loss: 0.09397597049005624, G Loss: 19.472875595092773\n",
      "Epoch: 19, Batch: 196, D Loss: 0.10077893892054379, G Loss: 19.661314010620117\n",
      "Epoch: 19, Batch: 197, D Loss: 0.0950665488128124, G Loss: 19.697307586669922\n",
      "Epoch: 19, Batch: 198, D Loss: 0.10224831242431132, G Loss: 19.71575355529785\n",
      "Epoch: 19, Batch: 199, D Loss: 0.09278191779297995, G Loss: 19.502120971679688\n",
      "Epoch: 19, Batch: 200, D Loss: 0.09944419747230537, G Loss: 19.342567443847656\n",
      "Epoch: 19, Batch: 201, D Loss: 0.09287716665614631, G Loss: 19.174331665039062\n",
      "Epoch: 19, Batch: 202, D Loss: 0.10050225488320819, G Loss: 19.21444320678711\n",
      "Epoch: 19, Batch: 203, D Loss: 0.09951672161690017, G Loss: 19.41214942932129\n",
      "Epoch: 19, Batch: 204, D Loss: 0.10418141049520258, G Loss: 19.6773681640625\n",
      "Epoch: 19, Batch: 205, D Loss: 0.09925437857974884, G Loss: 19.71733283996582\n",
      "Epoch: 19, Batch: 206, D Loss: 0.1050998284671617, G Loss: 19.651168823242188\n",
      "Epoch: 19, Batch: 207, D Loss: 0.10692259077651156, G Loss: 19.55832290649414\n",
      "Epoch: 19, Batch: 208, D Loss: 0.10130160477875294, G Loss: 19.381244659423828\n",
      "Epoch: 19, Batch: 209, D Loss: 0.09849852537444148, G Loss: 19.16942024230957\n",
      "Epoch: 19, Batch: 210, D Loss: 0.10380683335993268, G Loss: 19.128101348876953\n",
      "Epoch: 19, Batch: 211, D Loss: 0.10022828223480063, G Loss: 19.174373626708984\n",
      "Epoch: 19, Batch: 212, D Loss: 0.09830306701197289, G Loss: 19.21150016784668\n",
      "Epoch: 19, Batch: 213, D Loss: 0.09489374095230318, G Loss: 19.164335250854492\n",
      "Epoch: 19, Batch: 214, D Loss: 0.10085864601605499, G Loss: 19.174226760864258\n",
      "Epoch: 19, Batch: 215, D Loss: 0.09862635520489405, G Loss: 19.170713424682617\n",
      "Epoch: 19, Batch: 216, D Loss: 0.10042163962484763, G Loss: 19.19826889038086\n",
      "Epoch: 19, Batch: 217, D Loss: 0.09700314939188637, G Loss: 19.126995086669922\n",
      "Epoch: 19, Batch: 218, D Loss: 0.10315931084093743, G Loss: 19.174074172973633\n",
      "Epoch: 19, Batch: 219, D Loss: 0.09076450273426695, G Loss: 19.034547805786133\n",
      "Epoch: 19, Batch: 220, D Loss: 0.09994879646002519, G Loss: 18.96331024169922\n",
      "Epoch: 19, Batch: 221, D Loss: 0.10563035577502378, G Loss: 19.116046905517578\n",
      "Epoch: 19, Batch: 222, D Loss: 0.1002813600917174, G Loss: 19.248661041259766\n",
      "Epoch: 19, Batch: 223, D Loss: 0.09897330622351608, G Loss: 19.244150161743164\n",
      "Epoch: 19, Batch: 224, D Loss: 0.09978826576095656, G Loss: 19.138105392456055\n",
      "Epoch: 19, Batch: 225, D Loss: 0.09579550005521309, G Loss: 18.906076431274414\n",
      "Epoch: 19, Batch: 226, D Loss: 0.10225361892722362, G Loss: 18.91046905517578\n",
      "Epoch: 19, Batch: 227, D Loss: 0.0959066927822454, G Loss: 18.938886642456055\n",
      "Epoch: 19, Batch: 228, D Loss: 0.10139574384806327, G Loss: 19.095325469970703\n",
      "Epoch: 19, Batch: 229, D Loss: 0.09083590917938467, G Loss: 19.045988082885742\n",
      "Epoch: 19, Batch: 230, D Loss: 0.09485887268515514, G Loss: 18.977066040039062\n",
      "Epoch: 19, Batch: 231, D Loss: 0.0930373251623382, G Loss: 18.891685485839844\n",
      "Epoch: 19, Batch: 232, D Loss: 0.09492178574331356, G Loss: 18.88695526123047\n",
      "Epoch: 19, Batch: 233, D Loss: 0.09771882289429046, G Loss: 19.02439308166504\n",
      "Epoch: 19, Batch: 234, D Loss: 0.10376659264906452, G Loss: 19.358896255493164\n",
      "Epoch: 19, Batch: 235, D Loss: 0.10205467215435227, G Loss: 19.62445831298828\n",
      "Epoch: 19, Batch: 236, D Loss: 0.09945031404116988, G Loss: 19.642492294311523\n",
      "Epoch: 19, Batch: 237, D Loss: 0.10400896674950866, G Loss: 19.53997802734375\n",
      "Epoch: 19, Batch: 238, D Loss: 0.09413895956907425, G Loss: 19.144655227661133\n",
      "Epoch: 19, Batch: 239, D Loss: 0.10539230962536106, G Loss: 19.024900436401367\n",
      "Epoch: 19, Batch: 240, D Loss: 0.09198266558337798, G Loss: 18.90850830078125\n",
      "Epoch: 19, Batch: 241, D Loss: 0.0974086851218312, G Loss: 18.943944931030273\n",
      "Epoch: 19, Batch: 242, D Loss: 0.10038908839565153, G Loss: 19.130897521972656\n",
      "Epoch: 19, Batch: 243, D Loss: 0.09735825884241822, G Loss: 19.28719139099121\n",
      "Epoch: 19, Batch: 244, D Loss: 0.09666638284452689, G Loss: 19.306297302246094\n",
      "Epoch: 19, Batch: 245, D Loss: 0.1015530696158562, G Loss: 19.317180633544922\n",
      "Epoch: 19, Batch: 246, D Loss: 0.09881937713875177, G Loss: 19.261791229248047\n",
      "Epoch: 19, Batch: 247, D Loss: 0.09580500658289681, G Loss: 19.103363037109375\n",
      "Epoch: 19, Batch: 248, D Loss: 0.09380989051329292, G Loss: 18.94484519958496\n",
      "Epoch: 19, Batch: 249, D Loss: 0.10077926803462667, G Loss: 19.004568099975586\n",
      "Epoch: 19, Batch: 250, D Loss: 0.10146066049546154, G Loss: 19.22614097595215\n",
      "Epoch: 19, Batch: 251, D Loss: 0.09699693531254905, G Loss: 19.352582931518555\n",
      "Epoch: 19, Batch: 252, D Loss: 0.09902270331013163, G Loss: 19.39337158203125\n",
      "Epoch: 19, Batch: 253, D Loss: 0.09634941274793785, G Loss: 19.25318717956543\n",
      "Epoch: 19, Batch: 254, D Loss: 0.09805727240813145, G Loss: 19.099571228027344\n",
      "Epoch: 19, Batch: 255, D Loss: 0.09392488275531208, G Loss: 18.961441040039062\n",
      "Epoch: 19, Batch: 256, D Loss: 0.10164641862827883, G Loss: 19.078109741210938\n",
      "Epoch: 19, Batch: 257, D Loss: 0.09771950034678034, G Loss: 19.249149322509766\n",
      "Epoch: 19, Batch: 258, D Loss: 0.10132428456580955, G Loss: 19.435842514038086\n",
      "Epoch: 19, Batch: 259, D Loss: 0.09767367122914516, G Loss: 19.478580474853516\n",
      "Epoch: 19, Batch: 260, D Loss: 0.09481871318235102, G Loss: 19.305461883544922\n",
      "Epoch: 19, Batch: 261, D Loss: 0.0975137599294853, G Loss: 19.113574981689453\n",
      "Epoch: 19, Batch: 262, D Loss: 0.10003826277181371, G Loss: 19.076595306396484\n",
      "Epoch: 19, Batch: 263, D Loss: 0.10133514049288639, G Loss: 19.21696662902832\n",
      "Epoch: 19, Batch: 264, D Loss: 0.1023512353717535, G Loss: 19.43663787841797\n",
      "Epoch: 19, Batch: 265, D Loss: 0.09912323379299681, G Loss: 19.527027130126953\n",
      "Epoch: 19, Batch: 266, D Loss: 0.10631098012324125, G Loss: 19.600351333618164\n",
      "Epoch: 19, Batch: 267, D Loss: 0.09939404741825397, G Loss: 19.467676162719727\n",
      "Epoch: 19, Batch: 268, D Loss: 0.09932470515939107, G Loss: 19.2742862701416\n",
      "Epoch: 19, Batch: 269, D Loss: 0.0991290085876928, G Loss: 19.110620498657227\n",
      "Epoch: 19, Batch: 270, D Loss: 0.09852408131060097, G Loss: 19.054443359375\n",
      "Epoch: 19, Batch: 271, D Loss: 0.10238000993679441, G Loss: 19.22028160095215\n",
      "Epoch: 19, Batch: 272, D Loss: 0.09663545555402675, G Loss: 19.303958892822266\n",
      "Epoch: 19, Batch: 273, D Loss: 0.0954170099170677, G Loss: 19.262495040893555\n",
      "Epoch: 19, Batch: 274, D Loss: 0.1007237754416983, G Loss: 19.222732543945312\n",
      "Epoch: 19, Batch: 275, D Loss: 0.1006054751693568, G Loss: 19.218931198120117\n",
      "Epoch: 19, Batch: 276, D Loss: 0.09656182165940597, G Loss: 19.141618728637695\n",
      "Epoch: 19, Batch: 277, D Loss: 0.09699560208947688, G Loss: 19.07305335998535\n",
      "Epoch: 19, Batch: 278, D Loss: 0.09882895911288836, G Loss: 19.05606460571289\n",
      "Epoch: 19, Batch: 279, D Loss: 0.09536279263042702, G Loss: 19.01898765563965\n",
      "Epoch: 19, Batch: 280, D Loss: 0.10493915039036272, G Loss: 19.154115676879883\n",
      "Epoch: 19, Batch: 281, D Loss: 0.10205655026051108, G Loss: 19.26859474182129\n",
      "Epoch: 19, Batch: 282, D Loss: 0.0961436204362891, G Loss: 19.208946228027344\n",
      "Epoch: 19, Batch: 283, D Loss: 0.10767148658627246, G Loss: 19.24140739440918\n",
      "Epoch: 19, Batch: 284, D Loss: 0.10252499801910586, G Loss: 19.229143142700195\n",
      "Epoch: 19, Batch: 285, D Loss: 0.09680268411245607, G Loss: 19.06573486328125\n",
      "Epoch: 19, Batch: 286, D Loss: 0.10061241965077428, G Loss: 18.950796127319336\n",
      "Epoch: 19, Batch: 287, D Loss: 0.09787184301456442, G Loss: 18.905513763427734\n",
      "Epoch: 19, Batch: 288, D Loss: 0.09944942893168895, G Loss: 18.957979202270508\n",
      "Epoch: 19, Batch: 289, D Loss: 0.0963646946988419, G Loss: 19.008724212646484\n",
      "Epoch: 19, Batch: 290, D Loss: 0.09109510775990604, G Loss: 18.896753311157227\n",
      "Epoch: 19, Batch: 291, D Loss: 0.101398582823929, G Loss: 18.93343734741211\n",
      "Epoch: 19, Batch: 292, D Loss: 0.09276945446474816, G Loss: 18.914278030395508\n",
      "Epoch: 19, Batch: 293, D Loss: 0.09807920756054855, G Loss: 18.94676971435547\n",
      "Epoch: 19, Batch: 294, D Loss: 0.09677271077460459, G Loss: 19.066442489624023\n",
      "Epoch: 19, Batch: 295, D Loss: 0.10024740039953373, G Loss: 19.251115798950195\n",
      "Epoch: 19, Batch: 296, D Loss: 0.10454198930659508, G Loss: 19.29841423034668\n",
      "Epoch: 19, Batch: 297, D Loss: 0.10318169223823159, G Loss: 19.140466690063477\n",
      "Epoch: 19, Batch: 298, D Loss: 0.09849552332075451, G Loss: 18.966854095458984\n",
      "Epoch: 19, Batch: 299, D Loss: 0.09857434332033144, G Loss: 18.91569709777832\n",
      "Epoch: 19, Batch: 300, D Loss: 0.09412458854007011, G Loss: 18.853984832763672\n",
      "Epoch: 19, Batch: 301, D Loss: 0.10581867692548874, G Loss: 19.029199600219727\n",
      "Epoch: 19, Batch: 302, D Loss: 0.1012389833818148, G Loss: 19.19617462158203\n",
      "Epoch: 19, Batch: 303, D Loss: 0.1017537139388176, G Loss: 19.250261306762695\n",
      "Epoch: 19, Batch: 304, D Loss: 0.10093341255927846, G Loss: 19.123531341552734\n",
      "Epoch: 19, Batch: 305, D Loss: 0.09599715014354748, G Loss: 18.835708618164062\n",
      "Epoch: 19, Batch: 306, D Loss: 0.09681290764368367, G Loss: 18.58739471435547\n",
      "Epoch: 19, Batch: 307, D Loss: 0.09865796996338139, G Loss: 18.556365966796875\n",
      "Epoch: 19, Batch: 308, D Loss: 0.1065910048777372, G Loss: 18.857749938964844\n",
      "Epoch: 19, Batch: 309, D Loss: 0.09549109931106359, G Loss: 19.040565490722656\n",
      "Epoch: 19, Batch: 310, D Loss: 0.10096936187056182, G Loss: 19.111587524414062\n",
      "Epoch: 19, Batch: 311, D Loss: 0.09384903591323179, G Loss: 18.903270721435547\n",
      "Epoch: 19, Batch: 312, D Loss: 0.09899792417034603, G Loss: 18.70870018005371\n",
      "Epoch: 19, Batch: 313, D Loss: 0.0982147345827693, G Loss: 18.60383415222168\n",
      "Epoch: 19, Batch: 314, D Loss: 0.0972424488757535, G Loss: 18.623266220092773\n",
      "Epoch: 19, Batch: 315, D Loss: 0.10357469676379849, G Loss: 18.88330078125\n",
      "Epoch: 19, Batch: 316, D Loss: 0.09330278940169623, G Loss: 18.9429988861084\n",
      "Epoch: 19, Batch: 317, D Loss: 0.09885250327991657, G Loss: 18.94681739807129\n",
      "Epoch: 19, Batch: 318, D Loss: 0.10408708741690331, G Loss: 18.992366790771484\n",
      "Epoch: 19, Batch: 319, D Loss: 0.09692959782462052, G Loss: 18.908939361572266\n",
      "Epoch: 19, Batch: 320, D Loss: 0.0985584142931053, G Loss: 18.776277542114258\n",
      "Epoch: 19, Batch: 321, D Loss: 0.0936974921598206, G Loss: 18.59654426574707\n",
      "Epoch: 19, Batch: 322, D Loss: 0.08617765193902782, G Loss: 18.329910278320312\n",
      "Epoch: 19, Batch: 323, D Loss: 0.10877572469992103, G Loss: 18.620344161987305\n",
      "Epoch: 19, Batch: 324, D Loss: 0.0979295854182467, G Loss: 18.96312713623047\n",
      "Epoch: 19, Batch: 325, D Loss: 0.09988163668368544, G Loss: 19.19873809814453\n",
      "Epoch: 19, Batch: 326, D Loss: 0.09517554431901543, G Loss: 19.129871368408203\n",
      "Epoch: 19, Batch: 327, D Loss: 0.09849866009470021, G Loss: 18.919021606445312\n",
      "Epoch: 19, Batch: 328, D Loss: 0.09472342180221949, G Loss: 18.67862319946289\n",
      "Epoch: 19, Batch: 329, D Loss: 0.10387245197121464, G Loss: 18.727975845336914\n",
      "Epoch: 19, Batch: 330, D Loss: 0.09947005253210284, G Loss: 18.883180618286133\n",
      "Epoch: 19, Batch: 331, D Loss: 0.09786885522358912, G Loss: 19.03558921813965\n",
      "Epoch: 19, Batch: 332, D Loss: 0.09932813303278776, G Loss: 19.1475830078125\n",
      "Epoch: 19, Batch: 333, D Loss: 0.10112610691948154, G Loss: 19.220674514770508\n",
      "Epoch: 19, Batch: 334, D Loss: 0.09848608310840334, G Loss: 19.141441345214844\n",
      "Epoch: 19, Batch: 335, D Loss: 0.10057188829654096, G Loss: 19.021053314208984\n",
      "Epoch: 19, Batch: 336, D Loss: 0.10319131144855165, G Loss: 19.00193214416504\n",
      "Epoch: 19, Batch: 337, D Loss: 0.1047704693559619, G Loss: 19.08934783935547\n",
      "Epoch: 19, Batch: 338, D Loss: 0.0945328202904665, G Loss: 18.998214721679688\n",
      "Epoch: 19, Batch: 339, D Loss: 0.09338565482047878, G Loss: 18.80142593383789\n",
      "Epoch: 19, Batch: 340, D Loss: 0.10441601607783868, G Loss: 18.86003303527832\n",
      "Epoch: 19, Batch: 341, D Loss: 0.0989404649180714, G Loss: 18.968530654907227\n",
      "Epoch: 19, Batch: 342, D Loss: 0.10086605226004708, G Loss: 19.076385498046875\n",
      "Epoch: 19, Batch: 343, D Loss: 0.09283305979539436, G Loss: 18.96713638305664\n",
      "Epoch: 19, Batch: 344, D Loss: 0.09193460966153832, G Loss: 18.7598819732666\n",
      "Epoch: 19, Batch: 345, D Loss: 0.09802907328668442, G Loss: 18.69611930847168\n",
      "Epoch: 19, Batch: 346, D Loss: 0.10031891218903244, G Loss: 18.852170944213867\n",
      "Epoch: 19, Batch: 347, D Loss: 0.09507698865658942, G Loss: 19.003620147705078\n",
      "Epoch: 19, Batch: 348, D Loss: 0.09899352744107404, G Loss: 19.18899917602539\n",
      "Epoch: 19, Batch: 349, D Loss: 0.09689662830122248, G Loss: 19.250099182128906\n",
      "Epoch: 19, Batch: 350, D Loss: 0.1036120897396624, G Loss: 19.34762954711914\n",
      "Epoch: 19, Batch: 351, D Loss: 0.10764865757099551, G Loss: 19.528987884521484\n",
      "Epoch: 19, Batch: 352, D Loss: 0.09813493657092587, G Loss: 19.50849151611328\n",
      "Epoch: 19, Batch: 353, D Loss: 0.09868590713421688, G Loss: 19.38597297668457\n",
      "Epoch: 19, Batch: 354, D Loss: 0.10219180778232873, G Loss: 19.348236083984375\n",
      "Epoch: 19, Batch: 355, D Loss: 0.0963935797429043, G Loss: 19.33810043334961\n",
      "Epoch: 19, Batch: 356, D Loss: 0.10200073755159689, G Loss: 19.482816696166992\n",
      "Epoch: 19, Batch: 357, D Loss: 0.09676172003480299, G Loss: 19.580215454101562\n",
      "Epoch: 19, Batch: 358, D Loss: 0.1031427994297156, G Loss: 19.68672752380371\n",
      "Epoch: 19, Batch: 359, D Loss: 0.09743255521332217, G Loss: 19.63976287841797\n",
      "Epoch: 19, Batch: 360, D Loss: 0.10309949670635199, G Loss: 19.56888771057129\n",
      "Epoch: 19, Batch: 361, D Loss: 0.0951102244479759, G Loss: 19.381135940551758\n",
      "Epoch: 19, Batch: 362, D Loss: 0.10018333994825701, G Loss: 19.277217864990234\n",
      "Epoch: 19, Batch: 363, D Loss: 0.10081400187537093, G Loss: 19.295394897460938\n",
      "Epoch: 19, Batch: 364, D Loss: 0.10612231683158124, G Loss: 19.470157623291016\n",
      "Epoch: 19, Batch: 365, D Loss: 0.09896022249321779, G Loss: 19.54914093017578\n",
      "Epoch: 19, Batch: 366, D Loss: 0.09636992388390542, G Loss: 19.4295654296875\n",
      "Epoch: 19, Batch: 367, D Loss: 0.10303592873285683, G Loss: 19.337345123291016\n",
      "Epoch: 19, Batch: 368, D Loss: 0.10051961449831803, G Loss: 19.274492263793945\n",
      "Epoch: 19, Batch: 369, D Loss: 0.09551322684582209, G Loss: 19.174638748168945\n",
      "Epoch: 19, Batch: 370, D Loss: 0.10033173346611268, G Loss: 19.196922302246094\n",
      "Epoch: 19, Batch: 371, D Loss: 0.09653817344659354, G Loss: 19.219039916992188\n",
      "Epoch: 19, Batch: 372, D Loss: 0.10614000463154705, G Loss: 19.421005249023438\n",
      "Epoch: 19, Batch: 373, D Loss: 0.10516454444502843, G Loss: 19.62565803527832\n",
      "Epoch: 19, Batch: 374, D Loss: 0.09632449010347421, G Loss: 19.52170753479004\n",
      "Epoch: 19, Batch: 375, D Loss: 0.10118983870601372, G Loss: 19.322486877441406\n",
      "Epoch: 19, Batch: 376, D Loss: 0.1003203563133146, G Loss: 19.161012649536133\n",
      "Epoch: 19, Batch: 377, D Loss: 0.09478238482841661, G Loss: 19.01272964477539\n",
      "Epoch: 19, Batch: 378, D Loss: 0.1021875988871801, G Loss: 19.111927032470703\n",
      "Epoch: 19, Batch: 379, D Loss: 0.10135798376122218, G Loss: 19.359580993652344\n",
      "Epoch: 19, Batch: 380, D Loss: 0.09961484546609023, G Loss: 19.581220626831055\n",
      "Epoch: 19, Batch: 381, D Loss: 0.10164386182911644, G Loss: 19.677949905395508\n",
      "Epoch: 19, Batch: 382, D Loss: 0.09853625448511172, G Loss: 19.56454086303711\n",
      "Epoch: 19, Batch: 383, D Loss: 0.09729670168356785, G Loss: 19.329729080200195\n",
      "Epoch: 19, Batch: 384, D Loss: 0.09589655176427114, G Loss: 19.12688636779785\n",
      "Epoch: 19, Batch: 385, D Loss: 0.09286846495902568, G Loss: 18.918018341064453\n",
      "Epoch: 19, Batch: 386, D Loss: 0.10160117878589703, G Loss: 19.059675216674805\n",
      "Epoch: 19, Batch: 387, D Loss: 0.09770094093968451, G Loss: 19.274272918701172\n",
      "Epoch: 19, Batch: 388, D Loss: 0.09980030554463415, G Loss: 19.425710678100586\n",
      "Epoch: 19, Batch: 389, D Loss: 0.10484858029784538, G Loss: 19.537687301635742\n",
      "Epoch: 19, Batch: 390, D Loss: 0.09778675614863397, G Loss: 19.378931045532227\n",
      "Epoch: 19, Batch: 391, D Loss: 0.09690007790736033, G Loss: 19.08900260925293\n",
      "Epoch: 19, Batch: 392, D Loss: 0.09306583110663968, G Loss: 18.775175094604492\n",
      "Epoch: 19, Batch: 393, D Loss: 0.09930037323924568, G Loss: 18.716341018676758\n",
      "Epoch: 19, Batch: 394, D Loss: 0.09821266271402629, G Loss: 18.91228485107422\n",
      "Epoch: 19, Batch: 395, D Loss: 0.09809972608352302, G Loss: 19.20206642150879\n",
      "Epoch: 19, Batch: 396, D Loss: 0.09878741410915803, G Loss: 19.40060043334961\n",
      "Epoch: 19, Batch: 397, D Loss: 0.09668758701789715, G Loss: 19.375017166137695\n",
      "Epoch: 19, Batch: 398, D Loss: 0.09700324599115118, G Loss: 19.18517303466797\n",
      "Epoch: 19, Batch: 399, D Loss: 0.10382297875825341, G Loss: 19.121623992919922\n",
      "Epoch: 19, Batch: 400, D Loss: 0.09740844625010503, G Loss: 19.06154441833496\n",
      "Epoch: 19, Batch: 401, D Loss: 0.09579816731419633, G Loss: 19.009382247924805\n",
      "Epoch: 19, Batch: 402, D Loss: 0.10449034229190879, G Loss: 19.180862426757812\n",
      "Epoch: 19, Batch: 403, D Loss: 0.10178722654384686, G Loss: 19.356143951416016\n",
      "Epoch: 19, Batch: 404, D Loss: 0.09887229847334655, G Loss: 19.357177734375\n",
      "Epoch: 19, Batch: 405, D Loss: 0.09534578245229497, G Loss: 19.138591766357422\n",
      "Epoch: 19, Batch: 406, D Loss: 0.09853469110926505, G Loss: 18.906543731689453\n",
      "Epoch: 19, Batch: 407, D Loss: 0.09977009467706566, G Loss: 18.82989501953125\n",
      "Epoch: 19, Batch: 408, D Loss: 0.09612592638570194, G Loss: 18.848941802978516\n",
      "Epoch: 19, Batch: 409, D Loss: 0.10296298853140295, G Loss: 19.072397232055664\n",
      "Epoch: 19, Batch: 410, D Loss: 0.10043761368038284, G Loss: 19.277881622314453\n",
      "Epoch: 19, Batch: 411, D Loss: 0.09896084875746469, G Loss: 19.30233383178711\n",
      "Epoch: 19, Batch: 412, D Loss: 0.10102712580294892, G Loss: 19.21086883544922\n",
      "Epoch: 19, Batch: 413, D Loss: 0.10265964508154535, G Loss: 19.116146087646484\n",
      "Epoch: 19, Batch: 414, D Loss: 0.1029189403724633, G Loss: 19.05951690673828\n",
      "Epoch: 19, Batch: 415, D Loss: 0.10114141077159511, G Loss: 19.026920318603516\n",
      "Epoch: 19, Batch: 416, D Loss: 0.09879434393320263, G Loss: 18.94625473022461\n",
      "Epoch: 19, Batch: 417, D Loss: 0.10131848156124224, G Loss: 18.933366775512695\n",
      "Epoch: 19, Batch: 418, D Loss: 0.09807704692348418, G Loss: 18.909801483154297\n",
      "Epoch: 19, Batch: 419, D Loss: 0.09761911949772784, G Loss: 18.833993911743164\n",
      "Epoch: 19, Batch: 420, D Loss: 0.10674147615019658, G Loss: 18.974916458129883\n",
      "Epoch: 19, Batch: 421, D Loss: 0.10926019647693441, G Loss: 19.25904655456543\n",
      "Epoch: 19, Batch: 422, D Loss: 0.09774469804250163, G Loss: 19.226076126098633\n",
      "Epoch: 19, Batch: 423, D Loss: 0.10112998136486762, G Loss: 19.035907745361328\n",
      "Epoch: 19, Batch: 424, D Loss: 0.0997511551445307, G Loss: 18.805763244628906\n",
      "Epoch: 19, Batch: 425, D Loss: 0.09771368278274095, G Loss: 18.642467498779297\n",
      "Epoch: 19, Batch: 426, D Loss: 0.09934010002777116, G Loss: 18.6881160736084\n",
      "Epoch: 19, Batch: 427, D Loss: 0.10046600898128366, G Loss: 18.870197296142578\n",
      "Epoch: 19, Batch: 428, D Loss: 0.09922297589504447, G Loss: 19.04547882080078\n",
      "Epoch: 19, Batch: 429, D Loss: 0.0937708644070614, G Loss: 18.97309684753418\n",
      "Epoch: 19, Batch: 430, D Loss: 0.1003262132738314, G Loss: 18.88589859008789\n",
      "Epoch: 19, Batch: 431, D Loss: 0.10228552232552968, G Loss: 18.921056747436523\n",
      "Epoch: 19, Batch: 432, D Loss: 0.09452064651870273, G Loss: 18.8394775390625\n",
      "Epoch: 19, Batch: 433, D Loss: 0.09724515273845058, G Loss: 18.76358985900879\n",
      "Epoch: 19, Batch: 434, D Loss: 0.10051340956418153, G Loss: 18.808605194091797\n",
      "Epoch: 19, Batch: 435, D Loss: 0.10610712617754392, G Loss: 19.05385398864746\n",
      "Epoch: 19, Batch: 436, D Loss: 0.09885895505535647, G Loss: 19.14209747314453\n",
      "Epoch: 19, Batch: 437, D Loss: 0.09655067592712974, G Loss: 18.95233917236328\n",
      "Epoch: 19, Batch: 438, D Loss: 0.10561217671822098, G Loss: 18.886991500854492\n",
      "Epoch: 19, Batch: 439, D Loss: 0.10452001111313103, G Loss: 18.882278442382812\n",
      "Epoch: 19, Batch: 440, D Loss: 0.10298507974623528, G Loss: 18.88970184326172\n",
      "Epoch: 19, Batch: 441, D Loss: 0.09953737585398037, G Loss: 18.808822631835938\n",
      "Epoch: 19, Batch: 442, D Loss: 0.10146318723816017, G Loss: 18.761775970458984\n",
      "Epoch: 19, Batch: 443, D Loss: 0.0997939592859447, G Loss: 18.737226486206055\n",
      "Epoch: 19, Batch: 444, D Loss: 0.0908258373918076, G Loss: 18.554481506347656\n",
      "Epoch: 19, Batch: 445, D Loss: 0.1031513180878516, G Loss: 18.665380477905273\n",
      "Epoch: 19, Batch: 446, D Loss: 0.09997886772491227, G Loss: 18.861270904541016\n",
      "Epoch: 19, Batch: 447, D Loss: 0.1003581761933603, G Loss: 19.03202247619629\n",
      "Epoch: 19, Batch: 448, D Loss: 0.09150354111403991, G Loss: 18.890932083129883\n",
      "Epoch: 19, Batch: 449, D Loss: 0.10395212040216073, G Loss: 18.883155822753906\n",
      "Epoch: 19, Batch: 450, D Loss: 0.10065126725419726, G Loss: 18.935686111450195\n",
      "Epoch: 19, Batch: 451, D Loss: 0.09847400634383408, G Loss: 18.94778060913086\n",
      "Epoch: 19, Batch: 452, D Loss: 0.10695585880773839, G Loss: 19.10123062133789\n",
      "Epoch: 19, Batch: 453, D Loss: 0.09721614682312096, G Loss: 19.037242889404297\n",
      "Epoch: 19, Batch: 454, D Loss: 0.10368031540803768, G Loss: 18.9852352142334\n",
      "Epoch: 19, Batch: 455, D Loss: 0.0950823756290129, G Loss: 18.75950813293457\n",
      "Epoch: 19, Batch: 456, D Loss: 0.10368755085259651, G Loss: 18.685678482055664\n",
      "Epoch: 19, Batch: 457, D Loss: 0.11087186971916574, G Loss: 18.929590225219727\n",
      "Epoch: 19, Batch: 458, D Loss: 0.10104136451082724, G Loss: 19.050254821777344\n",
      "Epoch: 19, Batch: 459, D Loss: 0.09736912243907714, G Loss: 18.880077362060547\n",
      "Epoch: 19, Batch: 460, D Loss: 0.09796917058815358, G Loss: 18.6031494140625\n",
      "Epoch: 19, Batch: 461, D Loss: 0.09304021789490324, G Loss: 18.29192543029785\n",
      "Epoch: 19, Batch: 462, D Loss: 0.09647437771878131, G Loss: 18.23324966430664\n",
      "Epoch: 19, Batch: 463, D Loss: 0.1035487628938978, G Loss: 18.528919219970703\n",
      "Epoch: 19, Batch: 464, D Loss: 0.0964481869857039, G Loss: 18.782733917236328\n",
      "Epoch: 19, Batch: 465, D Loss: 0.1048203140406947, G Loss: 19.083553314208984\n",
      "Epoch: 19, Batch: 466, D Loss: 0.10276857268958395, G Loss: 19.137704849243164\n",
      "Epoch: 19, Batch: 467, D Loss: 0.09723028083585672, G Loss: 18.822938919067383\n",
      "Epoch: 20, Batch: 0, D Loss: 0.0969113748704089, G Loss: 18.427650451660156\n",
      "Epoch: 20, Batch: 1, D Loss: 0.09915614674680517, G Loss: 18.245683670043945\n",
      "Epoch: 20, Batch: 2, D Loss: 0.10220183979175745, G Loss: 18.407777786254883\n",
      "Epoch: 20, Batch: 3, D Loss: 0.10157330761299876, G Loss: 18.731678009033203\n",
      "Epoch: 20, Batch: 4, D Loss: 0.09477734167915486, G Loss: 18.833980560302734\n",
      "Epoch: 20, Batch: 5, D Loss: 0.09731430162366861, G Loss: 18.742847442626953\n",
      "Epoch: 20, Batch: 6, D Loss: 0.10000865553458826, G Loss: 18.593355178833008\n",
      "Epoch: 20, Batch: 7, D Loss: 0.09897502221772658, G Loss: 18.44468879699707\n",
      "Epoch: 20, Batch: 8, D Loss: 0.09713179378175818, G Loss: 18.380596160888672\n",
      "Epoch: 20, Batch: 9, D Loss: 0.09616563997246441, G Loss: 18.353858947753906\n",
      "Epoch: 20, Batch: 10, D Loss: 0.10262870531657864, G Loss: 18.52714729309082\n",
      "Epoch: 20, Batch: 11, D Loss: 0.09684123526236599, G Loss: 18.623607635498047\n",
      "Epoch: 20, Batch: 12, D Loss: 0.10271259037284608, G Loss: 18.734783172607422\n",
      "Epoch: 20, Batch: 13, D Loss: 0.10531933948660654, G Loss: 18.8546085357666\n",
      "Epoch: 20, Batch: 14, D Loss: 0.10464659652944674, G Loss: 18.88030433654785\n",
      "Epoch: 20, Batch: 15, D Loss: 0.09821831046558605, G Loss: 18.6490478515625\n",
      "Epoch: 20, Batch: 16, D Loss: 0.10520218736256703, G Loss: 18.531187057495117\n",
      "Epoch: 20, Batch: 17, D Loss: 0.09709980075510583, G Loss: 18.392669677734375\n",
      "Epoch: 20, Batch: 18, D Loss: 0.1003706431324698, G Loss: 18.42411994934082\n",
      "Epoch: 20, Batch: 19, D Loss: 0.09518089640726224, G Loss: 18.43634033203125\n",
      "Epoch: 20, Batch: 20, D Loss: 0.10047991287405811, G Loss: 18.57126235961914\n",
      "Epoch: 20, Batch: 21, D Loss: 0.09169383049763224, G Loss: 18.495441436767578\n",
      "Epoch: 20, Batch: 22, D Loss: 0.10327424551492959, G Loss: 18.586332321166992\n",
      "Epoch: 20, Batch: 23, D Loss: 0.10064807929564745, G Loss: 18.71836280822754\n",
      "Epoch: 20, Batch: 24, D Loss: 0.09754926338472414, G Loss: 18.714176177978516\n",
      "Epoch: 20, Batch: 25, D Loss: 0.10381198287563609, G Loss: 18.790939331054688\n",
      "Epoch: 20, Batch: 26, D Loss: 0.09978835638106376, G Loss: 18.747365951538086\n",
      "Epoch: 20, Batch: 27, D Loss: 0.09197767502938481, G Loss: 18.44017791748047\n",
      "Epoch: 20, Batch: 28, D Loss: 0.09043548855103323, G Loss: 18.059213638305664\n",
      "Epoch: 20, Batch: 29, D Loss: 0.10483539759687677, G Loss: 18.23329734802246\n",
      "Epoch: 20, Batch: 30, D Loss: 0.09656121349468272, G Loss: 18.541889190673828\n",
      "Epoch: 20, Batch: 31, D Loss: 0.09733632590896901, G Loss: 18.813968658447266\n",
      "Epoch: 20, Batch: 32, D Loss: 0.09686830963789039, G Loss: 18.891891479492188\n",
      "Epoch: 20, Batch: 33, D Loss: 0.09871834101292665, G Loss: 18.78758430480957\n",
      "Epoch: 20, Batch: 34, D Loss: 0.09903888044453968, G Loss: 18.587066650390625\n",
      "Epoch: 20, Batch: 35, D Loss: 0.10573786916409533, G Loss: 18.606122970581055\n",
      "Epoch: 20, Batch: 36, D Loss: 0.09828178259940978, G Loss: 18.5838565826416\n",
      "Epoch: 20, Batch: 37, D Loss: 0.10354341975681747, G Loss: 18.655723571777344\n",
      "Epoch: 20, Batch: 38, D Loss: 0.10024512210256953, G Loss: 18.652212142944336\n",
      "Epoch: 20, Batch: 39, D Loss: 0.09861350486884213, G Loss: 18.51107406616211\n",
      "Epoch: 20, Batch: 40, D Loss: 0.09541276612128291, G Loss: 18.284366607666016\n",
      "Epoch: 20, Batch: 41, D Loss: 0.09670921289743495, G Loss: 18.136451721191406\n",
      "Epoch: 20, Batch: 42, D Loss: 0.1034637974008561, G Loss: 18.3026180267334\n",
      "Epoch: 20, Batch: 43, D Loss: 0.09202815400521969, G Loss: 18.335432052612305\n",
      "Epoch: 20, Batch: 44, D Loss: 0.10164484145541586, G Loss: 18.464632034301758\n",
      "Epoch: 20, Batch: 45, D Loss: 0.09945138258470276, G Loss: 18.541610717773438\n",
      "Epoch: 20, Batch: 46, D Loss: 0.09938165249157649, G Loss: 18.518016815185547\n",
      "Epoch: 20, Batch: 47, D Loss: 0.099894036687318, G Loss: 18.409408569335938\n",
      "Epoch: 20, Batch: 48, D Loss: 0.09691376795398021, G Loss: 18.228843688964844\n",
      "Epoch: 20, Batch: 49, D Loss: 0.09526656492313723, G Loss: 18.040128707885742\n",
      "Epoch: 20, Batch: 50, D Loss: 0.10492823197449441, G Loss: 18.2093563079834\n",
      "Epoch: 20, Batch: 51, D Loss: 0.10291560524904719, G Loss: 18.498327255249023\n",
      "Epoch: 20, Batch: 52, D Loss: 0.10634166398829592, G Loss: 18.791418075561523\n",
      "Epoch: 20, Batch: 53, D Loss: 0.09781019016827042, G Loss: 18.648679733276367\n",
      "Epoch: 20, Batch: 54, D Loss: 0.10370944891249012, G Loss: 18.412315368652344\n",
      "Epoch: 20, Batch: 55, D Loss: 0.10483605211264901, G Loss: 18.277008056640625\n",
      "Epoch: 20, Batch: 56, D Loss: 0.09983990209105764, G Loss: 18.164636611938477\n",
      "Epoch: 20, Batch: 57, D Loss: 0.11114979334318287, G Loss: 18.491594314575195\n",
      "Epoch: 20, Batch: 58, D Loss: 0.09613976337274988, G Loss: 18.537914276123047\n",
      "Epoch: 20, Batch: 59, D Loss: 0.09766519550717723, G Loss: 18.389347076416016\n",
      "Epoch: 20, Batch: 60, D Loss: 0.09390250454170523, G Loss: 18.08453941345215\n",
      "Epoch: 20, Batch: 61, D Loss: 0.09846311794258522, G Loss: 18.00102996826172\n",
      "Epoch: 20, Batch: 62, D Loss: 0.10265950034281479, G Loss: 18.2550048828125\n",
      "Epoch: 20, Batch: 63, D Loss: 0.09483118904912313, G Loss: 18.390710830688477\n",
      "Epoch: 20, Batch: 64, D Loss: 0.1004451039907801, G Loss: 18.521589279174805\n",
      "Epoch: 20, Batch: 65, D Loss: 0.09730730664457354, G Loss: 18.49454116821289\n",
      "Epoch: 20, Batch: 66, D Loss: 0.10179997707480881, G Loss: 18.464754104614258\n",
      "Epoch: 20, Batch: 67, D Loss: 0.10314399471693614, G Loss: 18.5086727142334\n",
      "Epoch: 20, Batch: 68, D Loss: 0.09662148847613805, G Loss: 18.37603759765625\n",
      "Epoch: 20, Batch: 69, D Loss: 0.10295044401070985, G Loss: 18.404266357421875\n",
      "Epoch: 20, Batch: 70, D Loss: 0.09625904037251765, G Loss: 18.360950469970703\n",
      "Epoch: 20, Batch: 71, D Loss: 0.0969036425360148, G Loss: 18.299636840820312\n",
      "Epoch: 20, Batch: 72, D Loss: 0.09921444010284963, G Loss: 18.356719970703125\n",
      "Epoch: 20, Batch: 73, D Loss: 0.09394091901145529, G Loss: 18.356250762939453\n",
      "Epoch: 20, Batch: 74, D Loss: 0.09651065395576985, G Loss: 18.394731521606445\n",
      "Epoch: 20, Batch: 75, D Loss: 0.10754600589551888, G Loss: 18.764972686767578\n",
      "Epoch: 20, Batch: 76, D Loss: 0.10472612380457647, G Loss: 19.097537994384766\n",
      "Epoch: 20, Batch: 77, D Loss: 0.10356132186730349, G Loss: 19.162275314331055\n",
      "Epoch: 20, Batch: 78, D Loss: 0.10144888135148444, G Loss: 18.920501708984375\n",
      "Epoch: 20, Batch: 79, D Loss: 0.09652129199798809, G Loss: 18.470733642578125\n",
      "Epoch: 20, Batch: 80, D Loss: 0.09966473090953176, G Loss: 18.179052352905273\n",
      "Epoch: 20, Batch: 81, D Loss: 0.09914443537104356, G Loss: 18.169504165649414\n",
      "Epoch: 20, Batch: 82, D Loss: 0.09350699051773059, G Loss: 18.268474578857422\n",
      "Epoch: 20, Batch: 83, D Loss: 0.10466397277550143, G Loss: 18.67913246154785\n",
      "Epoch: 20, Batch: 84, D Loss: 0.10042650581861756, G Loss: 18.98186492919922\n",
      "Epoch: 20, Batch: 85, D Loss: 0.0956167459229591, G Loss: 18.915781021118164\n",
      "Epoch: 20, Batch: 86, D Loss: 0.10345529345856552, G Loss: 18.788055419921875\n",
      "Epoch: 20, Batch: 87, D Loss: 0.10430638844576245, G Loss: 18.755008697509766\n",
      "Epoch: 20, Batch: 88, D Loss: 0.10291280198852326, G Loss: 18.817405700683594\n",
      "Epoch: 20, Batch: 89, D Loss: 0.10495587001055395, G Loss: 18.986072540283203\n",
      "Epoch: 20, Batch: 90, D Loss: 0.09619590936540501, G Loss: 18.905345916748047\n",
      "Epoch: 20, Batch: 91, D Loss: 0.09536868677647914, G Loss: 18.696022033691406\n",
      "Epoch: 20, Batch: 92, D Loss: 0.0991678277488659, G Loss: 18.617870330810547\n",
      "Epoch: 20, Batch: 93, D Loss: 0.09521142808011351, G Loss: 18.59951400756836\n",
      "Epoch: 20, Batch: 94, D Loss: 0.10104135050675578, G Loss: 18.82291030883789\n",
      "Epoch: 20, Batch: 95, D Loss: 0.10076183371614955, G Loss: 19.087642669677734\n",
      "Epoch: 20, Batch: 96, D Loss: 0.10648237388781001, G Loss: 19.380273818969727\n",
      "Epoch: 20, Batch: 97, D Loss: 0.09932489887360862, G Loss: 19.354286193847656\n",
      "Epoch: 20, Batch: 98, D Loss: 0.10622810034088936, G Loss: 19.25851821899414\n",
      "Epoch: 20, Batch: 99, D Loss: 0.10047727323418032, G Loss: 19.020126342773438\n",
      "Epoch: 20, Batch: 100, D Loss: 0.10365100494754298, G Loss: 18.917871475219727\n",
      "Epoch: 20, Batch: 101, D Loss: 0.09471545702267314, G Loss: 18.741167068481445\n",
      "Epoch: 20, Batch: 102, D Loss: 0.0940068179516178, G Loss: 18.610252380371094\n",
      "Epoch: 20, Batch: 103, D Loss: 0.10528013468725606, G Loss: 18.882081985473633\n",
      "Epoch: 20, Batch: 104, D Loss: 0.09495273519340008, G Loss: 19.061323165893555\n",
      "Epoch: 20, Batch: 105, D Loss: 0.09394683954716831, G Loss: 19.044841766357422\n",
      "Epoch: 20, Batch: 106, D Loss: 0.10049296437948119, G Loss: 19.048019409179688\n",
      "Epoch: 20, Batch: 107, D Loss: 0.10076657194241756, G Loss: 19.12374496459961\n",
      "Epoch: 20, Batch: 108, D Loss: 0.10479678436244466, G Loss: 19.325345993041992\n",
      "Epoch: 20, Batch: 109, D Loss: 0.09563719689033556, G Loss: 19.275102615356445\n",
      "Epoch: 20, Batch: 110, D Loss: 0.10262331582396644, G Loss: 19.24809455871582\n",
      "Epoch: 20, Batch: 111, D Loss: 0.09819033237613661, G Loss: 19.065082550048828\n",
      "Epoch: 20, Batch: 112, D Loss: 0.09730851938271612, G Loss: 18.888973236083984\n",
      "Epoch: 20, Batch: 113, D Loss: 0.09736857151360478, G Loss: 18.77104949951172\n",
      "Epoch: 20, Batch: 114, D Loss: 0.09869438764626892, G Loss: 18.75763511657715\n",
      "Epoch: 20, Batch: 115, D Loss: 0.09725441394452838, G Loss: 18.76424789428711\n",
      "Epoch: 20, Batch: 116, D Loss: 0.10445459507775579, G Loss: 18.954862594604492\n",
      "Epoch: 20, Batch: 117, D Loss: 0.10393187669622184, G Loss: 19.13966941833496\n",
      "Epoch: 20, Batch: 118, D Loss: 0.09787716981225825, G Loss: 18.982112884521484\n",
      "Epoch: 20, Batch: 119, D Loss: 0.09975491788949764, G Loss: 18.735050201416016\n",
      "Epoch: 20, Batch: 120, D Loss: 0.09902048515330053, G Loss: 18.541336059570312\n",
      "Epoch: 20, Batch: 121, D Loss: 0.10003097799044625, G Loss: 18.540016174316406\n",
      "Epoch: 20, Batch: 122, D Loss: 0.10265235993850119, G Loss: 18.78094482421875\n",
      "Epoch: 20, Batch: 123, D Loss: 0.10357109010904608, G Loss: 19.075332641601562\n",
      "Epoch: 20, Batch: 124, D Loss: 0.09823180991951141, G Loss: 19.09768295288086\n",
      "Epoch: 20, Batch: 125, D Loss: 0.10884661470645551, G Loss: 19.181337356567383\n",
      "Epoch: 20, Batch: 126, D Loss: 0.0914230672853853, G Loss: 18.82703971862793\n",
      "Epoch: 20, Batch: 127, D Loss: 0.10400163743649515, G Loss: 18.67241668701172\n",
      "Epoch: 20, Batch: 128, D Loss: 0.1029652393795979, G Loss: 18.782638549804688\n",
      "Epoch: 20, Batch: 129, D Loss: 0.0998922171294756, G Loss: 18.94998550415039\n",
      "Epoch: 20, Batch: 130, D Loss: 0.09759821278847225, G Loss: 19.03882598876953\n",
      "Epoch: 20, Batch: 131, D Loss: 0.09631669799970988, G Loss: 18.975749969482422\n",
      "Epoch: 20, Batch: 132, D Loss: 0.09907707122423326, G Loss: 18.920936584472656\n",
      "Epoch: 20, Batch: 133, D Loss: 0.09726576820793165, G Loss: 18.85672950744629\n",
      "Epoch: 20, Batch: 134, D Loss: 0.10144539486377857, G Loss: 18.943462371826172\n",
      "Epoch: 20, Batch: 135, D Loss: 0.0990665583115029, G Loss: 19.04474639892578\n",
      "Epoch: 20, Batch: 136, D Loss: 0.09659378501879301, G Loss: 19.021102905273438\n",
      "Epoch: 20, Batch: 137, D Loss: 0.0921273113842529, G Loss: 18.767536163330078\n",
      "Epoch: 20, Batch: 138, D Loss: 0.09897536406380403, G Loss: 18.69659996032715\n",
      "Epoch: 20, Batch: 139, D Loss: 0.10218888864745956, G Loss: 18.885774612426758\n",
      "Epoch: 20, Batch: 140, D Loss: 0.09691009217282809, G Loss: 19.025482177734375\n",
      "Epoch: 20, Batch: 141, D Loss: 0.09623582938746611, G Loss: 18.99490737915039\n",
      "Epoch: 20, Batch: 142, D Loss: 0.10080503211334157, G Loss: 18.97889518737793\n",
      "Epoch: 20, Batch: 143, D Loss: 0.10247452092080023, G Loss: 19.0201358795166\n",
      "Epoch: 20, Batch: 144, D Loss: 0.09380439968660803, G Loss: 18.85361671447754\n",
      "Epoch: 20, Batch: 145, D Loss: 0.09387237952266902, G Loss: 18.584819793701172\n",
      "Epoch: 20, Batch: 146, D Loss: 0.10037213991528837, G Loss: 18.5709228515625\n",
      "Epoch: 20, Batch: 147, D Loss: 0.0985394308918921, G Loss: 18.724754333496094\n",
      "Epoch: 20, Batch: 148, D Loss: 0.10284634249539004, G Loss: 19.024639129638672\n",
      "Epoch: 20, Batch: 149, D Loss: 0.10089034094845428, G Loss: 19.173547744750977\n",
      "Epoch: 20, Batch: 150, D Loss: 0.1028986000872174, G Loss: 19.162019729614258\n",
      "Epoch: 20, Batch: 151, D Loss: 0.10381372525053867, G Loss: 19.055068969726562\n",
      "Epoch: 20, Batch: 152, D Loss: 0.09796106380118874, G Loss: 18.758981704711914\n",
      "Epoch: 20, Batch: 153, D Loss: 0.09924755636743798, G Loss: 18.58257484436035\n",
      "Epoch: 20, Batch: 154, D Loss: 0.09849328979043159, G Loss: 18.557170867919922\n",
      "Epoch: 20, Batch: 155, D Loss: 0.09729092236664671, G Loss: 18.659299850463867\n",
      "Epoch: 20, Batch: 156, D Loss: 0.10076725819896759, G Loss: 18.95612144470215\n",
      "Epoch: 20, Batch: 157, D Loss: 0.09602466492439743, G Loss: 19.132522583007812\n",
      "Epoch: 20, Batch: 158, D Loss: 0.09987591434344645, G Loss: 19.278154373168945\n",
      "Epoch: 20, Batch: 159, D Loss: 0.10127419434920015, G Loss: 19.375137329101562\n",
      "Epoch: 20, Batch: 160, D Loss: 0.10314303819002069, G Loss: 19.477407455444336\n",
      "Epoch: 20, Batch: 161, D Loss: 0.0996664034873157, G Loss: 19.471729278564453\n",
      "Epoch: 20, Batch: 162, D Loss: 0.09992242038914723, G Loss: 19.42161750793457\n",
      "Epoch: 20, Batch: 163, D Loss: 0.10019160991692322, G Loss: 19.413766860961914\n",
      "Epoch: 20, Batch: 164, D Loss: 0.10074523266075741, G Loss: 19.524524688720703\n",
      "Epoch: 20, Batch: 165, D Loss: 0.10170918854085764, G Loss: 19.702287673950195\n",
      "Epoch: 20, Batch: 166, D Loss: 0.09286804642390722, G Loss: 19.61737632751465\n",
      "Epoch: 20, Batch: 167, D Loss: 0.09738713657094811, G Loss: 19.578704833984375\n",
      "Epoch: 20, Batch: 168, D Loss: 0.0994524820764614, G Loss: 19.793920516967773\n",
      "Epoch: 20, Batch: 169, D Loss: 0.09629240746952028, G Loss: 19.979049682617188\n",
      "Epoch: 20, Batch: 170, D Loss: 0.10659831848669948, G Loss: 20.35376739501953\n",
      "Epoch: 20, Batch: 171, D Loss: 0.095777966782011, G Loss: 20.416793823242188\n",
      "Epoch: 20, Batch: 172, D Loss: 0.10426591404252689, G Loss: 20.428272247314453\n",
      "Epoch: 20, Batch: 173, D Loss: 0.10421831973566648, G Loss: 20.412384033203125\n",
      "Epoch: 20, Batch: 174, D Loss: 0.10396243701743851, G Loss: 20.366451263427734\n",
      "Epoch: 20, Batch: 175, D Loss: 0.10011715520303549, G Loss: 20.190858840942383\n",
      "Epoch: 20, Batch: 176, D Loss: 0.10355947996721449, G Loss: 20.194765090942383\n",
      "Epoch: 20, Batch: 177, D Loss: 0.09636683858143924, G Loss: 19.958356857299805\n",
      "Epoch: 20, Batch: 178, D Loss: 0.10160417969687763, G Loss: 19.831235885620117\n",
      "Epoch: 20, Batch: 179, D Loss: 0.09937229137096881, G Loss: 19.71666717529297\n",
      "Epoch: 20, Batch: 180, D Loss: 0.09938269256679566, G Loss: 19.56595230102539\n",
      "Epoch: 20, Batch: 181, D Loss: 0.102874325354809, G Loss: 19.52096176147461\n",
      "Epoch: 20, Batch: 182, D Loss: 0.09597195869915265, G Loss: 19.319734573364258\n",
      "Epoch: 20, Batch: 183, D Loss: 0.10103300433235929, G Loss: 19.17668914794922\n",
      "Epoch: 20, Batch: 184, D Loss: 0.10000775995654143, G Loss: 19.125774383544922\n",
      "Epoch: 20, Batch: 185, D Loss: 0.09732720513029913, G Loss: 19.050073623657227\n",
      "Epoch: 20, Batch: 186, D Loss: 0.10412200796141802, G Loss: 19.127838134765625\n",
      "Epoch: 20, Batch: 187, D Loss: 0.10184049836346754, G Loss: 19.259780883789062\n",
      "Epoch: 20, Batch: 188, D Loss: 0.10065084909006727, G Loss: 19.285472869873047\n",
      "Epoch: 20, Batch: 189, D Loss: 0.10007244572809126, G Loss: 19.165918350219727\n",
      "Epoch: 20, Batch: 190, D Loss: 0.10318009804667239, G Loss: 19.072511672973633\n",
      "Epoch: 20, Batch: 191, D Loss: 0.09743439693413225, G Loss: 18.887428283691406\n",
      "Epoch: 20, Batch: 192, D Loss: 0.09688249570934615, G Loss: 18.7308349609375\n",
      "Epoch: 20, Batch: 193, D Loss: 0.10244598580522624, G Loss: 18.870052337646484\n",
      "Epoch: 20, Batch: 194, D Loss: 0.0966897786117149, G Loss: 18.97123146057129\n",
      "Epoch: 20, Batch: 195, D Loss: 0.09067385217310964, G Loss: 18.781545639038086\n",
      "Epoch: 20, Batch: 196, D Loss: 0.09539870553874907, G Loss: 18.612070083618164\n",
      "Epoch: 20, Batch: 197, D Loss: 0.10197145130585517, G Loss: 18.751476287841797\n",
      "Epoch: 20, Batch: 198, D Loss: 0.1020543084589065, G Loss: 19.04100227355957\n",
      "Epoch: 20, Batch: 199, D Loss: 0.09472013531590595, G Loss: 19.05708885192871\n",
      "Epoch: 20, Batch: 200, D Loss: 0.09650606205650125, G Loss: 18.8919734954834\n",
      "Epoch: 20, Batch: 201, D Loss: 0.09592698864572524, G Loss: 18.67388916015625\n",
      "Epoch: 20, Batch: 202, D Loss: 0.0888183759075325, G Loss: 18.34670639038086\n",
      "Epoch: 20, Batch: 203, D Loss: 0.09469666869473681, G Loss: 18.351097106933594\n",
      "Epoch: 20, Batch: 204, D Loss: 0.10458220945222596, G Loss: 18.88774871826172\n",
      "Epoch: 20, Batch: 205, D Loss: 0.10230143597068264, G Loss: 19.48383331298828\n",
      "Epoch: 20, Batch: 206, D Loss: 0.09996903106704258, G Loss: 19.581562042236328\n",
      "Epoch: 20, Batch: 207, D Loss: 0.10206236126348989, G Loss: 19.305158615112305\n",
      "Epoch: 20, Batch: 208, D Loss: 0.0976812792056938, G Loss: 18.790639877319336\n",
      "Epoch: 20, Batch: 209, D Loss: 0.09680694766080844, G Loss: 18.398761749267578\n",
      "Epoch: 20, Batch: 210, D Loss: 0.09747437162382955, G Loss: 18.367956161499023\n",
      "Epoch: 20, Batch: 211, D Loss: 0.1027401727059174, G Loss: 18.828628540039062\n",
      "Epoch: 20, Batch: 212, D Loss: 0.10168342541333963, G Loss: 19.376970291137695\n",
      "Epoch: 20, Batch: 213, D Loss: 0.10191494393357159, G Loss: 19.64470100402832\n",
      "Epoch: 20, Batch: 214, D Loss: 0.10396550747810529, G Loss: 19.58110237121582\n",
      "Epoch: 20, Batch: 215, D Loss: 0.09807393156477318, G Loss: 19.10084342956543\n",
      "Epoch: 20, Batch: 216, D Loss: 0.0960053538056207, G Loss: 18.509302139282227\n",
      "Epoch: 20, Batch: 217, D Loss: 0.09718654822229578, G Loss: 18.276376724243164\n",
      "Epoch: 20, Batch: 218, D Loss: 0.09902739282107875, G Loss: 18.54250717163086\n",
      "Epoch: 20, Batch: 219, D Loss: 0.09680578462214107, G Loss: 18.989933013916016\n",
      "Epoch: 20, Batch: 220, D Loss: 0.0984940104990597, G Loss: 19.370820999145508\n",
      "Epoch: 20, Batch: 221, D Loss: 0.1013938504286418, G Loss: 19.53774642944336\n",
      "Epoch: 20, Batch: 222, D Loss: 0.10126824105497412, G Loss: 19.42588233947754\n",
      "Epoch: 20, Batch: 223, D Loss: 0.09681262303034921, G Loss: 19.01483726501465\n",
      "Epoch: 20, Batch: 224, D Loss: 0.09880489436869233, G Loss: 18.698965072631836\n",
      "Epoch: 20, Batch: 225, D Loss: 0.10591788935442392, G Loss: 18.872947692871094\n",
      "Epoch: 20, Batch: 226, D Loss: 0.0991869596557251, G Loss: 19.133838653564453\n",
      "Epoch: 20, Batch: 227, D Loss: 0.1062401850575807, G Loss: 19.574787139892578\n",
      "Epoch: 20, Batch: 228, D Loss: 0.0985686943739349, G Loss: 19.58252716064453\n",
      "Epoch: 20, Batch: 229, D Loss: 0.10252656218788003, G Loss: 19.356630325317383\n",
      "Epoch: 20, Batch: 230, D Loss: 0.10052842132235251, G Loss: 19.04991340637207\n",
      "Epoch: 20, Batch: 231, D Loss: 0.10808729638172565, G Loss: 19.11347770690918\n",
      "Epoch: 20, Batch: 232, D Loss: 0.09617363174516447, G Loss: 19.05448341369629\n",
      "Epoch: 20, Batch: 233, D Loss: 0.10137780269930063, G Loss: 19.098875045776367\n",
      "Epoch: 20, Batch: 234, D Loss: 0.0934906480668829, G Loss: 18.929162979125977\n",
      "Epoch: 20, Batch: 235, D Loss: 0.10086614190572862, G Loss: 18.952892303466797\n",
      "Epoch: 20, Batch: 236, D Loss: 0.10030874886917318, G Loss: 19.06450843811035\n",
      "Epoch: 20, Batch: 237, D Loss: 0.10333867610465175, G Loss: 19.24103546142578\n",
      "Epoch: 20, Batch: 238, D Loss: 0.10150066228291288, G Loss: 19.329317092895508\n",
      "Epoch: 20, Batch: 239, D Loss: 0.10305671594257393, G Loss: 19.340608596801758\n",
      "Epoch: 20, Batch: 240, D Loss: 0.09982634556187286, G Loss: 19.149133682250977\n",
      "Epoch: 20, Batch: 241, D Loss: 0.09968635713881935, G Loss: 18.90811538696289\n",
      "Epoch: 20, Batch: 242, D Loss: 0.09850384632769682, G Loss: 18.72772216796875\n",
      "Epoch: 20, Batch: 243, D Loss: 0.09619447978127837, G Loss: 18.621028900146484\n",
      "Epoch: 20, Batch: 244, D Loss: 0.10203510143957151, G Loss: 18.832763671875\n",
      "Epoch: 20, Batch: 245, D Loss: 0.09889836902085358, G Loss: 19.06741714477539\n",
      "Epoch: 20, Batch: 246, D Loss: 0.0924004046533431, G Loss: 18.92543601989746\n",
      "Epoch: 20, Batch: 247, D Loss: 0.0941126903726579, G Loss: 18.61210823059082\n",
      "Epoch: 20, Batch: 248, D Loss: 0.10253238342590043, G Loss: 18.62786865234375\n",
      "Epoch: 20, Batch: 249, D Loss: 0.10320873903084027, G Loss: 18.941917419433594\n",
      "Epoch: 20, Batch: 250, D Loss: 0.09998900702999625, G Loss: 19.1966495513916\n",
      "Epoch: 20, Batch: 251, D Loss: 0.09978948015185352, G Loss: 19.225597381591797\n",
      "Epoch: 20, Batch: 252, D Loss: 0.1002841914099275, G Loss: 19.07217788696289\n",
      "Epoch: 20, Batch: 253, D Loss: 0.09928012938052211, G Loss: 18.812950134277344\n",
      "Epoch: 20, Batch: 254, D Loss: 0.09889371313858142, G Loss: 18.662139892578125\n",
      "Epoch: 20, Batch: 255, D Loss: 0.09681996359531597, G Loss: 18.62135124206543\n",
      "Epoch: 20, Batch: 256, D Loss: 0.10302241498140341, G Loss: 18.909637451171875\n",
      "Epoch: 20, Batch: 257, D Loss: 0.09851250325291527, G Loss: 19.131834030151367\n",
      "Epoch: 20, Batch: 258, D Loss: 0.09691220767334552, G Loss: 19.133312225341797\n",
      "Epoch: 20, Batch: 259, D Loss: 0.0977271896500791, G Loss: 18.970111846923828\n",
      "Epoch: 20, Batch: 260, D Loss: 0.10391155172948996, G Loss: 18.97718620300293\n",
      "Epoch: 20, Batch: 261, D Loss: 0.09798917465221102, G Loss: 18.949642181396484\n",
      "Epoch: 20, Batch: 262, D Loss: 0.1022759480369837, G Loss: 19.05307388305664\n",
      "Epoch: 20, Batch: 263, D Loss: 0.10038234547503677, G Loss: 19.138519287109375\n",
      "Epoch: 20, Batch: 264, D Loss: 0.09586741290854084, G Loss: 19.01293182373047\n",
      "Epoch: 20, Batch: 265, D Loss: 0.09961039116990289, G Loss: 18.92913055419922\n",
      "Epoch: 20, Batch: 266, D Loss: 0.10075001716041188, G Loss: 18.95050048828125\n",
      "Epoch: 20, Batch: 267, D Loss: 0.10402363802307923, G Loss: 19.160781860351562\n",
      "Epoch: 20, Batch: 268, D Loss: 0.09693756939514997, G Loss: 19.15001106262207\n",
      "Epoch: 20, Batch: 269, D Loss: 0.0985880296538586, G Loss: 19.011688232421875\n",
      "Epoch: 20, Batch: 270, D Loss: 0.09905568061022074, G Loss: 18.886734008789062\n",
      "Epoch: 20, Batch: 271, D Loss: 0.10189456056542068, G Loss: 18.916669845581055\n",
      "Epoch: 20, Batch: 272, D Loss: 0.10630265146064, G Loss: 19.160898208618164\n",
      "Epoch: 20, Batch: 273, D Loss: 0.10071699547981017, G Loss: 19.257722854614258\n",
      "Epoch: 20, Batch: 274, D Loss: 0.09701349084309085, G Loss: 19.03753662109375\n",
      "Epoch: 20, Batch: 275, D Loss: 0.09409489817998873, G Loss: 18.624008178710938\n",
      "Epoch: 20, Batch: 276, D Loss: 0.0997777476154762, G Loss: 18.483274459838867\n",
      "Epoch: 20, Batch: 277, D Loss: 0.10410125211709698, G Loss: 18.77364158630371\n",
      "Epoch: 20, Batch: 278, D Loss: 0.09943877459724981, G Loss: 19.078882217407227\n",
      "Epoch: 20, Batch: 279, D Loss: 0.10290949276879813, G Loss: 19.301671981811523\n",
      "Epoch: 20, Batch: 280, D Loss: 0.09907895548540457, G Loss: 19.17144203186035\n",
      "Epoch: 20, Batch: 281, D Loss: 0.10260392988255984, G Loss: 18.967435836791992\n",
      "Epoch: 20, Batch: 282, D Loss: 0.09846273395945149, G Loss: 18.710737228393555\n",
      "Epoch: 20, Batch: 283, D Loss: 0.10705287357245918, G Loss: 18.850107192993164\n",
      "Epoch: 20, Batch: 284, D Loss: 0.09739676428790145, G Loss: 18.937646865844727\n",
      "Epoch: 20, Batch: 285, D Loss: 0.09221700900480734, G Loss: 18.79467010498047\n",
      "Epoch: 20, Batch: 286, D Loss: 0.09660757695140343, G Loss: 18.6978816986084\n",
      "Epoch: 20, Batch: 287, D Loss: 0.0926393459848609, G Loss: 18.579524993896484\n",
      "Epoch: 20, Batch: 288, D Loss: 0.09828214748743802, G Loss: 18.695871353149414\n",
      "Epoch: 20, Batch: 289, D Loss: 0.09491457400601688, G Loss: 18.82166862487793\n",
      "Epoch: 20, Batch: 290, D Loss: 0.0996756434840651, G Loss: 19.018056869506836\n",
      "Epoch: 20, Batch: 291, D Loss: 0.09938234352670228, G Loss: 19.112442016601562\n",
      "Epoch: 20, Batch: 292, D Loss: 0.09239890711832577, G Loss: 18.863414764404297\n",
      "Epoch: 20, Batch: 293, D Loss: 0.10224823245051451, G Loss: 18.77582359313965\n",
      "Epoch: 20, Batch: 294, D Loss: 0.0988299956227634, G Loss: 18.775562286376953\n",
      "Epoch: 20, Batch: 295, D Loss: 0.09232660014241478, G Loss: 18.641971588134766\n",
      "Epoch: 20, Batch: 296, D Loss: 0.09133059229111629, G Loss: 18.450725555419922\n",
      "Epoch: 20, Batch: 297, D Loss: 0.09864429101964145, G Loss: 18.54254913330078\n",
      "Epoch: 20, Batch: 298, D Loss: 0.09484318310084472, G Loss: 18.681594848632812\n",
      "Epoch: 20, Batch: 299, D Loss: 0.10087813770154597, G Loss: 18.95749855041504\n",
      "Epoch: 20, Batch: 300, D Loss: 0.09613223654121139, G Loss: 19.038244247436523\n",
      "Epoch: 20, Batch: 301, D Loss: 0.10012021185100584, G Loss: 19.040800094604492\n",
      "Epoch: 20, Batch: 302, D Loss: 0.10032110939795835, G Loss: 18.974807739257812\n",
      "Epoch: 20, Batch: 303, D Loss: 0.10449333764477586, G Loss: 19.054784774780273\n",
      "Epoch: 20, Batch: 304, D Loss: 0.09820412370993115, G Loss: 19.009912490844727\n",
      "Epoch: 20, Batch: 305, D Loss: 0.10369772732432847, G Loss: 19.073030471801758\n",
      "Epoch: 20, Batch: 306, D Loss: 0.10712693863619482, G Loss: 19.29302215576172\n",
      "Epoch: 20, Batch: 307, D Loss: 0.1028383617967581, G Loss: 19.35463523864746\n",
      "Epoch: 20, Batch: 308, D Loss: 0.10050782771748845, G Loss: 19.224641799926758\n",
      "Epoch: 20, Batch: 309, D Loss: 0.09474881265146662, G Loss: 18.855022430419922\n",
      "Epoch: 20, Batch: 310, D Loss: 0.10114822138093693, G Loss: 18.7272891998291\n",
      "Epoch: 20, Batch: 311, D Loss: 0.10598183730405308, G Loss: 19.06631088256836\n",
      "Epoch: 20, Batch: 312, D Loss: 0.09341736384801536, G Loss: 19.180591583251953\n",
      "Epoch: 20, Batch: 313, D Loss: 0.09921708929575734, G Loss: 19.24151039123535\n",
      "Epoch: 20, Batch: 314, D Loss: 0.1034583619191558, G Loss: 19.347299575805664\n",
      "Epoch: 20, Batch: 315, D Loss: 0.09991073061698863, G Loss: 19.34377098083496\n",
      "Epoch: 20, Batch: 316, D Loss: 0.09627947433134088, G Loss: 19.13386344909668\n",
      "Epoch: 20, Batch: 317, D Loss: 0.09894873461224307, G Loss: 19.026294708251953\n",
      "Epoch: 20, Batch: 318, D Loss: 0.09987972936797984, G Loss: 19.118322372436523\n",
      "Epoch: 20, Batch: 319, D Loss: 0.09305167447359786, G Loss: 19.116548538208008\n",
      "Epoch: 20, Batch: 320, D Loss: 0.0934729974116455, G Loss: 19.076025009155273\n",
      "Epoch: 20, Batch: 321, D Loss: 0.09789233156199395, G Loss: 19.17501449584961\n",
      "Epoch: 20, Batch: 322, D Loss: 0.10280023716070086, G Loss: 19.47475814819336\n",
      "Epoch: 20, Batch: 323, D Loss: 0.10216216150463509, G Loss: 19.727819442749023\n",
      "Epoch: 20, Batch: 324, D Loss: 0.10467197871620915, G Loss: 19.869592666625977\n",
      "Epoch: 20, Batch: 325, D Loss: 0.10362106682971317, G Loss: 19.807758331298828\n",
      "Epoch: 20, Batch: 326, D Loss: 0.09768964501520405, G Loss: 19.44296646118164\n",
      "Epoch: 20, Batch: 327, D Loss: 0.1031682064283801, G Loss: 19.240234375\n",
      "Epoch: 20, Batch: 328, D Loss: 0.10325725587035417, G Loss: 19.32785987854004\n",
      "Epoch: 20, Batch: 329, D Loss: 0.09858465384337767, G Loss: 19.44659996032715\n",
      "Epoch: 20, Batch: 330, D Loss: 0.09943874352897175, G Loss: 19.518857955932617\n",
      "Epoch: 20, Batch: 331, D Loss: 0.10334076888833721, G Loss: 19.640336990356445\n",
      "Epoch: 20, Batch: 332, D Loss: 0.09970268759476864, G Loss: 19.581497192382812\n",
      "Epoch: 20, Batch: 333, D Loss: 0.10181054639287623, G Loss: 19.467092514038086\n",
      "Epoch: 20, Batch: 334, D Loss: 0.098898263748467, G Loss: 19.255598068237305\n",
      "Epoch: 20, Batch: 335, D Loss: 0.09300159922044471, G Loss: 18.917888641357422\n",
      "Epoch: 20, Batch: 336, D Loss: 0.0946467403510447, G Loss: 18.721811294555664\n",
      "Epoch: 20, Batch: 337, D Loss: 0.09878243845516055, G Loss: 18.884828567504883\n",
      "Epoch: 20, Batch: 338, D Loss: 0.10024923342039616, G Loss: 19.274982452392578\n",
      "Epoch: 20, Batch: 339, D Loss: 0.0976733882110341, G Loss: 19.514877319335938\n",
      "Epoch: 20, Batch: 340, D Loss: 0.0965527313620912, G Loss: 19.424972534179688\n",
      "Epoch: 20, Batch: 341, D Loss: 0.09973182732147623, G Loss: 19.23027801513672\n",
      "Epoch: 20, Batch: 342, D Loss: 0.09590316081211303, G Loss: 18.91666030883789\n",
      "Epoch: 20, Batch: 343, D Loss: 0.09860849700360652, G Loss: 18.82371711730957\n",
      "Epoch: 20, Batch: 344, D Loss: 0.10145631728223559, G Loss: 19.05609893798828\n",
      "Epoch: 20, Batch: 345, D Loss: 0.09854635830923342, G Loss: 19.286449432373047\n",
      "Epoch: 20, Batch: 346, D Loss: 0.09959247164185969, G Loss: 19.374094009399414\n",
      "Epoch: 20, Batch: 347, D Loss: 0.1077113317747107, G Loss: 19.591960906982422\n",
      "Epoch: 20, Batch: 348, D Loss: 0.1026611641558759, G Loss: 19.603139877319336\n",
      "Epoch: 20, Batch: 349, D Loss: 0.10176873378854523, G Loss: 19.38671875\n",
      "Epoch: 20, Batch: 350, D Loss: 0.09966741727417583, G Loss: 19.067270278930664\n",
      "Epoch: 20, Batch: 351, D Loss: 0.09674930877586863, G Loss: 18.7773494720459\n",
      "Epoch: 20, Batch: 352, D Loss: 0.099564108752358, G Loss: 18.78898048400879\n",
      "Epoch: 20, Batch: 353, D Loss: 0.10099393421596381, G Loss: 19.109241485595703\n",
      "Epoch: 20, Batch: 354, D Loss: 0.09292494001052765, G Loss: 19.193273544311523\n",
      "Epoch: 20, Batch: 355, D Loss: 0.0955288583526861, G Loss: 19.094579696655273\n",
      "Epoch: 20, Batch: 356, D Loss: 0.10168493043894156, G Loss: 19.132783889770508\n",
      "Epoch: 20, Batch: 357, D Loss: 0.10361550972483391, G Loss: 19.3046817779541\n",
      "Epoch: 20, Batch: 358, D Loss: 0.10134329097585448, G Loss: 19.406606674194336\n",
      "Epoch: 20, Batch: 359, D Loss: 0.09549254396072349, G Loss: 19.1187744140625\n",
      "Epoch: 20, Batch: 360, D Loss: 0.0964033186562201, G Loss: 18.767532348632812\n",
      "Epoch: 20, Batch: 361, D Loss: 0.0974260159554654, G Loss: 18.63219451904297\n",
      "Epoch: 20, Batch: 362, D Loss: 0.09471633687770042, G Loss: 18.643447875976562\n",
      "Epoch: 20, Batch: 363, D Loss: 0.10519443762440028, G Loss: 19.12736701965332\n",
      "Epoch: 20, Batch: 364, D Loss: 0.10528702473032503, G Loss: 19.681425094604492\n",
      "Epoch: 20, Batch: 365, D Loss: 0.09987819333417969, G Loss: 19.723730087280273\n",
      "Epoch: 20, Batch: 366, D Loss: 0.10013169217585172, G Loss: 19.32745933532715\n",
      "Epoch: 20, Batch: 367, D Loss: 0.10177555188923693, G Loss: 18.893413543701172\n",
      "Epoch: 20, Batch: 368, D Loss: 0.10142764797303339, G Loss: 18.68341636657715\n",
      "Epoch: 20, Batch: 369, D Loss: 0.10086009276199803, G Loss: 18.758010864257812\n",
      "Epoch: 20, Batch: 370, D Loss: 0.10058909970751606, G Loss: 18.988645553588867\n",
      "Epoch: 20, Batch: 371, D Loss: 0.10279513395532858, G Loss: 19.265064239501953\n",
      "Epoch: 20, Batch: 372, D Loss: 0.10916907519987096, G Loss: 19.604944229125977\n",
      "Epoch: 20, Batch: 373, D Loss: 0.0985678079250305, G Loss: 19.35974884033203\n",
      "Epoch: 20, Batch: 374, D Loss: 0.10239921748796554, G Loss: 18.9813175201416\n",
      "Epoch: 20, Batch: 375, D Loss: 0.09745396297383868, G Loss: 18.493894577026367\n",
      "Epoch: 20, Batch: 376, D Loss: 0.10233515984118835, G Loss: 18.42120361328125\n",
      "Epoch: 20, Batch: 377, D Loss: 0.09838284269499731, G Loss: 18.56947898864746\n",
      "Epoch: 20, Batch: 378, D Loss: 0.10184971594357672, G Loss: 18.95789909362793\n",
      "Epoch: 20, Batch: 379, D Loss: 0.0973473888833527, G Loss: 19.10709571838379\n",
      "Epoch: 20, Batch: 380, D Loss: 0.09275818162992633, G Loss: 18.825742721557617\n",
      "Epoch: 20, Batch: 381, D Loss: 0.1021250223637249, G Loss: 18.719036102294922\n",
      "Epoch: 20, Batch: 382, D Loss: 0.10250361601350089, G Loss: 18.899105072021484\n",
      "Epoch: 20, Batch: 383, D Loss: 0.10021676399324231, G Loss: 19.11838150024414\n",
      "Epoch: 20, Batch: 384, D Loss: 0.09895509725090079, G Loss: 19.15909767150879\n",
      "Epoch: 20, Batch: 385, D Loss: 0.09255238905445462, G Loss: 18.837841033935547\n",
      "Epoch: 20, Batch: 386, D Loss: 0.09586131955822719, G Loss: 18.55127716064453\n",
      "Epoch: 20, Batch: 387, D Loss: 0.09592690777170088, G Loss: 18.46945571899414\n",
      "Epoch: 20, Batch: 388, D Loss: 0.10185212288919843, G Loss: 18.838878631591797\n",
      "Epoch: 20, Batch: 389, D Loss: 0.09026474819171937, G Loss: 18.931930541992188\n",
      "Epoch: 20, Batch: 390, D Loss: 0.10339974872465008, G Loss: 19.1999568939209\n",
      "Epoch: 20, Batch: 391, D Loss: 0.09656173220152175, G Loss: 19.200576782226562\n",
      "Epoch: 20, Batch: 392, D Loss: 0.09382853181059114, G Loss: 18.8959903717041\n",
      "Epoch: 20, Batch: 393, D Loss: 0.09670297415269524, G Loss: 18.62373161315918\n",
      "Epoch: 20, Batch: 394, D Loss: 0.09531710735145849, G Loss: 18.48902702331543\n",
      "Epoch: 20, Batch: 395, D Loss: 0.09986533631137862, G Loss: 18.752771377563477\n",
      "Epoch: 20, Batch: 396, D Loss: 0.08404624858639087, G Loss: 18.56178855895996\n",
      "Epoch: 20, Batch: 397, D Loss: 0.10080646366552726, G Loss: 18.774614334106445\n",
      "Epoch: 20, Batch: 398, D Loss: 0.10306202145020316, G Loss: 19.273923873901367\n",
      "Epoch: 20, Batch: 399, D Loss: 0.09929375533697171, G Loss: 19.560373306274414\n",
      "Epoch: 20, Batch: 400, D Loss: 0.10369980485779429, G Loss: 19.67595672607422\n",
      "Epoch: 20, Batch: 401, D Loss: 0.1057894095168237, G Loss: 19.670795440673828\n",
      "Epoch: 20, Batch: 402, D Loss: 0.10129454898030688, G Loss: 19.38949966430664\n",
      "Epoch: 20, Batch: 403, D Loss: 0.09328249357759444, G Loss: 18.780654907226562\n",
      "Epoch: 20, Batch: 404, D Loss: 0.09240185188212768, G Loss: 18.2387638092041\n",
      "Epoch: 20, Batch: 405, D Loss: 0.09145495942911985, G Loss: 18.095487594604492\n",
      "Epoch: 20, Batch: 406, D Loss: 0.09610640814554694, G Loss: 18.509695053100586\n",
      "Epoch: 20, Batch: 407, D Loss: 0.09146056686315318, G Loss: 18.95366859436035\n",
      "Epoch: 20, Batch: 408, D Loss: 0.10385227407503339, G Loss: 19.64093780517578\n",
      "Epoch: 20, Batch: 409, D Loss: 0.09819301349008946, G Loss: 19.864376068115234\n",
      "Epoch: 20, Batch: 410, D Loss: 0.09960925712374269, G Loss: 19.633094787597656\n",
      "Epoch: 20, Batch: 411, D Loss: 0.10029949431629803, G Loss: 19.23093032836914\n",
      "Epoch: 20, Batch: 412, D Loss: 0.1010917226610133, G Loss: 19.009565353393555\n",
      "Epoch: 20, Batch: 413, D Loss: 0.10498230408791831, G Loss: 19.21187400817871\n",
      "Epoch: 20, Batch: 414, D Loss: 0.098236354277907, G Loss: 19.381454467773438\n",
      "Epoch: 20, Batch: 415, D Loss: 0.10825033638752368, G Loss: 19.80735969543457\n",
      "Epoch: 20, Batch: 416, D Loss: 0.09681264442147652, G Loss: 19.716726303100586\n",
      "Epoch: 20, Batch: 417, D Loss: 0.09755940903775029, G Loss: 19.316692352294922\n",
      "Epoch: 20, Batch: 418, D Loss: 0.09754959741822433, G Loss: 18.946887969970703\n",
      "Epoch: 20, Batch: 419, D Loss: 0.09625134196399387, G Loss: 18.76964569091797\n",
      "Epoch: 20, Batch: 420, D Loss: 0.10113588272374519, G Loss: 19.097257614135742\n",
      "Epoch: 20, Batch: 421, D Loss: 0.09819014576327834, G Loss: 19.49752426147461\n",
      "Epoch: 20, Batch: 422, D Loss: 0.0979893595521214, G Loss: 19.684139251708984\n",
      "Epoch: 20, Batch: 423, D Loss: 0.09870097936206257, G Loss: 19.571191787719727\n",
      "Epoch: 20, Batch: 424, D Loss: 0.09810304824187333, G Loss: 19.30063247680664\n",
      "Epoch: 20, Batch: 425, D Loss: 0.10246323263131529, G Loss: 19.241056442260742\n",
      "Epoch: 20, Batch: 426, D Loss: 0.10095852077862588, G Loss: 19.335859298706055\n",
      "Epoch: 20, Batch: 427, D Loss: 0.10228125190491555, G Loss: 19.49129295349121\n",
      "Epoch: 20, Batch: 428, D Loss: 0.10775435855621018, G Loss: 19.879602432250977\n",
      "Epoch: 20, Batch: 429, D Loss: 0.10185755902710003, G Loss: 19.926395416259766\n",
      "Epoch: 20, Batch: 430, D Loss: 0.10502702862053181, G Loss: 19.78934669494629\n",
      "Epoch: 20, Batch: 431, D Loss: 0.10269303770452232, G Loss: 19.468891143798828\n",
      "Epoch: 20, Batch: 432, D Loss: 0.09256381049100537, G Loss: 18.772937774658203\n",
      "Epoch: 20, Batch: 433, D Loss: 0.09424645165574441, G Loss: 18.274169921875\n",
      "Epoch: 20, Batch: 434, D Loss: 0.09837840304513445, G Loss: 18.365522384643555\n",
      "Epoch: 20, Batch: 435, D Loss: 0.09347738776022751, G Loss: 18.66958999633789\n",
      "Epoch: 20, Batch: 436, D Loss: 0.10681696485811254, G Loss: 19.514236450195312\n",
      "Epoch: 20, Batch: 437, D Loss: 0.09916917370262979, G Loss: 19.915515899658203\n",
      "Epoch: 20, Batch: 438, D Loss: 0.1022015225831947, G Loss: 19.80847930908203\n",
      "Epoch: 20, Batch: 439, D Loss: 0.10396879321287544, G Loss: 19.39752769470215\n",
      "Epoch: 20, Batch: 440, D Loss: 0.09355755441761415, G Loss: 18.565210342407227\n",
      "Epoch: 20, Batch: 441, D Loss: 0.09709351329951499, G Loss: 18.057754516601562\n",
      "Epoch: 20, Batch: 442, D Loss: 0.10413696476588763, G Loss: 18.386550903320312\n",
      "Epoch: 20, Batch: 443, D Loss: 0.10077289114569532, G Loss: 19.034467697143555\n",
      "Epoch: 20, Batch: 444, D Loss: 0.09857008083404062, G Loss: 19.408660888671875\n",
      "Epoch: 20, Batch: 445, D Loss: 0.1035983430989843, G Loss: 19.523042678833008\n",
      "Epoch: 20, Batch: 446, D Loss: 0.09857239038471266, G Loss: 19.08249282836914\n",
      "Epoch: 20, Batch: 447, D Loss: 0.10303807577645396, G Loss: 18.679128646850586\n",
      "Epoch: 20, Batch: 448, D Loss: 0.10282241224636923, G Loss: 18.53553009033203\n",
      "Epoch: 20, Batch: 449, D Loss: 0.09319745512265909, G Loss: 18.287782669067383\n",
      "Epoch: 20, Batch: 450, D Loss: 0.10194016025894648, G Loss: 18.45611572265625\n",
      "Epoch: 20, Batch: 451, D Loss: 0.09513985076650977, G Loss: 18.564525604248047\n",
      "Epoch: 20, Batch: 452, D Loss: 0.09266588553068678, G Loss: 18.445613861083984\n",
      "Epoch: 20, Batch: 453, D Loss: 0.10336761613308898, G Loss: 18.656217575073242\n",
      "Epoch: 20, Batch: 454, D Loss: 0.10085621818904156, G Loss: 18.926868438720703\n",
      "Epoch: 20, Batch: 455, D Loss: 0.10389230665815585, G Loss: 19.170869827270508\n",
      "Epoch: 20, Batch: 456, D Loss: 0.10401813911849556, G Loss: 19.255104064941406\n",
      "Epoch: 20, Batch: 457, D Loss: 0.0961512354316898, G Loss: 18.83170509338379\n",
      "Epoch: 20, Batch: 458, D Loss: 0.10208647344574961, G Loss: 18.516189575195312\n",
      "Epoch: 20, Batch: 459, D Loss: 0.09761436042513294, G Loss: 18.320629119873047\n",
      "Epoch: 20, Batch: 460, D Loss: 0.09988397877853217, G Loss: 18.44470977783203\n",
      "Epoch: 20, Batch: 461, D Loss: 0.10281806823911888, G Loss: 18.897218704223633\n",
      "Epoch: 20, Batch: 462, D Loss: 0.09966701528112742, G Loss: 19.242137908935547\n",
      "Epoch: 20, Batch: 463, D Loss: 0.09938583002332857, G Loss: 19.20450210571289\n",
      "Epoch: 20, Batch: 464, D Loss: 0.100285912650933, G Loss: 18.971908569335938\n",
      "Epoch: 20, Batch: 465, D Loss: 0.10189168477396215, G Loss: 18.76000213623047\n",
      "Epoch: 20, Batch: 466, D Loss: 0.0990683623026074, G Loss: 18.656583786010742\n",
      "Epoch: 20, Batch: 467, D Loss: 0.09690752295919136, G Loss: 18.56098747253418\n",
      "Epoch: 21, Batch: 0, D Loss: 0.09638255526671724, G Loss: 18.550704956054688\n",
      "Epoch: 21, Batch: 1, D Loss: 0.10151337463203802, G Loss: 18.845603942871094\n",
      "Epoch: 21, Batch: 2, D Loss: 0.10154305673138997, G Loss: 19.17670249938965\n",
      "Epoch: 21, Batch: 3, D Loss: 0.09709496286750041, G Loss: 19.169889450073242\n",
      "Epoch: 21, Batch: 4, D Loss: 0.10508854917860377, G Loss: 19.217008590698242\n",
      "Epoch: 21, Batch: 5, D Loss: 0.09726523863673231, G Loss: 18.978412628173828\n",
      "Epoch: 21, Batch: 6, D Loss: 0.09377663196765629, G Loss: 18.546730041503906\n",
      "Epoch: 21, Batch: 7, D Loss: 0.09849901221374946, G Loss: 18.429576873779297\n",
      "Epoch: 21, Batch: 8, D Loss: 0.10132496474949138, G Loss: 18.762710571289062\n",
      "Epoch: 21, Batch: 9, D Loss: 0.10025373384288017, G Loss: 19.193944931030273\n",
      "Epoch: 21, Batch: 10, D Loss: 0.09967760945271009, G Loss: 19.432477951049805\n",
      "Epoch: 21, Batch: 11, D Loss: 0.09890071495978803, G Loss: 19.315893173217773\n",
      "Epoch: 21, Batch: 12, D Loss: 0.10424491980843653, G Loss: 19.194995880126953\n",
      "Epoch: 21, Batch: 13, D Loss: 0.10197238871219905, G Loss: 19.063251495361328\n",
      "Epoch: 21, Batch: 14, D Loss: 0.10474096493831264, G Loss: 19.120710372924805\n",
      "Epoch: 21, Batch: 15, D Loss: 0.10515948608107895, G Loss: 19.324241638183594\n",
      "Epoch: 21, Batch: 16, D Loss: 0.0999251624658044, G Loss: 19.294816970825195\n",
      "Epoch: 21, Batch: 17, D Loss: 0.09582574918205289, G Loss: 18.930883407592773\n",
      "Epoch: 21, Batch: 18, D Loss: 0.1007140461439997, G Loss: 18.716690063476562\n",
      "Epoch: 21, Batch: 19, D Loss: 0.10298190614578129, G Loss: 18.839887619018555\n",
      "Epoch: 21, Batch: 20, D Loss: 0.1005584030726181, G Loss: 19.066818237304688\n",
      "Epoch: 21, Batch: 21, D Loss: 0.09457229353764207, G Loss: 18.9691162109375\n",
      "Epoch: 21, Batch: 22, D Loss: 0.09986804727305953, G Loss: 18.888324737548828\n",
      "Epoch: 21, Batch: 23, D Loss: 0.10355821544582078, G Loss: 19.01776885986328\n",
      "Epoch: 21, Batch: 24, D Loss: 0.10344050322950604, G Loss: 19.251787185668945\n",
      "Epoch: 21, Batch: 25, D Loss: 0.09233119589144856, G Loss: 18.986948013305664\n",
      "Epoch: 21, Batch: 26, D Loss: 0.1042809813322132, G Loss: 18.9526424407959\n",
      "Epoch: 21, Batch: 27, D Loss: 0.09984001817104571, G Loss: 18.91441535949707\n",
      "Epoch: 21, Batch: 28, D Loss: 0.10306028562853076, G Loss: 19.037174224853516\n",
      "Epoch: 21, Batch: 29, D Loss: 0.09819071266062185, G Loss: 19.028724670410156\n",
      "Epoch: 21, Batch: 30, D Loss: 0.09790619009434054, G Loss: 18.897531509399414\n",
      "Epoch: 21, Batch: 31, D Loss: 0.09993799356665445, G Loss: 18.805622100830078\n",
      "Epoch: 21, Batch: 32, D Loss: 0.09977957941154281, G Loss: 18.836870193481445\n",
      "Epoch: 21, Batch: 33, D Loss: 0.09692862224571841, G Loss: 18.78110694885254\n",
      "Epoch: 21, Batch: 34, D Loss: 0.0926211291945247, G Loss: 18.562454223632812\n",
      "Epoch: 21, Batch: 35, D Loss: 0.0952203915637666, G Loss: 18.46007537841797\n",
      "Epoch: 21, Batch: 36, D Loss: 0.0970231339525065, G Loss: 18.59101676940918\n",
      "Epoch: 21, Batch: 37, D Loss: 0.09968269218273318, G Loss: 18.962072372436523\n",
      "Epoch: 21, Batch: 38, D Loss: 0.09814601641748322, G Loss: 19.249296188354492\n",
      "Epoch: 21, Batch: 39, D Loss: 0.09312428773742742, G Loss: 19.072189331054688\n",
      "Epoch: 21, Batch: 40, D Loss: 0.09828838993234879, G Loss: 18.88810920715332\n",
      "Epoch: 21, Batch: 41, D Loss: 0.10643051838802497, G Loss: 19.14252471923828\n",
      "Epoch: 21, Batch: 42, D Loss: 0.0993340186828553, G Loss: 19.296655654907227\n",
      "Epoch: 21, Batch: 43, D Loss: 0.09952573686593214, G Loss: 19.295812606811523\n",
      "Epoch: 21, Batch: 44, D Loss: 0.09581629429908123, G Loss: 19.003883361816406\n",
      "Epoch: 21, Batch: 45, D Loss: 0.09727041746758203, G Loss: 18.723848342895508\n",
      "Epoch: 21, Batch: 46, D Loss: 0.10226290277041561, G Loss: 18.83136749267578\n",
      "Epoch: 21, Batch: 47, D Loss: 0.09634989808145544, G Loss: 18.97174644470215\n",
      "Epoch: 21, Batch: 48, D Loss: 0.10394789515732006, G Loss: 19.34149742126465\n",
      "Epoch: 21, Batch: 49, D Loss: 0.09694063114223628, G Loss: 19.37372589111328\n",
      "Epoch: 21, Batch: 50, D Loss: 0.09862785253610795, G Loss: 19.191038131713867\n",
      "Epoch: 21, Batch: 51, D Loss: 0.09994284323823588, G Loss: 18.968467712402344\n",
      "Epoch: 21, Batch: 52, D Loss: 0.09251740934175157, G Loss: 18.555583953857422\n",
      "Epoch: 21, Batch: 53, D Loss: 0.09951120301765082, G Loss: 18.578895568847656\n",
      "Epoch: 21, Batch: 54, D Loss: 0.10700944372336907, G Loss: 19.20883560180664\n",
      "Epoch: 21, Batch: 55, D Loss: 0.1045849861139988, G Loss: 19.83690071105957\n",
      "Epoch: 21, Batch: 56, D Loss: 0.10056141142347208, G Loss: 19.803621292114258\n",
      "Epoch: 21, Batch: 57, D Loss: 0.09918003703631284, G Loss: 19.17708396911621\n",
      "Epoch: 21, Batch: 58, D Loss: 0.09413634608591748, G Loss: 18.32073974609375\n",
      "Epoch: 21, Batch: 59, D Loss: 0.0948510539463796, G Loss: 17.832712173461914\n",
      "Epoch: 21, Batch: 60, D Loss: 0.10227013357639914, G Loss: 18.249332427978516\n",
      "Epoch: 21, Batch: 61, D Loss: 0.1028919182477297, G Loss: 19.14433479309082\n",
      "Epoch: 21, Batch: 62, D Loss: 0.0972282085553472, G Loss: 19.646503448486328\n",
      "Epoch: 21, Batch: 63, D Loss: 0.09456861197682098, G Loss: 19.274003982543945\n",
      "Epoch: 21, Batch: 64, D Loss: 0.10121551438154897, G Loss: 18.739910125732422\n",
      "Epoch: 21, Batch: 65, D Loss: 0.09470911830290518, G Loss: 18.109521865844727\n",
      "Epoch: 21, Batch: 66, D Loss: 0.09981205305601737, G Loss: 17.967287063598633\n",
      "Epoch: 21, Batch: 67, D Loss: 0.09536606809115078, G Loss: 18.096620559692383\n",
      "Epoch: 21, Batch: 68, D Loss: 0.09873052509315938, G Loss: 18.471281051635742\n",
      "Epoch: 21, Batch: 69, D Loss: 0.10204734280581285, G Loss: 18.9351806640625\n",
      "Epoch: 21, Batch: 70, D Loss: 0.10197366296221233, G Loss: 19.14870262145996\n",
      "Epoch: 21, Batch: 71, D Loss: 0.10164615778741948, G Loss: 18.959077835083008\n",
      "Epoch: 21, Batch: 72, D Loss: 0.10172962010510078, G Loss: 18.570030212402344\n",
      "Epoch: 21, Batch: 73, D Loss: 0.10114475109738974, G Loss: 18.230436325073242\n",
      "Epoch: 21, Batch: 74, D Loss: 0.10229629910566418, G Loss: 18.147171020507812\n",
      "Epoch: 21, Batch: 75, D Loss: 0.09589656372817945, G Loss: 18.09697914123535\n",
      "Epoch: 21, Batch: 76, D Loss: 0.10142918555504776, G Loss: 18.291223526000977\n",
      "Epoch: 21, Batch: 77, D Loss: 0.09433048059588511, G Loss: 18.236581802368164\n",
      "Epoch: 21, Batch: 78, D Loss: 0.09656112538930417, G Loss: 18.110319137573242\n",
      "Epoch: 21, Batch: 79, D Loss: 0.09775616936478704, G Loss: 18.04114532470703\n",
      "Epoch: 21, Batch: 80, D Loss: 0.10246083069694434, G Loss: 18.197986602783203\n",
      "Epoch: 21, Batch: 81, D Loss: 0.09973376839565651, G Loss: 18.291574478149414\n",
      "Epoch: 21, Batch: 82, D Loss: 0.09738122556337414, G Loss: 18.104570388793945\n",
      "Epoch: 21, Batch: 83, D Loss: 0.09837987279383409, G Loss: 17.93522834777832\n",
      "Epoch: 21, Batch: 84, D Loss: 0.10120410529005586, G Loss: 17.962051391601562\n",
      "Epoch: 21, Batch: 85, D Loss: 0.10009709005783218, G Loss: 18.06426239013672\n",
      "Epoch: 21, Batch: 86, D Loss: 0.10467549293401657, G Loss: 18.31871223449707\n",
      "Epoch: 21, Batch: 87, D Loss: 0.09910075181318279, G Loss: 18.298938751220703\n",
      "Epoch: 21, Batch: 88, D Loss: 0.09886099296388728, G Loss: 18.052804946899414\n",
      "Epoch: 21, Batch: 89, D Loss: 0.10070724867060044, G Loss: 17.79802703857422\n",
      "Epoch: 21, Batch: 90, D Loss: 0.09541996913148854, G Loss: 17.50409507751465\n",
      "Epoch: 21, Batch: 91, D Loss: 0.09822922727429173, G Loss: 17.473922729492188\n",
      "Epoch: 21, Batch: 92, D Loss: 0.09134562211366415, G Loss: 17.336345672607422\n",
      "Epoch: 21, Batch: 93, D Loss: 0.09994876194677715, G Loss: 17.584184646606445\n",
      "Epoch: 21, Batch: 94, D Loss: 0.10309951871690615, G Loss: 18.139402389526367\n",
      "Epoch: 21, Batch: 95, D Loss: 0.09955192199098484, G Loss: 18.370861053466797\n",
      "Epoch: 21, Batch: 96, D Loss: 0.09354599483827108, G Loss: 17.928714752197266\n",
      "Epoch: 21, Batch: 97, D Loss: 0.1016484000769502, G Loss: 17.59042739868164\n",
      "Epoch: 21, Batch: 98, D Loss: 0.09316601500379473, G Loss: 17.231903076171875\n",
      "Epoch: 21, Batch: 99, D Loss: 0.09947705327465073, G Loss: 17.346261978149414\n",
      "Epoch: 21, Batch: 100, D Loss: 0.10481915906740547, G Loss: 18.0178279876709\n",
      "Epoch: 21, Batch: 101, D Loss: 0.1004185362398986, G Loss: 18.49062156677246\n",
      "Epoch: 21, Batch: 102, D Loss: 0.1045393911891983, G Loss: 18.66257095336914\n",
      "Epoch: 21, Batch: 103, D Loss: 0.10281649678360338, G Loss: 18.41914176940918\n",
      "Epoch: 21, Batch: 104, D Loss: 0.09893706367440824, G Loss: 17.867708206176758\n",
      "Epoch: 21, Batch: 105, D Loss: 0.09656700138793628, G Loss: 17.359394073486328\n",
      "Epoch: 21, Batch: 106, D Loss: 0.10048068998011761, G Loss: 17.385204315185547\n",
      "Epoch: 21, Batch: 107, D Loss: 0.10011845417832266, G Loss: 17.890056610107422\n",
      "Epoch: 21, Batch: 108, D Loss: 0.09750089726465161, G Loss: 18.323945999145508\n",
      "Epoch: 21, Batch: 109, D Loss: 0.0968418621740259, G Loss: 18.385162353515625\n",
      "Epoch: 21, Batch: 110, D Loss: 0.0975460319691206, G Loss: 18.154645919799805\n",
      "Epoch: 21, Batch: 111, D Loss: 0.092030392287195, G Loss: 17.62201499938965\n",
      "Epoch: 21, Batch: 112, D Loss: 0.10284027048453392, G Loss: 17.67652130126953\n",
      "Epoch: 21, Batch: 113, D Loss: 0.09721557241707579, G Loss: 17.90163230895996\n",
      "Epoch: 21, Batch: 114, D Loss: 0.09731241323629103, G Loss: 18.111366271972656\n",
      "Epoch: 21, Batch: 115, D Loss: 0.09868117302564094, G Loss: 18.27552032470703\n",
      "Epoch: 21, Batch: 116, D Loss: 0.10330974094225764, G Loss: 18.44667625427246\n",
      "Epoch: 21, Batch: 117, D Loss: 0.10114458695302897, G Loss: 18.42913818359375\n",
      "Epoch: 21, Batch: 118, D Loss: 0.09468192503993977, G Loss: 17.943281173706055\n",
      "Epoch: 21, Batch: 119, D Loss: 0.10283012073873721, G Loss: 17.78716468811035\n",
      "Epoch: 21, Batch: 120, D Loss: 0.10019157978354798, G Loss: 17.883604049682617\n",
      "Epoch: 21, Batch: 121, D Loss: 0.10160106396625546, G Loss: 18.209672927856445\n",
      "Epoch: 21, Batch: 122, D Loss: 0.10068101235588012, G Loss: 18.44930076599121\n",
      "Epoch: 21, Batch: 123, D Loss: 0.09441453034762315, G Loss: 18.176240921020508\n",
      "Epoch: 21, Batch: 124, D Loss: 0.1042287714124912, G Loss: 18.103219985961914\n",
      "Epoch: 21, Batch: 125, D Loss: 0.09780842075661944, G Loss: 17.92531967163086\n",
      "Epoch: 21, Batch: 126, D Loss: 0.09728888572495276, G Loss: 17.761735916137695\n",
      "Epoch: 21, Batch: 127, D Loss: 0.09556054601832287, G Loss: 17.656055450439453\n",
      "Epoch: 21, Batch: 128, D Loss: 0.09539816859407857, G Loss: 17.655500411987305\n",
      "Epoch: 21, Batch: 129, D Loss: 0.10075862138912317, G Loss: 17.9459285736084\n",
      "Epoch: 21, Batch: 130, D Loss: 0.10762811292632213, G Loss: 18.54788589477539\n",
      "Epoch: 21, Batch: 131, D Loss: 0.09922766355669443, G Loss: 18.660085678100586\n",
      "Epoch: 21, Batch: 132, D Loss: 0.1001655134068491, G Loss: 18.315622329711914\n",
      "Epoch: 21, Batch: 133, D Loss: 0.10028672910025671, G Loss: 17.899377822875977\n",
      "Epoch: 21, Batch: 134, D Loss: 0.10397469374815138, G Loss: 17.844999313354492\n",
      "Epoch: 21, Batch: 135, D Loss: 0.09741709511238827, G Loss: 17.877784729003906\n",
      "Epoch: 21, Batch: 136, D Loss: 0.09036454011285233, G Loss: 17.705896377563477\n",
      "Epoch: 21, Batch: 137, D Loss: 0.09324922016252213, G Loss: 17.579397201538086\n",
      "Epoch: 21, Batch: 138, D Loss: 0.10304580060413926, G Loss: 18.017473220825195\n",
      "Epoch: 21, Batch: 139, D Loss: 0.1059504201193735, G Loss: 18.78864288330078\n",
      "Epoch: 21, Batch: 140, D Loss: 0.10004964771865588, G Loss: 19.055923461914062\n",
      "Epoch: 21, Batch: 141, D Loss: 0.1029606342042646, G Loss: 18.851577758789062\n",
      "Epoch: 21, Batch: 142, D Loss: 0.10887695460944347, G Loss: 18.673311233520508\n",
      "Epoch: 21, Batch: 143, D Loss: 0.1024072960295559, G Loss: 18.395099639892578\n",
      "Epoch: 21, Batch: 144, D Loss: 0.09682048008749788, G Loss: 17.970600128173828\n",
      "Epoch: 21, Batch: 145, D Loss: 0.10566616812993601, G Loss: 18.045475006103516\n",
      "Epoch: 21, Batch: 146, D Loss: 0.09385606649254807, G Loss: 17.99545669555664\n",
      "Epoch: 21, Batch: 147, D Loss: 0.0958621580395711, G Loss: 17.948923110961914\n",
      "Epoch: 21, Batch: 148, D Loss: 0.09327498930179967, G Loss: 17.835065841674805\n",
      "Epoch: 21, Batch: 149, D Loss: 0.10258608341101105, G Loss: 18.11733627319336\n",
      "Epoch: 21, Batch: 150, D Loss: 0.09515061869986496, G Loss: 18.22467613220215\n",
      "Epoch: 21, Batch: 151, D Loss: 0.09933498333509316, G Loss: 18.32701873779297\n",
      "Epoch: 21, Batch: 152, D Loss: 0.10008122562874533, G Loss: 18.374374389648438\n",
      "Epoch: 21, Batch: 153, D Loss: 0.09843227815817368, G Loss: 18.287572860717773\n",
      "Epoch: 21, Batch: 154, D Loss: 0.09704542786591075, G Loss: 18.11317253112793\n",
      "Epoch: 21, Batch: 155, D Loss: 0.10583267972922838, G Loss: 18.314821243286133\n",
      "Epoch: 21, Batch: 156, D Loss: 0.1059798792312101, G Loss: 18.71630096435547\n",
      "Epoch: 21, Batch: 157, D Loss: 0.09913704901389564, G Loss: 18.795093536376953\n",
      "Epoch: 21, Batch: 158, D Loss: 0.09799887636185112, G Loss: 18.526132583618164\n",
      "Epoch: 21, Batch: 159, D Loss: 0.10030517484846957, G Loss: 18.31623649597168\n",
      "Epoch: 21, Batch: 160, D Loss: 0.10147997541903075, G Loss: 18.33489418029785\n",
      "Epoch: 21, Batch: 161, D Loss: 0.10166493537369803, G Loss: 18.579811096191406\n",
      "Epoch: 21, Batch: 162, D Loss: 0.09668502629793929, G Loss: 18.61784553527832\n",
      "Epoch: 21, Batch: 163, D Loss: 0.09547813683457784, G Loss: 18.458187103271484\n",
      "Epoch: 21, Batch: 164, D Loss: 0.10007285805906374, G Loss: 18.468931198120117\n",
      "Epoch: 21, Batch: 165, D Loss: 0.10911971704726975, G Loss: 18.928646087646484\n",
      "Epoch: 21, Batch: 166, D Loss: 0.1013090860432353, G Loss: 19.176652908325195\n",
      "Epoch: 21, Batch: 167, D Loss: 0.10347329313026288, G Loss: 19.192333221435547\n",
      "Epoch: 21, Batch: 168, D Loss: 0.0994382528342923, G Loss: 18.848804473876953\n",
      "Epoch: 21, Batch: 169, D Loss: 0.09652031635819824, G Loss: 18.3539981842041\n",
      "Epoch: 21, Batch: 170, D Loss: 0.09685449918366906, G Loss: 18.08497428894043\n",
      "Epoch: 21, Batch: 171, D Loss: 0.10136953609814947, G Loss: 18.33536148071289\n",
      "Epoch: 21, Batch: 172, D Loss: 0.09284468481935271, G Loss: 18.549570083618164\n",
      "Epoch: 21, Batch: 173, D Loss: 0.10150243702899542, G Loss: 18.924135208129883\n",
      "Epoch: 21, Batch: 174, D Loss: 0.1021855499639539, G Loss: 19.201608657836914\n",
      "Epoch: 21, Batch: 175, D Loss: 0.09641249731018076, G Loss: 19.011425018310547\n",
      "Epoch: 21, Batch: 176, D Loss: 0.0985951456949905, G Loss: 18.661211013793945\n",
      "Epoch: 21, Batch: 177, D Loss: 0.10437612629570348, G Loss: 18.65777587890625\n",
      "Epoch: 21, Batch: 178, D Loss: 0.10102300703511014, G Loss: 18.844919204711914\n",
      "Epoch: 21, Batch: 179, D Loss: 0.10052173880617876, G Loss: 19.03614044189453\n",
      "Epoch: 21, Batch: 180, D Loss: 0.10261898733859853, G Loss: 19.21454429626465\n",
      "Epoch: 21, Batch: 181, D Loss: 0.09858900546270366, G Loss: 19.119853973388672\n",
      "Epoch: 21, Batch: 182, D Loss: 0.10378189640212399, G Loss: 19.069366455078125\n",
      "Epoch: 21, Batch: 183, D Loss: 0.10036557442697491, G Loss: 18.973909378051758\n",
      "Epoch: 21, Batch: 184, D Loss: 0.09848647126840349, G Loss: 18.84869384765625\n",
      "Epoch: 21, Batch: 185, D Loss: 0.1006310019125809, G Loss: 18.825149536132812\n",
      "Epoch: 21, Batch: 186, D Loss: 0.09671454479854757, G Loss: 18.74472427368164\n",
      "Epoch: 21, Batch: 187, D Loss: 0.10406294045610176, G Loss: 18.94469451904297\n",
      "Epoch: 21, Batch: 188, D Loss: 0.1047420377902133, G Loss: 19.250734329223633\n",
      "Epoch: 21, Batch: 189, D Loss: 0.09545290705704979, G Loss: 19.10392189025879\n",
      "Epoch: 21, Batch: 190, D Loss: 0.09727192983601562, G Loss: 18.692745208740234\n",
      "Epoch: 21, Batch: 191, D Loss: 0.09987795784671905, G Loss: 18.45559310913086\n",
      "Epoch: 21, Batch: 192, D Loss: 0.10226794038471354, G Loss: 18.58522605895996\n",
      "Epoch: 21, Batch: 193, D Loss: 0.09272677129665707, G Loss: 18.58988380432129\n",
      "Epoch: 21, Batch: 194, D Loss: 0.09541161784187002, G Loss: 18.574617385864258\n",
      "Epoch: 21, Batch: 195, D Loss: 0.10192309709807246, G Loss: 18.75587272644043\n",
      "Epoch: 21, Batch: 196, D Loss: 0.09436431148910995, G Loss: 18.708415985107422\n",
      "Epoch: 21, Batch: 197, D Loss: 0.10358788423441112, G Loss: 18.83818244934082\n",
      "Epoch: 21, Batch: 198, D Loss: 0.0924756787112393, G Loss: 18.635910034179688\n",
      "Epoch: 21, Batch: 199, D Loss: 0.09299643827708737, G Loss: 18.26602554321289\n",
      "Epoch: 21, Batch: 200, D Loss: 0.10118074548008948, G Loss: 18.28618049621582\n",
      "Epoch: 21, Batch: 201, D Loss: 0.09631507624194491, G Loss: 18.455392837524414\n",
      "Epoch: 21, Batch: 202, D Loss: 0.09944960169250194, G Loss: 18.6386661529541\n",
      "Epoch: 21, Batch: 203, D Loss: 0.09948856056856448, G Loss: 18.566160202026367\n",
      "Epoch: 21, Batch: 204, D Loss: 0.09882282199505577, G Loss: 18.375478744506836\n",
      "Epoch: 21, Batch: 205, D Loss: 0.1046690020823311, G Loss: 18.518705368041992\n",
      "Epoch: 21, Batch: 206, D Loss: 0.09997799690093512, G Loss: 18.565332412719727\n",
      "Epoch: 21, Batch: 207, D Loss: 0.09933874456732994, G Loss: 18.51026725769043\n",
      "Epoch: 21, Batch: 208, D Loss: 0.1006663414442519, G Loss: 18.447309494018555\n",
      "Epoch: 21, Batch: 209, D Loss: 0.10034528870859294, G Loss: 18.412649154663086\n",
      "Epoch: 21, Batch: 210, D Loss: 0.09572138457494805, G Loss: 18.196392059326172\n",
      "Epoch: 21, Batch: 211, D Loss: 0.09208002698639906, G Loss: 17.835290908813477\n",
      "Epoch: 21, Batch: 212, D Loss: 0.10305709455791767, G Loss: 18.034738540649414\n",
      "Epoch: 21, Batch: 213, D Loss: 0.09886835377763648, G Loss: 18.399642944335938\n",
      "Epoch: 21, Batch: 214, D Loss: 0.10378674819482292, G Loss: 18.855619430541992\n",
      "Epoch: 21, Batch: 215, D Loss: 0.10671781279516557, G Loss: 19.158348083496094\n",
      "Epoch: 21, Batch: 216, D Loss: 0.09609362789558151, G Loss: 18.68617057800293\n",
      "Epoch: 21, Batch: 217, D Loss: 0.10024971294623697, G Loss: 18.089847564697266\n",
      "Epoch: 21, Batch: 218, D Loss: 0.10352168241381232, G Loss: 17.939254760742188\n",
      "Epoch: 21, Batch: 219, D Loss: 0.10290736655547628, G Loss: 18.228317260742188\n",
      "Epoch: 21, Batch: 220, D Loss: 0.09549369484563686, G Loss: 18.357547760009766\n",
      "Epoch: 21, Batch: 221, D Loss: 0.10179722797240309, G Loss: 18.524311065673828\n",
      "Epoch: 21, Batch: 222, D Loss: 0.09707529569351969, G Loss: 18.439922332763672\n",
      "Epoch: 21, Batch: 223, D Loss: 0.10059656731737965, G Loss: 18.297754287719727\n",
      "Epoch: 21, Batch: 224, D Loss: 0.09191179250267689, G Loss: 17.839378356933594\n",
      "Epoch: 21, Batch: 225, D Loss: 0.0995268095647246, G Loss: 17.757186889648438\n",
      "Epoch: 21, Batch: 226, D Loss: 0.10427840070556016, G Loss: 18.218191146850586\n",
      "Epoch: 21, Batch: 227, D Loss: 0.10204598769727902, G Loss: 18.752840042114258\n",
      "Epoch: 21, Batch: 228, D Loss: 0.09891119198072418, G Loss: 18.834321975708008\n",
      "Epoch: 21, Batch: 229, D Loss: 0.100770134637862, G Loss: 18.52872657775879\n",
      "Epoch: 21, Batch: 230, D Loss: 0.10430892319577101, G Loss: 18.29539680480957\n",
      "Epoch: 21, Batch: 231, D Loss: 0.10178554673508922, G Loss: 18.140304565429688\n",
      "Epoch: 21, Batch: 232, D Loss: 0.10058097459091009, G Loss: 18.139169692993164\n",
      "Epoch: 21, Batch: 233, D Loss: 0.10121807332994104, G Loss: 18.260713577270508\n",
      "Epoch: 21, Batch: 234, D Loss: 0.09517072770579293, G Loss: 18.128925323486328\n",
      "Epoch: 21, Batch: 235, D Loss: 0.09510692970388224, G Loss: 17.884733200073242\n",
      "Epoch: 21, Batch: 236, D Loss: 0.09871614847328392, G Loss: 17.859882354736328\n",
      "Epoch: 21, Batch: 237, D Loss: 0.1031474099722125, G Loss: 18.138452529907227\n",
      "Epoch: 21, Batch: 238, D Loss: 0.10847624133341682, G Loss: 18.724367141723633\n",
      "Epoch: 21, Batch: 239, D Loss: 0.10284685684898554, G Loss: 18.87312126159668\n",
      "Epoch: 21, Batch: 240, D Loss: 0.10010181770468707, G Loss: 18.423259735107422\n",
      "Epoch: 21, Batch: 241, D Loss: 0.10080281580100525, G Loss: 17.833080291748047\n",
      "Epoch: 21, Batch: 242, D Loss: 0.09994694944571236, G Loss: 17.455717086791992\n",
      "Epoch: 21, Batch: 243, D Loss: 0.09790569391600012, G Loss: 17.4227352142334\n",
      "Epoch: 21, Batch: 244, D Loss: 0.09062831005758021, G Loss: 17.377126693725586\n",
      "Epoch: 21, Batch: 245, D Loss: 0.10213364286415239, G Loss: 17.837080001831055\n",
      "Epoch: 21, Batch: 246, D Loss: 0.10118640150002456, G Loss: 18.361194610595703\n",
      "Epoch: 21, Batch: 247, D Loss: 0.09503995423036748, G Loss: 18.3261775970459\n",
      "Epoch: 21, Batch: 248, D Loss: 0.0960398235267208, G Loss: 17.92474937438965\n",
      "Epoch: 21, Batch: 249, D Loss: 0.10115004492885227, G Loss: 17.73763656616211\n",
      "Epoch: 21, Batch: 250, D Loss: 0.08981495804642314, G Loss: 17.376100540161133\n",
      "Epoch: 21, Batch: 251, D Loss: 0.10115344573953955, G Loss: 17.635799407958984\n",
      "Epoch: 21, Batch: 252, D Loss: 0.09861566963680879, G Loss: 18.149080276489258\n",
      "Epoch: 21, Batch: 253, D Loss: 0.0975785609087425, G Loss: 18.46352767944336\n",
      "Epoch: 21, Batch: 254, D Loss: 0.09670730428352403, G Loss: 18.409507751464844\n",
      "Epoch: 21, Batch: 255, D Loss: 0.1005466038714693, G Loss: 18.27290153503418\n",
      "Epoch: 21, Batch: 256, D Loss: 0.10335831172502719, G Loss: 18.294883728027344\n",
      "Epoch: 21, Batch: 257, D Loss: 0.09670225393560727, G Loss: 18.16383934020996\n",
      "Epoch: 21, Batch: 258, D Loss: 0.09729883035675124, G Loss: 17.998258590698242\n",
      "Epoch: 21, Batch: 259, D Loss: 0.1071179946692733, G Loss: 18.30378532409668\n",
      "Epoch: 21, Batch: 260, D Loss: 0.1009420132077885, G Loss: 18.523082733154297\n",
      "Epoch: 21, Batch: 261, D Loss: 0.09861688029710391, G Loss: 18.492740631103516\n",
      "Epoch: 21, Batch: 262, D Loss: 0.09923331958226012, G Loss: 18.285966873168945\n",
      "Epoch: 21, Batch: 263, D Loss: 0.10010301200567762, G Loss: 18.12294578552246\n",
      "Epoch: 21, Batch: 264, D Loss: 0.09640903757274843, G Loss: 17.96783447265625\n",
      "Epoch: 21, Batch: 265, D Loss: 0.10496900176768698, G Loss: 18.21463394165039\n",
      "Epoch: 21, Batch: 266, D Loss: 0.09269007197800727, G Loss: 18.116737365722656\n",
      "Epoch: 21, Batch: 267, D Loss: 0.09990502089524123, G Loss: 18.095991134643555\n",
      "Epoch: 21, Batch: 268, D Loss: 0.10191073928101879, G Loss: 18.188739776611328\n",
      "Epoch: 21, Batch: 269, D Loss: 0.10112387554887148, G Loss: 18.24395751953125\n",
      "Epoch: 21, Batch: 270, D Loss: 0.09819932914892604, G Loss: 18.133493423461914\n",
      "Epoch: 21, Batch: 271, D Loss: 0.09945905184367554, G Loss: 17.985919952392578\n",
      "Epoch: 21, Batch: 272, D Loss: 0.09797837682462252, G Loss: 17.823211669921875\n",
      "Epoch: 21, Batch: 273, D Loss: 0.09406589997820003, G Loss: 17.594846725463867\n",
      "Epoch: 21, Batch: 274, D Loss: 0.10146210643944986, G Loss: 17.763643264770508\n",
      "Epoch: 21, Batch: 275, D Loss: 0.088551039850989, G Loss: 17.643922805786133\n",
      "Epoch: 21, Batch: 276, D Loss: 0.09994562219428715, G Loss: 17.81645965576172\n",
      "Epoch: 21, Batch: 277, D Loss: 0.09870494985494993, G Loss: 18.007307052612305\n",
      "Epoch: 21, Batch: 278, D Loss: 0.09323275884011739, G Loss: 17.91443634033203\n",
      "Epoch: 21, Batch: 279, D Loss: 0.0997546398818221, G Loss: 17.90145492553711\n",
      "Epoch: 21, Batch: 280, D Loss: 0.09630105762065799, G Loss: 17.8541316986084\n",
      "Epoch: 21, Batch: 281, D Loss: 0.09671009503674544, G Loss: 17.781232833862305\n",
      "Epoch: 21, Batch: 282, D Loss: 0.09754566277295673, G Loss: 17.841999053955078\n",
      "Epoch: 21, Batch: 283, D Loss: 0.09939817406992724, G Loss: 18.020418167114258\n",
      "Epoch: 21, Batch: 284, D Loss: 0.09821484912153489, G Loss: 18.214719772338867\n",
      "Epoch: 21, Batch: 285, D Loss: 0.0955497981513358, G Loss: 18.22993278503418\n",
      "Epoch: 21, Batch: 286, D Loss: 0.10386046573299179, G Loss: 18.40890121459961\n",
      "Epoch: 21, Batch: 287, D Loss: 0.09734821811149841, G Loss: 18.465003967285156\n",
      "Epoch: 21, Batch: 288, D Loss: 0.09922650926958987, G Loss: 18.497529983520508\n",
      "Epoch: 21, Batch: 289, D Loss: 0.10161680421278518, G Loss: 18.60373878479004\n",
      "Epoch: 21, Batch: 290, D Loss: 0.09812804730597069, G Loss: 18.59255027770996\n",
      "Epoch: 21, Batch: 291, D Loss: 0.09495339274606085, G Loss: 18.356412887573242\n",
      "Epoch: 21, Batch: 292, D Loss: 0.09631728221351255, G Loss: 18.18017578125\n",
      "Epoch: 21, Batch: 293, D Loss: 0.09573015474471935, G Loss: 18.143779754638672\n",
      "Epoch: 21, Batch: 294, D Loss: 0.10082158272077857, G Loss: 18.419435501098633\n",
      "Epoch: 21, Batch: 295, D Loss: 0.10823415582075246, G Loss: 19.03073501586914\n",
      "Epoch: 21, Batch: 296, D Loss: 0.09334145795385651, G Loss: 18.786550521850586\n",
      "Epoch: 21, Batch: 297, D Loss: 0.09970827866704379, G Loss: 18.224842071533203\n",
      "Epoch: 21, Batch: 298, D Loss: 0.09514222428832131, G Loss: 17.52963638305664\n",
      "Epoch: 21, Batch: 299, D Loss: 0.10157856879794736, G Loss: 17.441776275634766\n",
      "Epoch: 21, Batch: 300, D Loss: 0.09887650188691222, G Loss: 17.861160278320312\n",
      "Epoch: 21, Batch: 301, D Loss: 0.0962926740612553, G Loss: 18.294694900512695\n",
      "Epoch: 21, Batch: 302, D Loss: 0.0985704707777626, G Loss: 18.638317108154297\n",
      "Epoch: 21, Batch: 303, D Loss: 0.09762353106720845, G Loss: 18.641782760620117\n",
      "Epoch: 21, Batch: 304, D Loss: 0.097582672447595, G Loss: 18.473529815673828\n",
      "Epoch: 21, Batch: 305, D Loss: 0.09411874942328247, G Loss: 18.26750946044922\n",
      "Epoch: 21, Batch: 306, D Loss: 0.10071336266102504, G Loss: 18.438072204589844\n",
      "Epoch: 21, Batch: 307, D Loss: 0.09376558372467914, G Loss: 18.580991744995117\n",
      "Epoch: 21, Batch: 308, D Loss: 0.09778484337833504, G Loss: 18.794879913330078\n",
      "Epoch: 21, Batch: 309, D Loss: 0.10460966358850143, G Loss: 19.196271896362305\n",
      "Epoch: 21, Batch: 310, D Loss: 0.10649652971838197, G Loss: 19.53181266784668\n",
      "Epoch: 21, Batch: 311, D Loss: 0.09908801502787623, G Loss: 19.303245544433594\n",
      "Epoch: 21, Batch: 312, D Loss: 0.09102797820134834, G Loss: 18.52100944519043\n",
      "Epoch: 21, Batch: 313, D Loss: 0.10074648053414847, G Loss: 18.197357177734375\n",
      "Epoch: 21, Batch: 314, D Loss: 0.09974053317782605, G Loss: 18.406625747680664\n",
      "Epoch: 21, Batch: 315, D Loss: 0.10170884053351359, G Loss: 19.015066146850586\n",
      "Epoch: 21, Batch: 316, D Loss: 0.09525147310560822, G Loss: 19.36020278930664\n",
      "Epoch: 21, Batch: 317, D Loss: 0.09987106363590059, G Loss: 19.420490264892578\n",
      "Epoch: 21, Batch: 318, D Loss: 0.09720285448659016, G Loss: 19.152820587158203\n",
      "Epoch: 21, Batch: 319, D Loss: 0.10070646820104945, G Loss: 18.962575912475586\n",
      "Epoch: 21, Batch: 320, D Loss: 0.09723462476146016, G Loss: 18.83139991760254\n",
      "Epoch: 21, Batch: 321, D Loss: 0.10886883997198948, G Loss: 19.282794952392578\n",
      "Epoch: 21, Batch: 322, D Loss: 0.09836533850491413, G Loss: 19.53589630126953\n",
      "Epoch: 21, Batch: 323, D Loss: 0.09522295184990637, G Loss: 19.287670135498047\n",
      "Epoch: 21, Batch: 324, D Loss: 0.10141793876376326, G Loss: 19.0519962310791\n",
      "Epoch: 21, Batch: 325, D Loss: 0.10514433929081335, G Loss: 19.19219207763672\n",
      "Epoch: 21, Batch: 326, D Loss: 0.09623509133864072, G Loss: 19.17401123046875\n",
      "Epoch: 21, Batch: 327, D Loss: 0.09727438042792369, G Loss: 19.071155548095703\n",
      "Epoch: 21, Batch: 328, D Loss: 0.09815948715893619, G Loss: 19.083101272583008\n",
      "Epoch: 21, Batch: 329, D Loss: 0.1011640601735353, G Loss: 19.2818546295166\n",
      "Epoch: 21, Batch: 330, D Loss: 0.10341452241660709, G Loss: 19.591943740844727\n",
      "Epoch: 21, Batch: 331, D Loss: 0.09989838451463029, G Loss: 19.663074493408203\n",
      "Epoch: 21, Batch: 332, D Loss: 0.09749318825230702, G Loss: 19.398509979248047\n",
      "Epoch: 21, Batch: 333, D Loss: 0.10275437132625687, G Loss: 19.331995010375977\n",
      "Epoch: 21, Batch: 334, D Loss: 0.09538528543519176, G Loss: 19.157825469970703\n",
      "Epoch: 21, Batch: 335, D Loss: 0.10366706017731242, G Loss: 19.38204002380371\n",
      "Epoch: 21, Batch: 336, D Loss: 0.10246236777290096, G Loss: 19.781206130981445\n",
      "Epoch: 21, Batch: 337, D Loss: 0.10248247635279273, G Loss: 20.229778289794922\n",
      "Epoch: 21, Batch: 338, D Loss: 0.09720192962655827, G Loss: 19.616466522216797\n",
      "Epoch: 21, Batch: 339, D Loss: 0.09069635230332795, G Loss: 18.611604690551758\n",
      "Epoch: 21, Batch: 340, D Loss: 0.09809363429586071, G Loss: 18.101913452148438\n",
      "Epoch: 21, Batch: 341, D Loss: 0.09492412911661718, G Loss: 18.063947677612305\n",
      "Epoch: 21, Batch: 342, D Loss: 0.09454916297415972, G Loss: 18.32114028930664\n",
      "Epoch: 21, Batch: 343, D Loss: 0.09679677043648871, G Loss: 18.705612182617188\n",
      "Epoch: 21, Batch: 344, D Loss: 0.10203838647640384, G Loss: 19.139162063598633\n",
      "Epoch: 21, Batch: 345, D Loss: 0.09777419520338149, G Loss: 19.082027435302734\n",
      "Epoch: 21, Batch: 346, D Loss: 0.09986457545123062, G Loss: 18.694366455078125\n",
      "Epoch: 21, Batch: 347, D Loss: 0.10074130901454259, G Loss: 18.350906372070312\n",
      "Epoch: 21, Batch: 348, D Loss: 0.09541117292489742, G Loss: 18.022354125976562\n",
      "Epoch: 21, Batch: 349, D Loss: 0.10751091537712654, G Loss: 18.452774047851562\n",
      "Epoch: 21, Batch: 350, D Loss: 0.09837705298193322, G Loss: 18.810195922851562\n",
      "Epoch: 21, Batch: 351, D Loss: 0.0991011815845062, G Loss: 18.897167205810547\n",
      "Epoch: 21, Batch: 352, D Loss: 0.0982465778076651, G Loss: 18.721763610839844\n",
      "Epoch: 21, Batch: 353, D Loss: 0.10391229013741299, G Loss: 18.734373092651367\n",
      "Epoch: 21, Batch: 354, D Loss: 0.09764403484298079, G Loss: 18.662874221801758\n",
      "Epoch: 21, Batch: 355, D Loss: 0.09806298869720065, G Loss: 18.60296058654785\n",
      "Epoch: 21, Batch: 356, D Loss: 0.08791335443786696, G Loss: 18.19425392150879\n",
      "Epoch: 21, Batch: 357, D Loss: 0.1045169213612569, G Loss: 18.484636306762695\n",
      "Epoch: 21, Batch: 358, D Loss: 0.10092601521216671, G Loss: 19.088993072509766\n",
      "Epoch: 21, Batch: 359, D Loss: 0.09746271594606792, G Loss: 19.355409622192383\n",
      "Epoch: 21, Batch: 360, D Loss: 0.10496358756657198, G Loss: 19.487215042114258\n",
      "Epoch: 21, Batch: 361, D Loss: 0.09838065704770105, G Loss: 19.204153060913086\n",
      "Epoch: 21, Batch: 362, D Loss: 0.0998565880344302, G Loss: 18.837360382080078\n",
      "Epoch: 21, Batch: 363, D Loss: 0.0921414463117265, G Loss: 18.327083587646484\n",
      "Epoch: 21, Batch: 364, D Loss: 0.09477799999776737, G Loss: 18.11773109436035\n",
      "Epoch: 21, Batch: 365, D Loss: 0.09757277943289022, G Loss: 18.43433952331543\n",
      "Epoch: 21, Batch: 366, D Loss: 0.10146919236284146, G Loss: 19.12061882019043\n",
      "Epoch: 21, Batch: 367, D Loss: 0.10157855045749487, G Loss: 19.62160873413086\n",
      "Epoch: 21, Batch: 368, D Loss: 0.10293942840729753, G Loss: 19.617145538330078\n",
      "Epoch: 21, Batch: 369, D Loss: 0.10087844932485157, G Loss: 19.05522346496582\n",
      "Epoch: 21, Batch: 370, D Loss: 0.09901029259213567, G Loss: 18.331478118896484\n",
      "Epoch: 21, Batch: 371, D Loss: 0.10299038018916118, G Loss: 18.089860916137695\n",
      "Epoch: 21, Batch: 372, D Loss: 0.10056771983680246, G Loss: 18.23424530029297\n",
      "Epoch: 21, Batch: 373, D Loss: 0.09281962200494887, G Loss: 18.305604934692383\n",
      "Epoch: 21, Batch: 374, D Loss: 0.0983608641002447, G Loss: 18.43525505065918\n",
      "Epoch: 21, Batch: 375, D Loss: 0.10065880873210853, G Loss: 18.585956573486328\n",
      "Epoch: 21, Batch: 376, D Loss: 0.0982431663775647, G Loss: 18.54108428955078\n",
      "Epoch: 21, Batch: 377, D Loss: 0.09501699148387521, G Loss: 18.18672752380371\n",
      "Epoch: 21, Batch: 378, D Loss: 0.09717807898429642, G Loss: 17.927274703979492\n",
      "Epoch: 21, Batch: 379, D Loss: 0.10093073574299005, G Loss: 18.039766311645508\n",
      "Epoch: 21, Batch: 380, D Loss: 0.0954615395441123, G Loss: 18.106523513793945\n",
      "Epoch: 21, Batch: 381, D Loss: 0.09993659575229108, G Loss: 18.310049057006836\n",
      "Epoch: 21, Batch: 382, D Loss: 0.0995511166587093, G Loss: 18.44818687438965\n",
      "Epoch: 21, Batch: 383, D Loss: 0.09481318849907927, G Loss: 18.200355529785156\n",
      "Epoch: 21, Batch: 384, D Loss: 0.09872137693558036, G Loss: 18.02629280090332\n",
      "Epoch: 21, Batch: 385, D Loss: 0.10092885764713033, G Loss: 18.090778350830078\n",
      "Epoch: 21, Batch: 386, D Loss: 0.09535697804179533, G Loss: 18.075260162353516\n",
      "Epoch: 21, Batch: 387, D Loss: 0.09567057342067287, G Loss: 17.97330093383789\n",
      "Epoch: 21, Batch: 388, D Loss: 0.10764569667841783, G Loss: 18.403764724731445\n",
      "Epoch: 21, Batch: 389, D Loss: 0.09588028242323299, G Loss: 18.44896125793457\n",
      "Epoch: 21, Batch: 390, D Loss: 0.10253622124540485, G Loss: 18.447372436523438\n",
      "Epoch: 21, Batch: 391, D Loss: 0.10102293403247975, G Loss: 18.36773109436035\n",
      "Epoch: 21, Batch: 392, D Loss: 0.10082381029132881, G Loss: 18.269350051879883\n",
      "Epoch: 21, Batch: 393, D Loss: 0.0962481714580865, G Loss: 18.0060977935791\n",
      "Epoch: 21, Batch: 394, D Loss: 0.10020157729552359, G Loss: 17.950958251953125\n",
      "Epoch: 21, Batch: 395, D Loss: 0.10006575273020113, G Loss: 18.121389389038086\n",
      "Epoch: 21, Batch: 396, D Loss: 0.09488262940806313, G Loss: 18.039457321166992\n",
      "Epoch: 21, Batch: 397, D Loss: 0.08947123030983128, G Loss: 17.57767677307129\n",
      "Epoch: 21, Batch: 398, D Loss: 0.09810930203790846, G Loss: 17.513017654418945\n",
      "Epoch: 21, Batch: 399, D Loss: 0.09976799316309126, G Loss: 17.88393783569336\n",
      "Epoch: 21, Batch: 400, D Loss: 0.09370525958303588, G Loss: 18.06760597229004\n",
      "Epoch: 21, Batch: 401, D Loss: 0.10198234643747917, G Loss: 18.324377059936523\n",
      "Epoch: 21, Batch: 402, D Loss: 0.09308377523379541, G Loss: 18.114791870117188\n",
      "Epoch: 21, Batch: 403, D Loss: 0.09510123069998944, G Loss: 17.733097076416016\n",
      "Epoch: 21, Batch: 404, D Loss: 0.10215117982794375, G Loss: 17.830942153930664\n",
      "Epoch: 21, Batch: 405, D Loss: 0.09861832899846235, G Loss: 18.089191436767578\n",
      "Epoch: 21, Batch: 406, D Loss: 0.0970620875204582, G Loss: 18.2447452545166\n",
      "Epoch: 21, Batch: 407, D Loss: 0.09329777116719562, G Loss: 18.079294204711914\n",
      "Epoch: 21, Batch: 408, D Loss: 0.10245597290182262, G Loss: 18.16556167602539\n",
      "Epoch: 21, Batch: 409, D Loss: 0.09883860359732433, G Loss: 18.285856246948242\n",
      "Epoch: 21, Batch: 410, D Loss: 0.09813761524626718, G Loss: 18.332691192626953\n",
      "Epoch: 21, Batch: 411, D Loss: 0.10789555742796653, G Loss: 18.779617309570312\n",
      "Epoch: 21, Batch: 412, D Loss: 0.0938116199947372, G Loss: 18.673885345458984\n",
      "Epoch: 21, Batch: 413, D Loss: 0.09761509742454733, G Loss: 18.422237396240234\n",
      "Epoch: 21, Batch: 414, D Loss: 0.09793577895907957, G Loss: 18.22987174987793\n",
      "Epoch: 21, Batch: 415, D Loss: 0.09543809174322426, G Loss: 18.170654296875\n",
      "Epoch: 21, Batch: 416, D Loss: 0.1038575447401433, G Loss: 18.5911865234375\n",
      "Epoch: 21, Batch: 417, D Loss: 0.10167602036752488, G Loss: 19.047710418701172\n",
      "Epoch: 21, Batch: 418, D Loss: 0.09635142509436423, G Loss: 19.01020050048828\n",
      "Epoch: 21, Batch: 419, D Loss: 0.10128141500624221, G Loss: 18.82571029663086\n",
      "Epoch: 21, Batch: 420, D Loss: 0.09854499635269676, G Loss: 18.55469512939453\n",
      "Epoch: 21, Batch: 421, D Loss: 0.10414958420782972, G Loss: 18.629512786865234\n",
      "Epoch: 21, Batch: 422, D Loss: 0.09329578706373676, G Loss: 18.538206100463867\n",
      "Epoch: 21, Batch: 423, D Loss: 0.09644452189951735, G Loss: 18.505327224731445\n",
      "Epoch: 21, Batch: 424, D Loss: 0.10152388766300158, G Loss: 18.758575439453125\n",
      "Epoch: 21, Batch: 425, D Loss: 0.09782282586712476, G Loss: 18.943387985229492\n",
      "Epoch: 21, Batch: 426, D Loss: 0.09687835279644874, G Loss: 18.91170310974121\n",
      "Epoch: 21, Batch: 427, D Loss: 0.10134332932779366, G Loss: 18.914064407348633\n",
      "Epoch: 21, Batch: 428, D Loss: 0.09837773755177026, G Loss: 18.86781883239746\n",
      "Epoch: 21, Batch: 429, D Loss: 0.09618188788552096, G Loss: 18.708721160888672\n",
      "Epoch: 21, Batch: 430, D Loss: 0.1003593093637618, G Loss: 18.773590087890625\n",
      "Epoch: 21, Batch: 431, D Loss: 0.10353469402252236, G Loss: 19.082252502441406\n",
      "Epoch: 21, Batch: 432, D Loss: 0.10421826161139092, G Loss: 19.423431396484375\n",
      "Epoch: 21, Batch: 433, D Loss: 0.09926830424443045, G Loss: 19.33414077758789\n",
      "Epoch: 21, Batch: 434, D Loss: 0.09674963613207743, G Loss: 18.85803985595703\n",
      "Epoch: 21, Batch: 435, D Loss: 0.09339710014043057, G Loss: 18.294260025024414\n",
      "Epoch: 21, Batch: 436, D Loss: 0.09671627589670395, G Loss: 18.17475128173828\n",
      "Epoch: 21, Batch: 437, D Loss: 0.10216532381613597, G Loss: 18.722990036010742\n",
      "Epoch: 21, Batch: 438, D Loss: 0.09735285026606721, G Loss: 19.245254516601562\n",
      "Epoch: 21, Batch: 439, D Loss: 0.10358894044006828, G Loss: 19.697998046875\n",
      "Epoch: 21, Batch: 440, D Loss: 0.09817700243156069, G Loss: 19.494850158691406\n",
      "Epoch: 21, Batch: 441, D Loss: 0.10406825890516269, G Loss: 19.203886032104492\n",
      "Epoch: 21, Batch: 442, D Loss: 0.09472693064051807, G Loss: 18.6472225189209\n",
      "Epoch: 21, Batch: 443, D Loss: 0.09154961047824495, G Loss: 18.088987350463867\n",
      "Epoch: 21, Batch: 444, D Loss: 0.09687445996960697, G Loss: 18.124704360961914\n",
      "Epoch: 21, Batch: 445, D Loss: 0.10223059066857898, G Loss: 18.862091064453125\n",
      "Epoch: 21, Batch: 446, D Loss: 0.09448780370847776, G Loss: 19.332862854003906\n",
      "Epoch: 21, Batch: 447, D Loss: 0.1008859518608144, G Loss: 19.507692337036133\n",
      "Epoch: 21, Batch: 448, D Loss: 0.10121811366258648, G Loss: 19.332210540771484\n",
      "Epoch: 21, Batch: 449, D Loss: 0.09461271309325925, G Loss: 18.627779006958008\n",
      "Epoch: 21, Batch: 450, D Loss: 0.10277231501045847, G Loss: 18.379375457763672\n",
      "Epoch: 21, Batch: 451, D Loss: 0.09475993157501561, G Loss: 18.321552276611328\n",
      "Epoch: 21, Batch: 452, D Loss: 0.10153150269000522, G Loss: 18.687057495117188\n",
      "Epoch: 21, Batch: 453, D Loss: 0.10405648029928227, G Loss: 19.31825828552246\n",
      "Epoch: 21, Batch: 454, D Loss: 0.10099676429833748, G Loss: 19.570940017700195\n",
      "Epoch: 21, Batch: 455, D Loss: 0.09677502718946673, G Loss: 19.07141876220703\n",
      "Epoch: 21, Batch: 456, D Loss: 0.09778695183098618, G Loss: 18.382238388061523\n",
      "Epoch: 21, Batch: 457, D Loss: 0.10020754325042347, G Loss: 18.161945343017578\n",
      "Epoch: 21, Batch: 458, D Loss: 0.0966478647191753, G Loss: 18.277141571044922\n",
      "Epoch: 21, Batch: 459, D Loss: 0.09560116883204284, G Loss: 18.540355682373047\n",
      "Epoch: 21, Batch: 460, D Loss: 0.09576324765959754, G Loss: 18.773771286010742\n",
      "Epoch: 21, Batch: 461, D Loss: 0.09574188632981206, G Loss: 18.8310489654541\n",
      "Epoch: 21, Batch: 462, D Loss: 0.10440783479936488, G Loss: 19.171751022338867\n",
      "Epoch: 21, Batch: 463, D Loss: 0.09455286960792297, G Loss: 19.067138671875\n",
      "Epoch: 21, Batch: 464, D Loss: 0.0977781147534158, G Loss: 18.773723602294922\n",
      "Epoch: 21, Batch: 465, D Loss: 0.09642099241287916, G Loss: 18.54060173034668\n",
      "Epoch: 21, Batch: 466, D Loss: 0.10307364529899088, G Loss: 18.91549301147461\n",
      "Epoch: 21, Batch: 467, D Loss: 0.09738826266690426, G Loss: 19.217933654785156\n",
      "Epoch: 22, Batch: 0, D Loss: 0.09735229820097446, G Loss: 19.364267349243164\n",
      "Epoch: 22, Batch: 1, D Loss: 0.10301554374448763, G Loss: 19.60614013671875\n",
      "Epoch: 22, Batch: 2, D Loss: 0.10143341268305961, G Loss: 19.7159423828125\n",
      "Epoch: 22, Batch: 3, D Loss: 0.10082762833308945, G Loss: 19.60832405090332\n",
      "Epoch: 22, Batch: 4, D Loss: 0.0981942209404929, G Loss: 19.328609466552734\n",
      "Epoch: 22, Batch: 5, D Loss: 0.10146792443884567, G Loss: 19.24413299560547\n",
      "Epoch: 22, Batch: 6, D Loss: 0.09827606599488758, G Loss: 19.244182586669922\n",
      "Epoch: 22, Batch: 7, D Loss: 0.10862834172403446, G Loss: 19.780109405517578\n",
      "Epoch: 22, Batch: 8, D Loss: 0.09562869496619908, G Loss: 19.80674171447754\n",
      "Epoch: 22, Batch: 9, D Loss: 0.10086588696406107, G Loss: 19.662912368774414\n",
      "Epoch: 22, Batch: 10, D Loss: 0.09913963992618757, G Loss: 19.375444412231445\n",
      "Epoch: 22, Batch: 11, D Loss: 0.10259326002275504, G Loss: 19.303194046020508\n",
      "Epoch: 22, Batch: 12, D Loss: 0.09150221444092566, G Loss: 18.979642868041992\n",
      "Epoch: 22, Batch: 13, D Loss: 0.1060936326073505, G Loss: 19.302265167236328\n",
      "Epoch: 22, Batch: 14, D Loss: 0.09662749059028874, G Loss: 19.50983428955078\n",
      "Epoch: 22, Batch: 15, D Loss: 0.09659514001807501, G Loss: 19.483121871948242\n",
      "Epoch: 22, Batch: 16, D Loss: 0.10008131145333565, G Loss: 19.430240631103516\n",
      "Epoch: 22, Batch: 17, D Loss: 0.09745334287856289, G Loss: 19.263580322265625\n",
      "Epoch: 22, Batch: 18, D Loss: 0.09926741043472553, G Loss: 19.23719024658203\n",
      "Epoch: 22, Batch: 19, D Loss: 0.09461266037013094, G Loss: 19.123743057250977\n",
      "Epoch: 22, Batch: 20, D Loss: 0.09637156380409895, G Loss: 19.093852996826172\n",
      "Epoch: 22, Batch: 21, D Loss: 0.0963548669739629, G Loss: 19.18142318725586\n",
      "Epoch: 22, Batch: 22, D Loss: 0.1043469029769748, G Loss: 19.682249069213867\n",
      "Epoch: 22, Batch: 23, D Loss: 0.10022189586111974, G Loss: 20.029211044311523\n",
      "Epoch: 22, Batch: 24, D Loss: 0.09506219743382716, G Loss: 19.717771530151367\n",
      "Epoch: 22, Batch: 25, D Loss: 0.10014949157079356, G Loss: 19.382566452026367\n",
      "Epoch: 22, Batch: 26, D Loss: 0.10253501132515286, G Loss: 19.35326385498047\n",
      "Epoch: 22, Batch: 27, D Loss: 0.10995963361050065, G Loss: 19.932960510253906\n",
      "Epoch: 22, Batch: 28, D Loss: 0.09910371999682999, G Loss: 20.116241455078125\n",
      "Epoch: 22, Batch: 29, D Loss: 0.10232075400015195, G Loss: 20.025972366333008\n",
      "Epoch: 22, Batch: 30, D Loss: 0.09517286859358232, G Loss: 19.376794815063477\n",
      "Epoch: 22, Batch: 31, D Loss: 0.09758417560738941, G Loss: 18.858522415161133\n",
      "Epoch: 22, Batch: 32, D Loss: 0.10748799408144905, G Loss: 19.247957229614258\n",
      "Epoch: 22, Batch: 33, D Loss: 0.09414444308443981, G Loss: 19.517988204956055\n",
      "Epoch: 22, Batch: 34, D Loss: 0.09935640690707237, G Loss: 19.759159088134766\n",
      "Epoch: 22, Batch: 35, D Loss: 0.09527209542258719, G Loss: 19.619646072387695\n",
      "Epoch: 22, Batch: 36, D Loss: 0.10278986546508051, G Loss: 19.603042602539062\n",
      "Epoch: 22, Batch: 37, D Loss: 0.10031256973727654, G Loss: 19.65718650817871\n",
      "Epoch: 22, Batch: 38, D Loss: 0.098490276923481, G Loss: 19.620573043823242\n",
      "Epoch: 22, Batch: 39, D Loss: 0.09374720036906237, G Loss: 19.295167922973633\n",
      "Epoch: 22, Batch: 40, D Loss: 0.09889623743754439, G Loss: 19.18535041809082\n",
      "Epoch: 22, Batch: 41, D Loss: 0.0992395452355781, G Loss: 19.331750869750977\n",
      "Epoch: 22, Batch: 42, D Loss: 0.10088649560528529, G Loss: 19.669036865234375\n",
      "Epoch: 22, Batch: 43, D Loss: 0.10582181923763334, G Loss: 20.13262367248535\n",
      "Epoch: 22, Batch: 44, D Loss: 0.0927664499744455, G Loss: 19.724424362182617\n",
      "Epoch: 22, Batch: 45, D Loss: 0.1027218716060565, G Loss: 19.343591690063477\n",
      "Epoch: 22, Batch: 46, D Loss: 0.10017974154652576, G Loss: 19.107421875\n",
      "Epoch: 22, Batch: 47, D Loss: 0.09679478675270814, G Loss: 18.985445022583008\n",
      "Epoch: 22, Batch: 48, D Loss: 0.10099528241727351, G Loss: 19.17823600769043\n",
      "Epoch: 22, Batch: 49, D Loss: 0.0995379483298604, G Loss: 19.436758041381836\n",
      "Epoch: 22, Batch: 50, D Loss: 0.09672411715892437, G Loss: 19.398929595947266\n",
      "Epoch: 22, Batch: 51, D Loss: 0.09291366726471861, G Loss: 18.944746017456055\n",
      "Epoch: 22, Batch: 52, D Loss: 0.09657518920643526, G Loss: 18.6001033782959\n",
      "Epoch: 22, Batch: 53, D Loss: 0.09656345541110989, G Loss: 18.494844436645508\n",
      "Epoch: 22, Batch: 54, D Loss: 0.09678259926418198, G Loss: 18.62159538269043\n",
      "Epoch: 22, Batch: 55, D Loss: 0.09867747476389521, G Loss: 18.926616668701172\n",
      "Epoch: 22, Batch: 56, D Loss: 0.0945592403502824, G Loss: 18.9433536529541\n",
      "Epoch: 22, Batch: 57, D Loss: 0.09468604214345278, G Loss: 18.710824966430664\n",
      "Epoch: 22, Batch: 58, D Loss: 0.10192028054875224, G Loss: 18.74872398376465\n",
      "Epoch: 22, Batch: 59, D Loss: 0.09998099841007702, G Loss: 18.886472702026367\n",
      "Epoch: 22, Batch: 60, D Loss: 0.099478642683003, G Loss: 18.959657669067383\n",
      "Epoch: 22, Batch: 61, D Loss: 0.09972526427430028, G Loss: 18.942832946777344\n",
      "Epoch: 22, Batch: 62, D Loss: 0.09652781082006845, G Loss: 18.6806640625\n",
      "Epoch: 22, Batch: 63, D Loss: 0.09813148213461931, G Loss: 18.473194122314453\n",
      "Epoch: 22, Batch: 64, D Loss: 0.09388222328723606, G Loss: 18.26945686340332\n",
      "Epoch: 22, Batch: 65, D Loss: 0.10178104547173472, G Loss: 18.541894912719727\n",
      "Epoch: 22, Batch: 66, D Loss: 0.10240011271648441, G Loss: 18.964984893798828\n",
      "Epoch: 22, Batch: 67, D Loss: 0.10169691850249918, G Loss: 19.189834594726562\n",
      "Epoch: 22, Batch: 68, D Loss: 0.0942997887968966, G Loss: 18.6962833404541\n",
      "Epoch: 22, Batch: 69, D Loss: 0.09650102773360114, G Loss: 18.114099502563477\n",
      "Epoch: 22, Batch: 70, D Loss: 0.10093996643447278, G Loss: 18.019433975219727\n",
      "Epoch: 22, Batch: 71, D Loss: 0.09292538489530688, G Loss: 17.96188735961914\n",
      "Epoch: 22, Batch: 72, D Loss: 0.09694258086658669, G Loss: 18.173973083496094\n",
      "Epoch: 22, Batch: 73, D Loss: 0.10181877520664884, G Loss: 18.62891387939453\n",
      "Epoch: 22, Batch: 74, D Loss: 0.09966110797926264, G Loss: 18.859052658081055\n",
      "Epoch: 22, Batch: 75, D Loss: 0.09741366268534657, G Loss: 18.656417846679688\n",
      "Epoch: 22, Batch: 76, D Loss: 0.10159338712498078, G Loss: 18.42283821105957\n",
      "Epoch: 22, Batch: 77, D Loss: 0.09631127707479337, G Loss: 18.110031127929688\n",
      "Epoch: 22, Batch: 78, D Loss: 0.1052789154856697, G Loss: 18.268640518188477\n",
      "Epoch: 22, Batch: 79, D Loss: 0.10048924904024625, G Loss: 18.49301528930664\n",
      "Epoch: 22, Batch: 80, D Loss: 0.09683007492740137, G Loss: 18.391677856445312\n",
      "Epoch: 22, Batch: 81, D Loss: 0.10138573299915654, G Loss: 18.275739669799805\n",
      "Epoch: 22, Batch: 82, D Loss: 0.10023007400771444, G Loss: 18.1936092376709\n",
      "Epoch: 22, Batch: 83, D Loss: 0.09852235668358889, G Loss: 18.13044548034668\n",
      "Epoch: 22, Batch: 84, D Loss: 0.1027436168153204, G Loss: 18.313013076782227\n",
      "Epoch: 22, Batch: 85, D Loss: 0.09003705430785391, G Loss: 18.03629493713379\n",
      "Epoch: 22, Batch: 86, D Loss: 0.0990381095942281, G Loss: 17.908504486083984\n",
      "Epoch: 22, Batch: 87, D Loss: 0.105303108007051, G Loss: 18.307924270629883\n",
      "Epoch: 22, Batch: 88, D Loss: 0.1061226244805078, G Loss: 18.909523010253906\n",
      "Epoch: 22, Batch: 89, D Loss: 0.0963944526798568, G Loss: 18.82493782043457\n",
      "Epoch: 22, Batch: 90, D Loss: 0.09627674983428003, G Loss: 18.200735092163086\n",
      "Epoch: 22, Batch: 91, D Loss: 0.09418728358429096, G Loss: 17.501754760742188\n",
      "Epoch: 22, Batch: 92, D Loss: 0.1015579527507473, G Loss: 17.50873374938965\n",
      "Epoch: 22, Batch: 93, D Loss: 0.10252548190917121, G Loss: 18.071189880371094\n",
      "Epoch: 22, Batch: 94, D Loss: 0.09709249988412072, G Loss: 18.549270629882812\n",
      "Epoch: 22, Batch: 95, D Loss: 0.10615026566955299, G Loss: 18.923044204711914\n",
      "Epoch: 22, Batch: 96, D Loss: 0.09119714469720996, G Loss: 18.30755615234375\n",
      "Epoch: 22, Batch: 97, D Loss: 0.09677466093448217, G Loss: 17.55353355407715\n",
      "Epoch: 22, Batch: 98, D Loss: 0.10162077685695081, G Loss: 17.3432559967041\n",
      "Epoch: 22, Batch: 99, D Loss: 0.09989955764931135, G Loss: 17.677452087402344\n",
      "Epoch: 22, Batch: 100, D Loss: 0.10690756052491146, G Loss: 18.574928283691406\n",
      "Epoch: 22, Batch: 101, D Loss: 0.10048422554065639, G Loss: 19.033355712890625\n",
      "Epoch: 22, Batch: 102, D Loss: 0.10092923336575521, G Loss: 18.895526885986328\n",
      "Epoch: 22, Batch: 103, D Loss: 0.09833753548344593, G Loss: 18.23826026916504\n",
      "Epoch: 22, Batch: 104, D Loss: 0.10168570288570766, G Loss: 17.806316375732422\n",
      "Epoch: 22, Batch: 105, D Loss: 0.10407008342467705, G Loss: 17.952396392822266\n",
      "Epoch: 22, Batch: 106, D Loss: 0.09811017626911456, G Loss: 18.17801284790039\n",
      "Epoch: 22, Batch: 107, D Loss: 0.09462678316876572, G Loss: 18.20302391052246\n",
      "Epoch: 22, Batch: 108, D Loss: 0.09874100097264371, G Loss: 18.258163452148438\n",
      "Epoch: 22, Batch: 109, D Loss: 0.09659040582014988, G Loss: 18.197385787963867\n",
      "Epoch: 22, Batch: 110, D Loss: 0.10163927661302852, G Loss: 18.331029891967773\n",
      "Epoch: 22, Batch: 111, D Loss: 0.1020907955965562, G Loss: 18.608322143554688\n",
      "Epoch: 22, Batch: 112, D Loss: 0.1040291151532009, G Loss: 18.882431030273438\n",
      "Epoch: 22, Batch: 113, D Loss: 0.10073250854291116, G Loss: 18.841114044189453\n",
      "Epoch: 22, Batch: 114, D Loss: 0.09847999789130046, G Loss: 18.351425170898438\n",
      "Epoch: 22, Batch: 115, D Loss: 0.09902644827060492, G Loss: 17.930086135864258\n",
      "Epoch: 22, Batch: 116, D Loss: 0.10258168045297378, G Loss: 17.951553344726562\n",
      "Epoch: 22, Batch: 117, D Loss: 0.09592758896647169, G Loss: 18.005786895751953\n",
      "Epoch: 22, Batch: 118, D Loss: 0.09965670817312056, G Loss: 18.13335609436035\n",
      "Epoch: 22, Batch: 119, D Loss: 0.10607602969616226, G Loss: 18.599702835083008\n",
      "Epoch: 22, Batch: 120, D Loss: 0.09307995937638092, G Loss: 18.266815185546875\n",
      "Epoch: 22, Batch: 121, D Loss: 0.10038822100292188, G Loss: 17.91796875\n",
      "Epoch: 22, Batch: 122, D Loss: 0.10138703292323026, G Loss: 17.758888244628906\n",
      "Epoch: 22, Batch: 123, D Loss: 0.09415740184046939, G Loss: 17.429391860961914\n",
      "Epoch: 22, Batch: 124, D Loss: 0.1020705824684276, G Loss: 17.57823944091797\n",
      "Epoch: 22, Batch: 125, D Loss: 0.09196532308032435, G Loss: 17.395252227783203\n",
      "Epoch: 22, Batch: 126, D Loss: 0.10490497638442786, G Loss: 17.712221145629883\n",
      "Epoch: 22, Batch: 127, D Loss: 0.10466031031385281, G Loss: 18.18680763244629\n",
      "Epoch: 22, Batch: 128, D Loss: 0.09908945015626403, G Loss: 18.14217758178711\n",
      "Epoch: 22, Batch: 129, D Loss: 0.09809760880230556, G Loss: 17.607131958007812\n",
      "Epoch: 22, Batch: 130, D Loss: 0.09392565747091908, G Loss: 16.777511596679688\n",
      "Epoch: 22, Batch: 131, D Loss: 0.09162355832009794, G Loss: 16.157703399658203\n",
      "Epoch: 22, Batch: 132, D Loss: 0.10677747065550136, G Loss: 16.843589782714844\n",
      "Epoch: 22, Batch: 133, D Loss: 0.09820805548666556, G Loss: 17.694812774658203\n",
      "Epoch: 22, Batch: 134, D Loss: 0.09779843004499611, G Loss: 18.16668128967285\n",
      "Epoch: 22, Batch: 135, D Loss: 0.09844461009138827, G Loss: 18.092357635498047\n",
      "Epoch: 22, Batch: 136, D Loss: 0.10454424445744914, G Loss: 18.024572372436523\n",
      "Epoch: 22, Batch: 137, D Loss: 0.10022144827586477, G Loss: 17.86701774597168\n",
      "Epoch: 22, Batch: 138, D Loss: 0.10184843962233892, G Loss: 17.870662689208984\n",
      "Epoch: 22, Batch: 139, D Loss: 0.09898711063717158, G Loss: 17.9943790435791\n",
      "Epoch: 22, Batch: 140, D Loss: 0.09313771970859541, G Loss: 17.816226959228516\n",
      "Epoch: 22, Batch: 141, D Loss: 0.0967841315268263, G Loss: 17.80034637451172\n",
      "Epoch: 22, Batch: 142, D Loss: 0.09532104556792564, G Loss: 17.930278778076172\n",
      "Epoch: 22, Batch: 143, D Loss: 0.09981636609072364, G Loss: 18.361967086791992\n",
      "Epoch: 22, Batch: 144, D Loss: 0.10125935475022008, G Loss: 18.912708282470703\n",
      "Epoch: 22, Batch: 145, D Loss: 0.097405198160885, G Loss: 18.997377395629883\n",
      "Epoch: 22, Batch: 146, D Loss: 0.10108686539297107, G Loss: 18.86800193786621\n",
      "Epoch: 22, Batch: 147, D Loss: 0.10075448067863024, G Loss: 18.646739959716797\n",
      "Epoch: 22, Batch: 148, D Loss: 0.10274512729813567, G Loss: 18.599618911743164\n",
      "Epoch: 22, Batch: 149, D Loss: 0.09741539218140716, G Loss: 18.439388275146484\n",
      "Epoch: 22, Batch: 150, D Loss: 0.09734222806722226, G Loss: 18.353273391723633\n",
      "Epoch: 22, Batch: 151, D Loss: 0.10312936174474441, G Loss: 18.622148513793945\n",
      "Epoch: 22, Batch: 152, D Loss: 0.0938450963938835, G Loss: 18.38422203063965\n",
      "Epoch: 22, Batch: 153, D Loss: 0.09423730390825735, G Loss: 18.066593170166016\n",
      "Epoch: 22, Batch: 154, D Loss: 0.10197753373666174, G Loss: 18.21468162536621\n",
      "Epoch: 22, Batch: 155, D Loss: 0.09785116276251005, G Loss: 18.400802612304688\n",
      "Epoch: 22, Batch: 156, D Loss: 0.10624702672451347, G Loss: 18.876108169555664\n",
      "Epoch: 22, Batch: 157, D Loss: 0.09638355240271523, G Loss: 18.90234375\n",
      "Epoch: 22, Batch: 158, D Loss: 0.0977447811880281, G Loss: 18.726255416870117\n",
      "Epoch: 22, Batch: 159, D Loss: 0.09382889864924104, G Loss: 18.36667823791504\n",
      "Epoch: 22, Batch: 160, D Loss: 0.1007317951879001, G Loss: 18.424631118774414\n",
      "Epoch: 22, Batch: 161, D Loss: 0.09730801407643774, G Loss: 18.743000030517578\n",
      "Epoch: 22, Batch: 162, D Loss: 0.10467960199891846, G Loss: 19.376359939575195\n",
      "Epoch: 22, Batch: 163, D Loss: 0.09903118923454557, G Loss: 19.678592681884766\n",
      "Epoch: 22, Batch: 164, D Loss: 0.10713757706614135, G Loss: 19.817880630493164\n",
      "Epoch: 22, Batch: 165, D Loss: 0.10190014683786153, G Loss: 19.545915603637695\n",
      "Epoch: 22, Batch: 166, D Loss: 0.1002303158384672, G Loss: 19.147560119628906\n",
      "Epoch: 22, Batch: 167, D Loss: 0.10146570474907812, G Loss: 18.943002700805664\n",
      "Epoch: 22, Batch: 168, D Loss: 0.10503743105504859, G Loss: 19.181549072265625\n",
      "Epoch: 22, Batch: 169, D Loss: 0.09984159674886639, G Loss: 19.42751693725586\n",
      "Epoch: 22, Batch: 170, D Loss: 0.0982247012874421, G Loss: 19.466421127319336\n",
      "Epoch: 22, Batch: 171, D Loss: 0.1019284146907602, G Loss: 19.44605827331543\n",
      "Epoch: 22, Batch: 172, D Loss: 0.09505808564684748, G Loss: 19.134626388549805\n",
      "Epoch: 22, Batch: 173, D Loss: 0.09275742174012702, G Loss: 18.75583839416504\n",
      "Epoch: 22, Batch: 174, D Loss: 0.10172798060022425, G Loss: 18.96464729309082\n",
      "Epoch: 22, Batch: 175, D Loss: 0.10106905018362555, G Loss: 19.546104431152344\n",
      "Epoch: 22, Batch: 176, D Loss: 0.0977825013842818, G Loss: 19.973413467407227\n",
      "Epoch: 22, Batch: 177, D Loss: 0.09213309108047973, G Loss: 19.76658821105957\n",
      "Epoch: 22, Batch: 178, D Loss: 0.09958648826605387, G Loss: 19.56183433532715\n",
      "Epoch: 22, Batch: 179, D Loss: 0.10393358912397466, G Loss: 19.741168975830078\n",
      "Epoch: 22, Batch: 180, D Loss: 0.09787462773897404, G Loss: 19.910022735595703\n",
      "Epoch: 22, Batch: 181, D Loss: 0.09532643227009574, G Loss: 19.83281898498535\n",
      "Epoch: 22, Batch: 182, D Loss: 0.1020355757780591, G Loss: 19.920934677124023\n",
      "Epoch: 22, Batch: 183, D Loss: 0.10583405287390601, G Loss: 20.313247680664062\n",
      "Epoch: 22, Batch: 184, D Loss: 0.10030243615799656, G Loss: 20.453140258789062\n",
      "Epoch: 22, Batch: 185, D Loss: 0.09825664087902858, G Loss: 20.213943481445312\n",
      "Epoch: 22, Batch: 186, D Loss: 0.09531431753823427, G Loss: 19.70612144470215\n",
      "Epoch: 22, Batch: 187, D Loss: 0.09339890054131905, G Loss: 19.31142234802246\n",
      "Epoch: 22, Batch: 188, D Loss: 0.1006121802728922, G Loss: 19.53106689453125\n",
      "Epoch: 22, Batch: 189, D Loss: 0.10228921585898887, G Loss: 20.2480525970459\n",
      "Epoch: 22, Batch: 190, D Loss: 0.09772440110737407, G Loss: 20.663166046142578\n",
      "Epoch: 22, Batch: 191, D Loss: 0.10244626603363116, G Loss: 20.7214298248291\n",
      "Epoch: 22, Batch: 192, D Loss: 0.10229763446651957, G Loss: 20.442184448242188\n",
      "Epoch: 22, Batch: 193, D Loss: 0.10334578983248938, G Loss: 20.04386329650879\n",
      "Epoch: 22, Batch: 194, D Loss: 0.09911438201541078, G Loss: 19.61103057861328\n",
      "Epoch: 22, Batch: 195, D Loss: 0.10215662576959972, G Loss: 19.548616409301758\n",
      "Epoch: 22, Batch: 196, D Loss: 0.0991643980565936, G Loss: 19.65302085876465\n",
      "Epoch: 22, Batch: 197, D Loss: 0.10104389622318477, G Loss: 19.81890106201172\n",
      "Epoch: 22, Batch: 198, D Loss: 0.10253841540666142, G Loss: 20.02759552001953\n",
      "Epoch: 22, Batch: 199, D Loss: 0.10133005781388948, G Loss: 19.981224060058594\n",
      "Epoch: 22, Batch: 200, D Loss: 0.09411952783282773, G Loss: 19.45220375061035\n",
      "Epoch: 22, Batch: 201, D Loss: 0.09825986838987766, G Loss: 19.09355354309082\n",
      "Epoch: 22, Batch: 202, D Loss: 0.0913846819550217, G Loss: 18.866168975830078\n",
      "Epoch: 22, Batch: 203, D Loss: 0.1038439000200535, G Loss: 19.383281707763672\n",
      "Epoch: 22, Batch: 204, D Loss: 0.10189305378962576, G Loss: 20.069013595581055\n",
      "Epoch: 22, Batch: 205, D Loss: 0.09609120429100304, G Loss: 20.195995330810547\n",
      "Epoch: 22, Batch: 206, D Loss: 0.0961115296471059, G Loss: 19.748836517333984\n",
      "Epoch: 22, Batch: 207, D Loss: 0.09918122904231796, G Loss: 19.324111938476562\n",
      "Epoch: 22, Batch: 208, D Loss: 0.09201373423629788, G Loss: 18.822507858276367\n",
      "Epoch: 22, Batch: 209, D Loss: 0.09814065266238137, G Loss: 18.928686141967773\n",
      "Epoch: 22, Batch: 210, D Loss: 0.09572191777290118, G Loss: 19.35127830505371\n",
      "Epoch: 22, Batch: 211, D Loss: 0.09349609338512632, G Loss: 19.60938262939453\n",
      "Epoch: 22, Batch: 212, D Loss: 0.09904497250958766, G Loss: 19.850942611694336\n",
      "Epoch: 22, Batch: 213, D Loss: 0.09969668201435644, G Loss: 19.991724014282227\n",
      "Epoch: 22, Batch: 214, D Loss: 0.09771897752767744, G Loss: 19.901748657226562\n",
      "Epoch: 22, Batch: 215, D Loss: 0.0992440295601984, G Loss: 19.75237274169922\n",
      "Epoch: 22, Batch: 216, D Loss: 0.09764582061218285, G Loss: 19.607362747192383\n",
      "Epoch: 22, Batch: 217, D Loss: 0.09813387839590637, G Loss: 19.670991897583008\n",
      "Epoch: 22, Batch: 218, D Loss: 0.09748014938183391, G Loss: 19.848167419433594\n",
      "Epoch: 22, Batch: 219, D Loss: 0.10109048434795331, G Loss: 20.231538772583008\n",
      "Epoch: 22, Batch: 220, D Loss: 0.10308927362827419, G Loss: 20.659494400024414\n",
      "Epoch: 22, Batch: 221, D Loss: 0.09884613059241204, G Loss: 20.708698272705078\n",
      "Epoch: 22, Batch: 222, D Loss: 0.10011424179798373, G Loss: 20.53687286376953\n",
      "Epoch: 22, Batch: 223, D Loss: 0.1014193898923898, G Loss: 20.407882690429688\n",
      "Epoch: 22, Batch: 224, D Loss: 0.09724297450057012, G Loss: 20.222332000732422\n",
      "Epoch: 22, Batch: 225, D Loss: 0.09267683420471562, G Loss: 19.98937225341797\n",
      "Epoch: 22, Batch: 226, D Loss: 0.10213526425717895, G Loss: 20.323101043701172\n",
      "Epoch: 22, Batch: 227, D Loss: 0.09769392818998757, G Loss: 20.723388671875\n",
      "Epoch: 22, Batch: 228, D Loss: 0.09498162616857198, G Loss: 20.752290725708008\n",
      "Epoch: 22, Batch: 229, D Loss: 0.09407644779204022, G Loss: 20.339059829711914\n",
      "Epoch: 22, Batch: 230, D Loss: 0.09896451318345112, G Loss: 20.094093322753906\n",
      "Epoch: 22, Batch: 231, D Loss: 0.09887634310353355, G Loss: 20.11853790283203\n",
      "Epoch: 22, Batch: 232, D Loss: 0.10072926511946556, G Loss: 20.37319564819336\n",
      "Epoch: 22, Batch: 233, D Loss: 0.10449484047974483, G Loss: 20.777969360351562\n",
      "Epoch: 22, Batch: 234, D Loss: 0.09955431569035383, G Loss: 20.747865676879883\n",
      "Epoch: 22, Batch: 235, D Loss: 0.09895741999942942, G Loss: 20.34166717529297\n",
      "Epoch: 22, Batch: 236, D Loss: 0.09056694924350095, G Loss: 19.42383575439453\n",
      "Epoch: 22, Batch: 237, D Loss: 0.10041579822590951, G Loss: 19.091304779052734\n",
      "Epoch: 22, Batch: 238, D Loss: 0.09882606790932513, G Loss: 19.334392547607422\n",
      "Epoch: 22, Batch: 239, D Loss: 0.09623200610467875, G Loss: 19.714921951293945\n",
      "Epoch: 22, Batch: 240, D Loss: 0.09729974840639655, G Loss: 19.909351348876953\n",
      "Epoch: 22, Batch: 241, D Loss: 0.09068418438255599, G Loss: 19.444957733154297\n",
      "Epoch: 22, Batch: 242, D Loss: 0.09765748902961424, G Loss: 19.030223846435547\n",
      "Epoch: 22, Batch: 243, D Loss: 0.0959141881641914, G Loss: 18.770448684692383\n",
      "Epoch: 22, Batch: 244, D Loss: 0.10304458732745503, G Loss: 19.118616104125977\n",
      "Epoch: 22, Batch: 245, D Loss: 0.1032977421034802, G Loss: 19.647891998291016\n",
      "Epoch: 22, Batch: 246, D Loss: 0.10482391841869199, G Loss: 19.922325134277344\n",
      "Epoch: 22, Batch: 247, D Loss: 0.1002949341017334, G Loss: 19.51656723022461\n",
      "Epoch: 22, Batch: 248, D Loss: 0.10666507685438176, G Loss: 19.14794921875\n",
      "Epoch: 22, Batch: 249, D Loss: 0.10012820661647592, G Loss: 18.74543571472168\n",
      "Epoch: 22, Batch: 250, D Loss: 0.09210518479811691, G Loss: 18.21710777282715\n",
      "Epoch: 22, Batch: 251, D Loss: 0.10319428700978817, G Loss: 18.40654754638672\n",
      "Epoch: 22, Batch: 252, D Loss: 0.10166196154840135, G Loss: 18.983318328857422\n",
      "Epoch: 22, Batch: 253, D Loss: 0.10415700290621777, G Loss: 19.538389205932617\n",
      "Epoch: 22, Batch: 254, D Loss: 0.09659023008433243, G Loss: 19.458589553833008\n",
      "Epoch: 22, Batch: 255, D Loss: 0.10091026335549635, G Loss: 19.150863647460938\n",
      "Epoch: 22, Batch: 256, D Loss: 0.09523932208001451, G Loss: 18.62605094909668\n",
      "Epoch: 22, Batch: 257, D Loss: 0.10236384390705622, G Loss: 18.585941314697266\n",
      "Epoch: 22, Batch: 258, D Loss: 0.09919795760269579, G Loss: 18.863513946533203\n",
      "Epoch: 22, Batch: 259, D Loss: 0.10253836463001553, G Loss: 19.350248336791992\n",
      "Epoch: 22, Batch: 260, D Loss: 0.10196332050153434, G Loss: 19.72871971130371\n",
      "Epoch: 22, Batch: 261, D Loss: 0.10292965299190293, G Loss: 19.869606018066406\n",
      "Epoch: 22, Batch: 262, D Loss: 0.09836498041847874, G Loss: 19.548860549926758\n",
      "Epoch: 22, Batch: 263, D Loss: 0.1026056352625141, G Loss: 19.320486068725586\n",
      "Epoch: 22, Batch: 264, D Loss: 0.09913142234769756, G Loss: 19.265932083129883\n",
      "Epoch: 22, Batch: 265, D Loss: 0.10486464380505689, G Loss: 19.62139320373535\n",
      "Epoch: 22, Batch: 266, D Loss: 0.09414942710861507, G Loss: 19.649858474731445\n",
      "Epoch: 22, Batch: 267, D Loss: 0.10211165378199649, G Loss: 19.891010284423828\n",
      "Epoch: 22, Batch: 268, D Loss: 0.10312963375926842, G Loss: 20.177915573120117\n",
      "Epoch: 22, Batch: 269, D Loss: 0.09866605786875288, G Loss: 20.144203186035156\n",
      "Epoch: 22, Batch: 270, D Loss: 0.10219270081125886, G Loss: 20.123477935791016\n",
      "Epoch: 22, Batch: 271, D Loss: 0.10042798615645887, G Loss: 20.01368522644043\n",
      "Epoch: 22, Batch: 272, D Loss: 0.09431488187833914, G Loss: 19.68368911743164\n",
      "Epoch: 22, Batch: 273, D Loss: 0.09166105263957303, G Loss: 19.306751251220703\n",
      "Epoch: 22, Batch: 274, D Loss: 0.10269621927607753, G Loss: 19.69595718383789\n",
      "Epoch: 22, Batch: 275, D Loss: 0.10199222803792013, G Loss: 20.52838706970215\n",
      "Epoch: 22, Batch: 276, D Loss: 0.10322474729597045, G Loss: 21.266094207763672\n",
      "Epoch: 22, Batch: 277, D Loss: 0.10174456267102025, G Loss: 21.312524795532227\n",
      "Epoch: 22, Batch: 278, D Loss: 0.10298052465033267, G Loss: 20.878509521484375\n",
      "Epoch: 22, Batch: 279, D Loss: 0.09828187585898351, G Loss: 20.217313766479492\n",
      "Epoch: 22, Batch: 280, D Loss: 0.10144282967873514, G Loss: 20.052865982055664\n",
      "Epoch: 22, Batch: 281, D Loss: 0.09951610948632578, G Loss: 20.309120178222656\n",
      "Epoch: 22, Batch: 282, D Loss: 0.09375044773904506, G Loss: 20.445512771606445\n",
      "Epoch: 22, Batch: 283, D Loss: 0.10124969539318474, G Loss: 20.7276611328125\n",
      "Epoch: 22, Batch: 284, D Loss: 0.10039659634394388, G Loss: 20.925479888916016\n",
      "Epoch: 22, Batch: 285, D Loss: 0.0949498717793586, G Loss: 20.627962112426758\n",
      "Epoch: 22, Batch: 286, D Loss: 0.10089135976967961, G Loss: 20.402976989746094\n",
      "Epoch: 22, Batch: 287, D Loss: 0.08692021766102254, G Loss: 19.728193283081055\n",
      "Epoch: 22, Batch: 288, D Loss: 0.09914558517903993, G Loss: 19.703197479248047\n",
      "Epoch: 22, Batch: 289, D Loss: 0.10188919405895058, G Loss: 20.321138381958008\n",
      "Epoch: 22, Batch: 290, D Loss: 0.10063203476442506, G Loss: 21.005233764648438\n",
      "Epoch: 22, Batch: 291, D Loss: 0.09798085724408026, G Loss: 21.15546989440918\n",
      "Epoch: 22, Batch: 292, D Loss: 0.09637070489861066, G Loss: 20.63593101501465\n",
      "Epoch: 22, Batch: 293, D Loss: 0.09990370344039362, G Loss: 20.15174674987793\n",
      "Epoch: 22, Batch: 294, D Loss: 0.10602384143380855, G Loss: 20.280357360839844\n",
      "Epoch: 22, Batch: 295, D Loss: 0.09866178109113544, G Loss: 20.39324951171875\n",
      "Epoch: 22, Batch: 296, D Loss: 0.10193671349027994, G Loss: 20.584314346313477\n",
      "Epoch: 22, Batch: 297, D Loss: 0.09755934091449286, G Loss: 20.451297760009766\n",
      "Epoch: 22, Batch: 298, D Loss: 0.10354714163216128, G Loss: 20.39453887939453\n",
      "Epoch: 22, Batch: 299, D Loss: 0.09459819728048624, G Loss: 20.04829978942871\n",
      "Epoch: 22, Batch: 300, D Loss: 0.10034938257548154, G Loss: 19.99616050720215\n",
      "Epoch: 22, Batch: 301, D Loss: 0.1037339427869517, G Loss: 20.316631317138672\n",
      "Epoch: 22, Batch: 302, D Loss: 0.09652143043747835, G Loss: 20.39677619934082\n",
      "Epoch: 22, Batch: 303, D Loss: 0.093510472089406, G Loss: 20.112764358520508\n",
      "Epoch: 22, Batch: 304, D Loss: 0.09954896669223379, G Loss: 19.95640754699707\n",
      "Epoch: 22, Batch: 305, D Loss: 0.10041043265934868, G Loss: 20.02972984313965\n",
      "Epoch: 22, Batch: 306, D Loss: 0.09321375299081203, G Loss: 19.886714935302734\n",
      "Epoch: 22, Batch: 307, D Loss: 0.09874087686710487, G Loss: 19.900344848632812\n",
      "Epoch: 22, Batch: 308, D Loss: 0.09859399601461583, G Loss: 20.07407569885254\n",
      "Epoch: 22, Batch: 309, D Loss: 0.10601802242409092, G Loss: 20.611297607421875\n",
      "Epoch: 22, Batch: 310, D Loss: 0.09597089195880071, G Loss: 20.668426513671875\n",
      "Epoch: 22, Batch: 311, D Loss: 0.09681634667556188, G Loss: 20.34540367126465\n",
      "Epoch: 22, Batch: 312, D Loss: 0.10008448445698714, G Loss: 20.0922908782959\n",
      "Epoch: 22, Batch: 313, D Loss: 0.10524052465010142, G Loss: 20.318193435668945\n",
      "Epoch: 22, Batch: 314, D Loss: 0.0908044882806921, G Loss: 20.162214279174805\n",
      "Epoch: 22, Batch: 315, D Loss: 0.09679235607311182, G Loss: 20.125823974609375\n",
      "Epoch: 22, Batch: 316, D Loss: 0.10216438850219661, G Loss: 20.369842529296875\n",
      "Epoch: 22, Batch: 317, D Loss: 0.10089490621628044, G Loss: 20.729434967041016\n",
      "Epoch: 22, Batch: 318, D Loss: 0.0966565911872419, G Loss: 20.767261505126953\n",
      "Epoch: 22, Batch: 319, D Loss: 0.09660071188136898, G Loss: 20.552522659301758\n",
      "Epoch: 22, Batch: 320, D Loss: 0.09988086732753398, G Loss: 20.464801788330078\n",
      "Epoch: 22, Batch: 321, D Loss: 0.10303743243033209, G Loss: 20.62849235534668\n",
      "Epoch: 22, Batch: 322, D Loss: 0.09763712490267934, G Loss: 20.651214599609375\n",
      "Epoch: 22, Batch: 323, D Loss: 0.0959879613101709, G Loss: 20.39874267578125\n",
      "Epoch: 22, Batch: 324, D Loss: 0.09612014966406118, G Loss: 20.202695846557617\n",
      "Epoch: 22, Batch: 325, D Loss: 0.0953728640024844, G Loss: 20.099441528320312\n",
      "Epoch: 22, Batch: 326, D Loss: 0.0931828180501808, G Loss: 20.06805419921875\n",
      "Epoch: 22, Batch: 327, D Loss: 0.09986861878162656, G Loss: 20.350568771362305\n",
      "Epoch: 22, Batch: 328, D Loss: 0.10470522991930797, G Loss: 20.991275787353516\n",
      "Epoch: 22, Batch: 329, D Loss: 0.10161381993012131, G Loss: 21.265775680541992\n",
      "Epoch: 22, Batch: 330, D Loss: 0.09144318147735275, G Loss: 20.471576690673828\n",
      "Epoch: 22, Batch: 331, D Loss: 0.1006270432154272, G Loss: 19.91374397277832\n",
      "Epoch: 22, Batch: 332, D Loss: 0.09832511965918855, G Loss: 19.731496810913086\n",
      "Epoch: 22, Batch: 333, D Loss: 0.09092705101007292, G Loss: 19.538408279418945\n",
      "Epoch: 22, Batch: 334, D Loss: 0.0959141567153361, G Loss: 19.740345001220703\n",
      "Epoch: 22, Batch: 335, D Loss: 0.09538506827705762, G Loss: 20.08894920349121\n",
      "Epoch: 22, Batch: 336, D Loss: 0.10598674477165032, G Loss: 20.928504943847656\n",
      "Epoch: 22, Batch: 337, D Loss: 0.10144396159599883, G Loss: 21.30677604675293\n",
      "Epoch: 22, Batch: 338, D Loss: 0.10381001263754092, G Loss: 21.18706512451172\n",
      "Epoch: 22, Batch: 339, D Loss: 0.10374496170926176, G Loss: 20.78706932067871\n",
      "Epoch: 22, Batch: 340, D Loss: 0.09846258227749694, G Loss: 20.188194274902344\n",
      "Epoch: 22, Batch: 341, D Loss: 0.09963148929271093, G Loss: 19.94672966003418\n",
      "Epoch: 22, Batch: 342, D Loss: 0.09813439947289182, G Loss: 20.08185386657715\n",
      "Epoch: 22, Batch: 343, D Loss: 0.08974419629005348, G Loss: 20.085330963134766\n",
      "Epoch: 22, Batch: 344, D Loss: 0.09172561859938844, G Loss: 20.073341369628906\n",
      "Epoch: 22, Batch: 345, D Loss: 0.10002484244834187, G Loss: 20.6094970703125\n",
      "Epoch: 22, Batch: 346, D Loss: 0.09761466873544014, G Loss: 21.128732681274414\n",
      "Epoch: 22, Batch: 347, D Loss: 0.09875053197677053, G Loss: 21.307273864746094\n",
      "Epoch: 22, Batch: 348, D Loss: 0.10189712075402677, G Loss: 21.311254501342773\n",
      "Epoch: 22, Batch: 349, D Loss: 0.09975570471483872, G Loss: 21.089975357055664\n",
      "Epoch: 22, Batch: 350, D Loss: 0.09948624710795348, G Loss: 20.799861907958984\n",
      "Epoch: 22, Batch: 351, D Loss: 0.10239335940612354, G Loss: 20.811735153198242\n",
      "Epoch: 22, Batch: 352, D Loss: 0.0999050368027653, G Loss: 21.00602912902832\n",
      "Epoch: 22, Batch: 353, D Loss: 0.09644244647876626, G Loss: 21.061012268066406\n",
      "Epoch: 22, Batch: 354, D Loss: 0.09469971099870422, G Loss: 20.8847713470459\n",
      "Epoch: 22, Batch: 355, D Loss: 0.10044904093897816, G Loss: 20.96895980834961\n",
      "Epoch: 22, Batch: 356, D Loss: 0.102344766583878, G Loss: 21.322471618652344\n",
      "Epoch: 22, Batch: 357, D Loss: 0.0997183399848165, G Loss: 21.5479679107666\n",
      "Epoch: 22, Batch: 358, D Loss: 0.09644045704724599, G Loss: 21.378652572631836\n",
      "Epoch: 22, Batch: 359, D Loss: 0.09715420039730635, G Loss: 20.979707717895508\n",
      "Epoch: 22, Batch: 360, D Loss: 0.11162854015170057, G Loss: 21.5128173828125\n",
      "Epoch: 22, Batch: 361, D Loss: 0.09807342311812779, G Loss: 21.667356491088867\n",
      "Epoch: 22, Batch: 362, D Loss: 0.10181579013755379, G Loss: 21.61858367919922\n",
      "Epoch: 22, Batch: 363, D Loss: 0.09598185894830766, G Loss: 21.029359817504883\n",
      "Epoch: 22, Batch: 364, D Loss: 0.10417499434403404, G Loss: 20.8160400390625\n",
      "Epoch: 22, Batch: 365, D Loss: 0.1054402891642206, G Loss: 21.150035858154297\n",
      "Epoch: 22, Batch: 366, D Loss: 0.09707466544633347, G Loss: 21.203256607055664\n",
      "Epoch: 22, Batch: 367, D Loss: 0.10435660957564238, G Loss: 21.32115364074707\n",
      "Epoch: 22, Batch: 368, D Loss: 0.10346957323825917, G Loss: 21.30784797668457\n",
      "Epoch: 22, Batch: 369, D Loss: 0.09871189330115077, G Loss: 20.9335994720459\n",
      "Epoch: 22, Batch: 370, D Loss: 0.09868963113740875, G Loss: 20.49032211303711\n",
      "Epoch: 22, Batch: 371, D Loss: 0.10452422560654406, G Loss: 20.55536651611328\n",
      "Epoch: 22, Batch: 372, D Loss: 0.09640307039471568, G Loss: 20.52647590637207\n",
      "Epoch: 22, Batch: 373, D Loss: 0.099065743974809, G Loss: 20.592361450195312\n",
      "Epoch: 22, Batch: 374, D Loss: 0.0931184000213176, G Loss: 20.373565673828125\n",
      "Epoch: 22, Batch: 375, D Loss: 0.10106149384763413, G Loss: 20.428178787231445\n",
      "Epoch: 22, Batch: 376, D Loss: 0.09109080663116853, G Loss: 20.089569091796875\n",
      "Epoch: 22, Batch: 377, D Loss: 0.09761069813712553, G Loss: 20.001985549926758\n",
      "Epoch: 22, Batch: 378, D Loss: 0.09703219777710415, G Loss: 20.1385498046875\n",
      "Epoch: 22, Batch: 379, D Loss: 0.1010978974067373, G Loss: 20.580055236816406\n",
      "Epoch: 22, Batch: 380, D Loss: 0.10609842879018327, G Loss: 21.167783737182617\n",
      "Epoch: 22, Batch: 381, D Loss: 0.09560631998147648, G Loss: 20.86890983581543\n",
      "Epoch: 22, Batch: 382, D Loss: 0.1027565753088579, G Loss: 20.374216079711914\n",
      "Epoch: 22, Batch: 383, D Loss: 0.09489383655013162, G Loss: 19.59957504272461\n",
      "Epoch: 22, Batch: 384, D Loss: 0.09837298276855255, G Loss: 19.28398323059082\n",
      "Epoch: 22, Batch: 385, D Loss: 0.09978056132348045, G Loss: 19.602487564086914\n",
      "Epoch: 22, Batch: 386, D Loss: 0.1028821106658141, G Loss: 20.262039184570312\n",
      "Epoch: 22, Batch: 387, D Loss: 0.09239720635210291, G Loss: 20.197677612304688\n",
      "Epoch: 22, Batch: 388, D Loss: 0.0969146127780739, G Loss: 19.83921241760254\n",
      "Epoch: 22, Batch: 389, D Loss: 0.0998437493322557, G Loss: 19.538000106811523\n",
      "Epoch: 22, Batch: 390, D Loss: 0.09697783176914576, G Loss: 19.31905174255371\n",
      "Epoch: 22, Batch: 391, D Loss: 0.10024844296657442, G Loss: 19.48487663269043\n",
      "Epoch: 22, Batch: 392, D Loss: 0.10573874534237937, G Loss: 20.16930389404297\n",
      "Epoch: 22, Batch: 393, D Loss: 0.09378925800850813, G Loss: 20.10663604736328\n",
      "Epoch: 22, Batch: 394, D Loss: 0.0995992582273425, G Loss: 19.752941131591797\n",
      "Epoch: 22, Batch: 395, D Loss: 0.09192013933112997, G Loss: 19.033674240112305\n",
      "Epoch: 22, Batch: 396, D Loss: 0.09188935516074181, G Loss: 18.517650604248047\n",
      "Epoch: 22, Batch: 397, D Loss: 0.09996247674776804, G Loss: 18.83972930908203\n",
      "Epoch: 22, Batch: 398, D Loss: 0.09902920044046937, G Loss: 19.645061492919922\n",
      "Epoch: 22, Batch: 399, D Loss: 0.09879797804873613, G Loss: 20.231964111328125\n",
      "Epoch: 22, Batch: 400, D Loss: 0.10279974412976733, G Loss: 20.483684539794922\n",
      "Epoch: 22, Batch: 401, D Loss: 0.09962351695426114, G Loss: 20.163219451904297\n",
      "Epoch: 22, Batch: 402, D Loss: 0.09114094230044145, G Loss: 19.1165714263916\n",
      "Epoch: 22, Batch: 403, D Loss: 0.09747177702961274, G Loss: 18.524702072143555\n",
      "Epoch: 22, Batch: 404, D Loss: 0.10375760859272232, G Loss: 18.933164596557617\n",
      "Epoch: 22, Batch: 405, D Loss: 0.09131045143459704, G Loss: 19.284423828125\n",
      "Epoch: 22, Batch: 406, D Loss: 0.09286399382412669, G Loss: 19.415864944458008\n",
      "Epoch: 22, Batch: 407, D Loss: 0.09496837299100802, G Loss: 19.366281509399414\n",
      "Epoch: 22, Batch: 408, D Loss: 0.09121164917518887, G Loss: 18.98045539855957\n",
      "Epoch: 22, Batch: 409, D Loss: 0.09987554241096386, G Loss: 18.972728729248047\n",
      "Epoch: 22, Batch: 410, D Loss: 0.0948816714867533, G Loss: 19.026447296142578\n",
      "Epoch: 22, Batch: 411, D Loss: 0.10305860112007093, G Loss: 19.448974609375\n",
      "Epoch: 22, Batch: 412, D Loss: 0.10050759618476646, G Loss: 19.733318328857422\n",
      "Epoch: 22, Batch: 413, D Loss: 0.10114140937904537, G Loss: 19.80853843688965\n",
      "Epoch: 22, Batch: 414, D Loss: 0.10492503766555883, G Loss: 19.82857322692871\n",
      "Epoch: 22, Batch: 415, D Loss: 0.09140993820976817, G Loss: 19.243165969848633\n",
      "Epoch: 22, Batch: 416, D Loss: 0.09238244886772828, G Loss: 18.69095230102539\n",
      "Epoch: 22, Batch: 417, D Loss: 0.10134095293428746, G Loss: 18.91177749633789\n",
      "Epoch: 22, Batch: 418, D Loss: 0.10341696636090614, G Loss: 19.76371192932129\n",
      "Epoch: 22, Batch: 419, D Loss: 0.09695655206348386, G Loss: 20.29120445251465\n",
      "Epoch: 22, Batch: 420, D Loss: 0.09569536228811787, G Loss: 20.23577880859375\n",
      "Epoch: 22, Batch: 421, D Loss: 0.10106863175296044, G Loss: 19.965545654296875\n",
      "Epoch: 22, Batch: 422, D Loss: 0.09767726193439885, G Loss: 19.59354591369629\n",
      "Epoch: 22, Batch: 423, D Loss: 0.09571089029034885, G Loss: 19.32065200805664\n",
      "Epoch: 22, Batch: 424, D Loss: 0.1024807932236218, G Loss: 19.643409729003906\n",
      "Epoch: 22, Batch: 425, D Loss: 0.10024709362591266, G Loss: 20.229589462280273\n",
      "Epoch: 22, Batch: 426, D Loss: 0.09824657511874291, G Loss: 20.482728958129883\n",
      "Epoch: 22, Batch: 427, D Loss: 0.09470053095193037, G Loss: 20.09308624267578\n",
      "Epoch: 22, Batch: 428, D Loss: 0.106528342715832, G Loss: 20.079904556274414\n",
      "Epoch: 22, Batch: 429, D Loss: 0.09478498360166321, G Loss: 19.8056697845459\n",
      "Epoch: 22, Batch: 430, D Loss: 0.09809138761742575, G Loss: 19.649885177612305\n",
      "Epoch: 22, Batch: 431, D Loss: 0.10125368966836445, G Loss: 19.825511932373047\n",
      "Epoch: 22, Batch: 432, D Loss: 0.1028018230826293, G Loss: 20.29816436767578\n",
      "Epoch: 22, Batch: 433, D Loss: 0.09932775864736687, G Loss: 20.486783981323242\n",
      "Epoch: 22, Batch: 434, D Loss: 0.09996189246141929, G Loss: 20.321571350097656\n",
      "Epoch: 22, Batch: 435, D Loss: 0.10212682272096507, G Loss: 20.08699607849121\n",
      "Epoch: 22, Batch: 436, D Loss: 0.10395860763788639, G Loss: 20.14197540283203\n",
      "Epoch: 22, Batch: 437, D Loss: 0.09311936904719398, G Loss: 19.765422821044922\n",
      "Epoch: 22, Batch: 438, D Loss: 0.09526278977813263, G Loss: 19.445650100708008\n",
      "Epoch: 22, Batch: 439, D Loss: 0.09952515528436756, G Loss: 19.60812759399414\n",
      "Epoch: 22, Batch: 440, D Loss: 0.1015553113018477, G Loss: 20.20753288269043\n",
      "Epoch: 22, Batch: 441, D Loss: 0.09836808662097257, G Loss: 20.548789978027344\n",
      "Epoch: 22, Batch: 442, D Loss: 0.10139555540103351, G Loss: 20.663557052612305\n",
      "Epoch: 22, Batch: 443, D Loss: 0.09472844817575071, G Loss: 20.196805953979492\n",
      "Epoch: 22, Batch: 444, D Loss: 0.09898074075413021, G Loss: 19.802656173706055\n",
      "Epoch: 22, Batch: 445, D Loss: 0.10264661274514442, G Loss: 20.029638290405273\n",
      "Epoch: 22, Batch: 446, D Loss: 0.09200927713273788, G Loss: 20.06717300415039\n",
      "Epoch: 22, Batch: 447, D Loss: 0.1016259946365089, G Loss: 20.447824478149414\n",
      "Epoch: 22, Batch: 448, D Loss: 0.09770612477809604, G Loss: 20.651769638061523\n",
      "Epoch: 22, Batch: 449, D Loss: 0.09758040365053328, G Loss: 20.56900978088379\n",
      "Epoch: 22, Batch: 450, D Loss: 0.09939567809132299, G Loss: 20.381851196289062\n",
      "Epoch: 22, Batch: 451, D Loss: 0.09238669365806301, G Loss: 19.922433853149414\n",
      "Epoch: 22, Batch: 452, D Loss: 0.10365805131323391, G Loss: 20.099924087524414\n",
      "Epoch: 22, Batch: 453, D Loss: 0.10691330646533714, G Loss: 20.797897338867188\n",
      "Epoch: 22, Batch: 454, D Loss: 0.10387705301444047, G Loss: 21.332578659057617\n",
      "Epoch: 22, Batch: 455, D Loss: 0.10219822851450816, G Loss: 21.314374923706055\n",
      "Epoch: 22, Batch: 456, D Loss: 0.09727157694139238, G Loss: 20.52925682067871\n",
      "Epoch: 22, Batch: 457, D Loss: 0.08903236804088732, G Loss: 19.263511657714844\n",
      "Epoch: 22, Batch: 458, D Loss: 0.09820491329080294, G Loss: 18.952735900878906\n",
      "Epoch: 22, Batch: 459, D Loss: 0.10129885578902109, G Loss: 19.65097427368164\n",
      "Epoch: 22, Batch: 460, D Loss: 0.10234223388141095, G Loss: 20.743757247924805\n",
      "Epoch: 22, Batch: 461, D Loss: 0.10137590053871998, G Loss: 21.494342803955078\n",
      "Epoch: 22, Batch: 462, D Loss: 0.09555640845438584, G Loss: 21.08224105834961\n",
      "Epoch: 22, Batch: 463, D Loss: 0.10139425148470371, G Loss: 20.413875579833984\n",
      "Epoch: 22, Batch: 464, D Loss: 0.09858815468941229, G Loss: 19.738012313842773\n",
      "Epoch: 22, Batch: 465, D Loss: 0.10194341977296706, G Loss: 19.66860580444336\n",
      "Epoch: 22, Batch: 466, D Loss: 0.09500856825687853, G Loss: 19.884870529174805\n",
      "Epoch: 22, Batch: 467, D Loss: 0.09612641581079473, G Loss: 20.206510543823242\n",
      "Epoch: 23, Batch: 0, D Loss: 0.09536415416548699, G Loss: 20.342878341674805\n",
      "Epoch: 23, Batch: 1, D Loss: 0.09421297988328631, G Loss: 20.160947799682617\n",
      "Epoch: 23, Batch: 2, D Loss: 0.10193799519890784, G Loss: 20.24842643737793\n",
      "Epoch: 23, Batch: 3, D Loss: 0.09474237349368414, G Loss: 20.11672592163086\n",
      "Epoch: 23, Batch: 4, D Loss: 0.08903440953698627, G Loss: 19.592504501342773\n",
      "Epoch: 23, Batch: 5, D Loss: 0.10313777765686727, G Loss: 19.783344268798828\n",
      "Epoch: 23, Batch: 6, D Loss: 0.09413080777420157, G Loss: 19.985126495361328\n",
      "Epoch: 23, Batch: 7, D Loss: 0.1001415559408178, G Loss: 20.33523941040039\n",
      "Epoch: 23, Batch: 8, D Loss: 0.09603303747540315, G Loss: 20.260820388793945\n",
      "Epoch: 23, Batch: 9, D Loss: 0.10548898651174443, G Loss: 20.40850257873535\n",
      "Epoch: 23, Batch: 10, D Loss: 0.0946304731757227, G Loss: 20.081741333007812\n",
      "Epoch: 23, Batch: 11, D Loss: 0.09292526682610691, G Loss: 19.345447540283203\n",
      "Epoch: 23, Batch: 12, D Loss: 0.10077964734159406, G Loss: 19.151897430419922\n",
      "Epoch: 23, Batch: 13, D Loss: 0.09746730541796289, G Loss: 19.374290466308594\n",
      "Epoch: 23, Batch: 14, D Loss: 0.09479911050781087, G Loss: 19.604745864868164\n",
      "Epoch: 23, Batch: 15, D Loss: 0.0972015275400463, G Loss: 19.808195114135742\n",
      "Epoch: 23, Batch: 16, D Loss: 0.0979364675054063, G Loss: 19.933269500732422\n",
      "Epoch: 23, Batch: 17, D Loss: 0.09663614753414163, G Loss: 19.72867202758789\n",
      "Epoch: 23, Batch: 18, D Loss: 0.10729968661300016, G Loss: 20.06127166748047\n",
      "Epoch: 23, Batch: 19, D Loss: 0.09794916313680191, G Loss: 19.981201171875\n",
      "Epoch: 23, Batch: 20, D Loss: 0.09575432680988283, G Loss: 19.407732009887695\n",
      "Epoch: 23, Batch: 21, D Loss: 0.0937306610627675, G Loss: 18.64893913269043\n",
      "Epoch: 23, Batch: 22, D Loss: 0.1017644370496642, G Loss: 18.657806396484375\n",
      "Epoch: 23, Batch: 23, D Loss: 0.10803833843745503, G Loss: 19.59483528137207\n",
      "Epoch: 23, Batch: 24, D Loss: 0.10012904671141498, G Loss: 20.1307430267334\n",
      "Epoch: 23, Batch: 25, D Loss: 0.09437116356985076, G Loss: 19.569480895996094\n",
      "Epoch: 23, Batch: 26, D Loss: 0.10133064027028404, G Loss: 18.830350875854492\n",
      "Epoch: 23, Batch: 27, D Loss: 0.09832230664263886, G Loss: 18.237592697143555\n",
      "Epoch: 23, Batch: 28, D Loss: 0.10254853036779643, G Loss: 18.361976623535156\n",
      "Epoch: 23, Batch: 29, D Loss: 0.09921739690908016, G Loss: 18.714664459228516\n",
      "Epoch: 23, Batch: 30, D Loss: 0.09831668009139971, G Loss: 19.018720626831055\n",
      "Epoch: 23, Batch: 31, D Loss: 0.10032726340307696, G Loss: 19.11779022216797\n",
      "Epoch: 23, Batch: 32, D Loss: 0.09543244859979194, G Loss: 18.646053314208984\n",
      "Epoch: 23, Batch: 33, D Loss: 0.09995086231569372, G Loss: 18.274188995361328\n",
      "Epoch: 23, Batch: 34, D Loss: 0.09338930991407857, G Loss: 17.803993225097656\n",
      "Epoch: 23, Batch: 35, D Loss: 0.10160061798112796, G Loss: 18.024173736572266\n",
      "Epoch: 23, Batch: 36, D Loss: 0.10163333093325466, G Loss: 18.526779174804688\n",
      "Epoch: 23, Batch: 37, D Loss: 0.09287459088149097, G Loss: 18.613489151000977\n",
      "Epoch: 23, Batch: 38, D Loss: 0.09980598506196925, G Loss: 18.606531143188477\n",
      "Epoch: 23, Batch: 39, D Loss: 0.0977373466325755, G Loss: 18.449281692504883\n",
      "Epoch: 23, Batch: 40, D Loss: 0.0978703627277806, G Loss: 18.25286865234375\n",
      "Epoch: 23, Batch: 41, D Loss: 0.10144097171121702, G Loss: 18.36431121826172\n",
      "Epoch: 23, Batch: 42, D Loss: 0.0970171741485566, G Loss: 18.417015075683594\n",
      "Epoch: 23, Batch: 43, D Loss: 0.09947576089640853, G Loss: 18.580217361450195\n",
      "Epoch: 23, Batch: 44, D Loss: 0.09918047151931786, G Loss: 18.658958435058594\n",
      "Epoch: 23, Batch: 45, D Loss: 0.09362391841284978, G Loss: 18.370729446411133\n",
      "Epoch: 23, Batch: 46, D Loss: 0.09454046839976504, G Loss: 17.96924591064453\n",
      "Epoch: 23, Batch: 47, D Loss: 0.1003608110980645, G Loss: 17.986509323120117\n",
      "Epoch: 23, Batch: 48, D Loss: 0.09956120609226149, G Loss: 18.302217483520508\n",
      "Epoch: 23, Batch: 49, D Loss: 0.09730770205117212, G Loss: 18.486494064331055\n",
      "Epoch: 23, Batch: 50, D Loss: 0.09427011539388364, G Loss: 18.265399932861328\n",
      "Epoch: 23, Batch: 51, D Loss: 0.10124283878908313, G Loss: 18.23194122314453\n",
      "Epoch: 23, Batch: 52, D Loss: 0.10295968280251033, G Loss: 18.508548736572266\n",
      "Epoch: 23, Batch: 53, D Loss: 0.09431377543482267, G Loss: 18.380643844604492\n",
      "Epoch: 23, Batch: 54, D Loss: 0.09711396533356664, G Loss: 18.163103103637695\n",
      "Epoch: 23, Batch: 55, D Loss: 0.10337043381488042, G Loss: 18.396005630493164\n",
      "Epoch: 23, Batch: 56, D Loss: 0.09269932471071529, G Loss: 18.23409652709961\n",
      "Epoch: 23, Batch: 57, D Loss: 0.09813111126193208, G Loss: 18.257450103759766\n",
      "Epoch: 23, Batch: 58, D Loss: 0.09468570952143196, G Loss: 18.221403121948242\n",
      "Epoch: 23, Batch: 59, D Loss: 0.10005280925104065, G Loss: 18.42249870300293\n",
      "Epoch: 23, Batch: 60, D Loss: 0.09958372696244089, G Loss: 18.70181655883789\n",
      "Epoch: 23, Batch: 61, D Loss: 0.09848624822101937, G Loss: 18.82354164123535\n",
      "Epoch: 23, Batch: 62, D Loss: 0.10289909999237024, G Loss: 18.97589874267578\n",
      "Epoch: 23, Batch: 63, D Loss: 0.09197928359275243, G Loss: 18.6107120513916\n",
      "Epoch: 23, Batch: 64, D Loss: 0.09923339333417047, G Loss: 18.479637145996094\n",
      "Epoch: 23, Batch: 65, D Loss: 0.09307590627984919, G Loss: 18.365650177001953\n",
      "Epoch: 23, Batch: 66, D Loss: 0.10001496665749388, G Loss: 18.71475601196289\n",
      "Epoch: 23, Batch: 67, D Loss: 0.10096355058505835, G Loss: 19.28561782836914\n",
      "Epoch: 23, Batch: 68, D Loss: 0.09975154876207804, G Loss: 19.603532791137695\n",
      "Epoch: 23, Batch: 69, D Loss: 0.09154414580534831, G Loss: 19.148521423339844\n",
      "Epoch: 23, Batch: 70, D Loss: 0.09987296448727778, G Loss: 18.836206436157227\n",
      "Epoch: 23, Batch: 71, D Loss: 0.09854117376899807, G Loss: 18.77484130859375\n",
      "Epoch: 23, Batch: 72, D Loss: 0.10231481777046891, G Loss: 19.173730850219727\n",
      "Epoch: 23, Batch: 73, D Loss: 0.10261841294338958, G Loss: 19.7303524017334\n",
      "Epoch: 23, Batch: 74, D Loss: 0.09588432451049067, G Loss: 19.674161911010742\n",
      "Epoch: 23, Batch: 75, D Loss: 0.09579435174950646, G Loss: 19.192657470703125\n",
      "Epoch: 23, Batch: 76, D Loss: 0.09445131138174068, G Loss: 18.614892959594727\n",
      "Epoch: 23, Batch: 77, D Loss: 0.10271987704493935, G Loss: 18.741270065307617\n",
      "Epoch: 23, Batch: 78, D Loss: 0.10154634237275117, G Loss: 19.315547943115234\n",
      "Epoch: 23, Batch: 79, D Loss: 0.10038656906599364, G Loss: 19.716659545898438\n",
      "Epoch: 23, Batch: 80, D Loss: 0.09719945642723105, G Loss: 19.511699676513672\n",
      "Epoch: 23, Batch: 81, D Loss: 0.10738185212102869, G Loss: 19.555194854736328\n",
      "Epoch: 23, Batch: 82, D Loss: 0.09754826326452393, G Loss: 19.158824920654297\n",
      "Epoch: 23, Batch: 83, D Loss: 0.0977786809797907, G Loss: 18.701725006103516\n",
      "Epoch: 23, Batch: 84, D Loss: 0.10299119712173188, G Loss: 18.79824447631836\n",
      "Epoch: 23, Batch: 85, D Loss: 0.10379894354485009, G Loss: 19.203022003173828\n",
      "Epoch: 23, Batch: 86, D Loss: 0.09861536540562255, G Loss: 19.305389404296875\n",
      "Epoch: 23, Batch: 87, D Loss: 0.10550923099603904, G Loss: 19.373334884643555\n",
      "Epoch: 23, Batch: 88, D Loss: 0.09902385106594869, G Loss: 19.043752670288086\n",
      "Epoch: 23, Batch: 89, D Loss: 0.10087059024374079, G Loss: 18.643085479736328\n",
      "Epoch: 23, Batch: 90, D Loss: 0.09994341159052267, G Loss: 18.336408615112305\n",
      "Epoch: 23, Batch: 91, D Loss: 0.10434745003544776, G Loss: 18.512338638305664\n",
      "Epoch: 23, Batch: 92, D Loss: 0.09535418172151777, G Loss: 18.472021102905273\n",
      "Epoch: 23, Batch: 93, D Loss: 0.09154277128744104, G Loss: 18.097993850708008\n",
      "Epoch: 23, Batch: 94, D Loss: 0.10027178345363863, G Loss: 18.0378475189209\n",
      "Epoch: 23, Batch: 95, D Loss: 0.10492325425815707, G Loss: 18.43111801147461\n",
      "Epoch: 23, Batch: 96, D Loss: 0.0970141337236341, G Loss: 18.586977005004883\n",
      "Epoch: 23, Batch: 97, D Loss: 0.09490111953969027, G Loss: 18.335689544677734\n",
      "Epoch: 23, Batch: 98, D Loss: 0.10066456189772754, G Loss: 18.194028854370117\n",
      "Epoch: 23, Batch: 99, D Loss: 0.09771302993427833, G Loss: 18.125335693359375\n",
      "Epoch: 23, Batch: 100, D Loss: 0.0908596146640539, G Loss: 17.84330177307129\n",
      "Epoch: 23, Batch: 101, D Loss: 0.0993997687357151, G Loss: 17.964143753051758\n",
      "Epoch: 23, Batch: 102, D Loss: 0.10071586686972189, G Loss: 18.441471099853516\n",
      "Epoch: 23, Batch: 103, D Loss: 0.09755319753986003, G Loss: 18.841121673583984\n",
      "Epoch: 23, Batch: 104, D Loss: 0.09887470609104754, G Loss: 18.987873077392578\n",
      "Epoch: 23, Batch: 105, D Loss: 0.10928663105721315, G Loss: 19.310287475585938\n",
      "Epoch: 23, Batch: 106, D Loss: 0.10494400753974809, G Loss: 19.428186416625977\n",
      "Epoch: 23, Batch: 107, D Loss: 0.1029934978351843, G Loss: 19.18731117248535\n",
      "Epoch: 23, Batch: 108, D Loss: 0.09778911172761418, G Loss: 18.71739959716797\n",
      "Epoch: 23, Batch: 109, D Loss: 0.09893494532806901, G Loss: 18.426895141601562\n",
      "Epoch: 23, Batch: 110, D Loss: 0.10396007142212937, G Loss: 18.66463279724121\n",
      "Epoch: 23, Batch: 111, D Loss: 0.10492734897702705, G Loss: 19.25774383544922\n",
      "Epoch: 23, Batch: 112, D Loss: 0.09950399589781989, G Loss: 19.49641990661621\n",
      "Epoch: 23, Batch: 113, D Loss: 0.10560062694719818, G Loss: 19.535911560058594\n",
      "Epoch: 23, Batch: 114, D Loss: 0.09693201115377592, G Loss: 18.898902893066406\n",
      "Epoch: 23, Batch: 115, D Loss: 0.09779413497275957, G Loss: 18.1809024810791\n",
      "Epoch: 23, Batch: 116, D Loss: 0.09924746280497354, G Loss: 17.943767547607422\n",
      "Epoch: 23, Batch: 117, D Loss: 0.09556391113372165, G Loss: 18.03630256652832\n",
      "Epoch: 23, Batch: 118, D Loss: 0.10407012505692137, G Loss: 18.588193893432617\n",
      "Epoch: 23, Batch: 119, D Loss: 0.09489503887448159, G Loss: 18.769590377807617\n",
      "Epoch: 23, Batch: 120, D Loss: 0.09512382430240862, G Loss: 18.39685821533203\n",
      "Epoch: 23, Batch: 121, D Loss: 0.100672228773099, G Loss: 18.0665283203125\n",
      "Epoch: 23, Batch: 122, D Loss: 0.10170923138110455, G Loss: 18.07630729675293\n",
      "Epoch: 23, Batch: 123, D Loss: 0.09606404568633353, G Loss: 18.063661575317383\n",
      "Epoch: 23, Batch: 124, D Loss: 0.10188431172956713, G Loss: 18.319801330566406\n",
      "Epoch: 23, Batch: 125, D Loss: 0.09721123210006333, G Loss: 18.410079956054688\n",
      "Epoch: 23, Batch: 126, D Loss: 0.10167526170552321, G Loss: 18.582448959350586\n",
      "Epoch: 23, Batch: 127, D Loss: 0.10279797385547873, G Loss: 18.85883903503418\n",
      "Epoch: 23, Batch: 128, D Loss: 0.09733911196241474, G Loss: 18.773548126220703\n",
      "Epoch: 23, Batch: 129, D Loss: 0.09479187854134974, G Loss: 18.41256332397461\n",
      "Epoch: 23, Batch: 130, D Loss: 0.10134776453651284, G Loss: 18.36606216430664\n",
      "Epoch: 23, Batch: 131, D Loss: 0.09825178726089856, G Loss: 18.511594772338867\n",
      "Epoch: 23, Batch: 132, D Loss: 0.09445537337971333, G Loss: 18.514259338378906\n",
      "Epoch: 23, Batch: 133, D Loss: 0.10388192904002835, G Loss: 18.912954330444336\n",
      "Epoch: 23, Batch: 134, D Loss: 0.09914279255618608, G Loss: 19.138412475585938\n",
      "Epoch: 23, Batch: 135, D Loss: 0.09969001511827358, G Loss: 19.10442543029785\n",
      "Epoch: 23, Batch: 136, D Loss: 0.09691424217201217, G Loss: 18.812179565429688\n",
      "Epoch: 23, Batch: 137, D Loss: 0.09775449731903496, G Loss: 18.51113510131836\n",
      "Epoch: 23, Batch: 138, D Loss: 0.10350391671258397, G Loss: 18.75257110595703\n",
      "Epoch: 23, Batch: 139, D Loss: 0.0992577776519068, G Loss: 19.09292221069336\n",
      "Epoch: 23, Batch: 140, D Loss: 0.09950317672096509, G Loss: 19.294490814208984\n",
      "Epoch: 23, Batch: 141, D Loss: 0.0974134304100569, G Loss: 19.125\n",
      "Epoch: 23, Batch: 142, D Loss: 0.10195015634784932, G Loss: 19.00155258178711\n",
      "Epoch: 23, Batch: 143, D Loss: 0.1029703940878175, G Loss: 19.158946990966797\n",
      "Epoch: 23, Batch: 144, D Loss: 0.10101039925531041, G Loss: 19.33534049987793\n",
      "Epoch: 23, Batch: 145, D Loss: 0.09703133472023517, G Loss: 19.18600845336914\n",
      "Epoch: 23, Batch: 146, D Loss: 0.09750692811808737, G Loss: 18.935688018798828\n",
      "Epoch: 23, Batch: 147, D Loss: 0.09950749877205967, G Loss: 18.9217472076416\n",
      "Epoch: 23, Batch: 148, D Loss: 0.10348747915304757, G Loss: 19.32828712463379\n",
      "Epoch: 23, Batch: 149, D Loss: 0.09844656469739743, G Loss: 19.53291893005371\n",
      "Epoch: 23, Batch: 150, D Loss: 0.10082822458262752, G Loss: 19.524139404296875\n",
      "Epoch: 23, Batch: 151, D Loss: 0.1048039661092035, G Loss: 19.57699966430664\n",
      "Epoch: 23, Batch: 152, D Loss: 0.09988166571994572, G Loss: 19.31954002380371\n",
      "Epoch: 23, Batch: 153, D Loss: 0.09661092122517911, G Loss: 18.866008758544922\n",
      "Epoch: 23, Batch: 154, D Loss: 0.09612387818421597, G Loss: 18.447101593017578\n",
      "Epoch: 23, Batch: 155, D Loss: 0.10358310904529411, G Loss: 18.75876808166504\n",
      "Epoch: 23, Batch: 156, D Loss: 0.09980137934809274, G Loss: 19.161518096923828\n",
      "Epoch: 23, Batch: 157, D Loss: 0.10239035076073633, G Loss: 19.642478942871094\n",
      "Epoch: 23, Batch: 158, D Loss: 0.09952917837474506, G Loss: 19.70750617980957\n",
      "Epoch: 23, Batch: 159, D Loss: 0.09686891906725681, G Loss: 19.288375854492188\n",
      "Epoch: 23, Batch: 160, D Loss: 0.09725491969071176, G Loss: 18.835514068603516\n",
      "Epoch: 23, Batch: 161, D Loss: 0.10580616731283987, G Loss: 19.103635787963867\n",
      "Epoch: 23, Batch: 162, D Loss: 0.1001894941225625, G Loss: 19.530702590942383\n",
      "Epoch: 23, Batch: 163, D Loss: 0.10362979901058966, G Loss: 19.96138572692871\n",
      "Epoch: 23, Batch: 164, D Loss: 0.09019461417232555, G Loss: 19.410804748535156\n",
      "Epoch: 23, Batch: 165, D Loss: 0.09453959294452297, G Loss: 18.65576934814453\n",
      "Epoch: 23, Batch: 166, D Loss: 0.10210693275042404, G Loss: 18.670425415039062\n",
      "Epoch: 23, Batch: 167, D Loss: 0.10054242904714261, G Loss: 19.20796012878418\n",
      "Epoch: 23, Batch: 168, D Loss: 0.0969676691057787, G Loss: 19.689638137817383\n",
      "Epoch: 23, Batch: 169, D Loss: 0.0971601842570774, G Loss: 19.747488021850586\n",
      "Epoch: 23, Batch: 170, D Loss: 0.10168683674904933, G Loss: 19.565811157226562\n",
      "Epoch: 23, Batch: 171, D Loss: 0.09666586875724659, G Loss: 19.051177978515625\n",
      "Epoch: 23, Batch: 172, D Loss: 0.09771868180090149, G Loss: 18.595733642578125\n",
      "Epoch: 23, Batch: 173, D Loss: 0.10103000350015323, G Loss: 18.71434211730957\n",
      "Epoch: 23, Batch: 174, D Loss: 0.09877476400593266, G Loss: 19.100521087646484\n",
      "Epoch: 23, Batch: 175, D Loss: 0.09070389987029959, G Loss: 18.98603057861328\n",
      "Epoch: 23, Batch: 176, D Loss: 0.11163984432241714, G Loss: 19.71645736694336\n",
      "Epoch: 23, Batch: 177, D Loss: 0.09922257187204175, G Loss: 19.943769454956055\n",
      "Epoch: 23, Batch: 178, D Loss: 0.10573475170506574, G Loss: 19.967973709106445\n",
      "Epoch: 23, Batch: 179, D Loss: 0.09623547798827459, G Loss: 19.247425079345703\n",
      "Epoch: 23, Batch: 180, D Loss: 0.10422158520455382, G Loss: 18.784385681152344\n",
      "Epoch: 23, Batch: 181, D Loss: 0.0951337114613664, G Loss: 18.28087615966797\n",
      "Epoch: 23, Batch: 182, D Loss: 0.1003747342223309, G Loss: 18.27277946472168\n",
      "Epoch: 23, Batch: 183, D Loss: 0.0953708120672716, G Loss: 18.44026756286621\n",
      "Epoch: 23, Batch: 184, D Loss: 0.09797780629359032, G Loss: 18.764678955078125\n",
      "Epoch: 23, Batch: 185, D Loss: 0.0973176692073543, G Loss: 18.849529266357422\n",
      "Epoch: 23, Batch: 186, D Loss: 0.0963962936067495, G Loss: 18.53760528564453\n",
      "Epoch: 23, Batch: 187, D Loss: 0.09456929377836154, G Loss: 18.107681274414062\n",
      "Epoch: 23, Batch: 188, D Loss: 0.10449579953308907, G Loss: 18.373388290405273\n",
      "Epoch: 23, Batch: 189, D Loss: 0.09268951210098342, G Loss: 18.321996688842773\n",
      "Epoch: 23, Batch: 190, D Loss: 0.09489861000894306, G Loss: 18.11754608154297\n",
      "Epoch: 23, Batch: 191, D Loss: 0.09812112850573262, G Loss: 18.062129974365234\n",
      "Epoch: 23, Batch: 192, D Loss: 0.100105128210771, G Loss: 18.253217697143555\n",
      "Epoch: 23, Batch: 193, D Loss: 0.10516605216611774, G Loss: 18.83540153503418\n",
      "Epoch: 23, Batch: 194, D Loss: 0.09525603416698125, G Loss: 18.669334411621094\n",
      "Epoch: 23, Batch: 195, D Loss: 0.1017503038498222, G Loss: 18.391983032226562\n",
      "Epoch: 23, Batch: 196, D Loss: 0.10573162634788558, G Loss: 18.46230125427246\n",
      "Epoch: 23, Batch: 197, D Loss: 0.09833793129245683, G Loss: 18.266590118408203\n",
      "Epoch: 23, Batch: 198, D Loss: 0.09094817286878865, G Loss: 17.574092864990234\n",
      "Epoch: 23, Batch: 199, D Loss: 0.09780570678195666, G Loss: 17.366371154785156\n",
      "Epoch: 23, Batch: 200, D Loss: 0.09596819950745505, G Loss: 17.61018943786621\n",
      "Epoch: 23, Batch: 201, D Loss: 0.10286304307806171, G Loss: 18.51738929748535\n",
      "Epoch: 23, Batch: 202, D Loss: 0.09823911227885262, G Loss: 19.091623306274414\n",
      "Epoch: 23, Batch: 203, D Loss: 0.10219267253447017, G Loss: 19.190149307250977\n",
      "Epoch: 23, Batch: 204, D Loss: 0.10399070647355368, G Loss: 18.933107376098633\n",
      "Epoch: 23, Batch: 205, D Loss: 0.09546626063016861, G Loss: 18.188447952270508\n",
      "Epoch: 23, Batch: 206, D Loss: 0.08965164009749049, G Loss: 17.172718048095703\n",
      "Epoch: 23, Batch: 207, D Loss: 0.10193840566804901, G Loss: 17.2899169921875\n",
      "Epoch: 23, Batch: 208, D Loss: 0.09727867272834789, G Loss: 17.99515151977539\n",
      "Epoch: 23, Batch: 209, D Loss: 0.10369134376823474, G Loss: 19.10114860534668\n",
      "Epoch: 23, Batch: 210, D Loss: 0.10133827659802264, G Loss: 19.72586441040039\n",
      "Epoch: 23, Batch: 211, D Loss: 0.10669109351469086, G Loss: 19.862390518188477\n",
      "Epoch: 23, Batch: 212, D Loss: 0.10210869620602969, G Loss: 19.294593811035156\n",
      "Epoch: 23, Batch: 213, D Loss: 0.09988266544473645, G Loss: 18.513113021850586\n",
      "Epoch: 23, Batch: 214, D Loss: 0.09695927681286198, G Loss: 17.906692504882812\n",
      "Epoch: 23, Batch: 215, D Loss: 0.09242756126146734, G Loss: 17.66399574279785\n",
      "Epoch: 23, Batch: 216, D Loss: 0.10524690846901441, G Loss: 18.474756240844727\n",
      "Epoch: 23, Batch: 217, D Loss: 0.09707683641691256, G Loss: 19.238935470581055\n",
      "Epoch: 23, Batch: 218, D Loss: 0.09669451602562273, G Loss: 19.550676345825195\n",
      "Epoch: 23, Batch: 219, D Loss: 0.10476840433391899, G Loss: 19.743854522705078\n",
      "Epoch: 23, Batch: 220, D Loss: 0.09486302158526061, G Loss: 19.275737762451172\n",
      "Epoch: 23, Batch: 221, D Loss: 0.09686382405552196, G Loss: 18.681514739990234\n",
      "Epoch: 23, Batch: 222, D Loss: 0.10100001484653509, G Loss: 18.669492721557617\n",
      "Epoch: 23, Batch: 223, D Loss: 0.10053552995492421, G Loss: 19.116147994995117\n",
      "Epoch: 23, Batch: 224, D Loss: 0.096504563650881, G Loss: 19.49106216430664\n",
      "Epoch: 23, Batch: 225, D Loss: 0.10241871470975095, G Loss: 19.82369041442871\n",
      "Epoch: 23, Batch: 226, D Loss: 0.10021185998958482, G Loss: 19.80732536315918\n",
      "Epoch: 23, Batch: 227, D Loss: 0.10314327613844587, G Loss: 19.654747009277344\n",
      "Epoch: 23, Batch: 228, D Loss: 0.09966722305250197, G Loss: 19.309860229492188\n",
      "Epoch: 23, Batch: 229, D Loss: 0.10082438809953387, G Loss: 19.16581916809082\n",
      "Epoch: 23, Batch: 230, D Loss: 0.10054727128158625, G Loss: 19.230579376220703\n",
      "Epoch: 23, Batch: 231, D Loss: 0.09338698042415094, G Loss: 18.999509811401367\n",
      "Epoch: 23, Batch: 232, D Loss: 0.10267428553522473, G Loss: 19.257436752319336\n",
      "Epoch: 23, Batch: 233, D Loss: 0.09943268639820779, G Loss: 19.489694595336914\n",
      "Epoch: 23, Batch: 234, D Loss: 0.10204968006435311, G Loss: 19.74387550354004\n",
      "Epoch: 23, Batch: 235, D Loss: 0.09566038257442255, G Loss: 19.44814109802246\n",
      "Epoch: 23, Batch: 236, D Loss: 0.09875098839899832, G Loss: 19.0230655670166\n",
      "Epoch: 23, Batch: 237, D Loss: 0.09723940821847354, G Loss: 18.667747497558594\n",
      "Epoch: 23, Batch: 238, D Loss: 0.09803110739766385, G Loss: 18.727888107299805\n",
      "Epoch: 23, Batch: 239, D Loss: 0.09537528037487442, G Loss: 18.95060157775879\n",
      "Epoch: 23, Batch: 240, D Loss: 0.10331118314422394, G Loss: 19.615631103515625\n",
      "Epoch: 23, Batch: 241, D Loss: 0.10626164178276032, G Loss: 20.408872604370117\n",
      "Epoch: 23, Batch: 242, D Loss: 0.09819762478673877, G Loss: 20.36876106262207\n",
      "Epoch: 23, Batch: 243, D Loss: 0.10002181027772572, G Loss: 19.843517303466797\n",
      "Epoch: 23, Batch: 244, D Loss: 0.10225152372085067, G Loss: 19.454612731933594\n",
      "Epoch: 23, Batch: 245, D Loss: 0.09186515449419574, G Loss: 18.905559539794922\n",
      "Epoch: 23, Batch: 246, D Loss: 0.09579707994863562, G Loss: 18.877046585083008\n",
      "Epoch: 23, Batch: 247, D Loss: 0.09590676694736233, G Loss: 19.19692611694336\n",
      "Epoch: 23, Batch: 248, D Loss: 0.09523011926636471, G Loss: 19.63681983947754\n",
      "Epoch: 23, Batch: 249, D Loss: 0.09885726985104304, G Loss: 20.100385665893555\n",
      "Epoch: 23, Batch: 250, D Loss: 0.09577228960742118, G Loss: 20.23652458190918\n",
      "Epoch: 23, Batch: 251, D Loss: 0.1031599350471859, G Loss: 20.353923797607422\n",
      "Epoch: 23, Batch: 252, D Loss: 0.1017159379727754, G Loss: 20.373804092407227\n",
      "Epoch: 23, Batch: 253, D Loss: 0.10303013843873748, G Loss: 20.342145919799805\n",
      "Epoch: 23, Batch: 254, D Loss: 0.09847848198489517, G Loss: 20.14652442932129\n",
      "Epoch: 23, Batch: 255, D Loss: 0.10643251320218716, G Loss: 20.350414276123047\n",
      "Epoch: 23, Batch: 256, D Loss: 0.10076101189992309, G Loss: 20.540042877197266\n",
      "Epoch: 23, Batch: 257, D Loss: 0.09647843307889731, G Loss: 20.355010986328125\n",
      "Epoch: 23, Batch: 258, D Loss: 0.10531384563736906, G Loss: 20.531564712524414\n",
      "Epoch: 23, Batch: 259, D Loss: 0.10411737166151858, G Loss: 20.820959091186523\n",
      "Epoch: 23, Batch: 260, D Loss: 0.10409145844271703, G Loss: 20.966176986694336\n",
      "Epoch: 23, Batch: 261, D Loss: 0.10435996988941179, G Loss: 20.96383285522461\n",
      "Epoch: 23, Batch: 262, D Loss: 0.10335128052671044, G Loss: 20.777740478515625\n",
      "Epoch: 23, Batch: 263, D Loss: 0.0991933500600416, G Loss: 20.391874313354492\n",
      "Epoch: 23, Batch: 264, D Loss: 0.10033760294289529, G Loss: 20.26458168029785\n",
      "Epoch: 23, Batch: 265, D Loss: 0.0995729796777966, G Loss: 20.3308162689209\n",
      "Epoch: 23, Batch: 266, D Loss: 0.1099161212936634, G Loss: 20.975818634033203\n",
      "Epoch: 23, Batch: 267, D Loss: 0.09907364133611041, G Loss: 21.262989044189453\n",
      "Epoch: 23, Batch: 268, D Loss: 0.1033338087714536, G Loss: 21.274168014526367\n",
      "Epoch: 23, Batch: 269, D Loss: 0.09739400483070224, G Loss: 20.816415786743164\n",
      "Epoch: 23, Batch: 270, D Loss: 0.0957251942209213, G Loss: 20.284841537475586\n",
      "Epoch: 23, Batch: 271, D Loss: 0.09634634936505748, G Loss: 20.129404067993164\n",
      "Epoch: 23, Batch: 272, D Loss: 0.10019505095975056, G Loss: 20.562232971191406\n",
      "Epoch: 23, Batch: 273, D Loss: 0.09502129303715373, G Loss: 20.985824584960938\n",
      "Epoch: 23, Batch: 274, D Loss: 0.09763439032853208, G Loss: 21.26482391357422\n",
      "Epoch: 23, Batch: 275, D Loss: 0.10634762073195364, G Loss: 21.5928955078125\n",
      "Epoch: 23, Batch: 276, D Loss: 0.09846779726391755, G Loss: 21.474918365478516\n",
      "Epoch: 23, Batch: 277, D Loss: 0.09837113350684223, G Loss: 21.02545166015625\n",
      "Epoch: 23, Batch: 278, D Loss: 0.10183577281882952, G Loss: 20.765804290771484\n",
      "Epoch: 23, Batch: 279, D Loss: 0.09803326477748991, G Loss: 20.692304611206055\n",
      "Epoch: 23, Batch: 280, D Loss: 0.10103733883803906, G Loss: 20.901208877563477\n",
      "Epoch: 23, Batch: 281, D Loss: 0.10097774899782924, G Loss: 21.15884780883789\n",
      "Epoch: 23, Batch: 282, D Loss: 0.10170630394390895, G Loss: 21.38054847717285\n",
      "Epoch: 23, Batch: 283, D Loss: 0.10258143421039065, G Loss: 21.385013580322266\n",
      "Epoch: 23, Batch: 284, D Loss: 0.09896636039062912, G Loss: 21.107568740844727\n",
      "Epoch: 23, Batch: 285, D Loss: 0.09812710474741282, G Loss: 20.775232315063477\n",
      "Epoch: 23, Batch: 286, D Loss: 0.10057120074723008, G Loss: 20.693241119384766\n",
      "Epoch: 23, Batch: 287, D Loss: 0.10265682681964344, G Loss: 20.981163024902344\n",
      "Epoch: 23, Batch: 288, D Loss: 0.09934149716807239, G Loss: 21.207670211791992\n",
      "Epoch: 23, Batch: 289, D Loss: 0.10138373852685778, G Loss: 21.213327407836914\n",
      "Epoch: 23, Batch: 290, D Loss: 0.10389556022491506, G Loss: 21.142396926879883\n",
      "Epoch: 23, Batch: 291, D Loss: 0.09397406921406651, G Loss: 20.53145408630371\n",
      "Epoch: 23, Batch: 292, D Loss: 0.101455964885944, G Loss: 20.156293869018555\n",
      "Epoch: 23, Batch: 293, D Loss: 0.0944735268947402, G Loss: 19.891481399536133\n",
      "Epoch: 23, Batch: 294, D Loss: 0.09641865009570039, G Loss: 19.910554885864258\n",
      "Epoch: 23, Batch: 295, D Loss: 0.09492103118810635, G Loss: 19.98484230041504\n",
      "Epoch: 23, Batch: 296, D Loss: 0.10051085144493127, G Loss: 20.27894401550293\n",
      "Epoch: 23, Batch: 297, D Loss: 0.0982004485963131, G Loss: 20.3812255859375\n",
      "Epoch: 23, Batch: 298, D Loss: 0.10071282160244588, G Loss: 20.352096557617188\n",
      "Epoch: 23, Batch: 299, D Loss: 0.09830328905859564, G Loss: 20.077905654907227\n",
      "Epoch: 23, Batch: 300, D Loss: 0.10010487692297487, G Loss: 19.87598419189453\n",
      "Epoch: 23, Batch: 301, D Loss: 0.09426495570471083, G Loss: 19.562746047973633\n",
      "Epoch: 23, Batch: 302, D Loss: 0.09647420213439284, G Loss: 19.503093719482422\n",
      "Epoch: 23, Batch: 303, D Loss: 0.10206140712684664, G Loss: 19.936046600341797\n",
      "Epoch: 23, Batch: 304, D Loss: 0.10156431133854604, G Loss: 20.428617477416992\n",
      "Epoch: 23, Batch: 305, D Loss: 0.09933495585005925, G Loss: 20.535690307617188\n",
      "Epoch: 23, Batch: 306, D Loss: 0.09787403120041643, G Loss: 20.1739501953125\n",
      "Epoch: 23, Batch: 307, D Loss: 0.10273181008169785, G Loss: 19.78701400756836\n",
      "Epoch: 23, Batch: 308, D Loss: 0.09674091800577, G Loss: 19.316537857055664\n",
      "Epoch: 23, Batch: 309, D Loss: 0.10073228384967536, G Loss: 19.313352584838867\n",
      "Epoch: 23, Batch: 310, D Loss: 0.09595272147342215, G Loss: 19.33672332763672\n",
      "Epoch: 23, Batch: 311, D Loss: 0.09153697116681014, G Loss: 19.139095306396484\n",
      "Epoch: 23, Batch: 312, D Loss: 0.0952085580003077, G Loss: 19.06163787841797\n",
      "Epoch: 23, Batch: 313, D Loss: 0.10010236733584565, G Loss: 19.303987503051758\n",
      "Epoch: 23, Batch: 314, D Loss: 0.10166509619424857, G Loss: 19.67705535888672\n",
      "Epoch: 23, Batch: 315, D Loss: 0.10351790611444445, G Loss: 19.944164276123047\n",
      "Epoch: 23, Batch: 316, D Loss: 0.0957382036621216, G Loss: 19.567276000976562\n",
      "Epoch: 23, Batch: 317, D Loss: 0.1001669188731722, G Loss: 19.10563850402832\n",
      "Epoch: 23, Batch: 318, D Loss: 0.10101145777688147, G Loss: 18.96344566345215\n",
      "Epoch: 23, Batch: 319, D Loss: 0.09908134769447208, G Loss: 19.040401458740234\n",
      "Epoch: 23, Batch: 320, D Loss: 0.09747510649943836, G Loss: 19.207244873046875\n",
      "Epoch: 23, Batch: 321, D Loss: 0.10067977211162216, G Loss: 19.454875946044922\n",
      "Epoch: 23, Batch: 322, D Loss: 0.09936099665174103, G Loss: 19.588829040527344\n",
      "Epoch: 23, Batch: 323, D Loss: 0.0979511009159939, G Loss: 19.488544464111328\n",
      "Epoch: 23, Batch: 324, D Loss: 0.09850980531664222, G Loss: 19.296245574951172\n",
      "Epoch: 23, Batch: 325, D Loss: 0.09840724841855564, G Loss: 19.153892517089844\n",
      "Epoch: 23, Batch: 326, D Loss: 0.09580487269117843, G Loss: 19.031774520874023\n",
      "Epoch: 23, Batch: 327, D Loss: 0.10167566180141985, G Loss: 19.279197692871094\n",
      "Epoch: 23, Batch: 328, D Loss: 0.10155159404429548, G Loss: 19.705078125\n",
      "Epoch: 23, Batch: 329, D Loss: 0.09651354092230291, G Loss: 19.725597381591797\n",
      "Epoch: 23, Batch: 330, D Loss: 0.09784946002538464, G Loss: 19.4482479095459\n",
      "Epoch: 23, Batch: 331, D Loss: 0.09524940173842, G Loss: 19.058439254760742\n",
      "Epoch: 23, Batch: 332, D Loss: 0.09641458382125556, G Loss: 18.89580726623535\n",
      "Epoch: 23, Batch: 333, D Loss: 0.09686104496588865, G Loss: 19.039945602416992\n",
      "Epoch: 23, Batch: 334, D Loss: 0.09710184707111558, G Loss: 19.402507781982422\n",
      "Epoch: 23, Batch: 335, D Loss: 0.09691196841799021, G Loss: 19.68278694152832\n",
      "Epoch: 23, Batch: 336, D Loss: 0.10569942106715535, G Loss: 20.17547035217285\n",
      "Epoch: 23, Batch: 337, D Loss: 0.10506563709570654, G Loss: 20.42360496520996\n",
      "Epoch: 23, Batch: 338, D Loss: 0.0954017424790295, G Loss: 19.84390640258789\n",
      "Epoch: 23, Batch: 339, D Loss: 0.100413137815896, G Loss: 19.26814842224121\n",
      "Epoch: 23, Batch: 340, D Loss: 0.0965351860778314, G Loss: 18.90932273864746\n",
      "Epoch: 23, Batch: 341, D Loss: 0.09866609711395191, G Loss: 19.036483764648438\n",
      "Epoch: 23, Batch: 342, D Loss: 0.09693708491066211, G Loss: 19.42330551147461\n",
      "Epoch: 23, Batch: 343, D Loss: 0.0959665343815439, G Loss: 19.738571166992188\n",
      "Epoch: 23, Batch: 344, D Loss: 0.093600647076435, G Loss: 19.63336753845215\n",
      "Epoch: 23, Batch: 345, D Loss: 0.09277114455574809, G Loss: 19.23370933532715\n",
      "Epoch: 23, Batch: 346, D Loss: 0.10429931638993284, G Loss: 19.365018844604492\n",
      "Epoch: 23, Batch: 347, D Loss: 0.08804993561710894, G Loss: 19.044063568115234\n",
      "Epoch: 23, Batch: 348, D Loss: 0.09864425923364095, G Loss: 19.072834014892578\n",
      "Epoch: 23, Batch: 349, D Loss: 0.09978682025040042, G Loss: 19.373538970947266\n",
      "Epoch: 23, Batch: 350, D Loss: 0.09684178407832855, G Loss: 19.561817169189453\n",
      "Epoch: 23, Batch: 351, D Loss: 0.0993292347105944, G Loss: 19.63070297241211\n",
      "Epoch: 23, Batch: 352, D Loss: 0.0979433672366764, G Loss: 19.424135208129883\n",
      "Epoch: 23, Batch: 353, D Loss: 0.10061773112315109, G Loss: 19.26325225830078\n",
      "Epoch: 23, Batch: 354, D Loss: 0.10531208113147628, G Loss: 19.461559295654297\n",
      "Epoch: 23, Batch: 355, D Loss: 0.09645675314775826, G Loss: 19.302762985229492\n",
      "Epoch: 23, Batch: 356, D Loss: 0.09726885205296765, G Loss: 18.988256454467773\n",
      "Epoch: 23, Batch: 357, D Loss: 0.09932321620426299, G Loss: 18.81696319580078\n",
      "Epoch: 23, Batch: 358, D Loss: 0.09707188200259997, G Loss: 18.803443908691406\n",
      "Epoch: 23, Batch: 359, D Loss: 0.09879728718008263, G Loss: 18.977510452270508\n",
      "Epoch: 23, Batch: 360, D Loss: 0.1023475103572824, G Loss: 19.407386779785156\n",
      "Epoch: 23, Batch: 361, D Loss: 0.09760581879473695, G Loss: 19.50130271911621\n",
      "Epoch: 23, Batch: 362, D Loss: 0.10372992021758332, G Loss: 19.592050552368164\n",
      "Epoch: 23, Batch: 363, D Loss: 0.10272485920920615, G Loss: 19.554977416992188\n",
      "Epoch: 23, Batch: 364, D Loss: 0.09738135535002512, G Loss: 19.16805076599121\n",
      "Epoch: 23, Batch: 365, D Loss: 0.09964734586117885, G Loss: 18.917573928833008\n",
      "Epoch: 23, Batch: 366, D Loss: 0.10022945998472066, G Loss: 18.96823501586914\n",
      "Epoch: 23, Batch: 367, D Loss: 0.10347227987405172, G Loss: 19.360036849975586\n",
      "Epoch: 23, Batch: 368, D Loss: 0.09921210443078488, G Loss: 19.47652244567871\n",
      "Epoch: 23, Batch: 369, D Loss: 0.10032166725356295, G Loss: 19.362951278686523\n",
      "Epoch: 23, Batch: 370, D Loss: 0.10283197670139099, G Loss: 19.24366569519043\n",
      "Epoch: 23, Batch: 371, D Loss: 0.09705210744027126, G Loss: 18.871719360351562\n",
      "Epoch: 23, Batch: 372, D Loss: 0.09885536499957226, G Loss: 18.610254287719727\n",
      "Epoch: 23, Batch: 373, D Loss: 0.09840627426425685, G Loss: 18.62062644958496\n",
      "Epoch: 23, Batch: 374, D Loss: 0.10296275053030746, G Loss: 19.02297019958496\n",
      "Epoch: 23, Batch: 375, D Loss: 0.09892322365748263, G Loss: 19.252700805664062\n",
      "Epoch: 23, Batch: 376, D Loss: 0.0987644665866172, G Loss: 19.125612258911133\n",
      "Epoch: 23, Batch: 377, D Loss: 0.09608855423507778, G Loss: 18.60441780090332\n",
      "Epoch: 23, Batch: 378, D Loss: 0.10140958898032837, G Loss: 18.376136779785156\n",
      "Epoch: 23, Batch: 379, D Loss: 0.09858868805468202, G Loss: 18.33672332763672\n",
      "Epoch: 23, Batch: 380, D Loss: 0.0994390000998826, G Loss: 18.528287887573242\n",
      "Epoch: 23, Batch: 381, D Loss: 0.09854915402777475, G Loss: 18.70379638671875\n",
      "Epoch: 23, Batch: 382, D Loss: 0.09101088043993277, G Loss: 18.3929443359375\n",
      "Epoch: 23, Batch: 383, D Loss: 0.1004116588841204, G Loss: 18.313831329345703\n",
      "Epoch: 23, Batch: 384, D Loss: 0.09844084618483517, G Loss: 18.392534255981445\n",
      "Epoch: 23, Batch: 385, D Loss: 0.09713197236376869, G Loss: 18.518020629882812\n",
      "Epoch: 23, Batch: 386, D Loss: 0.09885499298426392, G Loss: 18.658885955810547\n",
      "Epoch: 23, Batch: 387, D Loss: 0.10263406813272091, G Loss: 18.990266799926758\n",
      "Epoch: 23, Batch: 388, D Loss: 0.09859839361311562, G Loss: 19.013980865478516\n",
      "Epoch: 23, Batch: 389, D Loss: 0.09624547094604585, G Loss: 18.686664581298828\n",
      "Epoch: 23, Batch: 390, D Loss: 0.09050858546546836, G Loss: 18.08686065673828\n",
      "Epoch: 23, Batch: 391, D Loss: 0.09447916646228283, G Loss: 17.845060348510742\n",
      "Epoch: 23, Batch: 392, D Loss: 0.09815453661259, G Loss: 18.389312744140625\n",
      "Epoch: 23, Batch: 393, D Loss: 0.09653468781161756, G Loss: 19.12012481689453\n",
      "Epoch: 23, Batch: 394, D Loss: 0.09531872917099782, G Loss: 19.554643630981445\n",
      "Epoch: 23, Batch: 395, D Loss: 0.09672106212559295, G Loss: 19.624191284179688\n",
      "Epoch: 23, Batch: 396, D Loss: 0.09670321838773588, G Loss: 19.12003517150879\n",
      "Epoch: 23, Batch: 397, D Loss: 0.09558295036788422, G Loss: 18.620166778564453\n",
      "Epoch: 23, Batch: 398, D Loss: 0.09747480311648049, G Loss: 18.419456481933594\n",
      "Epoch: 23, Batch: 399, D Loss: 0.09877706792992669, G Loss: 18.525474548339844\n",
      "Epoch: 23, Batch: 400, D Loss: 0.09990346833404473, G Loss: 18.74366569519043\n",
      "Epoch: 23, Batch: 401, D Loss: 0.0885821698940572, G Loss: 18.39385414123535\n",
      "Epoch: 23, Batch: 402, D Loss: 0.10019810317638722, G Loss: 18.215044021606445\n",
      "Epoch: 23, Batch: 403, D Loss: 0.09744445132605684, G Loss: 18.130062103271484\n",
      "Epoch: 23, Batch: 404, D Loss: 0.09937564174733504, G Loss: 18.227142333984375\n",
      "Epoch: 23, Batch: 405, D Loss: 0.09547748294691871, G Loss: 18.17917251586914\n",
      "Epoch: 23, Batch: 406, D Loss: 0.09974537654916871, G Loss: 18.262218475341797\n",
      "Epoch: 23, Batch: 407, D Loss: 0.10112055181106294, G Loss: 18.436534881591797\n",
      "Epoch: 23, Batch: 408, D Loss: 0.09191547890292107, G Loss: 18.20628547668457\n",
      "Epoch: 23, Batch: 409, D Loss: 0.09808110368785661, G Loss: 18.065614700317383\n",
      "Epoch: 23, Batch: 410, D Loss: 0.1014288580467797, G Loss: 18.226303100585938\n",
      "Epoch: 23, Batch: 411, D Loss: 0.10095757780549564, G Loss: 18.470592498779297\n",
      "Epoch: 23, Batch: 412, D Loss: 0.09960195143060746, G Loss: 18.511611938476562\n",
      "Epoch: 23, Batch: 413, D Loss: 0.09841143103617833, G Loss: 18.30755615234375\n",
      "Epoch: 23, Batch: 414, D Loss: 0.09648602395355388, G Loss: 17.927736282348633\n",
      "Epoch: 23, Batch: 415, D Loss: 0.1045961827470192, G Loss: 18.09857940673828\n",
      "Epoch: 23, Batch: 416, D Loss: 0.1071280141998181, G Loss: 18.709091186523438\n",
      "Epoch: 23, Batch: 417, D Loss: 0.09524851671369827, G Loss: 18.68906593322754\n",
      "Epoch: 23, Batch: 418, D Loss: 0.1068600900012715, G Loss: 18.76327896118164\n",
      "Epoch: 23, Batch: 419, D Loss: 0.0966591878751677, G Loss: 18.367542266845703\n",
      "Epoch: 23, Batch: 420, D Loss: 0.10281660226218614, G Loss: 18.243558883666992\n",
      "Epoch: 23, Batch: 421, D Loss: 0.09744769944475262, G Loss: 18.205734252929688\n",
      "Epoch: 23, Batch: 422, D Loss: 0.09614819914706674, G Loss: 18.1883487701416\n",
      "Epoch: 23, Batch: 423, D Loss: 0.10097033312181747, G Loss: 18.53272247314453\n",
      "Epoch: 23, Batch: 424, D Loss: 0.0998579821744483, G Loss: 18.918027877807617\n",
      "Epoch: 23, Batch: 425, D Loss: 0.09411055159222426, G Loss: 18.88503646850586\n",
      "Epoch: 23, Batch: 426, D Loss: 0.10303455137013873, G Loss: 19.033296585083008\n",
      "Epoch: 23, Batch: 427, D Loss: 0.09690101721899036, G Loss: 18.991336822509766\n",
      "Epoch: 23, Batch: 428, D Loss: 0.10347602767338371, G Loss: 19.21809196472168\n",
      "Epoch: 23, Batch: 429, D Loss: 0.09690946565678904, G Loss: 19.220138549804688\n",
      "Epoch: 23, Batch: 430, D Loss: 0.10181246905271313, G Loss: 19.374271392822266\n",
      "Epoch: 23, Batch: 431, D Loss: 0.09846552651241747, G Loss: 19.40315055847168\n",
      "Epoch: 23, Batch: 432, D Loss: 0.09662635827197485, G Loss: 19.25181770324707\n",
      "Epoch: 23, Batch: 433, D Loss: 0.0909489271493682, G Loss: 18.823631286621094\n",
      "Epoch: 23, Batch: 434, D Loss: 0.10193671595323228, G Loss: 18.971920013427734\n",
      "Epoch: 23, Batch: 435, D Loss: 0.0956355284532655, G Loss: 19.189191818237305\n",
      "Epoch: 23, Batch: 436, D Loss: 0.09770388355940796, G Loss: 19.47283363342285\n",
      "Epoch: 23, Batch: 437, D Loss: 0.09787620022664734, G Loss: 19.59611701965332\n",
      "Epoch: 23, Batch: 438, D Loss: 0.09855702677557154, G Loss: 19.550539016723633\n",
      "Epoch: 23, Batch: 439, D Loss: 0.09923336825252327, G Loss: 19.450281143188477\n",
      "Epoch: 23, Batch: 440, D Loss: 0.09798858499694507, G Loss: 19.384450912475586\n",
      "Epoch: 23, Batch: 441, D Loss: 0.1009902077664605, G Loss: 19.534278869628906\n",
      "Epoch: 23, Batch: 442, D Loss: 0.09819803546164785, G Loss: 19.593059539794922\n",
      "Epoch: 23, Batch: 443, D Loss: 0.0978779212503782, G Loss: 19.55927276611328\n",
      "Epoch: 23, Batch: 444, D Loss: 0.09922068731199252, G Loss: 19.501779556274414\n",
      "Epoch: 23, Batch: 445, D Loss: 0.10126781634099324, G Loss: 19.49282455444336\n",
      "Epoch: 23, Batch: 446, D Loss: 0.0943336060644353, G Loss: 19.11688804626465\n",
      "Epoch: 23, Batch: 447, D Loss: 0.10080790027508968, G Loss: 19.090585708618164\n",
      "Epoch: 23, Batch: 448, D Loss: 0.08660618548217358, G Loss: 18.59238052368164\n",
      "Epoch: 23, Batch: 449, D Loss: 0.10039110869354984, G Loss: 18.751506805419922\n",
      "Epoch: 23, Batch: 450, D Loss: 0.10120083646784295, G Loss: 19.39999008178711\n",
      "Epoch: 23, Batch: 451, D Loss: 0.10091680423690419, G Loss: 20.021129608154297\n",
      "Epoch: 23, Batch: 452, D Loss: 0.09233492728944326, G Loss: 19.754636764526367\n",
      "Epoch: 23, Batch: 453, D Loss: 0.09477603622791508, G Loss: 19.084909439086914\n",
      "Epoch: 23, Batch: 454, D Loss: 0.09742942773955843, G Loss: 18.6611385345459\n",
      "Epoch: 23, Batch: 455, D Loss: 0.09135117086833855, G Loss: 18.40624237060547\n",
      "Epoch: 23, Batch: 456, D Loss: 0.1058312390632381, G Loss: 19.155006408691406\n",
      "Epoch: 23, Batch: 457, D Loss: 0.09902363433539585, G Loss: 19.88801383972168\n",
      "Epoch: 23, Batch: 458, D Loss: 0.10417646261068281, G Loss: 20.329530715942383\n",
      "Epoch: 23, Batch: 459, D Loss: 0.09975159259799443, G Loss: 19.929214477539062\n",
      "Epoch: 23, Batch: 460, D Loss: 0.09979158804889399, G Loss: 19.168272018432617\n",
      "Epoch: 23, Batch: 461, D Loss: 0.10004727857764961, G Loss: 18.622785568237305\n",
      "Epoch: 23, Batch: 462, D Loss: 0.1027511844168516, G Loss: 18.71877098083496\n",
      "Epoch: 23, Batch: 463, D Loss: 0.09311322475823403, G Loss: 18.815221786499023\n",
      "Epoch: 23, Batch: 464, D Loss: 0.09497630910617927, G Loss: 18.948028564453125\n",
      "Epoch: 23, Batch: 465, D Loss: 0.09921483950928756, G Loss: 19.22317886352539\n",
      "Epoch: 23, Batch: 466, D Loss: 0.10183917173489654, G Loss: 19.56251335144043\n",
      "Epoch: 23, Batch: 467, D Loss: 0.10234635469011788, G Loss: 19.736064910888672\n",
      "Epoch: 24, Batch: 0, D Loss: 0.09806287441653838, G Loss: 19.48726463317871\n",
      "Epoch: 24, Batch: 1, D Loss: 0.09738561734352169, G Loss: 18.992250442504883\n",
      "Epoch: 24, Batch: 2, D Loss: 0.09691894385689026, G Loss: 18.689449310302734\n",
      "Epoch: 24, Batch: 3, D Loss: 0.09929357082735657, G Loss: 18.811267852783203\n",
      "Epoch: 24, Batch: 4, D Loss: 0.09928731902591625, G Loss: 19.156206130981445\n",
      "Epoch: 24, Batch: 5, D Loss: 0.10128915503133262, G Loss: 19.565391540527344\n",
      "Epoch: 24, Batch: 6, D Loss: 0.09706067462006585, G Loss: 19.461894989013672\n",
      "Epoch: 24, Batch: 7, D Loss: 0.10628735444607706, G Loss: 19.528095245361328\n",
      "Epoch: 24, Batch: 8, D Loss: 0.09279574687455638, G Loss: 18.86942481994629\n",
      "Epoch: 24, Batch: 9, D Loss: 0.09669606073904724, G Loss: 18.299009323120117\n",
      "Epoch: 24, Batch: 10, D Loss: 0.10566820663988574, G Loss: 18.69198226928711\n",
      "Epoch: 24, Batch: 11, D Loss: 0.10150599750908329, G Loss: 19.33881378173828\n",
      "Epoch: 24, Batch: 12, D Loss: 0.0975420045778379, G Loss: 19.556676864624023\n",
      "Epoch: 24, Batch: 13, D Loss: 0.10442377784300183, G Loss: 19.59498405456543\n",
      "Epoch: 24, Batch: 14, D Loss: 0.10039973438677285, G Loss: 19.308528900146484\n",
      "Epoch: 24, Batch: 15, D Loss: 0.09786430286312164, G Loss: 18.689504623413086\n",
      "Epoch: 24, Batch: 16, D Loss: 0.09573653833467333, G Loss: 18.20707130432129\n",
      "Epoch: 24, Batch: 17, D Loss: 0.10924017862597468, G Loss: 18.88690185546875\n",
      "Epoch: 24, Batch: 18, D Loss: 0.09800422430256939, G Loss: 19.406782150268555\n",
      "Epoch: 24, Batch: 19, D Loss: 0.09691091807757868, G Loss: 19.465906143188477\n",
      "Epoch: 24, Batch: 20, D Loss: 0.10204154436554891, G Loss: 19.384742736816406\n",
      "Epoch: 24, Batch: 21, D Loss: 0.09546349449373914, G Loss: 18.856904983520508\n",
      "Epoch: 24, Batch: 22, D Loss: 0.09704278050114068, G Loss: 18.522960662841797\n",
      "Epoch: 24, Batch: 23, D Loss: 0.08952281421448749, G Loss: 18.174943923950195\n",
      "Epoch: 24, Batch: 24, D Loss: 0.09621693726537428, G Loss: 18.52334976196289\n",
      "Epoch: 24, Batch: 25, D Loss: 0.10348551965593322, G Loss: 19.68091583251953\n",
      "Epoch: 24, Batch: 26, D Loss: 0.0953780572109868, G Loss: 20.265357971191406\n",
      "Epoch: 24, Batch: 27, D Loss: 0.09339117353046655, G Loss: 19.93073272705078\n",
      "Epoch: 24, Batch: 28, D Loss: 0.10314819341963122, G Loss: 19.69225311279297\n",
      "Epoch: 24, Batch: 29, D Loss: 0.10883938636485802, G Loss: 20.06337547302246\n",
      "Epoch: 24, Batch: 30, D Loss: 0.0913526427058714, G Loss: 19.77922821044922\n",
      "Epoch: 24, Batch: 31, D Loss: 0.09439699510272148, G Loss: 19.380760192871094\n",
      "Epoch: 24, Batch: 32, D Loss: 0.09427419521150471, G Loss: 19.149383544921875\n",
      "Epoch: 24, Batch: 33, D Loss: 0.09635877086098943, G Loss: 19.30928611755371\n",
      "Epoch: 24, Batch: 34, D Loss: 0.1086868356583991, G Loss: 20.521272659301758\n",
      "Epoch: 24, Batch: 35, D Loss: 0.09368487497279426, G Loss: 20.9134521484375\n",
      "Epoch: 24, Batch: 36, D Loss: 0.09936608422538573, G Loss: 20.613021850585938\n",
      "Epoch: 24, Batch: 37, D Loss: 0.10070049091633004, G Loss: 20.078571319580078\n",
      "Epoch: 24, Batch: 38, D Loss: 0.10029812275818684, G Loss: 19.66126823425293\n",
      "Epoch: 24, Batch: 39, D Loss: 0.09734280564099185, G Loss: 19.50968360900879\n",
      "Epoch: 24, Batch: 40, D Loss: 0.09611195491282021, G Loss: 19.542831420898438\n",
      "Epoch: 24, Batch: 41, D Loss: 0.09347246756903282, G Loss: 19.465412139892578\n",
      "Epoch: 24, Batch: 42, D Loss: 0.10089455691862637, G Loss: 19.807788848876953\n",
      "Epoch: 24, Batch: 43, D Loss: 0.10033333405003453, G Loss: 20.165525436401367\n",
      "Epoch: 24, Batch: 44, D Loss: 0.10286428858620084, G Loss: 20.350215911865234\n",
      "Epoch: 24, Batch: 45, D Loss: 0.09629027641787846, G Loss: 19.8126220703125\n",
      "Epoch: 24, Batch: 46, D Loss: 0.09933675251779273, G Loss: 19.203737258911133\n",
      "Epoch: 24, Batch: 47, D Loss: 0.10040716362507185, G Loss: 18.814664840698242\n",
      "Epoch: 24, Batch: 48, D Loss: 0.09204106460983708, G Loss: 18.362483978271484\n",
      "Epoch: 24, Batch: 49, D Loss: 0.10407616619525228, G Loss: 18.798992156982422\n",
      "Epoch: 24, Batch: 50, D Loss: 0.10301756346625579, G Loss: 19.53192710876465\n",
      "Epoch: 24, Batch: 51, D Loss: 0.09533571615481129, G Loss: 19.544208526611328\n",
      "Epoch: 24, Batch: 52, D Loss: 0.0997713153544828, G Loss: 19.165084838867188\n",
      "Epoch: 24, Batch: 53, D Loss: 0.10007071802969669, G Loss: 18.673372268676758\n",
      "Epoch: 24, Batch: 54, D Loss: 0.1001025334747041, G Loss: 18.376371383666992\n",
      "Epoch: 24, Batch: 55, D Loss: 0.09730204006968668, G Loss: 18.25712776184082\n",
      "Epoch: 24, Batch: 56, D Loss: 0.09844727631249794, G Loss: 18.347883224487305\n",
      "Epoch: 24, Batch: 57, D Loss: 0.10061551330684404, G Loss: 18.708206176757812\n",
      "Epoch: 24, Batch: 58, D Loss: 0.10249829592121529, G Loss: 19.134763717651367\n",
      "Epoch: 24, Batch: 59, D Loss: 0.09998013318663457, G Loss: 19.17763900756836\n",
      "Epoch: 24, Batch: 60, D Loss: 0.09578831055836146, G Loss: 18.66680908203125\n",
      "Epoch: 24, Batch: 61, D Loss: 0.10294660612069162, G Loss: 18.481882095336914\n",
      "Epoch: 24, Batch: 62, D Loss: 0.10066773441996801, G Loss: 18.5907039642334\n",
      "Epoch: 24, Batch: 63, D Loss: 0.1037212342779319, G Loss: 19.204851150512695\n",
      "Epoch: 24, Batch: 64, D Loss: 0.09846597358698617, G Loss: 19.516252517700195\n",
      "Epoch: 24, Batch: 65, D Loss: 0.09606670782836568, G Loss: 19.228404998779297\n",
      "Epoch: 24, Batch: 66, D Loss: 0.0943576127213388, G Loss: 18.682926177978516\n",
      "Epoch: 24, Batch: 67, D Loss: 0.10474542134895248, G Loss: 18.85553741455078\n",
      "Epoch: 24, Batch: 68, D Loss: 0.09838293765720918, G Loss: 19.180938720703125\n",
      "Epoch: 24, Batch: 69, D Loss: 0.10202508596235038, G Loss: 19.715391159057617\n",
      "Epoch: 24, Batch: 70, D Loss: 0.10458491851699725, G Loss: 20.1483211517334\n",
      "Epoch: 24, Batch: 71, D Loss: 0.10234993785029645, G Loss: 20.149433135986328\n",
      "Epoch: 24, Batch: 72, D Loss: 0.10334531320196993, G Loss: 19.878032684326172\n",
      "Epoch: 24, Batch: 73, D Loss: 0.09921690971027619, G Loss: 19.404359817504883\n",
      "Epoch: 24, Batch: 74, D Loss: 0.09809774391124026, G Loss: 19.005151748657227\n",
      "Epoch: 24, Batch: 75, D Loss: 0.09585379354859502, G Loss: 18.925811767578125\n",
      "Epoch: 24, Batch: 76, D Loss: 0.09804935258813763, G Loss: 19.280029296875\n",
      "Epoch: 24, Batch: 77, D Loss: 0.10302291947560471, G Loss: 20.105670928955078\n",
      "Epoch: 24, Batch: 78, D Loss: 0.10477383496898124, G Loss: 20.867395401000977\n",
      "Epoch: 24, Batch: 79, D Loss: 0.09956030591420426, G Loss: 20.84522247314453\n",
      "Epoch: 24, Batch: 80, D Loss: 0.09522570737440988, G Loss: 20.034353256225586\n",
      "Epoch: 24, Batch: 81, D Loss: 0.10304727530633717, G Loss: 19.597148895263672\n",
      "Epoch: 24, Batch: 82, D Loss: 0.10087369533821788, G Loss: 19.631994247436523\n",
      "Epoch: 24, Batch: 83, D Loss: 0.09950786952740176, G Loss: 19.983898162841797\n",
      "Epoch: 24, Batch: 84, D Loss: 0.09866029856261105, G Loss: 20.334712982177734\n",
      "Epoch: 24, Batch: 85, D Loss: 0.09542141929668124, G Loss: 20.30526351928711\n",
      "Epoch: 24, Batch: 86, D Loss: 0.10221931412042501, G Loss: 20.36182403564453\n",
      "Epoch: 24, Batch: 87, D Loss: 0.10241434048402487, G Loss: 20.40088653564453\n",
      "Epoch: 24, Batch: 88, D Loss: 0.0980005122919474, G Loss: 20.205907821655273\n",
      "Epoch: 24, Batch: 89, D Loss: 0.10578629455670396, G Loss: 20.26874542236328\n",
      "Epoch: 24, Batch: 90, D Loss: 0.0951446750921045, G Loss: 19.994356155395508\n",
      "Epoch: 24, Batch: 91, D Loss: 0.10233289853400973, G Loss: 19.97058868408203\n",
      "Epoch: 24, Batch: 92, D Loss: 0.10298965221121448, G Loss: 20.18457794189453\n",
      "Epoch: 24, Batch: 93, D Loss: 0.09484810475600236, G Loss: 20.019689559936523\n",
      "Epoch: 24, Batch: 94, D Loss: 0.09282358867481899, G Loss: 19.5162353515625\n",
      "Epoch: 24, Batch: 95, D Loss: 0.1010747420167043, G Loss: 19.45626449584961\n",
      "Epoch: 24, Batch: 96, D Loss: 0.10432359705912586, G Loss: 20.052396774291992\n",
      "Epoch: 24, Batch: 97, D Loss: 0.09661339309676753, G Loss: 20.290414810180664\n",
      "Epoch: 24, Batch: 98, D Loss: 0.10499870100646069, G Loss: 20.512819290161133\n",
      "Epoch: 24, Batch: 99, D Loss: 0.09709523696328054, G Loss: 20.064647674560547\n",
      "Epoch: 24, Batch: 100, D Loss: 0.1019621280193227, G Loss: 19.60902214050293\n",
      "Epoch: 24, Batch: 101, D Loss: 0.09246539536237708, G Loss: 18.983827590942383\n",
      "Epoch: 24, Batch: 102, D Loss: 0.09978810248745584, G Loss: 18.911211013793945\n",
      "Epoch: 24, Batch: 103, D Loss: 0.1023010709464347, G Loss: 19.4199275970459\n",
      "Epoch: 24, Batch: 104, D Loss: 0.09987982508141136, G Loss: 19.86505699157715\n",
      "Epoch: 24, Batch: 105, D Loss: 0.09935403729353609, G Loss: 19.928197860717773\n",
      "Epoch: 24, Batch: 106, D Loss: 0.10323669140563507, G Loss: 19.71040916442871\n",
      "Epoch: 24, Batch: 107, D Loss: 0.09001121173585158, G Loss: 18.584575653076172\n",
      "Epoch: 24, Batch: 108, D Loss: 0.10328291857846805, G Loss: 18.270959854125977\n",
      "Epoch: 24, Batch: 109, D Loss: 0.09932031207717884, G Loss: 18.67469024658203\n",
      "Epoch: 24, Batch: 110, D Loss: 0.09369907854814596, G Loss: 19.002185821533203\n",
      "Epoch: 24, Batch: 111, D Loss: 0.10336674204767649, G Loss: 19.63596534729004\n",
      "Epoch: 24, Batch: 112, D Loss: 0.09957113993266442, G Loss: 19.86897850036621\n",
      "Epoch: 24, Batch: 113, D Loss: 0.09946097570072865, G Loss: 19.584123611450195\n",
      "Epoch: 24, Batch: 114, D Loss: 0.1002448518875656, G Loss: 19.146198272705078\n",
      "Epoch: 24, Batch: 115, D Loss: 0.09306577194019283, G Loss: 18.468273162841797\n",
      "Epoch: 24, Batch: 116, D Loss: 0.10001175583224908, G Loss: 18.466955184936523\n",
      "Epoch: 24, Batch: 117, D Loss: 0.09653434562192631, G Loss: 18.782712936401367\n",
      "Epoch: 24, Batch: 118, D Loss: 0.10509623812035329, G Loss: 19.612085342407227\n",
      "Epoch: 24, Batch: 119, D Loss: 0.10052299620803529, G Loss: 20.0395565032959\n",
      "Epoch: 24, Batch: 120, D Loss: 0.09603242702715298, G Loss: 19.573312759399414\n",
      "Epoch: 24, Batch: 121, D Loss: 0.10105232356976179, G Loss: 19.053422927856445\n",
      "Epoch: 24, Batch: 122, D Loss: 0.09940413702719897, G Loss: 18.717700958251953\n",
      "Epoch: 24, Batch: 123, D Loss: 0.09189856500238491, G Loss: 18.365692138671875\n",
      "Epoch: 24, Batch: 124, D Loss: 0.10263818866124463, G Loss: 19.07799530029297\n",
      "Epoch: 24, Batch: 125, D Loss: 0.09746689525309427, G Loss: 19.74311637878418\n",
      "Epoch: 24, Batch: 126, D Loss: 0.10085654364274732, G Loss: 20.186059951782227\n",
      "Epoch: 24, Batch: 127, D Loss: 0.09947156989646772, G Loss: 20.23236083984375\n",
      "Epoch: 24, Batch: 128, D Loss: 0.10237552311825371, G Loss: 20.1297550201416\n",
      "Epoch: 24, Batch: 129, D Loss: 0.10187316041024319, G Loss: 19.937501907348633\n",
      "Epoch: 24, Batch: 130, D Loss: 0.09471053022981957, G Loss: 19.50235366821289\n",
      "Epoch: 24, Batch: 131, D Loss: 0.09559150241302405, G Loss: 19.177841186523438\n",
      "Epoch: 24, Batch: 132, D Loss: 0.09308344376877775, G Loss: 19.04882049560547\n",
      "Epoch: 24, Batch: 133, D Loss: 0.10410420777686846, G Loss: 19.784391403198242\n",
      "Epoch: 24, Batch: 134, D Loss: 0.09525294703223264, G Loss: 20.2263126373291\n",
      "Epoch: 24, Batch: 135, D Loss: 0.09494602021976378, G Loss: 20.122203826904297\n",
      "Epoch: 24, Batch: 136, D Loss: 0.10336219610523156, G Loss: 20.123830795288086\n",
      "Epoch: 24, Batch: 137, D Loss: 0.09815900872906136, G Loss: 19.94430923461914\n",
      "Epoch: 24, Batch: 138, D Loss: 0.09571983045340038, G Loss: 19.68094825744629\n",
      "Epoch: 24, Batch: 139, D Loss: 0.10031765836026052, G Loss: 19.751934051513672\n",
      "Epoch: 24, Batch: 140, D Loss: 0.09889942525759743, G Loss: 19.963979721069336\n",
      "Epoch: 24, Batch: 141, D Loss: 0.0992826977927801, G Loss: 20.188133239746094\n",
      "Epoch: 24, Batch: 142, D Loss: 0.09124649422393238, G Loss: 19.771455764770508\n",
      "Epoch: 24, Batch: 143, D Loss: 0.10754658393195526, G Loss: 20.058238983154297\n",
      "Epoch: 24, Batch: 144, D Loss: 0.10458255636266434, G Loss: 20.49950408935547\n",
      "Epoch: 24, Batch: 145, D Loss: 0.0990545756193123, G Loss: 20.418048858642578\n",
      "Epoch: 24, Batch: 146, D Loss: 0.09802939085956303, G Loss: 19.918832778930664\n",
      "Epoch: 24, Batch: 147, D Loss: 0.103695162849465, G Loss: 19.770444869995117\n",
      "Epoch: 24, Batch: 148, D Loss: 0.09862861926763766, G Loss: 19.565629959106445\n",
      "Epoch: 24, Batch: 149, D Loss: 0.096730554352221, G Loss: 19.398183822631836\n",
      "Epoch: 24, Batch: 150, D Loss: 0.10188681796471122, G Loss: 19.65728759765625\n",
      "Epoch: 24, Batch: 151, D Loss: 0.1001735491268757, G Loss: 19.922510147094727\n",
      "Epoch: 24, Batch: 152, D Loss: 0.09768175446777694, G Loss: 19.894622802734375\n",
      "Epoch: 24, Batch: 153, D Loss: 0.10176826385647764, G Loss: 19.85085678100586\n",
      "Epoch: 24, Batch: 154, D Loss: 0.10093195120102394, G Loss: 19.71184539794922\n",
      "Epoch: 24, Batch: 155, D Loss: 0.10444238916752391, G Loss: 19.74946403503418\n",
      "Epoch: 24, Batch: 156, D Loss: 0.09449716074748482, G Loss: 19.355844497680664\n",
      "Epoch: 24, Batch: 157, D Loss: 0.10159476315336224, G Loss: 19.19220733642578\n",
      "Epoch: 24, Batch: 158, D Loss: 0.1023172160074064, G Loss: 19.463199615478516\n",
      "Epoch: 24, Batch: 159, D Loss: 0.09886636003651761, G Loss: 19.604503631591797\n",
      "Epoch: 24, Batch: 160, D Loss: 0.09960100959057461, G Loss: 19.529775619506836\n",
      "Epoch: 24, Batch: 161, D Loss: 0.0986694562924969, G Loss: 19.32562828063965\n",
      "Epoch: 24, Batch: 162, D Loss: 0.09581563142374927, G Loss: 18.808956146240234\n",
      "Epoch: 24, Batch: 163, D Loss: 0.09713807359763527, G Loss: 18.484359741210938\n",
      "Epoch: 24, Batch: 164, D Loss: 0.09791981124122051, G Loss: 18.606979370117188\n",
      "Epoch: 24, Batch: 165, D Loss: 0.10101303773093973, G Loss: 19.13317108154297\n",
      "Epoch: 24, Batch: 166, D Loss: 0.09975897719833382, G Loss: 19.53008460998535\n",
      "Epoch: 24, Batch: 167, D Loss: 0.10270470530155085, G Loss: 19.718448638916016\n",
      "Epoch: 24, Batch: 168, D Loss: 0.09328417670035605, G Loss: 19.09029769897461\n",
      "Epoch: 24, Batch: 169, D Loss: 0.1068656172726743, G Loss: 19.04715347290039\n",
      "Epoch: 24, Batch: 170, D Loss: 0.105145128932421, G Loss: 19.291589736938477\n",
      "Epoch: 24, Batch: 171, D Loss: 0.10037067729923765, G Loss: 19.403759002685547\n",
      "Epoch: 24, Batch: 172, D Loss: 0.09562489617681336, G Loss: 19.034626007080078\n",
      "Epoch: 24, Batch: 173, D Loss: 0.10483236876698343, G Loss: 19.069944381713867\n",
      "Epoch: 24, Batch: 174, D Loss: 0.10560231874128245, G Loss: 19.412050247192383\n",
      "Epoch: 24, Batch: 175, D Loss: 0.10167578032384506, G Loss: 19.583036422729492\n",
      "Epoch: 24, Batch: 176, D Loss: 0.09857017728859219, G Loss: 19.295560836791992\n",
      "Epoch: 24, Batch: 177, D Loss: 0.09356764255460548, G Loss: 18.62693977355957\n",
      "Epoch: 24, Batch: 178, D Loss: 0.10573694467785222, G Loss: 18.872272491455078\n",
      "Epoch: 24, Batch: 179, D Loss: 0.09740018371043946, G Loss: 19.175838470458984\n",
      "Epoch: 24, Batch: 180, D Loss: 0.09807318654209363, G Loss: 19.43427085876465\n",
      "Epoch: 24, Batch: 181, D Loss: 0.1014324442735961, G Loss: 19.664012908935547\n",
      "Epoch: 24, Batch: 182, D Loss: 0.10184052724182047, G Loss: 19.753482818603516\n",
      "Epoch: 24, Batch: 183, D Loss: 0.09934126733609072, G Loss: 19.53624153137207\n",
      "Epoch: 24, Batch: 184, D Loss: 0.09654922985639747, G Loss: 19.136547088623047\n",
      "Epoch: 24, Batch: 185, D Loss: 0.10336651149451637, G Loss: 19.160619735717773\n",
      "Epoch: 24, Batch: 186, D Loss: 0.1013914739880466, G Loss: 19.435251235961914\n",
      "Epoch: 24, Batch: 187, D Loss: 0.10033844570984085, G Loss: 19.677846908569336\n",
      "Epoch: 24, Batch: 188, D Loss: 0.09725764538059878, G Loss: 19.651647567749023\n",
      "Epoch: 24, Batch: 189, D Loss: 0.10287223151399405, G Loss: 19.73018455505371\n",
      "Epoch: 24, Batch: 190, D Loss: 0.0984452976521678, G Loss: 19.710060119628906\n",
      "Epoch: 24, Batch: 191, D Loss: 0.0990021838902857, G Loss: 19.67061424255371\n",
      "Epoch: 24, Batch: 192, D Loss: 0.09682653249742412, G Loss: 19.578327178955078\n",
      "Epoch: 24, Batch: 193, D Loss: 0.10368781674064809, G Loss: 19.835651397705078\n",
      "Epoch: 24, Batch: 194, D Loss: 0.09497960032034458, G Loss: 19.856014251708984\n",
      "Epoch: 24, Batch: 195, D Loss: 0.09490213667317349, G Loss: 19.776363372802734\n",
      "Epoch: 24, Batch: 196, D Loss: 0.09538608919801617, G Loss: 19.755355834960938\n",
      "Epoch: 24, Batch: 197, D Loss: 0.10032469150974821, G Loss: 19.98323631286621\n",
      "Epoch: 24, Batch: 198, D Loss: 0.09507855869675297, G Loss: 20.1364803314209\n",
      "Epoch: 24, Batch: 199, D Loss: 0.09949530745102786, G Loss: 20.266077041625977\n",
      "Epoch: 24, Batch: 200, D Loss: 0.09271381134581763, G Loss: 20.14396858215332\n",
      "Epoch: 24, Batch: 201, D Loss: 0.10385426960641747, G Loss: 20.311716079711914\n",
      "Epoch: 24, Batch: 202, D Loss: 0.09841112860816159, G Loss: 20.500757217407227\n",
      "Epoch: 24, Batch: 203, D Loss: 0.10021914599117804, G Loss: 20.661663055419922\n",
      "Epoch: 24, Batch: 204, D Loss: 0.1031791200197747, G Loss: 20.80778694152832\n",
      "Epoch: 24, Batch: 205, D Loss: 0.10154561743257867, G Loss: 20.855194091796875\n",
      "Epoch: 24, Batch: 206, D Loss: 0.09978919522664151, G Loss: 20.74674415588379\n",
      "Epoch: 24, Batch: 207, D Loss: 0.101426452896684, G Loss: 20.708507537841797\n",
      "Epoch: 24, Batch: 208, D Loss: 0.10124722175047823, G Loss: 20.665904998779297\n",
      "Epoch: 24, Batch: 209, D Loss: 0.09128867150728898, G Loss: 20.397563934326172\n",
      "Epoch: 24, Batch: 210, D Loss: 0.09772194995546835, G Loss: 20.282730102539062\n",
      "Epoch: 24, Batch: 211, D Loss: 0.09862542227948501, G Loss: 20.335906982421875\n",
      "Epoch: 24, Batch: 212, D Loss: 0.09464679735564685, G Loss: 20.24806785583496\n",
      "Epoch: 24, Batch: 213, D Loss: 0.10166539327785767, G Loss: 20.355817794799805\n",
      "Epoch: 24, Batch: 214, D Loss: 0.10846310916420604, G Loss: 20.629915237426758\n",
      "Epoch: 24, Batch: 215, D Loss: 0.09792847998044374, G Loss: 20.26091957092285\n",
      "Epoch: 24, Batch: 216, D Loss: 0.0968783733819234, G Loss: 19.39813995361328\n",
      "Epoch: 24, Batch: 217, D Loss: 0.09123306313181168, G Loss: 18.29344367980957\n",
      "Epoch: 24, Batch: 218, D Loss: 0.1025943218494918, G Loss: 18.241933822631836\n",
      "Epoch: 24, Batch: 219, D Loss: 0.09783508337299729, G Loss: 18.769668579101562\n",
      "Epoch: 24, Batch: 220, D Loss: 0.09836320840992063, G Loss: 19.33454132080078\n",
      "Epoch: 24, Batch: 221, D Loss: 0.10490363251144541, G Loss: 19.763864517211914\n",
      "Epoch: 24, Batch: 222, D Loss: 0.08956627739716971, G Loss: 19.0296573638916\n",
      "Epoch: 24, Batch: 223, D Loss: 0.10165041333212477, G Loss: 18.329736709594727\n",
      "Epoch: 24, Batch: 224, D Loss: 0.09644073967439848, G Loss: 17.814205169677734\n",
      "Epoch: 24, Batch: 225, D Loss: 0.09404281025807126, G Loss: 17.67547607421875\n",
      "Epoch: 24, Batch: 226, D Loss: 0.09975063874623036, G Loss: 18.155860900878906\n",
      "Epoch: 24, Batch: 227, D Loss: 0.10293463278565929, G Loss: 19.055118560791016\n",
      "Epoch: 24, Batch: 228, D Loss: 0.11134743097323418, G Loss: 20.10999870300293\n",
      "Epoch: 24, Batch: 229, D Loss: 0.10360640377812241, G Loss: 20.150197982788086\n",
      "Epoch: 24, Batch: 230, D Loss: 0.09761022189896429, G Loss: 19.041481018066406\n",
      "Epoch: 24, Batch: 231, D Loss: 0.09255026865898586, G Loss: 17.5628662109375\n",
      "Epoch: 24, Batch: 232, D Loss: 0.10377528329939079, G Loss: 17.381608963012695\n",
      "Epoch: 24, Batch: 233, D Loss: 0.10101717886248096, G Loss: 18.19762420654297\n",
      "Epoch: 24, Batch: 234, D Loss: 0.0956298897790937, G Loss: 19.05489158630371\n",
      "Epoch: 24, Batch: 235, D Loss: 0.09708940446039294, G Loss: 19.51425552368164\n",
      "Epoch: 24, Batch: 236, D Loss: 0.10641108594671256, G Loss: 19.836633682250977\n",
      "Epoch: 24, Batch: 237, D Loss: 0.10210029914395702, G Loss: 19.655391693115234\n",
      "Epoch: 24, Batch: 238, D Loss: 0.1010491122191044, G Loss: 19.122608184814453\n",
      "Epoch: 24, Batch: 239, D Loss: 0.09532349938349194, G Loss: 18.303560256958008\n",
      "Epoch: 24, Batch: 240, D Loss: 0.09536457780072016, G Loss: 17.839468002319336\n",
      "Epoch: 24, Batch: 241, D Loss: 0.09715128731166534, G Loss: 18.087875366210938\n",
      "Epoch: 24, Batch: 242, D Loss: 0.10504696205444164, G Loss: 18.99648094177246\n",
      "Epoch: 24, Batch: 243, D Loss: 0.09247683225755798, G Loss: 19.322107315063477\n",
      "Epoch: 24, Batch: 244, D Loss: 0.098304437854565, G Loss: 19.13286590576172\n",
      "Epoch: 24, Batch: 245, D Loss: 0.10327987650359827, G Loss: 18.9003963470459\n",
      "Epoch: 24, Batch: 246, D Loss: 0.10286568440880495, G Loss: 18.747703552246094\n",
      "Epoch: 24, Batch: 247, D Loss: 0.09532805979003145, G Loss: 18.342185974121094\n",
      "Epoch: 24, Batch: 248, D Loss: 0.1011836285047445, G Loss: 18.337709426879883\n",
      "Epoch: 24, Batch: 249, D Loss: 0.09935077771645062, G Loss: 18.529151916503906\n",
      "Epoch: 24, Batch: 250, D Loss: 0.09922764102699366, G Loss: 18.761423110961914\n",
      "Epoch: 24, Batch: 251, D Loss: 0.09473743668262857, G Loss: 18.64485740661621\n",
      "Epoch: 24, Batch: 252, D Loss: 0.10070848126639032, G Loss: 18.613327026367188\n",
      "Epoch: 24, Batch: 253, D Loss: 0.09855835555992254, G Loss: 18.597881317138672\n",
      "Epoch: 24, Batch: 254, D Loss: 0.10214779167658072, G Loss: 18.751474380493164\n",
      "Epoch: 24, Batch: 255, D Loss: 0.09498627869898701, G Loss: 18.616512298583984\n",
      "Epoch: 24, Batch: 256, D Loss: 0.0984968138565172, G Loss: 18.55328369140625\n",
      "Epoch: 24, Batch: 257, D Loss: 0.09810388527697356, G Loss: 18.548812866210938\n",
      "Epoch: 24, Batch: 258, D Loss: 0.10297252608537577, G Loss: 18.876850128173828\n",
      "Epoch: 24, Batch: 259, D Loss: 0.09399553705267216, G Loss: 18.8781795501709\n",
      "Epoch: 24, Batch: 260, D Loss: 0.09625243003917494, G Loss: 18.670896530151367\n",
      "Epoch: 24, Batch: 261, D Loss: 0.09977212932858315, G Loss: 18.696035385131836\n",
      "Epoch: 24, Batch: 262, D Loss: 0.10014457604583482, G Loss: 18.858667373657227\n",
      "Epoch: 24, Batch: 263, D Loss: 0.09574319748499738, G Loss: 18.839332580566406\n",
      "Epoch: 24, Batch: 264, D Loss: 0.09936346432170384, G Loss: 18.90242576599121\n",
      "Epoch: 24, Batch: 265, D Loss: 0.09726324259550712, G Loss: 18.79475212097168\n",
      "Epoch: 24, Batch: 266, D Loss: 0.09986070136440683, G Loss: 18.82986068725586\n",
      "Epoch: 24, Batch: 267, D Loss: 0.1035486934407539, G Loss: 19.18093490600586\n",
      "Epoch: 24, Batch: 268, D Loss: 0.0984844290021265, G Loss: 19.241870880126953\n",
      "Epoch: 24, Batch: 269, D Loss: 0.09903852136473223, G Loss: 19.07764434814453\n",
      "Epoch: 24, Batch: 270, D Loss: 0.09842818522882979, G Loss: 18.84969711303711\n",
      "Epoch: 24, Batch: 271, D Loss: 0.10025617806567566, G Loss: 18.847150802612305\n",
      "Epoch: 24, Batch: 272, D Loss: 0.0997361720355503, G Loss: 18.974485397338867\n",
      "Epoch: 24, Batch: 273, D Loss: 0.10216325765785306, G Loss: 19.28448486328125\n",
      "Epoch: 24, Batch: 274, D Loss: 0.10516401551775678, G Loss: 19.677080154418945\n",
      "Epoch: 24, Batch: 275, D Loss: 0.10278643058721659, G Loss: 19.763132095336914\n",
      "Epoch: 24, Batch: 276, D Loss: 0.10128503440437808, G Loss: 19.53069496154785\n",
      "Epoch: 24, Batch: 277, D Loss: 0.09732157219356496, G Loss: 18.919992446899414\n",
      "Epoch: 24, Batch: 278, D Loss: 0.10201578187226423, G Loss: 18.677907943725586\n",
      "Epoch: 24, Batch: 279, D Loss: 0.09588730750886132, G Loss: 18.54268455505371\n",
      "Epoch: 24, Batch: 280, D Loss: 0.09967069721348532, G Loss: 18.76813507080078\n",
      "Epoch: 24, Batch: 281, D Loss: 0.09917380210532234, G Loss: 19.113353729248047\n",
      "Epoch: 24, Batch: 282, D Loss: 0.09986601985559607, G Loss: 19.396442413330078\n",
      "Epoch: 24, Batch: 283, D Loss: 0.10525307218271851, G Loss: 19.72008514404297\n",
      "Epoch: 24, Batch: 284, D Loss: 0.09956857714370737, G Loss: 19.510417938232422\n",
      "Epoch: 24, Batch: 285, D Loss: 0.09969762181018926, G Loss: 19.05896759033203\n",
      "Epoch: 24, Batch: 286, D Loss: 0.09758177739197915, G Loss: 18.583988189697266\n",
      "Epoch: 24, Batch: 287, D Loss: 0.09372132792601429, G Loss: 18.197404861450195\n",
      "Epoch: 24, Batch: 288, D Loss: 0.10469256828142326, G Loss: 18.675039291381836\n",
      "Epoch: 24, Batch: 289, D Loss: 0.10299550247133715, G Loss: 19.509458541870117\n",
      "Epoch: 24, Batch: 290, D Loss: 0.10026577252211943, G Loss: 19.89877700805664\n",
      "Epoch: 24, Batch: 291, D Loss: 0.1017309886752642, G Loss: 19.731477737426758\n",
      "Epoch: 24, Batch: 292, D Loss: 0.10025774122932007, G Loss: 19.17698097229004\n",
      "Epoch: 24, Batch: 293, D Loss: 0.09865546548535398, G Loss: 18.578441619873047\n",
      "Epoch: 24, Batch: 294, D Loss: 0.09603738570220655, G Loss: 18.168371200561523\n",
      "Epoch: 24, Batch: 295, D Loss: 0.10159577977016498, G Loss: 18.477094650268555\n",
      "Epoch: 24, Batch: 296, D Loss: 0.09941055976579682, G Loss: 19.043790817260742\n",
      "Epoch: 24, Batch: 297, D Loss: 0.09954536932021263, G Loss: 19.371488571166992\n",
      "Epoch: 24, Batch: 298, D Loss: 0.0968439228235296, G Loss: 19.147119522094727\n",
      "Epoch: 24, Batch: 299, D Loss: 0.10552717267657297, G Loss: 18.95775032043457\n",
      "Epoch: 24, Batch: 300, D Loss: 0.09671070053750386, G Loss: 18.49993896484375\n",
      "Epoch: 24, Batch: 301, D Loss: 0.10048176871631398, G Loss: 18.264934539794922\n",
      "Epoch: 24, Batch: 302, D Loss: 0.09742759820083036, G Loss: 18.06052017211914\n",
      "Epoch: 24, Batch: 303, D Loss: 0.0962915271055027, G Loss: 18.00272560119629\n",
      "Epoch: 24, Batch: 304, D Loss: 0.10402688994926734, G Loss: 18.42092514038086\n",
      "Epoch: 24, Batch: 305, D Loss: 0.09628108630071974, G Loss: 18.475873947143555\n",
      "Epoch: 24, Batch: 306, D Loss: 0.09781989977015337, G Loss: 18.292545318603516\n",
      "Epoch: 24, Batch: 307, D Loss: 0.10111496465591552, G Loss: 18.151620864868164\n",
      "Epoch: 24, Batch: 308, D Loss: 0.09426094638580462, G Loss: 17.793149948120117\n",
      "Epoch: 24, Batch: 309, D Loss: 0.09868685399541999, G Loss: 17.695568084716797\n",
      "Epoch: 24, Batch: 310, D Loss: 0.10394249923199705, G Loss: 18.15631866455078\n",
      "Epoch: 24, Batch: 311, D Loss: 0.10451360514285657, G Loss: 18.787826538085938\n",
      "Epoch: 24, Batch: 312, D Loss: 0.10017311921274086, G Loss: 18.779176712036133\n",
      "Epoch: 24, Batch: 313, D Loss: 0.09667175769924485, G Loss: 18.074871063232422\n",
      "Epoch: 24, Batch: 314, D Loss: 0.09734846250559315, G Loss: 17.256742477416992\n",
      "Epoch: 24, Batch: 315, D Loss: 0.09866391516417572, G Loss: 16.957103729248047\n",
      "Epoch: 24, Batch: 316, D Loss: 0.10002552340974447, G Loss: 17.25300407409668\n",
      "Epoch: 24, Batch: 317, D Loss: 0.09826504899802657, G Loss: 17.804452896118164\n",
      "Epoch: 24, Batch: 318, D Loss: 0.09915982164549897, G Loss: 18.278242111206055\n",
      "Epoch: 24, Batch: 319, D Loss: 0.10452159953924633, G Loss: 18.71042251586914\n",
      "Epoch: 24, Batch: 320, D Loss: 0.09704155168491857, G Loss: 18.410491943359375\n",
      "Epoch: 24, Batch: 321, D Loss: 0.10517474074463973, G Loss: 18.232614517211914\n",
      "Epoch: 24, Batch: 322, D Loss: 0.10360613333192159, G Loss: 18.206188201904297\n",
      "Epoch: 24, Batch: 323, D Loss: 0.09527431401109077, G Loss: 17.930261611938477\n",
      "Epoch: 24, Batch: 324, D Loss: 0.10399212655176537, G Loss: 18.19408416748047\n",
      "Epoch: 24, Batch: 325, D Loss: 0.10247485826702585, G Loss: 18.67719268798828\n",
      "Epoch: 24, Batch: 326, D Loss: 0.10548983792491984, G Loss: 19.30441665649414\n",
      "Epoch: 24, Batch: 327, D Loss: 0.10149645258318718, G Loss: 19.3862361907959\n",
      "Epoch: 24, Batch: 328, D Loss: 0.09691275910287933, G Loss: 18.83808135986328\n",
      "Epoch: 24, Batch: 329, D Loss: 0.09557387714688881, G Loss: 18.116418838500977\n",
      "Epoch: 24, Batch: 330, D Loss: 0.10296071267162432, G Loss: 18.082277297973633\n",
      "Epoch: 24, Batch: 331, D Loss: 0.1022432500220063, G Loss: 18.590394973754883\n",
      "Epoch: 24, Batch: 332, D Loss: 0.10261567245267034, G Loss: 19.189205169677734\n",
      "Epoch: 24, Batch: 333, D Loss: 0.10735254163577901, G Loss: 19.737144470214844\n",
      "Epoch: 24, Batch: 334, D Loss: 0.09313379415250611, G Loss: 19.104251861572266\n",
      "Epoch: 24, Batch: 335, D Loss: 0.09947678099053592, G Loss: 18.242197036743164\n",
      "Epoch: 24, Batch: 336, D Loss: 0.09314982747298561, G Loss: 17.469297409057617\n",
      "Epoch: 24, Batch: 337, D Loss: 0.09965298134374301, G Loss: 17.469039916992188\n",
      "Epoch: 24, Batch: 338, D Loss: 0.0926664360409033, G Loss: 17.745616912841797\n",
      "Epoch: 24, Batch: 339, D Loss: 0.10188431192035496, G Loss: 18.548084259033203\n",
      "Epoch: 24, Batch: 340, D Loss: 0.09827210349355653, G Loss: 19.038427352905273\n",
      "Epoch: 24, Batch: 341, D Loss: 0.10204449541811922, G Loss: 19.215028762817383\n",
      "Epoch: 24, Batch: 342, D Loss: 0.0955195532557509, G Loss: 18.607528686523438\n",
      "Epoch: 24, Batch: 343, D Loss: 0.09521513328630071, G Loss: 17.78032875061035\n",
      "Epoch: 24, Batch: 344, D Loss: 0.09956417583146493, G Loss: 17.512535095214844\n",
      "Epoch: 24, Batch: 345, D Loss: 0.095482063082037, G Loss: 17.627622604370117\n",
      "Epoch: 24, Batch: 346, D Loss: 0.09724037462549795, G Loss: 18.111679077148438\n",
      "Epoch: 24, Batch: 347, D Loss: 0.09758397708706124, G Loss: 18.63765525817871\n",
      "Epoch: 24, Batch: 348, D Loss: 0.09516651572983248, G Loss: 18.70151138305664\n",
      "Epoch: 24, Batch: 349, D Loss: 0.10255189602916914, G Loss: 18.778648376464844\n",
      "Epoch: 24, Batch: 350, D Loss: 0.105838681949324, G Loss: 18.964740753173828\n",
      "Epoch: 24, Batch: 351, D Loss: 0.10598467543499734, G Loss: 19.22587776184082\n",
      "Epoch: 24, Batch: 352, D Loss: 0.10029742377095285, G Loss: 18.973520278930664\n",
      "Epoch: 24, Batch: 353, D Loss: 0.1026633267861159, G Loss: 18.600610733032227\n",
      "Epoch: 24, Batch: 354, D Loss: 0.10162023933429509, G Loss: 18.34449577331543\n",
      "Epoch: 24, Batch: 355, D Loss: 0.09960989475140547, G Loss: 18.256303787231445\n",
      "Epoch: 24, Batch: 356, D Loss: 0.09997048014649579, G Loss: 18.45827865600586\n",
      "Epoch: 24, Batch: 357, D Loss: 0.09419011057238302, G Loss: 18.47639274597168\n",
      "Epoch: 24, Batch: 358, D Loss: 0.10302914319206335, G Loss: 18.867990493774414\n",
      "Epoch: 24, Batch: 359, D Loss: 0.09803628469475867, G Loss: 19.035018920898438\n",
      "Epoch: 24, Batch: 360, D Loss: 0.09615144421792632, G Loss: 18.915861129760742\n",
      "Epoch: 24, Batch: 361, D Loss: 0.09936485019629204, G Loss: 18.79437828063965\n",
      "Epoch: 24, Batch: 362, D Loss: 0.0970783866336562, G Loss: 18.676660537719727\n",
      "Epoch: 24, Batch: 363, D Loss: 0.0998408830442965, G Loss: 18.81439781188965\n",
      "Epoch: 24, Batch: 364, D Loss: 0.09603496980997228, G Loss: 18.800601959228516\n",
      "Epoch: 24, Batch: 365, D Loss: 0.09644180867141561, G Loss: 18.86511993408203\n",
      "Epoch: 24, Batch: 366, D Loss: 0.094557929359812, G Loss: 18.8114013671875\n",
      "Epoch: 24, Batch: 367, D Loss: 0.10017080904490738, G Loss: 19.044681549072266\n",
      "Epoch: 24, Batch: 368, D Loss: 0.10294573215577074, G Loss: 19.53927993774414\n",
      "Epoch: 24, Batch: 369, D Loss: 0.09624941063953807, G Loss: 19.556644439697266\n",
      "Epoch: 24, Batch: 370, D Loss: 0.0944518317769365, G Loss: 19.153051376342773\n",
      "Epoch: 24, Batch: 371, D Loss: 0.10092520971151142, G Loss: 19.024803161621094\n",
      "Epoch: 24, Batch: 372, D Loss: 0.10035464410544437, G Loss: 19.24964714050293\n",
      "Epoch: 24, Batch: 373, D Loss: 0.0956026186682859, G Loss: 19.41621971130371\n",
      "Epoch: 24, Batch: 374, D Loss: 0.0981433258570441, G Loss: 19.689208984375\n",
      "Epoch: 24, Batch: 375, D Loss: 0.1049873913757684, G Loss: 20.268848419189453\n",
      "Epoch: 24, Batch: 376, D Loss: 0.09992683004719866, G Loss: 20.468929290771484\n",
      "Epoch: 24, Batch: 377, D Loss: 0.1037728047932765, G Loss: 20.44751739501953\n",
      "Epoch: 24, Batch: 378, D Loss: 0.10182282402791437, G Loss: 20.222078323364258\n",
      "Epoch: 24, Batch: 379, D Loss: 0.09724930034989498, G Loss: 19.74259376525879\n",
      "Epoch: 24, Batch: 380, D Loss: 0.0959445701573175, G Loss: 19.346343994140625\n",
      "Epoch: 24, Batch: 381, D Loss: 0.0995790827054388, G Loss: 19.56576156616211\n",
      "Epoch: 24, Batch: 382, D Loss: 0.0999189776025079, G Loss: 20.139240264892578\n",
      "Epoch: 24, Batch: 383, D Loss: 0.10418446421679955, G Loss: 20.913007736206055\n",
      "Epoch: 24, Batch: 384, D Loss: 0.10226285493040677, G Loss: 21.207983016967773\n",
      "Epoch: 24, Batch: 385, D Loss: 0.09919281345654668, G Loss: 20.629779815673828\n",
      "Epoch: 24, Batch: 386, D Loss: 0.09703144521951157, G Loss: 19.67081069946289\n",
      "Epoch: 24, Batch: 387, D Loss: 0.10115245171672727, G Loss: 19.163814544677734\n",
      "Epoch: 24, Batch: 388, D Loss: 0.09864373746115107, G Loss: 19.139787673950195\n",
      "Epoch: 24, Batch: 389, D Loss: 0.09914227030976197, G Loss: 19.50597381591797\n",
      "Epoch: 24, Batch: 390, D Loss: 0.10422984629634802, G Loss: 20.171358108520508\n",
      "Epoch: 24, Batch: 391, D Loss: 0.10187307075307, G Loss: 20.447370529174805\n",
      "Epoch: 24, Batch: 392, D Loss: 0.09947471402650593, G Loss: 20.032264709472656\n",
      "Epoch: 24, Batch: 393, D Loss: 0.10101499546969028, G Loss: 19.408933639526367\n",
      "Epoch: 24, Batch: 394, D Loss: 0.09703313078196962, G Loss: 18.7448787689209\n",
      "Epoch: 24, Batch: 395, D Loss: 0.09864297922961418, G Loss: 18.490497589111328\n",
      "Epoch: 24, Batch: 396, D Loss: 0.0994580875390687, G Loss: 18.769935607910156\n",
      "Epoch: 24, Batch: 397, D Loss: 0.09946550703973656, G Loss: 19.24204444885254\n",
      "Epoch: 24, Batch: 398, D Loss: 0.092406021891553, G Loss: 19.138980865478516\n",
      "Epoch: 24, Batch: 399, D Loss: 0.09906668488174075, G Loss: 18.930906295776367\n",
      "Epoch: 24, Batch: 400, D Loss: 0.09870421475702718, G Loss: 18.727855682373047\n",
      "Epoch: 24, Batch: 401, D Loss: 0.10115855554206354, G Loss: 18.733489990234375\n",
      "Epoch: 24, Batch: 402, D Loss: 0.09871717174304617, G Loss: 18.677776336669922\n",
      "Epoch: 24, Batch: 403, D Loss: 0.09936738410036661, G Loss: 18.63522720336914\n",
      "Epoch: 24, Batch: 404, D Loss: 0.09941558189153143, G Loss: 18.680660247802734\n",
      "Epoch: 24, Batch: 405, D Loss: 0.09374972141579319, G Loss: 18.37286376953125\n",
      "Epoch: 24, Batch: 406, D Loss: 0.09427820782908247, G Loss: 18.006847381591797\n",
      "Epoch: 24, Batch: 407, D Loss: 0.0968544633351458, G Loss: 18.00994300842285\n",
      "Epoch: 24, Batch: 408, D Loss: 0.08987342604244208, G Loss: 17.94200325012207\n",
      "Epoch: 24, Batch: 409, D Loss: 0.10459891487911044, G Loss: 18.755325317382812\n",
      "Epoch: 24, Batch: 410, D Loss: 0.0950342891941085, G Loss: 19.212461471557617\n",
      "Epoch: 24, Batch: 411, D Loss: 0.09960004894844077, G Loss: 19.37984275817871\n",
      "Epoch: 24, Batch: 412, D Loss: 0.09983721589317485, G Loss: 19.172075271606445\n",
      "Epoch: 24, Batch: 413, D Loss: 0.09441870034329103, G Loss: 18.54347801208496\n",
      "Epoch: 24, Batch: 414, D Loss: 0.1038610905523023, G Loss: 18.520370483398438\n",
      "Epoch: 24, Batch: 415, D Loss: 0.10749781448289575, G Loss: 19.199888229370117\n",
      "Epoch: 24, Batch: 416, D Loss: 0.10156601856500913, G Loss: 19.56691551208496\n",
      "Epoch: 24, Batch: 417, D Loss: 0.09621155456185737, G Loss: 19.186016082763672\n",
      "Epoch: 24, Batch: 418, D Loss: 0.09818665253223768, G Loss: 18.610029220581055\n",
      "Epoch: 24, Batch: 419, D Loss: 0.09733094781866924, G Loss: 18.226303100585938\n",
      "Epoch: 24, Batch: 420, D Loss: 0.10287698852481464, G Loss: 18.62023162841797\n",
      "Epoch: 24, Batch: 421, D Loss: 0.09697337782646542, G Loss: 19.008867263793945\n",
      "Epoch: 24, Batch: 422, D Loss: 0.0963033686686563, G Loss: 19.176406860351562\n",
      "Epoch: 24, Batch: 423, D Loss: 0.09719003978308649, G Loss: 19.12577247619629\n",
      "Epoch: 24, Batch: 424, D Loss: 0.09827187915247637, G Loss: 19.045316696166992\n",
      "Epoch: 24, Batch: 425, D Loss: 0.10478864840503599, G Loss: 19.33234977722168\n",
      "Epoch: 24, Batch: 426, D Loss: 0.10441106721531557, G Loss: 19.722105026245117\n",
      "Epoch: 24, Batch: 427, D Loss: 0.1006268276919281, G Loss: 19.661149978637695\n",
      "Epoch: 24, Batch: 428, D Loss: 0.09993437855958409, G Loss: 19.263200759887695\n",
      "Epoch: 24, Batch: 429, D Loss: 0.0939785423781927, G Loss: 18.469493865966797\n",
      "Epoch: 24, Batch: 430, D Loss: 0.09839012309514139, G Loss: 18.094911575317383\n",
      "Epoch: 24, Batch: 431, D Loss: 0.09794565160622604, G Loss: 18.32219886779785\n",
      "Epoch: 24, Batch: 432, D Loss: 0.09637143143229654, G Loss: 18.81788444519043\n",
      "Epoch: 24, Batch: 433, D Loss: 0.0933561206406206, G Loss: 19.013580322265625\n",
      "Epoch: 24, Batch: 434, D Loss: 0.10058895005309076, G Loss: 19.191232681274414\n",
      "Epoch: 24, Batch: 435, D Loss: 0.1057410109995236, G Loss: 19.582637786865234\n",
      "Epoch: 24, Batch: 436, D Loss: 0.09864204533285503, G Loss: 19.584503173828125\n",
      "Epoch: 24, Batch: 437, D Loss: 0.09786847430980172, G Loss: 19.140714645385742\n",
      "Epoch: 24, Batch: 438, D Loss: 0.10187980053060586, G Loss: 18.976709365844727\n",
      "Epoch: 24, Batch: 439, D Loss: 0.10001839970987403, G Loss: 19.067102432250977\n",
      "Epoch: 24, Batch: 440, D Loss: 0.10242933245354768, G Loss: 19.483705520629883\n",
      "Epoch: 24, Batch: 441, D Loss: 0.09575534780158579, G Loss: 19.534610748291016\n",
      "Epoch: 24, Batch: 442, D Loss: 0.10258703825160864, G Loss: 19.75372886657715\n",
      "Epoch: 24, Batch: 443, D Loss: 0.09919029606131058, G Loss: 19.753889083862305\n",
      "Epoch: 24, Batch: 444, D Loss: 0.09713871929815077, G Loss: 19.474084854125977\n",
      "Epoch: 24, Batch: 445, D Loss: 0.09506292852138443, G Loss: 19.112634658813477\n",
      "Epoch: 24, Batch: 446, D Loss: 0.09929220610538447, G Loss: 19.256988525390625\n",
      "Epoch: 24, Batch: 447, D Loss: 0.09960585264249056, G Loss: 19.644588470458984\n",
      "Epoch: 24, Batch: 448, D Loss: 0.09945452328672588, G Loss: 20.10546112060547\n",
      "Epoch: 24, Batch: 449, D Loss: 0.09382468559705881, G Loss: 20.006622314453125\n",
      "Epoch: 24, Batch: 450, D Loss: 0.10692088386377069, G Loss: 20.465835571289062\n",
      "Epoch: 24, Batch: 451, D Loss: 0.09897628486005305, G Loss: 20.626277923583984\n",
      "Epoch: 24, Batch: 452, D Loss: 0.10389100064720946, G Loss: 20.82801055908203\n",
      "Epoch: 24, Batch: 453, D Loss: 0.10297191184543486, G Loss: 20.982908248901367\n",
      "Epoch: 24, Batch: 454, D Loss: 0.10306124427929256, G Loss: 20.973743438720703\n",
      "Epoch: 24, Batch: 455, D Loss: 0.10173410219665088, G Loss: 20.809675216674805\n",
      "Epoch: 24, Batch: 456, D Loss: 0.09615995047523318, G Loss: 20.374679565429688\n",
      "Epoch: 24, Batch: 457, D Loss: 0.10070557965435117, G Loss: 20.315431594848633\n",
      "Epoch: 24, Batch: 458, D Loss: 0.1042272305324724, G Loss: 20.8094482421875\n",
      "Epoch: 24, Batch: 459, D Loss: 0.10382512246078698, G Loss: 21.362424850463867\n",
      "Epoch: 24, Batch: 460, D Loss: 0.09145674142230567, G Loss: 20.950057983398438\n",
      "Epoch: 24, Batch: 461, D Loss: 0.10092723418213789, G Loss: 20.572757720947266\n",
      "Epoch: 24, Batch: 462, D Loss: 0.09487917345306779, G Loss: 20.190961837768555\n",
      "Epoch: 24, Batch: 463, D Loss: 0.09547560756252749, G Loss: 19.998825073242188\n",
      "Epoch: 24, Batch: 464, D Loss: 0.10286292516981627, G Loss: 20.40662956237793\n",
      "Epoch: 24, Batch: 465, D Loss: 0.1018285905077067, G Loss: 21.11615753173828\n",
      "Epoch: 24, Batch: 466, D Loss: 0.09552769395926505, G Loss: 21.15932846069336\n",
      "Epoch: 24, Batch: 467, D Loss: 0.10071032531643903, G Loss: 20.885744094848633\n",
      "Epoch: 25, Batch: 0, D Loss: 0.09840465392327352, G Loss: 20.385465621948242\n",
      "Epoch: 25, Batch: 1, D Loss: 0.10017275891630467, G Loss: 20.101760864257812\n",
      "Epoch: 25, Batch: 2, D Loss: 0.1039140083209642, G Loss: 20.44686508178711\n",
      "Epoch: 25, Batch: 3, D Loss: 0.09436558996723843, G Loss: 20.483943939208984\n",
      "Epoch: 25, Batch: 4, D Loss: 0.09979221285830064, G Loss: 20.559797286987305\n",
      "Epoch: 25, Batch: 5, D Loss: 0.10012923236636201, G Loss: 20.66975975036621\n",
      "Epoch: 25, Batch: 6, D Loss: 0.10559919519479105, G Loss: 21.05954933166504\n",
      "Epoch: 25, Batch: 7, D Loss: 0.10340173573117645, G Loss: 21.35249137878418\n",
      "Epoch: 25, Batch: 8, D Loss: 0.09815716773919841, G Loss: 21.099071502685547\n",
      "Epoch: 25, Batch: 9, D Loss: 0.09799473032541742, G Loss: 20.58930778503418\n",
      "Epoch: 25, Batch: 10, D Loss: 0.09643808077629668, G Loss: 20.193876266479492\n",
      "Epoch: 25, Batch: 11, D Loss: 0.09917814362461391, G Loss: 20.357728958129883\n",
      "Epoch: 25, Batch: 12, D Loss: 0.09327749970860277, G Loss: 20.616775512695312\n",
      "Epoch: 25, Batch: 13, D Loss: 0.103563979639053, G Loss: 21.386091232299805\n",
      "Epoch: 25, Batch: 14, D Loss: 0.10224854219011593, G Loss: 22.075645446777344\n",
      "Epoch: 25, Batch: 15, D Loss: 0.09639428572797698, G Loss: 21.575960159301758\n",
      "Epoch: 25, Batch: 16, D Loss: 0.098006308423222, G Loss: 20.66330337524414\n",
      "Epoch: 25, Batch: 17, D Loss: 0.10749256672098301, G Loss: 20.39285659790039\n",
      "Epoch: 25, Batch: 18, D Loss: 0.09430597808824398, G Loss: 19.983896255493164\n",
      "Epoch: 25, Batch: 19, D Loss: 0.10090638804519714, G Loss: 19.937089920043945\n",
      "Epoch: 25, Batch: 20, D Loss: 0.09027055789045679, G Loss: 19.500919342041016\n",
      "Epoch: 25, Batch: 21, D Loss: 0.10102413007115518, G Loss: 19.644670486450195\n",
      "Epoch: 25, Batch: 22, D Loss: 0.10698934740742583, G Loss: 20.44828224182129\n",
      "Epoch: 25, Batch: 23, D Loss: 0.10235036961789296, G Loss: 20.888872146606445\n",
      "Epoch: 25, Batch: 24, D Loss: 0.09556096849666484, G Loss: 20.310693740844727\n",
      "Epoch: 25, Batch: 25, D Loss: 0.09858545775727923, G Loss: 19.514875411987305\n",
      "Epoch: 25, Batch: 26, D Loss: 0.09596845732832082, G Loss: 18.950767517089844\n",
      "Epoch: 25, Batch: 27, D Loss: 0.10241648800593262, G Loss: 19.293577194213867\n",
      "Epoch: 25, Batch: 28, D Loss: 0.0943749862013884, G Loss: 19.68701934814453\n",
      "Epoch: 25, Batch: 29, D Loss: 0.09874032546936562, G Loss: 20.17291259765625\n",
      "Epoch: 25, Batch: 30, D Loss: 0.09457010117437248, G Loss: 20.1734561920166\n",
      "Epoch: 25, Batch: 31, D Loss: 0.09423010901159168, G Loss: 19.811138153076172\n",
      "Epoch: 25, Batch: 32, D Loss: 0.09575992968080438, G Loss: 19.515989303588867\n",
      "Epoch: 25, Batch: 33, D Loss: 0.10061828192284461, G Loss: 19.78438377380371\n",
      "Epoch: 25, Batch: 34, D Loss: 0.09789811925284164, G Loss: 20.150062561035156\n",
      "Epoch: 25, Batch: 35, D Loss: 0.09921707284557663, G Loss: 20.556758880615234\n",
      "Epoch: 25, Batch: 36, D Loss: 0.10043445282182306, G Loss: 20.77552604675293\n",
      "Epoch: 25, Batch: 37, D Loss: 0.10553197604112782, G Loss: 21.034170150756836\n",
      "Epoch: 25, Batch: 38, D Loss: 0.10191299058163925, G Loss: 21.019832611083984\n",
      "Epoch: 25, Batch: 39, D Loss: 0.09806840167616182, G Loss: 20.61996841430664\n",
      "Epoch: 25, Batch: 40, D Loss: 0.09427082612427617, G Loss: 20.075246810913086\n",
      "Epoch: 25, Batch: 41, D Loss: 0.10320418416296973, G Loss: 20.22748374938965\n",
      "Epoch: 25, Batch: 42, D Loss: 0.10029783907842821, G Loss: 20.733890533447266\n",
      "Epoch: 25, Batch: 43, D Loss: 0.09404022290408445, G Loss: 20.96505355834961\n",
      "Epoch: 25, Batch: 44, D Loss: 0.0944195543064223, G Loss: 20.79006576538086\n",
      "Epoch: 25, Batch: 45, D Loss: 0.09757768415403179, G Loss: 20.56560707092285\n",
      "Epoch: 25, Batch: 46, D Loss: 0.09929139225164474, G Loss: 20.58041000366211\n",
      "Epoch: 25, Batch: 47, D Loss: 0.10183992285948129, G Loss: 20.886882781982422\n",
      "Epoch: 25, Batch: 48, D Loss: 0.09316791639698849, G Loss: 20.748563766479492\n",
      "Epoch: 25, Batch: 49, D Loss: 0.10795948694312951, G Loss: 21.12933349609375\n",
      "Epoch: 25, Batch: 50, D Loss: 0.09720151160919288, G Loss: 21.061092376708984\n",
      "Epoch: 25, Batch: 51, D Loss: 0.09770487292439142, G Loss: 20.68242073059082\n",
      "Epoch: 25, Batch: 52, D Loss: 0.10023277313293161, G Loss: 20.401918411254883\n",
      "Epoch: 25, Batch: 53, D Loss: 0.09555570860654294, G Loss: 20.13344955444336\n",
      "Epoch: 25, Batch: 54, D Loss: 0.10519288551875738, G Loss: 20.571779251098633\n",
      "Epoch: 25, Batch: 55, D Loss: 0.09761409512578995, G Loss: 20.81912612915039\n",
      "Epoch: 25, Batch: 56, D Loss: 0.10195103330619668, G Loss: 20.92731285095215\n",
      "Epoch: 25, Batch: 57, D Loss: 0.10212846887792085, G Loss: 20.85301399230957\n",
      "Epoch: 25, Batch: 58, D Loss: 0.10074226610769932, G Loss: 20.511632919311523\n",
      "Epoch: 25, Batch: 59, D Loss: 0.10094754470800482, G Loss: 20.196674346923828\n",
      "Epoch: 25, Batch: 60, D Loss: 0.10005563589435806, G Loss: 20.041349411010742\n",
      "Epoch: 25, Batch: 61, D Loss: 0.10391776349438125, G Loss: 20.312965393066406\n",
      "Epoch: 25, Batch: 62, D Loss: 0.10062287071013121, G Loss: 20.50273895263672\n",
      "Epoch: 25, Batch: 63, D Loss: 0.09938795185450855, G Loss: 20.396743774414062\n",
      "Epoch: 25, Batch: 64, D Loss: 0.10364247184774933, G Loss: 20.34300994873047\n",
      "Epoch: 25, Batch: 65, D Loss: 0.0975322583325301, G Loss: 19.959716796875\n",
      "Epoch: 25, Batch: 66, D Loss: 0.09841071946085778, G Loss: 19.56937026977539\n",
      "Epoch: 25, Batch: 67, D Loss: 0.09649831243068019, G Loss: 19.26165008544922\n",
      "Epoch: 25, Batch: 68, D Loss: 0.1019110697850435, G Loss: 19.582244873046875\n",
      "Epoch: 25, Batch: 69, D Loss: 0.10390094773395109, G Loss: 20.32659339904785\n",
      "Epoch: 25, Batch: 70, D Loss: 0.09597627888482413, G Loss: 20.44420623779297\n",
      "Epoch: 25, Batch: 71, D Loss: 0.09400366333113569, G Loss: 19.934337615966797\n",
      "Epoch: 25, Batch: 72, D Loss: 0.10687856481311342, G Loss: 20.021705627441406\n",
      "Epoch: 25, Batch: 73, D Loss: 0.09639766169615216, G Loss: 19.99411964416504\n",
      "Epoch: 25, Batch: 74, D Loss: 0.09228935960805695, G Loss: 19.66841697692871\n",
      "Epoch: 25, Batch: 75, D Loss: 0.09600159666841934, G Loss: 19.70400047302246\n",
      "Epoch: 25, Batch: 76, D Loss: 0.09610983844629817, G Loss: 20.05428123474121\n",
      "Epoch: 25, Batch: 77, D Loss: 0.10640963967954115, G Loss: 21.111907958984375\n",
      "Epoch: 25, Batch: 78, D Loss: 0.09703482714271236, G Loss: 21.558347702026367\n",
      "Epoch: 25, Batch: 79, D Loss: 0.1051838399914062, G Loss: 21.776180267333984\n",
      "Epoch: 25, Batch: 80, D Loss: 0.10149514695298967, G Loss: 21.50123405456543\n",
      "Epoch: 25, Batch: 81, D Loss: 0.09966762394098908, G Loss: 20.980743408203125\n",
      "Epoch: 25, Batch: 82, D Loss: 0.09454970860154938, G Loss: 20.368717193603516\n",
      "Epoch: 25, Batch: 83, D Loss: 0.09983620116631037, G Loss: 20.4290828704834\n",
      "Epoch: 25, Batch: 84, D Loss: 0.10337904144099885, G Loss: 21.04730987548828\n",
      "Epoch: 25, Batch: 85, D Loss: 0.10144800718713695, G Loss: 21.678733825683594\n",
      "Epoch: 25, Batch: 86, D Loss: 0.09845624884013858, G Loss: 21.612730026245117\n",
      "Epoch: 25, Batch: 87, D Loss: 0.10056391384729407, G Loss: 21.139070510864258\n",
      "Epoch: 25, Batch: 88, D Loss: 0.09727038491546369, G Loss: 20.408992767333984\n",
      "Epoch: 25, Batch: 89, D Loss: 0.09784172564871096, G Loss: 19.89898681640625\n",
      "Epoch: 25, Batch: 90, D Loss: 0.09833506615555254, G Loss: 19.789852142333984\n",
      "Epoch: 25, Batch: 91, D Loss: 0.10460136175124474, G Loss: 20.458572387695312\n",
      "Epoch: 25, Batch: 92, D Loss: 0.0959971254825005, G Loss: 20.705604553222656\n",
      "Epoch: 25, Batch: 93, D Loss: 0.10174547187157457, G Loss: 20.689634323120117\n",
      "Epoch: 25, Batch: 94, D Loss: 0.09860773450911159, G Loss: 20.21640396118164\n",
      "Epoch: 25, Batch: 95, D Loss: 0.09267120944163454, G Loss: 19.279115676879883\n",
      "Epoch: 25, Batch: 96, D Loss: 0.09780408715924094, G Loss: 18.792423248291016\n",
      "Epoch: 25, Batch: 97, D Loss: 0.0990506292060016, G Loss: 19.02840232849121\n",
      "Epoch: 25, Batch: 98, D Loss: 0.09753886820250735, G Loss: 19.52228546142578\n",
      "Epoch: 25, Batch: 99, D Loss: 0.09523444766346345, G Loss: 19.80022430419922\n",
      "Epoch: 25, Batch: 100, D Loss: 0.10618627167274908, G Loss: 20.316299438476562\n",
      "Epoch: 25, Batch: 101, D Loss: 0.09923401555042216, G Loss: 20.194791793823242\n",
      "Epoch: 25, Batch: 102, D Loss: 0.09488139430558151, G Loss: 19.396257400512695\n",
      "Epoch: 25, Batch: 103, D Loss: 0.09912630420018176, G Loss: 18.86433982849121\n",
      "Epoch: 25, Batch: 104, D Loss: 0.10120560520912858, G Loss: 19.044397354125977\n",
      "Epoch: 25, Batch: 105, D Loss: 0.09057288124448304, G Loss: 19.15802574157715\n",
      "Epoch: 25, Batch: 106, D Loss: 0.09349372468660966, G Loss: 19.227693557739258\n",
      "Epoch: 25, Batch: 107, D Loss: 0.09343851578285478, G Loss: 19.25043296813965\n",
      "Epoch: 25, Batch: 108, D Loss: 0.09878260833740349, G Loss: 19.49873161315918\n",
      "Epoch: 25, Batch: 109, D Loss: 0.0989199743071364, G Loss: 19.701303482055664\n",
      "Epoch: 25, Batch: 110, D Loss: 0.10463364539209496, G Loss: 20.02978515625\n",
      "Epoch: 25, Batch: 111, D Loss: 0.09762913099482307, G Loss: 19.835777282714844\n",
      "Epoch: 25, Batch: 112, D Loss: 0.0980310456257718, G Loss: 19.289060592651367\n",
      "Epoch: 25, Batch: 113, D Loss: 0.10420168424170217, G Loss: 19.091373443603516\n",
      "Epoch: 25, Batch: 114, D Loss: 0.0928745226626766, G Loss: 18.704843521118164\n",
      "Epoch: 25, Batch: 115, D Loss: 0.09833792224711324, G Loss: 18.725351333618164\n",
      "Epoch: 25, Batch: 116, D Loss: 0.10253122721616537, G Loss: 19.29905128479004\n",
      "Epoch: 25, Batch: 117, D Loss: 0.09302720623384997, G Loss: 19.41183090209961\n",
      "Epoch: 25, Batch: 118, D Loss: 0.1000447440278589, G Loss: 19.469518661499023\n",
      "Epoch: 25, Batch: 119, D Loss: 0.10215614154769415, G Loss: 19.598575592041016\n",
      "Epoch: 25, Batch: 120, D Loss: 0.10367630561366048, G Loss: 19.790138244628906\n",
      "Epoch: 25, Batch: 121, D Loss: 0.09594604516361516, G Loss: 19.561988830566406\n",
      "Epoch: 25, Batch: 122, D Loss: 0.09679880192938439, G Loss: 19.137453079223633\n",
      "Epoch: 25, Batch: 123, D Loss: 0.09075909432368667, G Loss: 18.597858428955078\n",
      "Epoch: 25, Batch: 124, D Loss: 0.09761433700794342, G Loss: 18.69975471496582\n",
      "Epoch: 25, Batch: 125, D Loss: 0.09882475702949756, G Loss: 19.360597610473633\n",
      "Epoch: 25, Batch: 126, D Loss: 0.1021977376926706, G Loss: 20.298965454101562\n",
      "Epoch: 25, Batch: 127, D Loss: 0.10022418261622629, G Loss: 20.738719940185547\n",
      "Epoch: 25, Batch: 128, D Loss: 0.09698583249111853, G Loss: 20.25737190246582\n",
      "Epoch: 25, Batch: 129, D Loss: 0.09698380654598404, G Loss: 19.40422248840332\n",
      "Epoch: 25, Batch: 130, D Loss: 0.09343085733032419, G Loss: 18.53727149963379\n",
      "Epoch: 25, Batch: 131, D Loss: 0.0970099987325912, G Loss: 18.45926856994629\n",
      "Epoch: 25, Batch: 132, D Loss: 0.09703491238041151, G Loss: 19.038166046142578\n",
      "Epoch: 25, Batch: 133, D Loss: 0.10031210055188855, G Loss: 19.923236846923828\n",
      "Epoch: 25, Batch: 134, D Loss: 0.10075208628873089, G Loss: 20.453763961791992\n",
      "Epoch: 25, Batch: 135, D Loss: 0.09527871836399521, G Loss: 20.105134963989258\n",
      "Epoch: 25, Batch: 136, D Loss: 0.10712903843070476, G Loss: 19.869464874267578\n",
      "Epoch: 25, Batch: 137, D Loss: 0.09709802426526282, G Loss: 19.322490692138672\n",
      "Epoch: 25, Batch: 138, D Loss: 0.09868389605151284, G Loss: 19.027816772460938\n",
      "Epoch: 25, Batch: 139, D Loss: 0.09856785345734065, G Loss: 19.14061737060547\n",
      "Epoch: 25, Batch: 140, D Loss: 0.09725699040491254, G Loss: 19.405929565429688\n",
      "Epoch: 25, Batch: 141, D Loss: 0.09801971329504866, G Loss: 19.67396354675293\n",
      "Epoch: 25, Batch: 142, D Loss: 0.09935023765924078, G Loss: 19.848569869995117\n",
      "Epoch: 25, Batch: 143, D Loss: 0.10298733519764547, G Loss: 20.073558807373047\n",
      "Epoch: 25, Batch: 144, D Loss: 0.10298116595543627, G Loss: 20.183338165283203\n",
      "Epoch: 25, Batch: 145, D Loss: 0.0977644707076617, G Loss: 19.84648323059082\n",
      "Epoch: 25, Batch: 146, D Loss: 0.09943135975176032, G Loss: 19.458593368530273\n",
      "Epoch: 25, Batch: 147, D Loss: 0.1032101082619653, G Loss: 19.460777282714844\n",
      "Epoch: 25, Batch: 148, D Loss: 0.09815693819644777, G Loss: 19.50243377685547\n",
      "Epoch: 25, Batch: 149, D Loss: 0.0979877429294359, G Loss: 19.50061798095703\n",
      "Epoch: 25, Batch: 150, D Loss: 0.10596613717025394, G Loss: 19.99262237548828\n",
      "Epoch: 25, Batch: 151, D Loss: 0.09747202793532839, G Loss: 20.08131980895996\n",
      "Epoch: 25, Batch: 152, D Loss: 0.0930069697602931, G Loss: 19.541536331176758\n",
      "Epoch: 25, Batch: 153, D Loss: 0.09667954808102075, G Loss: 19.022851943969727\n",
      "Epoch: 25, Batch: 154, D Loss: 0.0966773360898181, G Loss: 18.86802101135254\n",
      "Epoch: 25, Batch: 155, D Loss: 0.10299091278083128, G Loss: 19.437223434448242\n",
      "Epoch: 25, Batch: 156, D Loss: 0.10290722671291519, G Loss: 20.18012046813965\n",
      "Epoch: 25, Batch: 157, D Loss: 0.09955168589295554, G Loss: 20.47129249572754\n",
      "Epoch: 25, Batch: 158, D Loss: 0.10165326364396166, G Loss: 20.391136169433594\n",
      "Epoch: 25, Batch: 159, D Loss: 0.1005910941412193, G Loss: 20.037744522094727\n",
      "Epoch: 25, Batch: 160, D Loss: 0.0967122031463834, G Loss: 19.50617027282715\n",
      "Epoch: 25, Batch: 161, D Loss: 0.10066416288823965, G Loss: 19.447528839111328\n",
      "Epoch: 25, Batch: 162, D Loss: 0.09655457901290876, G Loss: 19.58991050720215\n",
      "Epoch: 25, Batch: 163, D Loss: 0.10288583599745571, G Loss: 20.202804565429688\n",
      "Epoch: 25, Batch: 164, D Loss: 0.09479770143293731, G Loss: 20.324508666992188\n",
      "Epoch: 25, Batch: 165, D Loss: 0.10132560951741176, G Loss: 20.370126724243164\n",
      "Epoch: 25, Batch: 166, D Loss: 0.09812615893370508, G Loss: 20.112028121948242\n",
      "Epoch: 25, Batch: 167, D Loss: 0.10118933119552131, G Loss: 20.00446128845215\n",
      "Epoch: 25, Batch: 168, D Loss: 0.1006685058133453, G Loss: 20.093809127807617\n",
      "Epoch: 25, Batch: 169, D Loss: 0.10149506561963667, G Loss: 20.3395938873291\n",
      "Epoch: 25, Batch: 170, D Loss: 0.09842583612079303, G Loss: 20.299236297607422\n",
      "Epoch: 25, Batch: 171, D Loss: 0.09467496817070897, G Loss: 19.902790069580078\n",
      "Epoch: 25, Batch: 172, D Loss: 0.09127580536627256, G Loss: 19.226646423339844\n",
      "Epoch: 25, Batch: 173, D Loss: 0.10394086129576907, G Loss: 19.577152252197266\n",
      "Epoch: 25, Batch: 174, D Loss: 0.09357623136740667, G Loss: 20.001102447509766\n",
      "Epoch: 25, Batch: 175, D Loss: 0.0960715794168937, G Loss: 20.35495376586914\n",
      "Epoch: 25, Batch: 176, D Loss: 0.10695527544404393, G Loss: 21.036916732788086\n",
      "Epoch: 25, Batch: 177, D Loss: 0.09566624501101514, G Loss: 20.938072204589844\n",
      "Epoch: 25, Batch: 178, D Loss: 0.09628753420260816, G Loss: 20.307756423950195\n",
      "Epoch: 25, Batch: 179, D Loss: 0.098327056593844, G Loss: 19.741514205932617\n",
      "Epoch: 25, Batch: 180, D Loss: 0.09543649259961517, G Loss: 19.48572540283203\n",
      "Epoch: 25, Batch: 181, D Loss: 0.1036538941941586, G Loss: 19.993486404418945\n",
      "Epoch: 25, Batch: 182, D Loss: 0.10330721058455389, G Loss: 20.806791305541992\n",
      "Epoch: 25, Batch: 183, D Loss: 0.09908594231519263, G Loss: 21.051105499267578\n",
      "Epoch: 25, Batch: 184, D Loss: 0.0997626785699108, G Loss: 20.74364471435547\n",
      "Epoch: 25, Batch: 185, D Loss: 0.09458467441148705, G Loss: 19.88648796081543\n",
      "Epoch: 25, Batch: 186, D Loss: 0.09483430705879592, G Loss: 19.13603401184082\n",
      "Epoch: 25, Batch: 187, D Loss: 0.10165459134166999, G Loss: 19.368057250976562\n",
      "Epoch: 25, Batch: 188, D Loss: 0.09450124354924161, G Loss: 19.846263885498047\n",
      "Epoch: 25, Batch: 189, D Loss: 0.10520222855271782, G Loss: 20.812734603881836\n",
      "Epoch: 25, Batch: 190, D Loss: 0.09763533660683027, G Loss: 21.13245964050293\n",
      "Epoch: 25, Batch: 191, D Loss: 0.10114282406059083, G Loss: 20.956159591674805\n",
      "Epoch: 25, Batch: 192, D Loss: 0.09680137095892899, G Loss: 20.24112319946289\n",
      "Epoch: 25, Batch: 193, D Loss: 0.09122510391098138, G Loss: 19.243677139282227\n",
      "Epoch: 25, Batch: 194, D Loss: 0.10110741324972716, G Loss: 19.27329444885254\n",
      "Epoch: 25, Batch: 195, D Loss: 0.09682023686013708, G Loss: 19.809179306030273\n",
      "Epoch: 25, Batch: 196, D Loss: 0.098006659091107, G Loss: 20.569828033447266\n",
      "Epoch: 25, Batch: 197, D Loss: 0.09520575454023533, G Loss: 20.867338180541992\n",
      "Epoch: 25, Batch: 198, D Loss: 0.1007960666471649, G Loss: 20.91345977783203\n",
      "Epoch: 25, Batch: 199, D Loss: 0.10327979221305433, G Loss: 20.79166603088379\n",
      "Epoch: 25, Batch: 200, D Loss: 0.09741591721653864, G Loss: 20.331409454345703\n",
      "Epoch: 25, Batch: 201, D Loss: 0.0970037365195639, G Loss: 19.921945571899414\n",
      "Epoch: 25, Batch: 202, D Loss: 0.09663777917380922, G Loss: 19.79810333251953\n",
      "Epoch: 25, Batch: 203, D Loss: 0.09964320170626373, G Loss: 20.110166549682617\n",
      "Epoch: 25, Batch: 204, D Loss: 0.09656685665855985, G Loss: 20.501678466796875\n",
      "Epoch: 25, Batch: 205, D Loss: 0.09855695119646041, G Loss: 20.89267921447754\n",
      "Epoch: 25, Batch: 206, D Loss: 0.09895294944729857, G Loss: 20.994083404541016\n",
      "Epoch: 25, Batch: 207, D Loss: 0.10414950584862351, G Loss: 21.14358901977539\n",
      "Epoch: 25, Batch: 208, D Loss: 0.09828195755508146, G Loss: 21.044885635375977\n",
      "Epoch: 25, Batch: 209, D Loss: 0.10430818832397126, G Loss: 21.045618057250977\n",
      "Epoch: 25, Batch: 210, D Loss: 0.09608576487015058, G Loss: 20.845584869384766\n",
      "Epoch: 25, Batch: 211, D Loss: 0.09249061402331588, G Loss: 20.388643264770508\n",
      "Epoch: 25, Batch: 212, D Loss: 0.10152550857683323, G Loss: 20.3599910736084\n",
      "Epoch: 25, Batch: 213, D Loss: 0.09700262613869753, G Loss: 20.48509407043457\n",
      "Epoch: 25, Batch: 214, D Loss: 0.10084679778889516, G Loss: 20.71876335144043\n",
      "Epoch: 25, Batch: 215, D Loss: 0.10185945825060036, G Loss: 20.886695861816406\n",
      "Epoch: 25, Batch: 216, D Loss: 0.09818977168534881, G Loss: 20.539390563964844\n",
      "Epoch: 25, Batch: 217, D Loss: 0.10137218313795437, G Loss: 20.071453094482422\n",
      "Epoch: 25, Batch: 218, D Loss: 0.09815935914182294, G Loss: 19.58983039855957\n",
      "Epoch: 25, Batch: 219, D Loss: 0.10155838886037716, G Loss: 19.557233810424805\n",
      "Epoch: 25, Batch: 220, D Loss: 0.09779925053705663, G Loss: 19.631797790527344\n",
      "Epoch: 25, Batch: 221, D Loss: 0.09368085270897819, G Loss: 19.55994987487793\n",
      "Epoch: 25, Batch: 222, D Loss: 0.10282556101245843, G Loss: 19.902462005615234\n",
      "Epoch: 25, Batch: 223, D Loss: 0.09106385830631802, G Loss: 19.755800247192383\n",
      "Epoch: 25, Batch: 224, D Loss: 0.10047042492861025, G Loss: 19.88422203063965\n",
      "Epoch: 25, Batch: 225, D Loss: 0.09781207251086921, G Loss: 20.036670684814453\n",
      "Epoch: 25, Batch: 226, D Loss: 0.10638224409884439, G Loss: 20.536314010620117\n",
      "Epoch: 25, Batch: 227, D Loss: 0.0972750341959992, G Loss: 20.536483764648438\n",
      "Epoch: 25, Batch: 228, D Loss: 0.10189787363338998, G Loss: 20.396074295043945\n",
      "Epoch: 25, Batch: 229, D Loss: 0.10233368053417163, G Loss: 20.275962829589844\n",
      "Epoch: 25, Batch: 230, D Loss: 0.10507739408877664, G Loss: 20.3922119140625\n",
      "Epoch: 25, Batch: 231, D Loss: 0.09814401047309979, G Loss: 20.216447830200195\n",
      "Epoch: 25, Batch: 232, D Loss: 0.10095249204736922, G Loss: 20.09884262084961\n",
      "Epoch: 25, Batch: 233, D Loss: 0.10146939101591163, G Loss: 20.123796463012695\n",
      "Epoch: 25, Batch: 234, D Loss: 0.10164209540043878, G Loss: 20.259653091430664\n",
      "Epoch: 25, Batch: 235, D Loss: 0.11006756184867789, G Loss: 20.85831069946289\n",
      "Epoch: 25, Batch: 236, D Loss: 0.09303589219530323, G Loss: 20.44377899169922\n",
      "Epoch: 25, Batch: 237, D Loss: 0.10252337982642618, G Loss: 20.084930419921875\n",
      "Epoch: 25, Batch: 238, D Loss: 0.09981722491457046, G Loss: 19.856637954711914\n",
      "Epoch: 25, Batch: 239, D Loss: 0.09712992731368064, G Loss: 19.79631805419922\n",
      "Epoch: 25, Batch: 240, D Loss: 0.09984144678633522, G Loss: 20.056655883789062\n",
      "Epoch: 25, Batch: 241, D Loss: 0.09462820085422419, G Loss: 20.166656494140625\n",
      "Epoch: 25, Batch: 242, D Loss: 0.096139871476987, G Loss: 20.122743606567383\n",
      "Epoch: 25, Batch: 243, D Loss: 0.09346734835219173, G Loss: 19.894071578979492\n",
      "Epoch: 25, Batch: 244, D Loss: 0.09416227170322244, G Loss: 19.689273834228516\n",
      "Epoch: 25, Batch: 245, D Loss: 0.10221068677599787, G Loss: 20.046573638916016\n",
      "Epoch: 25, Batch: 246, D Loss: 0.10428929397815495, G Loss: 20.721942901611328\n",
      "Epoch: 25, Batch: 247, D Loss: 0.09797351109690589, G Loss: 20.826416015625\n",
      "Epoch: 25, Batch: 248, D Loss: 0.0932382202568603, G Loss: 20.165691375732422\n",
      "Epoch: 25, Batch: 249, D Loss: 0.09821006027033052, G Loss: 19.619003295898438\n",
      "Epoch: 25, Batch: 250, D Loss: 0.1021425589497934, G Loss: 19.69756507873535\n",
      "Epoch: 25, Batch: 251, D Loss: 0.10206575798451745, G Loss: 20.205110549926758\n",
      "Epoch: 25, Batch: 252, D Loss: 0.10017891292795988, G Loss: 20.70261001586914\n",
      "Epoch: 25, Batch: 253, D Loss: 0.098644957441762, G Loss: 20.759702682495117\n",
      "Epoch: 25, Batch: 254, D Loss: 0.0982411062444084, G Loss: 20.445653915405273\n",
      "Epoch: 25, Batch: 255, D Loss: 0.09522254852969686, G Loss: 19.899808883666992\n",
      "Epoch: 25, Batch: 256, D Loss: 0.10218056407274545, G Loss: 19.86711883544922\n",
      "Epoch: 25, Batch: 257, D Loss: 0.09625589961306524, G Loss: 19.932758331298828\n",
      "Epoch: 25, Batch: 258, D Loss: 0.09830971163101165, G Loss: 20.10076332092285\n",
      "Epoch: 25, Batch: 259, D Loss: 0.10091608842613681, G Loss: 20.39368438720703\n",
      "Epoch: 25, Batch: 260, D Loss: 0.09852022746871153, G Loss: 20.402477264404297\n",
      "Epoch: 25, Batch: 261, D Loss: 0.09470621581337157, G Loss: 20.005935668945312\n",
      "Epoch: 25, Batch: 262, D Loss: 0.10197037563259059, G Loss: 19.962646484375\n",
      "Epoch: 25, Batch: 263, D Loss: 0.10045087435750666, G Loss: 20.124773025512695\n",
      "Epoch: 25, Batch: 264, D Loss: 0.09927566436046498, G Loss: 20.220022201538086\n",
      "Epoch: 25, Batch: 265, D Loss: 0.09754984168342518, G Loss: 20.112287521362305\n",
      "Epoch: 25, Batch: 266, D Loss: 0.09807005627500343, G Loss: 19.9029483795166\n",
      "Epoch: 25, Batch: 267, D Loss: 0.09698864195974577, G Loss: 19.745433807373047\n",
      "Epoch: 25, Batch: 268, D Loss: 0.09674810759187669, G Loss: 19.6339054107666\n",
      "Epoch: 25, Batch: 269, D Loss: 0.10254843660109403, G Loss: 19.9318790435791\n",
      "Epoch: 25, Batch: 270, D Loss: 0.10013292826664988, G Loss: 20.180421829223633\n",
      "Epoch: 25, Batch: 271, D Loss: 0.09813112853160288, G Loss: 20.146650314331055\n",
      "Epoch: 25, Batch: 272, D Loss: 0.0987913916879899, G Loss: 19.868263244628906\n",
      "Epoch: 25, Batch: 273, D Loss: 0.09345995050278655, G Loss: 19.27589988708496\n",
      "Epoch: 25, Batch: 274, D Loss: 0.09645119564061, G Loss: 18.933992385864258\n",
      "Epoch: 25, Batch: 275, D Loss: 0.09750795634492615, G Loss: 19.13001823425293\n",
      "Epoch: 25, Batch: 276, D Loss: 0.09761670421117596, G Loss: 19.628026962280273\n",
      "Epoch: 25, Batch: 277, D Loss: 0.09529829152634883, G Loss: 19.93289566040039\n",
      "Epoch: 25, Batch: 278, D Loss: 0.10246639044869377, G Loss: 20.293197631835938\n",
      "Epoch: 25, Batch: 279, D Loss: 0.09569768694085595, G Loss: 20.069766998291016\n",
      "Epoch: 25, Batch: 280, D Loss: 0.09908496702896896, G Loss: 19.738454818725586\n",
      "Epoch: 25, Batch: 281, D Loss: 0.10234109446378925, G Loss: 19.736064910888672\n",
      "Epoch: 25, Batch: 282, D Loss: 0.10176140933437305, G Loss: 19.97409439086914\n",
      "Epoch: 25, Batch: 283, D Loss: 0.09293025845639569, G Loss: 19.838768005371094\n",
      "Epoch: 25, Batch: 284, D Loss: 0.09939403956251569, G Loss: 19.78976821899414\n",
      "Epoch: 25, Batch: 285, D Loss: 0.10152848924419466, G Loss: 19.990333557128906\n",
      "Epoch: 25, Batch: 286, D Loss: 0.09786403278209144, G Loss: 20.084766387939453\n",
      "Epoch: 25, Batch: 287, D Loss: 0.0999752739331532, G Loss: 20.13981056213379\n",
      "Epoch: 25, Batch: 288, D Loss: 0.1009930604615692, G Loss: 20.161815643310547\n",
      "Epoch: 25, Batch: 289, D Loss: 0.10221713867407756, G Loss: 20.197486877441406\n",
      "Epoch: 25, Batch: 290, D Loss: 0.10142781671313084, G Loss: 20.169675827026367\n",
      "Epoch: 25, Batch: 291, D Loss: 0.0960050683266972, G Loss: 19.727874755859375\n",
      "Epoch: 25, Batch: 292, D Loss: 0.10282262557070176, G Loss: 19.631616592407227\n",
      "Epoch: 25, Batch: 293, D Loss: 0.10508184258309006, G Loss: 19.990381240844727\n",
      "Epoch: 25, Batch: 294, D Loss: 0.10478435538905928, G Loss: 20.439208984375\n",
      "Epoch: 25, Batch: 295, D Loss: 0.09592934030602329, G Loss: 20.13917350769043\n",
      "Epoch: 25, Batch: 296, D Loss: 0.10203652194524782, G Loss: 19.739717483520508\n",
      "Epoch: 25, Batch: 297, D Loss: 0.09804137967283899, G Loss: 19.271007537841797\n",
      "Epoch: 25, Batch: 298, D Loss: 0.10679601317150733, G Loss: 19.552757263183594\n",
      "Epoch: 25, Batch: 299, D Loss: 0.10325735925302659, G Loss: 20.14702606201172\n",
      "Epoch: 25, Batch: 300, D Loss: 0.09911519368495403, G Loss: 20.36168670654297\n",
      "Epoch: 25, Batch: 301, D Loss: 0.10005633611938175, G Loss: 20.181346893310547\n",
      "Epoch: 25, Batch: 302, D Loss: 0.09911692247477111, G Loss: 19.801448822021484\n",
      "Epoch: 25, Batch: 303, D Loss: 0.10288331791163796, G Loss: 19.687374114990234\n",
      "Epoch: 25, Batch: 304, D Loss: 0.09627690320451165, G Loss: 19.516250610351562\n",
      "Epoch: 25, Batch: 305, D Loss: 0.10060711354556673, G Loss: 19.728641510009766\n",
      "Epoch: 25, Batch: 306, D Loss: 0.10509387501424028, G Loss: 20.345273971557617\n",
      "Epoch: 25, Batch: 307, D Loss: 0.09711413900289217, G Loss: 20.430816650390625\n",
      "Epoch: 25, Batch: 308, D Loss: 0.09098167070158092, G Loss: 19.711143493652344\n",
      "Epoch: 25, Batch: 309, D Loss: 0.09416143054101944, G Loss: 18.9714412689209\n",
      "Epoch: 25, Batch: 310, D Loss: 0.10220545789186875, G Loss: 19.17706871032715\n",
      "Epoch: 25, Batch: 311, D Loss: 0.0970218870393007, G Loss: 19.65715789794922\n",
      "Epoch: 25, Batch: 312, D Loss: 0.10017853336390348, G Loss: 20.25184440612793\n",
      "Epoch: 25, Batch: 313, D Loss: 0.09947528019013518, G Loss: 20.403608322143555\n",
      "Epoch: 25, Batch: 314, D Loss: 0.10014139195750654, G Loss: 20.11947250366211\n",
      "Epoch: 25, Batch: 315, D Loss: 0.09537159041286014, G Loss: 19.38096809387207\n",
      "Epoch: 25, Batch: 316, D Loss: 0.09479917117653014, G Loss: 18.67958641052246\n",
      "Epoch: 25, Batch: 317, D Loss: 0.09640133052515099, G Loss: 18.53631019592285\n",
      "Epoch: 25, Batch: 318, D Loss: 0.10140904351610036, G Loss: 19.210233688354492\n",
      "Epoch: 25, Batch: 319, D Loss: 0.10239267481754466, G Loss: 20.23124885559082\n",
      "Epoch: 25, Batch: 320, D Loss: 0.0955130018361009, G Loss: 20.391613006591797\n",
      "Epoch: 25, Batch: 321, D Loss: 0.10481992436798554, G Loss: 20.30655288696289\n",
      "Epoch: 25, Batch: 322, D Loss: 0.10064652660200668, G Loss: 19.818300247192383\n",
      "Epoch: 25, Batch: 323, D Loss: 0.10701860619935744, G Loss: 19.687129974365234\n",
      "Epoch: 25, Batch: 324, D Loss: 0.09994851949312078, G Loss: 19.550405502319336\n",
      "Epoch: 25, Batch: 325, D Loss: 0.09958034175155861, G Loss: 19.495098114013672\n",
      "Epoch: 25, Batch: 326, D Loss: 0.10212008807227035, G Loss: 19.715002059936523\n",
      "Epoch: 25, Batch: 327, D Loss: 0.10683859986055355, G Loss: 20.288774490356445\n",
      "Epoch: 25, Batch: 328, D Loss: 0.09317627638590215, G Loss: 20.009986877441406\n",
      "Epoch: 25, Batch: 329, D Loss: 0.0971125526722556, G Loss: 19.490894317626953\n",
      "Epoch: 25, Batch: 330, D Loss: 0.10252016214150816, G Loss: 19.437456130981445\n",
      "Epoch: 25, Batch: 331, D Loss: 0.09551738379059171, G Loss: 19.48517417907715\n",
      "Epoch: 25, Batch: 332, D Loss: 0.09867219026888507, G Loss: 19.8148193359375\n",
      "Epoch: 25, Batch: 333, D Loss: 0.09646432212079337, G Loss: 20.037343978881836\n",
      "Epoch: 25, Batch: 334, D Loss: 0.10544842553330896, G Loss: 20.65448570251465\n",
      "Epoch: 25, Batch: 335, D Loss: 0.09602663720038324, G Loss: 20.638235092163086\n",
      "Epoch: 25, Batch: 336, D Loss: 0.09781757809845504, G Loss: 20.224117279052734\n",
      "Epoch: 25, Batch: 337, D Loss: 0.09550504497815082, G Loss: 19.650150299072266\n",
      "Epoch: 25, Batch: 338, D Loss: 0.09494316010144954, G Loss: 19.284738540649414\n",
      "Epoch: 25, Batch: 339, D Loss: 0.10501442994515697, G Loss: 19.996191024780273\n",
      "Epoch: 25, Batch: 340, D Loss: 0.09490975817296815, G Loss: 20.49077796936035\n",
      "Epoch: 25, Batch: 341, D Loss: 0.0994059002137383, G Loss: 20.6843204498291\n",
      "Epoch: 25, Batch: 342, D Loss: 0.09912025240206102, G Loss: 20.517431259155273\n",
      "Epoch: 25, Batch: 343, D Loss: 0.09353844910826342, G Loss: 19.803918838500977\n",
      "Epoch: 25, Batch: 344, D Loss: 0.1009168490057184, G Loss: 19.569351196289062\n",
      "Epoch: 25, Batch: 345, D Loss: 0.09718328872966575, G Loss: 19.5694637298584\n",
      "Epoch: 25, Batch: 346, D Loss: 0.09853952517353859, G Loss: 19.815309524536133\n",
      "Epoch: 25, Batch: 347, D Loss: 0.10081447759737205, G Loss: 20.246257781982422\n",
      "Epoch: 25, Batch: 348, D Loss: 0.10220709511325954, G Loss: 20.561891555786133\n",
      "Epoch: 25, Batch: 349, D Loss: 0.09933148386824481, G Loss: 20.44976043701172\n",
      "Epoch: 25, Batch: 350, D Loss: 0.09689219384332798, G Loss: 19.88715171813965\n",
      "Epoch: 25, Batch: 351, D Loss: 0.09306104652188885, G Loss: 19.138916015625\n",
      "Epoch: 25, Batch: 352, D Loss: 0.098933647133578, G Loss: 19.06192398071289\n",
      "Epoch: 25, Batch: 353, D Loss: 0.09834841094357527, G Loss: 19.579299926757812\n",
      "Epoch: 25, Batch: 354, D Loss: 0.09992228554071425, G Loss: 20.330101013183594\n",
      "Epoch: 25, Batch: 355, D Loss: 0.10290372425371813, G Loss: 20.940523147583008\n",
      "Epoch: 25, Batch: 356, D Loss: 0.09779320700746963, G Loss: 20.792728424072266\n",
      "Epoch: 25, Batch: 357, D Loss: 0.10697209885478931, G Loss: 20.64478302001953\n",
      "Epoch: 25, Batch: 358, D Loss: 0.09552390953512663, G Loss: 19.89764976501465\n",
      "Epoch: 25, Batch: 359, D Loss: 0.08995045924037526, G Loss: 18.807584762573242\n",
      "Epoch: 25, Batch: 360, D Loss: 0.10712802679476541, G Loss: 19.249507904052734\n",
      "Epoch: 25, Batch: 361, D Loss: 0.09725520157677925, G Loss: 20.053537368774414\n",
      "Epoch: 25, Batch: 362, D Loss: 0.09803354810577453, G Loss: 20.674152374267578\n",
      "Epoch: 25, Batch: 363, D Loss: 0.0954256063382326, G Loss: 20.53786277770996\n",
      "Epoch: 25, Batch: 364, D Loss: 0.09848044142911772, G Loss: 20.11214256286621\n",
      "Epoch: 25, Batch: 365, D Loss: 0.09722866980609379, G Loss: 19.648283004760742\n",
      "Epoch: 25, Batch: 366, D Loss: 0.09055018613567656, G Loss: 19.168672561645508\n",
      "Epoch: 25, Batch: 367, D Loss: 0.10096341561589006, G Loss: 19.58628273010254\n",
      "Epoch: 25, Batch: 368, D Loss: 0.10357676537232352, G Loss: 20.610923767089844\n",
      "Epoch: 25, Batch: 369, D Loss: 0.10220908411008828, G Loss: 21.3742618560791\n",
      "Epoch: 25, Batch: 370, D Loss: 0.10000112678321854, G Loss: 21.413665771484375\n",
      "Epoch: 25, Batch: 371, D Loss: 0.09813684260434294, G Loss: 20.759546279907227\n",
      "Epoch: 25, Batch: 372, D Loss: 0.1013661480205143, G Loss: 20.276477813720703\n",
      "Epoch: 25, Batch: 373, D Loss: 0.09913462488324576, G Loss: 20.05396270751953\n",
      "Epoch: 25, Batch: 374, D Loss: 0.0926975022843407, G Loss: 19.824935913085938\n",
      "Epoch: 25, Batch: 375, D Loss: 0.09438135594262642, G Loss: 19.879512786865234\n",
      "Epoch: 25, Batch: 376, D Loss: 0.10503032135487134, G Loss: 20.660451889038086\n",
      "Epoch: 25, Batch: 377, D Loss: 0.10346983407775714, G Loss: 21.477296829223633\n",
      "Epoch: 25, Batch: 378, D Loss: 0.10210022351168749, G Loss: 21.703420639038086\n",
      "Epoch: 25, Batch: 379, D Loss: 0.0978903028135438, G Loss: 20.979768753051758\n",
      "Epoch: 25, Batch: 380, D Loss: 0.10360300596221506, G Loss: 20.299970626831055\n",
      "Epoch: 25, Batch: 381, D Loss: 0.09828107158177146, G Loss: 19.802764892578125\n",
      "Epoch: 25, Batch: 382, D Loss: 0.10391639281202192, G Loss: 20.08591651916504\n",
      "Epoch: 25, Batch: 383, D Loss: 0.10397170548333151, G Loss: 20.818737030029297\n",
      "Epoch: 25, Batch: 384, D Loss: 0.10038986092968469, G Loss: 21.265207290649414\n",
      "Epoch: 25, Batch: 385, D Loss: 0.09834261270666639, G Loss: 21.078041076660156\n",
      "Epoch: 25, Batch: 386, D Loss: 0.09572030654133706, G Loss: 20.393230438232422\n",
      "Epoch: 25, Batch: 387, D Loss: 0.09892265586879734, G Loss: 19.940757751464844\n",
      "Epoch: 25, Batch: 388, D Loss: 0.10358019266759966, G Loss: 20.236209869384766\n",
      "Epoch: 25, Batch: 389, D Loss: 0.10437602606037083, G Loss: 20.936573028564453\n",
      "Epoch: 25, Batch: 390, D Loss: 0.10074187846553587, G Loss: 21.417896270751953\n",
      "Epoch: 25, Batch: 391, D Loss: 0.09814974693573161, G Loss: 21.204544067382812\n",
      "Epoch: 25, Batch: 392, D Loss: 0.09774646205980622, G Loss: 20.575746536254883\n",
      "Epoch: 25, Batch: 393, D Loss: 0.10210660167738145, G Loss: 20.27862548828125\n",
      "Epoch: 25, Batch: 394, D Loss: 0.10306179592883041, G Loss: 20.5004940032959\n",
      "Epoch: 25, Batch: 395, D Loss: 0.09887849592681247, G Loss: 20.807241439819336\n",
      "Epoch: 25, Batch: 396, D Loss: 0.09839748631859738, G Loss: 21.040023803710938\n",
      "Epoch: 25, Batch: 397, D Loss: 0.09526841381885878, G Loss: 20.889190673828125\n",
      "Epoch: 25, Batch: 398, D Loss: 0.10273104947654799, G Loss: 20.92491912841797\n",
      "Epoch: 25, Batch: 399, D Loss: 0.10184381941773354, G Loss: 20.98723030090332\n",
      "Epoch: 25, Batch: 400, D Loss: 0.0963157866747664, G Loss: 20.762310028076172\n",
      "Epoch: 25, Batch: 401, D Loss: 0.09964472853213147, G Loss: 20.587692260742188\n",
      "Epoch: 25, Batch: 402, D Loss: 0.09583690828764835, G Loss: 20.310924530029297\n",
      "Epoch: 25, Batch: 403, D Loss: 0.10087151898102903, G Loss: 20.384252548217773\n",
      "Epoch: 25, Batch: 404, D Loss: 0.10070827665540238, G Loss: 20.613805770874023\n",
      "Epoch: 25, Batch: 405, D Loss: 0.09713336880775586, G Loss: 20.627111434936523\n",
      "Epoch: 25, Batch: 406, D Loss: 0.0966510033800686, G Loss: 20.415401458740234\n",
      "Epoch: 25, Batch: 407, D Loss: 0.09736333865002739, G Loss: 20.166316986083984\n",
      "Epoch: 25, Batch: 408, D Loss: 0.10270864593460133, G Loss: 20.405433654785156\n",
      "Epoch: 25, Batch: 409, D Loss: 0.10343974880186929, G Loss: 20.953819274902344\n",
      "Epoch: 25, Batch: 410, D Loss: 0.09847168660290803, G Loss: 21.145923614501953\n",
      "Epoch: 25, Batch: 411, D Loss: 0.10547143996758934, G Loss: 21.263652801513672\n",
      "Epoch: 25, Batch: 412, D Loss: 0.10077992116097292, G Loss: 20.944272994995117\n",
      "Epoch: 25, Batch: 413, D Loss: 0.10122323085368146, G Loss: 20.5556697845459\n",
      "Epoch: 25, Batch: 414, D Loss: 0.10242772165121655, G Loss: 20.442358016967773\n",
      "Epoch: 25, Batch: 415, D Loss: 0.10168088292558713, G Loss: 20.47657012939453\n",
      "Epoch: 25, Batch: 416, D Loss: 0.09826538031711868, G Loss: 20.447725296020508\n",
      "Epoch: 25, Batch: 417, D Loss: 0.1019400960485351, G Loss: 20.549718856811523\n",
      "Epoch: 25, Batch: 418, D Loss: 0.09915170882188012, G Loss: 20.42205810546875\n",
      "Epoch: 25, Batch: 419, D Loss: 0.09517547574842711, G Loss: 19.950847625732422\n",
      "Epoch: 25, Batch: 420, D Loss: 0.09515230497079985, G Loss: 19.470895767211914\n",
      "Epoch: 25, Batch: 421, D Loss: 0.10170281106543333, G Loss: 19.49121856689453\n",
      "Epoch: 25, Batch: 422, D Loss: 0.09388114680608317, G Loss: 19.523212432861328\n",
      "Epoch: 25, Batch: 423, D Loss: 0.10194598273428868, G Loss: 19.91547393798828\n",
      "Epoch: 25, Batch: 424, D Loss: 0.10264151629892043, G Loss: 20.408626556396484\n",
      "Epoch: 25, Batch: 425, D Loss: 0.09260510736434263, G Loss: 20.039655685424805\n",
      "Epoch: 25, Batch: 426, D Loss: 0.09681100533829323, G Loss: 19.44392204284668\n",
      "Epoch: 25, Batch: 427, D Loss: 0.10081468724473663, G Loss: 19.223623275756836\n",
      "Epoch: 25, Batch: 428, D Loss: 0.10733388528525223, G Loss: 19.81431770324707\n",
      "Epoch: 25, Batch: 429, D Loss: 0.09898839994226682, G Loss: 20.163352966308594\n",
      "Epoch: 25, Batch: 430, D Loss: 0.1005667009856791, G Loss: 20.14329719543457\n",
      "Epoch: 25, Batch: 431, D Loss: 0.09493382400575656, G Loss: 19.49683952331543\n",
      "Epoch: 25, Batch: 432, D Loss: 0.09758229048494127, G Loss: 18.848100662231445\n",
      "Epoch: 25, Batch: 433, D Loss: 0.09706721074395741, G Loss: 18.638145446777344\n",
      "Epoch: 25, Batch: 434, D Loss: 0.09913237728461577, G Loss: 18.984582901000977\n",
      "Epoch: 25, Batch: 435, D Loss: 0.0960143976309682, G Loss: 19.410573959350586\n",
      "Epoch: 25, Batch: 436, D Loss: 0.1038579804190971, G Loss: 20.17836570739746\n",
      "Epoch: 25, Batch: 437, D Loss: 0.10148102861186958, G Loss: 20.545991897583008\n",
      "Epoch: 25, Batch: 438, D Loss: 0.09928682514064613, G Loss: 20.310579299926758\n",
      "Epoch: 25, Batch: 439, D Loss: 0.10318634006771804, G Loss: 19.919954299926758\n",
      "Epoch: 25, Batch: 440, D Loss: 0.09842635834435498, G Loss: 19.446619033813477\n",
      "Epoch: 25, Batch: 441, D Loss: 0.09908901344292342, G Loss: 19.34392738342285\n",
      "Epoch: 25, Batch: 442, D Loss: 0.1057915255000571, G Loss: 19.945480346679688\n",
      "Epoch: 25, Batch: 443, D Loss: 0.09792792141776024, G Loss: 20.31195831298828\n",
      "Epoch: 25, Batch: 444, D Loss: 0.10682341512819415, G Loss: 20.864763259887695\n",
      "Epoch: 25, Batch: 445, D Loss: 0.10203987404744097, G Loss: 20.807214736938477\n",
      "Epoch: 25, Batch: 446, D Loss: 0.09255078513185111, G Loss: 19.79388427734375\n",
      "Epoch: 25, Batch: 447, D Loss: 0.09357625466992925, G Loss: 18.73451805114746\n",
      "Epoch: 25, Batch: 448, D Loss: 0.09719460114830936, G Loss: 18.553617477416992\n",
      "Epoch: 25, Batch: 449, D Loss: 0.10689334802660921, G Loss: 19.763700485229492\n",
      "Epoch: 25, Batch: 450, D Loss: 0.09381991708534398, G Loss: 20.60618019104004\n",
      "Epoch: 25, Batch: 451, D Loss: 0.09854779440092154, G Loss: 20.92180061340332\n",
      "Epoch: 25, Batch: 452, D Loss: 0.09764975358855416, G Loss: 20.564191818237305\n",
      "Epoch: 25, Batch: 453, D Loss: 0.09895539363018113, G Loss: 19.98997688293457\n",
      "Epoch: 25, Batch: 454, D Loss: 0.09915900360987828, G Loss: 19.559656143188477\n",
      "Epoch: 25, Batch: 455, D Loss: 0.10406032352747419, G Loss: 19.70793342590332\n",
      "Epoch: 25, Batch: 456, D Loss: 0.09593084590450696, G Loss: 19.737844467163086\n",
      "Epoch: 25, Batch: 457, D Loss: 0.10339083632447044, G Loss: 20.114173889160156\n",
      "Epoch: 25, Batch: 458, D Loss: 0.09725649751893073, G Loss: 20.01236343383789\n",
      "Epoch: 25, Batch: 459, D Loss: 0.10457269948972048, G Loss: 20.016944885253906\n",
      "Epoch: 25, Batch: 460, D Loss: 0.0990473639993672, G Loss: 19.704090118408203\n",
      "Epoch: 25, Batch: 461, D Loss: 0.10111862583279618, G Loss: 19.404890060424805\n",
      "Epoch: 25, Batch: 462, D Loss: 0.09902568375401266, G Loss: 19.14957046508789\n",
      "Epoch: 25, Batch: 463, D Loss: 0.10265654557292936, G Loss: 19.226734161376953\n",
      "Epoch: 25, Batch: 464, D Loss: 0.10335259326581281, G Loss: 19.56434440612793\n",
      "Epoch: 25, Batch: 465, D Loss: 0.10008951425606238, G Loss: 19.691688537597656\n",
      "Epoch: 25, Batch: 466, D Loss: 0.10398517688691089, G Loss: 19.701004028320312\n",
      "Epoch: 25, Batch: 467, D Loss: 0.10470353214037476, G Loss: 19.5937442779541\n",
      "Epoch: 26, Batch: 0, D Loss: 0.10428044361031397, G Loss: 19.518022537231445\n",
      "Epoch: 26, Batch: 1, D Loss: 0.09766888829917364, G Loss: 19.069011688232422\n",
      "Epoch: 26, Batch: 2, D Loss: 0.09979559786361314, G Loss: 18.77701759338379\n",
      "Epoch: 26, Batch: 3, D Loss: 0.0908351887407357, G Loss: 18.15151023864746\n",
      "Epoch: 26, Batch: 4, D Loss: 0.10003331946159122, G Loss: 18.190393447875977\n",
      "Epoch: 26, Batch: 5, D Loss: 0.0987302264516976, G Loss: 18.609113693237305\n",
      "Epoch: 26, Batch: 6, D Loss: 0.09502248825397142, G Loss: 18.88064956665039\n",
      "Epoch: 26, Batch: 7, D Loss: 0.1067300312520354, G Loss: 19.511608123779297\n",
      "Epoch: 26, Batch: 8, D Loss: 0.10629761343184052, G Loss: 20.0856990814209\n",
      "Epoch: 26, Batch: 9, D Loss: 0.10067819164070846, G Loss: 19.884672164916992\n",
      "Epoch: 26, Batch: 10, D Loss: 0.09989001026481514, G Loss: 19.156431198120117\n",
      "Epoch: 26, Batch: 11, D Loss: 0.10362682783748411, G Loss: 18.780969619750977\n",
      "Epoch: 26, Batch: 12, D Loss: 0.10054803248087163, G Loss: 18.757516860961914\n",
      "Epoch: 26, Batch: 13, D Loss: 0.1052766913959502, G Loss: 19.46469497680664\n",
      "Epoch: 26, Batch: 14, D Loss: 0.09546170536135723, G Loss: 19.738845825195312\n",
      "Epoch: 26, Batch: 15, D Loss: 0.09615440816352439, G Loss: 19.526729583740234\n",
      "Epoch: 26, Batch: 16, D Loss: 0.09694705357288869, G Loss: 19.17831039428711\n",
      "Epoch: 26, Batch: 17, D Loss: 0.0951319811902136, G Loss: 18.843931198120117\n",
      "Epoch: 26, Batch: 18, D Loss: 0.09633159964336868, G Loss: 18.849395751953125\n",
      "Epoch: 26, Batch: 19, D Loss: 0.09344376187063252, G Loss: 18.954421997070312\n",
      "Epoch: 26, Batch: 20, D Loss: 0.09858902773711953, G Loss: 19.4179744720459\n",
      "Epoch: 26, Batch: 21, D Loss: 0.10019772631316182, G Loss: 20.060678482055664\n",
      "Epoch: 26, Batch: 22, D Loss: 0.09735442785480958, G Loss: 20.257328033447266\n",
      "Epoch: 26, Batch: 23, D Loss: 0.10053032717609917, G Loss: 20.227298736572266\n",
      "Epoch: 26, Batch: 24, D Loss: 0.09493768322421614, G Loss: 19.719635009765625\n",
      "Epoch: 26, Batch: 25, D Loss: 0.10139102632328578, G Loss: 19.623262405395508\n",
      "Epoch: 26, Batch: 26, D Loss: 0.10515722004830552, G Loss: 20.090560913085938\n",
      "Epoch: 26, Batch: 27, D Loss: 0.09865588028775452, G Loss: 20.423402786254883\n",
      "Epoch: 26, Batch: 28, D Loss: 0.09486747607282048, G Loss: 20.243492126464844\n",
      "Epoch: 26, Batch: 29, D Loss: 0.09981609969584543, G Loss: 20.067214965820312\n",
      "Epoch: 26, Batch: 30, D Loss: 0.09915386240604318, G Loss: 19.99248504638672\n",
      "Epoch: 26, Batch: 31, D Loss: 0.09980802334742545, G Loss: 20.12736701965332\n",
      "Epoch: 26, Batch: 32, D Loss: 0.10097140149276601, G Loss: 20.476652145385742\n",
      "Epoch: 26, Batch: 33, D Loss: 0.1016383623721056, G Loss: 20.728605270385742\n",
      "Epoch: 26, Batch: 34, D Loss: 0.09682677743662382, G Loss: 20.454814910888672\n",
      "Epoch: 26, Batch: 35, D Loss: 0.09580689007305965, G Loss: 19.985387802124023\n",
      "Epoch: 26, Batch: 36, D Loss: 0.0979577836572132, G Loss: 19.709009170532227\n",
      "Epoch: 26, Batch: 37, D Loss: 0.10316316898763034, G Loss: 20.04848289489746\n",
      "Epoch: 26, Batch: 38, D Loss: 0.10133548158486805, G Loss: 20.496057510375977\n",
      "Epoch: 26, Batch: 39, D Loss: 0.09518235988011936, G Loss: 20.396289825439453\n",
      "Epoch: 26, Batch: 40, D Loss: 0.09453083664603662, G Loss: 19.903854370117188\n",
      "Epoch: 26, Batch: 41, D Loss: 0.0987988127081536, G Loss: 19.68659782409668\n",
      "Epoch: 26, Batch: 42, D Loss: 0.101652973610172, G Loss: 19.97784423828125\n",
      "Epoch: 26, Batch: 43, D Loss: 0.09701553822114894, G Loss: 20.278539657592773\n",
      "Epoch: 26, Batch: 44, D Loss: 0.09770225059310977, G Loss: 20.46176528930664\n",
      "Epoch: 26, Batch: 45, D Loss: 0.10569088211850652, G Loss: 20.926250457763672\n",
      "Epoch: 26, Batch: 46, D Loss: 0.09622677456570125, G Loss: 20.91969108581543\n",
      "Epoch: 26, Batch: 47, D Loss: 0.10203243833674747, G Loss: 20.895357131958008\n",
      "Epoch: 26, Batch: 48, D Loss: 0.10026667310841758, G Loss: 20.821998596191406\n",
      "Epoch: 26, Batch: 49, D Loss: 0.09898588108739931, G Loss: 20.735858917236328\n",
      "Epoch: 26, Batch: 50, D Loss: 0.10289990947378472, G Loss: 20.894189834594727\n",
      "Epoch: 26, Batch: 51, D Loss: 0.09804037254975054, G Loss: 20.91687774658203\n",
      "Epoch: 26, Batch: 52, D Loss: 0.10122277627172024, G Loss: 20.996173858642578\n",
      "Epoch: 26, Batch: 53, D Loss: 0.09253110784952695, G Loss: 20.541173934936523\n",
      "Epoch: 26, Batch: 54, D Loss: 0.09811088514062155, G Loss: 20.2155704498291\n",
      "Epoch: 26, Batch: 55, D Loss: 0.10490615737197911, G Loss: 20.507827758789062\n",
      "Epoch: 26, Batch: 56, D Loss: 0.10012861393140882, G Loss: 20.846160888671875\n",
      "Epoch: 26, Batch: 57, D Loss: 0.10218595753003545, G Loss: 21.054553985595703\n",
      "Epoch: 26, Batch: 58, D Loss: 0.09617375626131677, G Loss: 20.681867599487305\n",
      "Epoch: 26, Batch: 59, D Loss: 0.10435854702603153, G Loss: 20.44562339782715\n",
      "Epoch: 26, Batch: 60, D Loss: 0.09903217926705643, G Loss: 20.21424102783203\n",
      "Epoch: 26, Batch: 61, D Loss: 0.09753767490680282, G Loss: 20.071455001831055\n",
      "Epoch: 26, Batch: 62, D Loss: 0.09890235307568584, G Loss: 20.14899253845215\n",
      "Epoch: 26, Batch: 63, D Loss: 0.1040599353148206, G Loss: 20.606277465820312\n",
      "Epoch: 26, Batch: 64, D Loss: 0.09246078936533669, G Loss: 20.550460815429688\n",
      "Epoch: 26, Batch: 65, D Loss: 0.09554150770565045, G Loss: 20.240442276000977\n",
      "Epoch: 26, Batch: 66, D Loss: 0.0978356757924903, G Loss: 20.019250869750977\n",
      "Epoch: 26, Batch: 67, D Loss: 0.09853534498315897, G Loss: 20.081819534301758\n",
      "Epoch: 26, Batch: 68, D Loss: 0.10100989122092935, G Loss: 20.448238372802734\n",
      "Epoch: 26, Batch: 69, D Loss: 0.09549672962641742, G Loss: 20.593000411987305\n",
      "Epoch: 26, Batch: 70, D Loss: 0.10302092183339356, G Loss: 20.90300178527832\n",
      "Epoch: 26, Batch: 71, D Loss: 0.1003772024399665, G Loss: 20.95760726928711\n",
      "Epoch: 26, Batch: 72, D Loss: 0.10439270028624473, G Loss: 20.989837646484375\n",
      "Epoch: 26, Batch: 73, D Loss: 0.1058525297810671, G Loss: 21.032630920410156\n",
      "Epoch: 26, Batch: 74, D Loss: 0.09967856896689853, G Loss: 20.75428581237793\n",
      "Epoch: 26, Batch: 75, D Loss: 0.09917347191331449, G Loss: 20.40758514404297\n",
      "Epoch: 26, Batch: 76, D Loss: 0.10201957890824304, G Loss: 20.396623611450195\n",
      "Epoch: 26, Batch: 77, D Loss: 0.10028635774353295, G Loss: 20.552854537963867\n",
      "Epoch: 26, Batch: 78, D Loss: 0.10443598080044769, G Loss: 20.952234268188477\n",
      "Epoch: 26, Batch: 79, D Loss: 0.0986867699838348, G Loss: 21.058820724487305\n",
      "Epoch: 26, Batch: 80, D Loss: 0.09228582723176618, G Loss: 20.723440170288086\n",
      "Epoch: 26, Batch: 81, D Loss: 0.0969263320850896, G Loss: 20.49209213256836\n",
      "Epoch: 26, Batch: 82, D Loss: 0.1015299266328471, G Loss: 20.67868995666504\n",
      "Epoch: 26, Batch: 83, D Loss: 0.09939053696038105, G Loss: 21.15387535095215\n",
      "Epoch: 26, Batch: 84, D Loss: 0.09165097058859165, G Loss: 21.2539119720459\n",
      "Epoch: 26, Batch: 85, D Loss: 0.10253350462203428, G Loss: 21.524137496948242\n",
      "Epoch: 26, Batch: 86, D Loss: 0.09923186175088548, G Loss: 21.569860458374023\n",
      "Epoch: 26, Batch: 87, D Loss: 0.09523087019884938, G Loss: 21.278717041015625\n",
      "Epoch: 26, Batch: 88, D Loss: 0.10077681423305279, G Loss: 21.139511108398438\n",
      "Epoch: 26, Batch: 89, D Loss: 0.10704526331422459, G Loss: 21.574867248535156\n",
      "Epoch: 26, Batch: 90, D Loss: 0.10208110529853198, G Loss: 21.840599060058594\n",
      "Epoch: 26, Batch: 91, D Loss: 0.09738992173003636, G Loss: 21.61648178100586\n",
      "Epoch: 26, Batch: 92, D Loss: 0.10014589899007215, G Loss: 21.38901710510254\n",
      "Epoch: 26, Batch: 93, D Loss: 0.10369550461046179, G Loss: 21.494356155395508\n",
      "Epoch: 26, Batch: 94, D Loss: 0.10428160448863914, G Loss: 21.783632278442383\n",
      "Epoch: 26, Batch: 95, D Loss: 0.09690692293957032, G Loss: 21.689739227294922\n",
      "Epoch: 26, Batch: 96, D Loss: 0.09651215396756778, G Loss: 21.388519287109375\n",
      "Epoch: 26, Batch: 97, D Loss: 0.10388269300892358, G Loss: 21.406675338745117\n",
      "Epoch: 26, Batch: 98, D Loss: 0.10072869085991928, G Loss: 21.537334442138672\n",
      "Epoch: 26, Batch: 99, D Loss: 0.09600881510161906, G Loss: 21.463533401489258\n",
      "Epoch: 26, Batch: 100, D Loss: 0.09728039827047585, G Loss: 21.304840087890625\n",
      "Epoch: 26, Batch: 101, D Loss: 0.0984741675653247, G Loss: 21.315500259399414\n",
      "Epoch: 26, Batch: 102, D Loss: 0.09469020394349012, G Loss: 21.313926696777344\n",
      "Epoch: 26, Batch: 103, D Loss: 0.09716250029250498, G Loss: 21.372026443481445\n",
      "Epoch: 26, Batch: 104, D Loss: 0.10336898288205613, G Loss: 21.79315757751465\n",
      "Epoch: 26, Batch: 105, D Loss: 0.09955402478502706, G Loss: 22.06538200378418\n",
      "Epoch: 26, Batch: 106, D Loss: 0.09795236601681695, G Loss: 21.90986442565918\n",
      "Epoch: 26, Batch: 107, D Loss: 0.09679155070113339, G Loss: 21.554153442382812\n",
      "Epoch: 26, Batch: 108, D Loss: 0.1095724852677042, G Loss: 21.933725357055664\n",
      "Epoch: 26, Batch: 109, D Loss: 0.09871879978126186, G Loss: 22.18465805053711\n",
      "Epoch: 26, Batch: 110, D Loss: 0.09969325374482627, G Loss: 22.311626434326172\n",
      "Epoch: 26, Batch: 111, D Loss: 0.1034274251205679, G Loss: 22.47563362121582\n",
      "Epoch: 26, Batch: 112, D Loss: 0.09429594884608927, G Loss: 22.160884857177734\n",
      "Epoch: 26, Batch: 113, D Loss: 0.0930107535506639, G Loss: 21.62640380859375\n",
      "Epoch: 26, Batch: 114, D Loss: 0.09981989881408507, G Loss: 21.57027816772461\n",
      "Epoch: 26, Batch: 115, D Loss: 0.10614656671985066, G Loss: 22.249980926513672\n",
      "Epoch: 26, Batch: 116, D Loss: 0.10062382377625556, G Loss: 22.97381591796875\n",
      "Epoch: 26, Batch: 117, D Loss: 0.10049474244514899, G Loss: 23.01083755493164\n",
      "Epoch: 26, Batch: 118, D Loss: 0.10265439755020692, G Loss: 22.613330841064453\n",
      "Epoch: 26, Batch: 119, D Loss: 0.09923562418299625, G Loss: 21.923179626464844\n",
      "Epoch: 26, Batch: 120, D Loss: 0.09528870900036647, G Loss: 21.43815040588379\n",
      "Epoch: 26, Batch: 121, D Loss: 0.10000620804622648, G Loss: 21.618728637695312\n",
      "Epoch: 26, Batch: 122, D Loss: 0.09940423086080649, G Loss: 22.243667602539062\n",
      "Epoch: 26, Batch: 123, D Loss: 0.10212373740753575, G Loss: 23.016454696655273\n",
      "Epoch: 26, Batch: 124, D Loss: 0.09989158068637431, G Loss: 23.2305908203125\n",
      "Epoch: 26, Batch: 125, D Loss: 0.10146227483182586, G Loss: 23.172176361083984\n",
      "Epoch: 26, Batch: 126, D Loss: 0.10209412877307082, G Loss: 23.087905883789062\n",
      "Epoch: 26, Batch: 127, D Loss: 0.09602272516560847, G Loss: 22.6026668548584\n",
      "Epoch: 26, Batch: 128, D Loss: 0.10069226480397667, G Loss: 22.81511878967285\n",
      "Epoch: 26, Batch: 129, D Loss: 0.10064196591306457, G Loss: 23.3343563079834\n",
      "Epoch: 26, Batch: 130, D Loss: 0.09921126815333581, G Loss: 23.961576461791992\n",
      "Epoch: 26, Batch: 131, D Loss: 0.1024335921011776, G Loss: 23.952739715576172\n",
      "Epoch: 26, Batch: 132, D Loss: 0.09918224813368293, G Loss: 24.11776351928711\n",
      "Epoch: 26, Batch: 133, D Loss: 0.1029054001121977, G Loss: 24.3529052734375\n",
      "Epoch: 26, Batch: 134, D Loss: 0.09923110904013623, G Loss: 23.876895904541016\n",
      "Epoch: 26, Batch: 135, D Loss: 0.10281856360498545, G Loss: 23.617971420288086\n",
      "Epoch: 26, Batch: 136, D Loss: 0.10271070900418616, G Loss: 23.567975997924805\n",
      "Epoch: 26, Batch: 137, D Loss: 0.10198532047582703, G Loss: 23.712364196777344\n",
      "Epoch: 26, Batch: 138, D Loss: 0.09905289860843555, G Loss: 23.91345977783203\n",
      "Epoch: 26, Batch: 139, D Loss: 0.09667554500089333, G Loss: 23.644784927368164\n",
      "Epoch: 26, Batch: 140, D Loss: 0.09738587590860738, G Loss: 23.5775146484375\n",
      "Epoch: 26, Batch: 141, D Loss: 0.09919271621272335, G Loss: 23.41058349609375\n",
      "Epoch: 26, Batch: 142, D Loss: 0.10323536399305369, G Loss: 23.480621337890625\n",
      "Epoch: 26, Batch: 143, D Loss: 0.09212066237302192, G Loss: 22.973339080810547\n",
      "Epoch: 26, Batch: 144, D Loss: 0.097106866611564, G Loss: 22.353527069091797\n",
      "Epoch: 26, Batch: 145, D Loss: 0.0989112706408822, G Loss: 21.65159797668457\n",
      "Epoch: 26, Batch: 146, D Loss: 0.09712256523623536, G Loss: 20.7095947265625\n",
      "Epoch: 26, Batch: 147, D Loss: 0.10062374985017608, G Loss: 20.2269287109375\n",
      "Epoch: 26, Batch: 148, D Loss: 0.10435360756559386, G Loss: 20.1295108795166\n",
      "Epoch: 26, Batch: 149, D Loss: 0.10482495373696232, G Loss: 20.02646827697754\n",
      "Epoch: 26, Batch: 150, D Loss: 0.09114414609303811, G Loss: 19.190961837768555\n",
      "Epoch: 26, Batch: 151, D Loss: 0.1018238995515599, G Loss: 18.47150421142578\n",
      "Epoch: 26, Batch: 152, D Loss: 0.09480237906172517, G Loss: 17.76585578918457\n",
      "Epoch: 26, Batch: 153, D Loss: 0.09833555989841702, G Loss: 17.57818031311035\n",
      "Epoch: 26, Batch: 154, D Loss: 0.10350810950099998, G Loss: 17.94709014892578\n",
      "Epoch: 26, Batch: 155, D Loss: 0.09164472028426651, G Loss: 17.846147537231445\n",
      "Epoch: 26, Batch: 156, D Loss: 0.10479081541093205, G Loss: 17.90398406982422\n",
      "Epoch: 26, Batch: 157, D Loss: 0.09838792894572013, G Loss: 17.656566619873047\n",
      "Epoch: 26, Batch: 158, D Loss: 0.10299177138398097, G Loss: 17.515928268432617\n",
      "Epoch: 26, Batch: 159, D Loss: 0.09862701459640277, G Loss: 17.349750518798828\n",
      "Epoch: 26, Batch: 160, D Loss: 0.09827387394164688, G Loss: 17.243417739868164\n",
      "Epoch: 26, Batch: 161, D Loss: 0.09784171168166012, G Loss: 17.19652557373047\n",
      "Epoch: 26, Batch: 162, D Loss: 0.09905896451315144, G Loss: 17.31652069091797\n",
      "Epoch: 26, Batch: 163, D Loss: 0.10411849325633327, G Loss: 17.76192283630371\n",
      "Epoch: 26, Batch: 164, D Loss: 0.09999779715759782, G Loss: 18.013383865356445\n",
      "Epoch: 26, Batch: 165, D Loss: 0.10109797867366144, G Loss: 18.028791427612305\n",
      "Epoch: 26, Batch: 166, D Loss: 0.09667591906976458, G Loss: 17.65923500061035\n",
      "Epoch: 26, Batch: 167, D Loss: 0.09487288389567361, G Loss: 17.109554290771484\n",
      "Epoch: 26, Batch: 168, D Loss: 0.09875031265099565, G Loss: 17.038087844848633\n",
      "Epoch: 26, Batch: 169, D Loss: 0.09908337259902567, G Loss: 17.460538864135742\n",
      "Epoch: 26, Batch: 170, D Loss: 0.0951457805637359, G Loss: 17.768722534179688\n",
      "Epoch: 26, Batch: 171, D Loss: 0.09545967172312508, G Loss: 17.825347900390625\n",
      "Epoch: 26, Batch: 172, D Loss: 0.09825517416716423, G Loss: 17.794721603393555\n",
      "Epoch: 26, Batch: 173, D Loss: 0.09957720505923806, G Loss: 17.848939895629883\n",
      "Epoch: 26, Batch: 174, D Loss: 0.1020360594325549, G Loss: 18.05243492126465\n",
      "Epoch: 26, Batch: 175, D Loss: 0.09403722782248991, G Loss: 17.878639221191406\n",
      "Epoch: 26, Batch: 176, D Loss: 0.09924078128330827, G Loss: 17.828100204467773\n",
      "Epoch: 26, Batch: 177, D Loss: 0.0979328688577965, G Loss: 17.928909301757812\n",
      "Epoch: 26, Batch: 178, D Loss: 0.09869707361219593, G Loss: 18.148115158081055\n",
      "Epoch: 26, Batch: 179, D Loss: 0.09504771135603907, G Loss: 18.17763328552246\n",
      "Epoch: 26, Batch: 180, D Loss: 0.10262980105497022, G Loss: 18.502098083496094\n",
      "Epoch: 26, Batch: 181, D Loss: 0.1033965535841781, G Loss: 18.889522552490234\n",
      "Epoch: 26, Batch: 182, D Loss: 0.09882325247444212, G Loss: 18.88817596435547\n",
      "Epoch: 26, Batch: 183, D Loss: 0.1008997817441295, G Loss: 18.71392822265625\n",
      "Epoch: 26, Batch: 184, D Loss: 0.09550001951020759, G Loss: 18.241498947143555\n",
      "Epoch: 26, Batch: 185, D Loss: 0.10467454614651794, G Loss: 18.341482162475586\n",
      "Epoch: 26, Batch: 186, D Loss: 0.10054865952109937, G Loss: 18.601959228515625\n",
      "Epoch: 26, Batch: 187, D Loss: 0.09321336154183024, G Loss: 18.456363677978516\n",
      "Epoch: 26, Batch: 188, D Loss: 0.10053474924813477, G Loss: 18.51445960998535\n",
      "Epoch: 26, Batch: 189, D Loss: 0.09752479668203895, G Loss: 18.446596145629883\n",
      "Epoch: 26, Batch: 190, D Loss: 0.09990776804199397, G Loss: 18.50225067138672\n",
      "Epoch: 26, Batch: 191, D Loss: 0.09866120385065402, G Loss: 18.493038177490234\n",
      "Epoch: 26, Batch: 192, D Loss: 0.09718636181324447, G Loss: 18.347518920898438\n",
      "Epoch: 26, Batch: 193, D Loss: 0.09829386126584172, G Loss: 18.31634521484375\n",
      "Epoch: 26, Batch: 194, D Loss: 0.09907889156341199, G Loss: 18.38890838623047\n",
      "Epoch: 26, Batch: 195, D Loss: 0.08914514523891004, G Loss: 17.99032974243164\n",
      "Epoch: 26, Batch: 196, D Loss: 0.10633838799270912, G Loss: 18.395357131958008\n",
      "Epoch: 26, Batch: 197, D Loss: 0.0906619333824672, G Loss: 18.327659606933594\n",
      "Epoch: 26, Batch: 198, D Loss: 0.0984758193702362, G Loss: 18.325664520263672\n",
      "Epoch: 26, Batch: 199, D Loss: 0.09405436220686347, G Loss: 18.1672306060791\n",
      "Epoch: 26, Batch: 200, D Loss: 0.09567154867632155, G Loss: 18.10097312927246\n",
      "Epoch: 26, Batch: 201, D Loss: 0.09768003852077056, G Loss: 18.2835636138916\n",
      "Epoch: 26, Batch: 202, D Loss: 0.090488909288712, G Loss: 18.181644439697266\n",
      "Epoch: 26, Batch: 203, D Loss: 0.10537422179338396, G Loss: 18.73186683654785\n",
      "Epoch: 26, Batch: 204, D Loss: 0.10196022960590545, G Loss: 19.30367660522461\n",
      "Epoch: 26, Batch: 205, D Loss: 0.09004345047112094, G Loss: 18.8994083404541\n",
      "Epoch: 26, Batch: 206, D Loss: 0.09558357726253197, G Loss: 18.287281036376953\n",
      "Epoch: 26, Batch: 207, D Loss: 0.10018323192004619, G Loss: 18.278675079345703\n",
      "Epoch: 26, Batch: 208, D Loss: 0.10299382053738437, G Loss: 18.793720245361328\n",
      "Epoch: 26, Batch: 209, D Loss: 0.09401233069504489, G Loss: 18.933542251586914\n",
      "Epoch: 26, Batch: 210, D Loss: 0.09874388863960726, G Loss: 19.006620407104492\n",
      "Epoch: 26, Batch: 211, D Loss: 0.0999334705213244, G Loss: 19.054868698120117\n",
      "Epoch: 26, Batch: 212, D Loss: 0.0991747406506327, G Loss: 19.008378982543945\n",
      "Epoch: 26, Batch: 213, D Loss: 0.097375209713493, G Loss: 18.824129104614258\n",
      "Epoch: 26, Batch: 214, D Loss: 0.10636374635943335, G Loss: 19.1502685546875\n",
      "Epoch: 26, Batch: 215, D Loss: 0.10009652585064766, G Loss: 19.42369842529297\n",
      "Epoch: 26, Batch: 216, D Loss: 0.09621159186858863, G Loss: 19.264232635498047\n",
      "Epoch: 26, Batch: 217, D Loss: 0.10155171386526773, G Loss: 19.133573532104492\n",
      "Epoch: 26, Batch: 218, D Loss: 0.09871565073457544, G Loss: 18.96617317199707\n",
      "Epoch: 26, Batch: 219, D Loss: 0.10071097601109713, G Loss: 18.988195419311523\n",
      "Epoch: 26, Batch: 220, D Loss: 0.09978181397086572, G Loss: 19.05916976928711\n",
      "Epoch: 26, Batch: 221, D Loss: 0.0987496923913318, G Loss: 19.06606674194336\n",
      "Epoch: 26, Batch: 222, D Loss: 0.0934247407047144, G Loss: 18.6594181060791\n",
      "Epoch: 26, Batch: 223, D Loss: 0.09879583558752225, G Loss: 18.45870018005371\n",
      "Epoch: 26, Batch: 224, D Loss: 0.1012849999394394, G Loss: 18.69174575805664\n",
      "Epoch: 26, Batch: 225, D Loss: 0.10296616992975438, G Loss: 19.214801788330078\n",
      "Epoch: 26, Batch: 226, D Loss: 0.09488949412632586, G Loss: 19.158536911010742\n",
      "Epoch: 26, Batch: 227, D Loss: 0.10243021203190494, G Loss: 19.064464569091797\n",
      "Epoch: 26, Batch: 228, D Loss: 0.09648287620700735, G Loss: 18.664974212646484\n",
      "Epoch: 26, Batch: 229, D Loss: 0.09479864430695573, G Loss: 18.24583625793457\n",
      "Epoch: 26, Batch: 230, D Loss: 0.09717201310450774, G Loss: 18.19236183166504\n",
      "Epoch: 26, Batch: 231, D Loss: 0.10635893462945134, G Loss: 18.976375579833984\n",
      "Epoch: 26, Batch: 232, D Loss: 0.10082159392571066, G Loss: 19.647851943969727\n",
      "Epoch: 26, Batch: 233, D Loss: 0.09900249683033957, G Loss: 19.705917358398438\n",
      "Epoch: 26, Batch: 234, D Loss: 0.10333438371851134, G Loss: 19.499801635742188\n",
      "Epoch: 26, Batch: 235, D Loss: 0.10379867447706603, G Loss: 19.26893424987793\n",
      "Epoch: 26, Batch: 236, D Loss: 0.10288108372890581, G Loss: 19.11238670349121\n",
      "Epoch: 26, Batch: 237, D Loss: 0.09559771718456833, G Loss: 18.770729064941406\n",
      "Epoch: 26, Batch: 238, D Loss: 0.09419742649348706, G Loss: 18.427165985107422\n",
      "Epoch: 26, Batch: 239, D Loss: 0.10224207154554854, G Loss: 18.799530029296875\n",
      "Epoch: 26, Batch: 240, D Loss: 0.09924040252595412, G Loss: 19.30238151550293\n",
      "Epoch: 26, Batch: 241, D Loss: 0.09399201182064254, G Loss: 19.31190299987793\n",
      "Epoch: 26, Batch: 242, D Loss: 0.1028285344050135, G Loss: 19.411325454711914\n",
      "Epoch: 26, Batch: 243, D Loss: 0.09560644842067867, G Loss: 19.129985809326172\n",
      "Epoch: 26, Batch: 244, D Loss: 0.09529309283514475, G Loss: 18.699670791625977\n",
      "Epoch: 26, Batch: 245, D Loss: 0.10271194930264582, G Loss: 18.8333797454834\n",
      "Epoch: 26, Batch: 246, D Loss: 0.09833021749133253, G Loss: 19.10480499267578\n",
      "Epoch: 26, Batch: 247, D Loss: 0.104296894829085, G Loss: 19.596921920776367\n",
      "Epoch: 26, Batch: 248, D Loss: 0.09451959450601777, G Loss: 19.43041229248047\n",
      "Epoch: 26, Batch: 249, D Loss: 0.09832532924499704, G Loss: 19.067480087280273\n",
      "Epoch: 26, Batch: 250, D Loss: 0.09816319049870703, G Loss: 18.814489364624023\n",
      "Epoch: 26, Batch: 251, D Loss: 0.10037251136843928, G Loss: 18.916645050048828\n",
      "Epoch: 26, Batch: 252, D Loss: 0.10711694721191023, G Loss: 19.601037979125977\n",
      "Epoch: 26, Batch: 253, D Loss: 0.09830308094754747, G Loss: 19.857593536376953\n",
      "Epoch: 26, Batch: 254, D Loss: 0.10480098538797511, G Loss: 19.96318817138672\n",
      "Epoch: 26, Batch: 255, D Loss: 0.0963332965041388, G Loss: 19.454782485961914\n",
      "Epoch: 26, Batch: 256, D Loss: 0.10789143471639051, G Loss: 19.4586124420166\n",
      "Epoch: 26, Batch: 257, D Loss: 0.09824338744617123, G Loss: 19.333499908447266\n",
      "Epoch: 26, Batch: 258, D Loss: 0.1029687766056453, G Loss: 19.46949005126953\n",
      "Epoch: 26, Batch: 259, D Loss: 0.09849902415590261, G Loss: 19.49276351928711\n",
      "Epoch: 26, Batch: 260, D Loss: 0.10375152681221533, G Loss: 19.707595825195312\n",
      "Epoch: 26, Batch: 261, D Loss: 0.09865783293979258, G Loss: 19.695528030395508\n",
      "Epoch: 26, Batch: 262, D Loss: 0.09506257046824096, G Loss: 19.341053009033203\n",
      "Epoch: 26, Batch: 263, D Loss: 0.0950382972357986, G Loss: 18.953712463378906\n",
      "Epoch: 26, Batch: 264, D Loss: 0.1045811498446041, G Loss: 19.32734489440918\n",
      "Epoch: 26, Batch: 265, D Loss: 0.09578453178813973, G Loss: 19.60649299621582\n",
      "Epoch: 26, Batch: 266, D Loss: 0.09897387165263138, G Loss: 19.807052612304688\n",
      "Epoch: 26, Batch: 267, D Loss: 0.09915714831074474, G Loss: 19.883453369140625\n",
      "Epoch: 26, Batch: 268, D Loss: 0.09758030001164786, G Loss: 19.769153594970703\n",
      "Epoch: 26, Batch: 269, D Loss: 0.09951421753521272, G Loss: 19.695154190063477\n",
      "Epoch: 26, Batch: 270, D Loss: 0.09870686518492122, G Loss: 19.742313385009766\n",
      "Epoch: 26, Batch: 271, D Loss: 0.0987657470231067, G Loss: 19.84486961364746\n",
      "Epoch: 26, Batch: 272, D Loss: 0.09506520008570396, G Loss: 19.77834701538086\n",
      "Epoch: 26, Batch: 273, D Loss: 0.10213910904560575, G Loss: 19.971242904663086\n",
      "Epoch: 26, Batch: 274, D Loss: 0.09033284461559365, G Loss: 19.656166076660156\n",
      "Epoch: 26, Batch: 275, D Loss: 0.0988756582064988, G Loss: 19.619722366333008\n",
      "Epoch: 26, Batch: 276, D Loss: 0.10669745617224147, G Loss: 20.178293228149414\n",
      "Epoch: 26, Batch: 277, D Loss: 0.10360825128817452, G Loss: 20.65465545654297\n",
      "Epoch: 26, Batch: 278, D Loss: 0.10049879604862494, G Loss: 20.641704559326172\n",
      "Epoch: 26, Batch: 279, D Loss: 0.09354119083424112, G Loss: 19.874353408813477\n",
      "Epoch: 26, Batch: 280, D Loss: 0.09280662430110542, G Loss: 18.933685302734375\n",
      "Epoch: 26, Batch: 281, D Loss: 0.10057029432230835, G Loss: 18.90571403503418\n",
      "Epoch: 26, Batch: 282, D Loss: 0.09967702847840165, G Loss: 19.53885841369629\n",
      "Epoch: 26, Batch: 283, D Loss: 0.09822621309274715, G Loss: 20.24201774597168\n",
      "Epoch: 26, Batch: 284, D Loss: 0.10801038198045138, G Loss: 21.079914093017578\n",
      "Epoch: 26, Batch: 285, D Loss: 0.10302871497660748, G Loss: 21.25179100036621\n",
      "Epoch: 26, Batch: 286, D Loss: 0.10455485469645498, G Loss: 20.855335235595703\n",
      "Epoch: 26, Batch: 287, D Loss: 0.10367281794092836, G Loss: 20.283859252929688\n",
      "Epoch: 26, Batch: 288, D Loss: 0.10022652247667896, G Loss: 19.8299503326416\n",
      "Epoch: 26, Batch: 289, D Loss: 0.10426220413854359, G Loss: 19.928485870361328\n",
      "Epoch: 26, Batch: 290, D Loss: 0.10427910173128968, G Loss: 20.44988250732422\n",
      "Epoch: 26, Batch: 291, D Loss: 0.10088500434912268, G Loss: 20.809232711791992\n",
      "Epoch: 26, Batch: 292, D Loss: 0.10218860997807391, G Loss: 20.899459838867188\n",
      "Epoch: 26, Batch: 293, D Loss: 0.09706059895709679, G Loss: 20.47484016418457\n",
      "Epoch: 26, Batch: 294, D Loss: 0.09320650341920561, G Loss: 19.76874542236328\n",
      "Epoch: 26, Batch: 295, D Loss: 0.08738240051858859, G Loss: 18.972349166870117\n",
      "Epoch: 26, Batch: 296, D Loss: 0.09744970771479888, G Loss: 19.089221954345703\n",
      "Epoch: 26, Batch: 297, D Loss: 0.09386205113614188, G Loss: 19.70328712463379\n",
      "Epoch: 26, Batch: 298, D Loss: 0.1015149884707558, G Loss: 20.68012046813965\n",
      "Epoch: 26, Batch: 299, D Loss: 0.09902576398099658, G Loss: 21.139881134033203\n",
      "Epoch: 26, Batch: 300, D Loss: 0.10116403585357572, G Loss: 21.002199172973633\n",
      "Epoch: 26, Batch: 301, D Loss: 0.0956130629773802, G Loss: 20.13893699645996\n",
      "Epoch: 26, Batch: 302, D Loss: 0.09415041062179075, G Loss: 19.120943069458008\n",
      "Epoch: 26, Batch: 303, D Loss: 0.10131486772551224, G Loss: 18.982465744018555\n",
      "Epoch: 26, Batch: 304, D Loss: 0.10343671041218072, G Loss: 19.69007682800293\n",
      "Epoch: 26, Batch: 305, D Loss: 0.0988154495567386, G Loss: 20.384130477905273\n",
      "Epoch: 26, Batch: 306, D Loss: 0.1051962082989486, G Loss: 20.891956329345703\n",
      "Epoch: 26, Batch: 307, D Loss: 0.10388532324685415, G Loss: 20.824901580810547\n",
      "Epoch: 26, Batch: 308, D Loss: 0.10284172802955355, G Loss: 20.30502700805664\n",
      "Epoch: 26, Batch: 309, D Loss: 0.10092495490183306, G Loss: 19.62939453125\n",
      "Epoch: 26, Batch: 310, D Loss: 0.09616781977478595, G Loss: 19.007291793823242\n",
      "Epoch: 26, Batch: 311, D Loss: 0.0989433554985577, G Loss: 18.997108459472656\n",
      "Epoch: 26, Batch: 312, D Loss: 0.10812113605032225, G Loss: 19.925161361694336\n",
      "Epoch: 26, Batch: 313, D Loss: 0.09771062515962936, G Loss: 20.49563980102539\n",
      "Epoch: 26, Batch: 314, D Loss: 0.09637334264796887, G Loss: 20.371435165405273\n",
      "Epoch: 26, Batch: 315, D Loss: 0.09872353912724202, G Loss: 19.907350540161133\n",
      "Epoch: 26, Batch: 316, D Loss: 0.09249168805726371, G Loss: 19.109678268432617\n",
      "Epoch: 26, Batch: 317, D Loss: 0.10678200648943292, G Loss: 19.31434440612793\n",
      "Epoch: 26, Batch: 318, D Loss: 0.09380079985118928, G Loss: 19.566499710083008\n",
      "Epoch: 26, Batch: 319, D Loss: 0.09706788645864706, G Loss: 19.867063522338867\n",
      "Epoch: 26, Batch: 320, D Loss: 0.10421689690056624, G Loss: 20.37045669555664\n",
      "Epoch: 26, Batch: 321, D Loss: 0.10065496777949734, G Loss: 20.541921615600586\n",
      "Epoch: 26, Batch: 322, D Loss: 0.09814614874039002, G Loss: 20.20863914489746\n",
      "Epoch: 26, Batch: 323, D Loss: 0.10003033385891946, G Loss: 19.767559051513672\n",
      "Epoch: 26, Batch: 324, D Loss: 0.10257218917502087, G Loss: 19.63672637939453\n",
      "Epoch: 26, Batch: 325, D Loss: 0.09909249243361962, G Loss: 19.662946701049805\n",
      "Epoch: 26, Batch: 326, D Loss: 0.09987427426865214, G Loss: 19.82526969909668\n",
      "Epoch: 26, Batch: 327, D Loss: 0.09779302154097447, G Loss: 19.81756019592285\n",
      "Epoch: 26, Batch: 328, D Loss: 0.1021642845702011, G Loss: 19.915266036987305\n",
      "Epoch: 26, Batch: 329, D Loss: 0.10141202170580788, G Loss: 19.984338760375977\n",
      "Epoch: 26, Batch: 330, D Loss: 0.0968255263898481, G Loss: 19.685998916625977\n",
      "Epoch: 26, Batch: 331, D Loss: 0.10278242979800412, G Loss: 19.52876091003418\n",
      "Epoch: 26, Batch: 332, D Loss: 0.10223587761138953, G Loss: 19.604341506958008\n",
      "Epoch: 26, Batch: 333, D Loss: 0.10234421627481971, G Loss: 19.832046508789062\n",
      "Epoch: 26, Batch: 334, D Loss: 0.09069328160934487, G Loss: 19.427814483642578\n",
      "Epoch: 26, Batch: 335, D Loss: 0.10128162244525152, G Loss: 19.371044158935547\n",
      "Epoch: 26, Batch: 336, D Loss: 0.10653677730694178, G Loss: 19.87923812866211\n",
      "Epoch: 26, Batch: 337, D Loss: 0.09962920947005216, G Loss: 20.120487213134766\n",
      "Epoch: 26, Batch: 338, D Loss: 0.104291991260471, G Loss: 20.233558654785156\n",
      "Epoch: 26, Batch: 339, D Loss: 0.09727926656374841, G Loss: 19.77109146118164\n",
      "Epoch: 26, Batch: 340, D Loss: 0.09394542323097, G Loss: 18.99118995666504\n",
      "Epoch: 26, Batch: 341, D Loss: 0.09477049488570266, G Loss: 18.442277908325195\n",
      "Epoch: 26, Batch: 342, D Loss: 0.09576624362611907, G Loss: 18.49940299987793\n",
      "Epoch: 26, Batch: 343, D Loss: 0.09756326245706548, G Loss: 19.2154541015625\n",
      "Epoch: 26, Batch: 344, D Loss: 0.09284393659814005, G Loss: 19.750648498535156\n",
      "Epoch: 26, Batch: 345, D Loss: 0.10131796549507344, G Loss: 20.280052185058594\n",
      "Epoch: 26, Batch: 346, D Loss: 0.0953157701356192, G Loss: 20.180883407592773\n",
      "Epoch: 26, Batch: 347, D Loss: 0.09452799821873215, G Loss: 19.641422271728516\n",
      "Epoch: 26, Batch: 348, D Loss: 0.09913569869017669, G Loss: 19.26171875\n",
      "Epoch: 26, Batch: 349, D Loss: 0.09554469816411237, G Loss: 19.132774353027344\n",
      "Epoch: 26, Batch: 350, D Loss: 0.0975467882092722, G Loss: 19.394325256347656\n",
      "Epoch: 26, Batch: 351, D Loss: 0.10240407419592445, G Loss: 20.081541061401367\n",
      "Epoch: 26, Batch: 352, D Loss: 0.09725720515111058, G Loss: 20.414621353149414\n",
      "Epoch: 26, Batch: 353, D Loss: 0.09995754876914292, G Loss: 20.397151947021484\n",
      "Epoch: 26, Batch: 354, D Loss: 0.10049536903246309, G Loss: 20.14750099182129\n",
      "Epoch: 26, Batch: 355, D Loss: 0.09389410286909639, G Loss: 19.591655731201172\n",
      "Epoch: 26, Batch: 356, D Loss: 0.09991117738191879, G Loss: 19.402572631835938\n",
      "Epoch: 26, Batch: 357, D Loss: 0.09955693947045186, G Loss: 19.63702964782715\n",
      "Epoch: 26, Batch: 358, D Loss: 0.09823906544064775, G Loss: 20.000431060791016\n",
      "Epoch: 26, Batch: 359, D Loss: 0.10145422898681578, G Loss: 20.4246883392334\n",
      "Epoch: 26, Batch: 360, D Loss: 0.09220989124140061, G Loss: 20.205324172973633\n",
      "Epoch: 26, Batch: 361, D Loss: 0.09662056070915959, G Loss: 19.840965270996094\n",
      "Epoch: 26, Batch: 362, D Loss: 0.10648531574552289, G Loss: 20.057802200317383\n",
      "Epoch: 26, Batch: 363, D Loss: 0.09986531819490646, G Loss: 20.313982009887695\n",
      "Epoch: 26, Batch: 364, D Loss: 0.10166974433197351, G Loss: 20.522241592407227\n",
      "Epoch: 26, Batch: 365, D Loss: 0.10044053256746882, G Loss: 20.563297271728516\n",
      "Epoch: 26, Batch: 366, D Loss: 0.10336308984375098, G Loss: 20.58466911315918\n",
      "Epoch: 26, Batch: 367, D Loss: 0.10186091868864572, G Loss: 20.553377151489258\n",
      "Epoch: 26, Batch: 368, D Loss: 0.10150578680193978, G Loss: 20.463478088378906\n",
      "Epoch: 26, Batch: 369, D Loss: 0.1060338174983414, G Loss: 20.72634506225586\n",
      "Epoch: 26, Batch: 370, D Loss: 0.09503053183541033, G Loss: 20.545879364013672\n",
      "Epoch: 26, Batch: 371, D Loss: 0.10495920535677428, G Loss: 20.655256271362305\n",
      "Epoch: 26, Batch: 372, D Loss: 0.09932057610103773, G Loss: 20.76180076599121\n",
      "Epoch: 26, Batch: 373, D Loss: 0.10362157266269442, G Loss: 21.081724166870117\n",
      "Epoch: 26, Batch: 374, D Loss: 0.10280489951481625, G Loss: 21.377052307128906\n",
      "Epoch: 26, Batch: 375, D Loss: 0.09753707077778356, G Loss: 21.341148376464844\n",
      "Epoch: 26, Batch: 376, D Loss: 0.1016475561026492, G Loss: 21.306241989135742\n",
      "Epoch: 26, Batch: 377, D Loss: 0.10104072121315655, G Loss: 21.344928741455078\n",
      "Epoch: 26, Batch: 378, D Loss: 0.09465593128139749, G Loss: 21.228759765625\n",
      "Epoch: 26, Batch: 379, D Loss: 0.10080315200222006, G Loss: 21.401023864746094\n",
      "Epoch: 26, Batch: 380, D Loss: 0.10178603253091052, G Loss: 21.744789123535156\n",
      "Epoch: 26, Batch: 381, D Loss: 0.09900484994371965, G Loss: 22.064342498779297\n",
      "Epoch: 26, Batch: 382, D Loss: 0.10841698954676222, G Loss: 22.553030014038086\n",
      "Epoch: 26, Batch: 383, D Loss: 0.10521852977280058, G Loss: 22.770004272460938\n",
      "Epoch: 26, Batch: 384, D Loss: 0.10077769316944753, G Loss: 22.444419860839844\n",
      "Epoch: 26, Batch: 385, D Loss: 0.09187004729360063, G Loss: 21.568767547607422\n",
      "Epoch: 26, Batch: 386, D Loss: 0.10098977413699442, G Loss: 21.15116310119629\n",
      "Epoch: 26, Batch: 387, D Loss: 0.10193365094191181, G Loss: 21.51287841796875\n",
      "Epoch: 26, Batch: 388, D Loss: 0.0951992796590233, G Loss: 22.04074478149414\n",
      "Epoch: 26, Batch: 389, D Loss: 0.09469489019157838, G Loss: 22.419841766357422\n",
      "Epoch: 26, Batch: 390, D Loss: 0.09986464687062542, G Loss: 22.72110939025879\n",
      "Epoch: 26, Batch: 391, D Loss: 0.10264729714543366, G Loss: 22.919130325317383\n",
      "Epoch: 26, Batch: 392, D Loss: 0.09852489835103503, G Loss: 22.7626953125\n",
      "Epoch: 26, Batch: 393, D Loss: 0.10475292808434315, G Loss: 22.741785049438477\n",
      "Epoch: 26, Batch: 394, D Loss: 0.0945239887422306, G Loss: 22.43449592590332\n",
      "Epoch: 26, Batch: 395, D Loss: 0.1075160355152324, G Loss: 22.721981048583984\n",
      "Epoch: 26, Batch: 396, D Loss: 0.10052682464983738, G Loss: 23.07390022277832\n",
      "Epoch: 26, Batch: 397, D Loss: 0.10157588128414288, G Loss: 23.341638565063477\n",
      "Epoch: 26, Batch: 398, D Loss: 0.10085369650007148, G Loss: 23.44234848022461\n",
      "Epoch: 26, Batch: 399, D Loss: 0.09901711348368268, G Loss: 23.248943328857422\n",
      "Epoch: 26, Batch: 400, D Loss: 0.09718893473137136, G Loss: 22.918907165527344\n",
      "Epoch: 26, Batch: 401, D Loss: 0.10659942035739961, G Loss: 23.186279296875\n",
      "Epoch: 26, Batch: 402, D Loss: 0.1006459296094184, G Loss: 23.588895797729492\n",
      "Epoch: 26, Batch: 403, D Loss: 0.10022829475533919, G Loss: 23.82470703125\n",
      "Epoch: 26, Batch: 404, D Loss: 0.09960213305793503, G Loss: 23.84303092956543\n",
      "Epoch: 26, Batch: 405, D Loss: 0.09493978324212006, G Loss: 23.488685607910156\n",
      "Epoch: 26, Batch: 406, D Loss: 0.10106089714369643, G Loss: 23.4687557220459\n",
      "Epoch: 26, Batch: 407, D Loss: 0.10078479352321469, G Loss: 23.792125701904297\n",
      "Epoch: 26, Batch: 408, D Loss: 0.09829224648015222, G Loss: 24.150861740112305\n",
      "Epoch: 26, Batch: 409, D Loss: 0.09626713396596288, G Loss: 24.329710006713867\n",
      "Epoch: 26, Batch: 410, D Loss: 0.09901693464588612, G Loss: 24.466617584228516\n",
      "Epoch: 26, Batch: 411, D Loss: 0.09664832056763764, G Loss: 24.448448181152344\n",
      "Epoch: 26, Batch: 412, D Loss: 0.10038091243418609, G Loss: 24.61359214782715\n",
      "Epoch: 26, Batch: 413, D Loss: 0.09802114964518725, G Loss: 24.679279327392578\n",
      "Epoch: 26, Batch: 414, D Loss: 0.09465055913826079, G Loss: 24.427181243896484\n",
      "Epoch: 26, Batch: 415, D Loss: 0.09903930128951856, G Loss: 24.27916145324707\n",
      "Epoch: 26, Batch: 416, D Loss: 0.09704456479899316, G Loss: 24.132904052734375\n",
      "Epoch: 26, Batch: 417, D Loss: 0.09359440209375082, G Loss: 23.874059677124023\n",
      "Epoch: 26, Batch: 418, D Loss: 0.1025755405629262, G Loss: 23.97268295288086\n",
      "Epoch: 26, Batch: 419, D Loss: 0.09614072742025542, G Loss: 23.96509552001953\n",
      "Epoch: 26, Batch: 420, D Loss: 0.0972251668783336, G Loss: 23.820505142211914\n",
      "Epoch: 26, Batch: 421, D Loss: 0.10011973979281327, G Loss: 23.877113342285156\n",
      "Epoch: 26, Batch: 422, D Loss: 0.10321033747906436, G Loss: 24.095626831054688\n",
      "Epoch: 26, Batch: 423, D Loss: 0.10168218614280648, G Loss: 24.216453552246094\n",
      "Epoch: 26, Batch: 424, D Loss: 0.0976731330335073, G Loss: 23.90927505493164\n",
      "Epoch: 26, Batch: 425, D Loss: 0.10666200520718462, G Loss: 23.869638442993164\n",
      "Epoch: 26, Batch: 426, D Loss: 0.09955160322177237, G Loss: 23.683137893676758\n",
      "Epoch: 26, Batch: 427, D Loss: 0.10340377691126, G Loss: 23.59235191345215\n",
      "Epoch: 26, Batch: 428, D Loss: 0.10008820894437065, G Loss: 23.450843811035156\n",
      "Epoch: 26, Batch: 429, D Loss: 0.09923503551572234, G Loss: 23.233169555664062\n",
      "Epoch: 26, Batch: 430, D Loss: 0.09509673719390528, G Loss: 22.935203552246094\n",
      "Epoch: 26, Batch: 431, D Loss: 0.1004033983287171, G Loss: 22.98454475402832\n",
      "Epoch: 26, Batch: 432, D Loss: 0.10292277489320943, G Loss: 23.39876365661621\n",
      "Epoch: 26, Batch: 433, D Loss: 0.09308220449465156, G Loss: 23.44816017150879\n",
      "Epoch: 26, Batch: 434, D Loss: 0.09818866852248735, G Loss: 23.43345069885254\n",
      "Epoch: 26, Batch: 435, D Loss: 0.1035581454939396, G Loss: 23.599817276000977\n",
      "Epoch: 26, Batch: 436, D Loss: 0.09864941987133001, G Loss: 23.667478561401367\n",
      "Epoch: 26, Batch: 437, D Loss: 0.09382349255670304, G Loss: 23.437902450561523\n",
      "Epoch: 26, Batch: 438, D Loss: 0.09731963280487661, G Loss: 23.266048431396484\n",
      "Epoch: 26, Batch: 439, D Loss: 0.0970050171407538, G Loss: 23.282337188720703\n",
      "Epoch: 26, Batch: 440, D Loss: 0.09842161837606375, G Loss: 23.546428680419922\n",
      "Epoch: 26, Batch: 441, D Loss: 0.09557747843619514, G Loss: 23.701351165771484\n",
      "Epoch: 26, Batch: 442, D Loss: 0.09744661303851038, G Loss: 23.75275993347168\n",
      "Epoch: 26, Batch: 443, D Loss: 0.09920531513749316, G Loss: 23.695545196533203\n",
      "Epoch: 26, Batch: 444, D Loss: 0.09675071391177693, G Loss: 23.5640869140625\n",
      "Epoch: 26, Batch: 445, D Loss: 0.1019481122780558, G Loss: 23.597360610961914\n",
      "Epoch: 26, Batch: 446, D Loss: 0.09924144300633964, G Loss: 23.61602783203125\n",
      "Epoch: 26, Batch: 447, D Loss: 0.10121531042120076, G Loss: 23.705474853515625\n",
      "Epoch: 26, Batch: 448, D Loss: 0.10180944951904636, G Loss: 23.718944549560547\n",
      "Epoch: 26, Batch: 449, D Loss: 0.09288832548522795, G Loss: 23.224205017089844\n",
      "Epoch: 26, Batch: 450, D Loss: 0.09894581888880205, G Loss: 22.950721740722656\n",
      "Epoch: 26, Batch: 451, D Loss: 0.09964051847916455, G Loss: 23.00917625427246\n",
      "Epoch: 26, Batch: 452, D Loss: 0.09946053479535108, G Loss: 23.28631019592285\n",
      "Epoch: 26, Batch: 453, D Loss: 0.09525593373907407, G Loss: 23.3593692779541\n",
      "Epoch: 26, Batch: 454, D Loss: 0.09472864870179061, G Loss: 23.18680191040039\n",
      "Epoch: 26, Batch: 455, D Loss: 0.09349125628575615, G Loss: 22.929677963256836\n",
      "Epoch: 26, Batch: 456, D Loss: 0.09304308897500693, G Loss: 22.70238494873047\n",
      "Epoch: 26, Batch: 457, D Loss: 0.10112310206698435, G Loss: 23.04527473449707\n",
      "Epoch: 26, Batch: 458, D Loss: 0.09561112527190381, G Loss: 23.37978744506836\n",
      "Epoch: 26, Batch: 459, D Loss: 0.09693056348314866, G Loss: 23.480175018310547\n",
      "Epoch: 26, Batch: 460, D Loss: 0.09268742058515261, G Loss: 23.130834579467773\n",
      "Epoch: 26, Batch: 461, D Loss: 0.09711069618770923, G Loss: 22.902591705322266\n",
      "Epoch: 26, Batch: 462, D Loss: 0.11165704582005823, G Loss: 23.634429931640625\n",
      "Epoch: 26, Batch: 463, D Loss: 0.09877411278292911, G Loss: 24.046138763427734\n",
      "Epoch: 26, Batch: 464, D Loss: 0.09301196040908477, G Loss: 23.6798152923584\n",
      "Epoch: 26, Batch: 465, D Loss: 0.09694855663760425, G Loss: 23.081087112426758\n",
      "Epoch: 26, Batch: 466, D Loss: 0.0942374468460739, G Loss: 22.594871520996094\n",
      "Epoch: 26, Batch: 467, D Loss: 0.09458981462338922, G Loss: 22.528724670410156\n",
      "Epoch: 27, Batch: 0, D Loss: 0.10493716602728369, G Loss: 23.407758712768555\n",
      "Epoch: 27, Batch: 1, D Loss: 0.09518761190394912, G Loss: 23.92244529724121\n",
      "Epoch: 27, Batch: 2, D Loss: 0.10094839336325294, G Loss: 24.121129989624023\n",
      "Epoch: 27, Batch: 3, D Loss: 0.10421650113409467, G Loss: 24.052021026611328\n",
      "Epoch: 27, Batch: 4, D Loss: 0.10366398098226093, G Loss: 23.71312141418457\n",
      "Epoch: 27, Batch: 5, D Loss: 0.09693653885161652, G Loss: 23.024154663085938\n",
      "Epoch: 27, Batch: 6, D Loss: 0.09775778657779663, G Loss: 22.516258239746094\n",
      "Epoch: 27, Batch: 7, D Loss: 0.10098529615038795, G Loss: 22.59596061706543\n",
      "Epoch: 27, Batch: 8, D Loss: 0.10015819972722427, G Loss: 23.088403701782227\n",
      "Epoch: 27, Batch: 9, D Loss: 0.10201671723079223, G Loss: 23.631519317626953\n",
      "Epoch: 27, Batch: 10, D Loss: 0.10313658418603841, G Loss: 23.929128646850586\n",
      "Epoch: 27, Batch: 11, D Loss: 0.1036165654868926, G Loss: 23.86423683166504\n",
      "Epoch: 27, Batch: 12, D Loss: 0.09764921668230808, G Loss: 23.217361450195312\n",
      "Epoch: 27, Batch: 13, D Loss: 0.09990486508357724, G Loss: 22.60039710998535\n",
      "Epoch: 27, Batch: 14, D Loss: 0.09923619040591289, G Loss: 22.359546661376953\n",
      "Epoch: 27, Batch: 15, D Loss: 0.10007601240008066, G Loss: 22.57933807373047\n",
      "Epoch: 27, Batch: 16, D Loss: 0.0958967060530341, G Loss: 22.844758987426758\n",
      "Epoch: 27, Batch: 17, D Loss: 0.09984293585201044, G Loss: 23.13400650024414\n",
      "Epoch: 27, Batch: 18, D Loss: 0.09738539163880153, G Loss: 23.094316482543945\n",
      "Epoch: 27, Batch: 19, D Loss: 0.09746868913832704, G Loss: 22.808109283447266\n",
      "Epoch: 27, Batch: 20, D Loss: 0.10316759354045475, G Loss: 22.834794998168945\n",
      "Epoch: 27, Batch: 21, D Loss: 0.09760391718432963, G Loss: 22.775074005126953\n",
      "Epoch: 27, Batch: 22, D Loss: 0.09021835037506201, G Loss: 22.269407272338867\n",
      "Epoch: 27, Batch: 23, D Loss: 0.10862509169615865, G Loss: 22.72456932067871\n",
      "Epoch: 27, Batch: 24, D Loss: 0.0993544236375041, G Loss: 23.11717414855957\n",
      "Epoch: 27, Batch: 25, D Loss: 0.09857448194881085, G Loss: 23.173452377319336\n",
      "Epoch: 27, Batch: 26, D Loss: 0.10574285690088553, G Loss: 23.282886505126953\n",
      "Epoch: 27, Batch: 27, D Loss: 0.09725450729097108, G Loss: 22.89792823791504\n",
      "Epoch: 27, Batch: 28, D Loss: 0.09845146544184757, G Loss: 22.406845092773438\n",
      "Epoch: 27, Batch: 29, D Loss: 0.10324452826725189, G Loss: 22.406984329223633\n",
      "Epoch: 27, Batch: 30, D Loss: 0.10065311201476906, G Loss: 22.68720054626465\n",
      "Epoch: 27, Batch: 31, D Loss: 0.09939539438828847, G Loss: 22.890491485595703\n",
      "Epoch: 27, Batch: 32, D Loss: 0.0991796106660115, G Loss: 22.9322509765625\n",
      "Epoch: 27, Batch: 33, D Loss: 0.10124977683660569, G Loss: 22.894800186157227\n",
      "Epoch: 27, Batch: 34, D Loss: 0.09853478527430225, G Loss: 22.69806480407715\n",
      "Epoch: 27, Batch: 35, D Loss: 0.10531598336229721, G Loss: 22.7689208984375\n",
      "Epoch: 27, Batch: 36, D Loss: 0.09691730893814827, G Loss: 22.58642578125\n",
      "Epoch: 27, Batch: 37, D Loss: 0.09624503561960425, G Loss: 22.29444694519043\n",
      "Epoch: 27, Batch: 38, D Loss: 0.098973617064405, G Loss: 22.24327850341797\n",
      "Epoch: 27, Batch: 39, D Loss: 0.0967693031901076, G Loss: 22.29026985168457\n",
      "Epoch: 27, Batch: 40, D Loss: 0.09988759467201007, G Loss: 22.5424747467041\n",
      "Epoch: 27, Batch: 41, D Loss: 0.09230089196395524, G Loss: 22.392547607421875\n",
      "Epoch: 27, Batch: 42, D Loss: 0.10121643552528725, G Loss: 22.419767379760742\n",
      "Epoch: 27, Batch: 43, D Loss: 0.10075232394985381, G Loss: 22.586711883544922\n",
      "Epoch: 27, Batch: 44, D Loss: 0.10125873990082163, G Loss: 22.734619140625\n",
      "Epoch: 27, Batch: 45, D Loss: 0.09486877926168838, G Loss: 22.41256332397461\n",
      "Epoch: 27, Batch: 46, D Loss: 0.10030642162310024, G Loss: 22.172086715698242\n",
      "Epoch: 27, Batch: 47, D Loss: 0.09832506639352731, G Loss: 22.05205726623535\n",
      "Epoch: 27, Batch: 48, D Loss: 0.10217176389635733, G Loss: 22.260807037353516\n",
      "Epoch: 27, Batch: 49, D Loss: 0.09844087819035965, G Loss: 22.453102111816406\n",
      "Epoch: 27, Batch: 50, D Loss: 0.09942235805866906, G Loss: 22.596120834350586\n",
      "Epoch: 27, Batch: 51, D Loss: 0.09294834742039135, G Loss: 22.289642333984375\n",
      "Epoch: 27, Batch: 52, D Loss: 0.09508293134343122, G Loss: 21.979393005371094\n",
      "Epoch: 27, Batch: 53, D Loss: 0.10805995027351771, G Loss: 22.63857650756836\n",
      "Epoch: 27, Batch: 54, D Loss: 0.09825667744800598, G Loss: 23.064001083374023\n",
      "Epoch: 27, Batch: 55, D Loss: 0.10363827649842405, G Loss: 23.385257720947266\n",
      "Epoch: 27, Batch: 56, D Loss: 0.10207121077910901, G Loss: 23.26870346069336\n",
      "Epoch: 27, Batch: 57, D Loss: 0.09537599986607097, G Loss: 22.53156852722168\n",
      "Epoch: 27, Batch: 58, D Loss: 0.09415939463660461, G Loss: 21.59717559814453\n",
      "Epoch: 27, Batch: 59, D Loss: 0.10097953698654476, G Loss: 21.542530059814453\n",
      "Epoch: 27, Batch: 60, D Loss: 0.0997772516435823, G Loss: 22.132532119750977\n",
      "Epoch: 27, Batch: 61, D Loss: 0.10499136902279407, G Loss: 23.099199295043945\n",
      "Epoch: 27, Batch: 62, D Loss: 0.09689244632034308, G Loss: 23.34534454345703\n",
      "Epoch: 27, Batch: 63, D Loss: 0.10408639911748384, G Loss: 23.204734802246094\n",
      "Epoch: 27, Batch: 64, D Loss: 0.0955548138054324, G Loss: 22.43031883239746\n",
      "Epoch: 27, Batch: 65, D Loss: 0.10173179220646451, G Loss: 21.993009567260742\n",
      "Epoch: 27, Batch: 66, D Loss: 0.09815061852558964, G Loss: 21.85246467590332\n",
      "Epoch: 27, Batch: 67, D Loss: 0.10100816203845907, G Loss: 22.180858612060547\n",
      "Epoch: 27, Batch: 68, D Loss: 0.10361427076390965, G Loss: 22.97066879272461\n",
      "Epoch: 27, Batch: 69, D Loss: 0.09966736291065068, G Loss: 23.41257095336914\n",
      "Epoch: 27, Batch: 70, D Loss: 0.10410667958982031, G Loss: 23.582448959350586\n",
      "Epoch: 27, Batch: 71, D Loss: 0.09785577658756685, G Loss: 22.98783302307129\n",
      "Epoch: 27, Batch: 72, D Loss: 0.10887452220308322, G Loss: 22.93077278137207\n",
      "Epoch: 27, Batch: 73, D Loss: 0.10582885151047967, G Loss: 23.147085189819336\n",
      "Epoch: 27, Batch: 74, D Loss: 0.09449404483933777, G Loss: 22.614269256591797\n",
      "Epoch: 27, Batch: 75, D Loss: 0.10241214939672243, G Loss: 22.35232162475586\n",
      "Epoch: 27, Batch: 76, D Loss: 0.09832109521478671, G Loss: 22.20802879333496\n",
      "Epoch: 27, Batch: 77, D Loss: 0.10150433341321868, G Loss: 22.523645401000977\n",
      "Epoch: 27, Batch: 78, D Loss: 0.09929509468310045, G Loss: 22.737228393554688\n",
      "Epoch: 27, Batch: 79, D Loss: 0.0976655856474579, G Loss: 22.647193908691406\n",
      "Epoch: 27, Batch: 80, D Loss: 0.09216663251404657, G Loss: 22.045726776123047\n",
      "Epoch: 27, Batch: 81, D Loss: 0.09597259776324278, G Loss: 21.648197174072266\n",
      "Epoch: 27, Batch: 82, D Loss: 0.10022662596764614, G Loss: 21.968589782714844\n",
      "Epoch: 27, Batch: 83, D Loss: 0.09799945365553815, G Loss: 22.463882446289062\n",
      "Epoch: 27, Batch: 84, D Loss: 0.09666678316722946, G Loss: 22.81741714477539\n",
      "Epoch: 27, Batch: 85, D Loss: 0.09901580965280968, G Loss: 22.957035064697266\n",
      "Epoch: 27, Batch: 86, D Loss: 0.10327167814117691, G Loss: 23.047170639038086\n",
      "Epoch: 27, Batch: 87, D Loss: 0.0956507325788935, G Loss: 22.608495712280273\n",
      "Epoch: 27, Batch: 88, D Loss: 0.10101665565003143, G Loss: 22.377065658569336\n",
      "Epoch: 27, Batch: 89, D Loss: 0.09428289544266234, G Loss: 22.01041030883789\n",
      "Epoch: 27, Batch: 90, D Loss: 0.0991425068549844, G Loss: 22.0338077545166\n",
      "Epoch: 27, Batch: 91, D Loss: 0.10038468252730043, G Loss: 22.414216995239258\n",
      "Epoch: 27, Batch: 92, D Loss: 0.10296118266516241, G Loss: 22.913772583007812\n",
      "Epoch: 27, Batch: 93, D Loss: 0.09084995842964087, G Loss: 22.502391815185547\n",
      "Epoch: 27, Batch: 94, D Loss: 0.09953630725979828, G Loss: 22.110340118408203\n",
      "Epoch: 27, Batch: 95, D Loss: 0.10018371058977349, G Loss: 21.978618621826172\n",
      "Epoch: 27, Batch: 96, D Loss: 0.09703733786068208, G Loss: 22.00827407836914\n",
      "Epoch: 27, Batch: 97, D Loss: 0.10585254440862917, G Loss: 22.6069278717041\n",
      "Epoch: 27, Batch: 98, D Loss: 0.09477186210317223, G Loss: 22.680187225341797\n",
      "Epoch: 27, Batch: 99, D Loss: 0.09592562922292491, G Loss: 22.351789474487305\n",
      "Epoch: 27, Batch: 100, D Loss: 0.10493975142253506, G Loss: 22.40314292907715\n",
      "Epoch: 27, Batch: 101, D Loss: 0.09957882026237351, G Loss: 22.399097442626953\n",
      "Epoch: 27, Batch: 102, D Loss: 0.10327804842126748, G Loss: 22.587142944335938\n",
      "Epoch: 27, Batch: 103, D Loss: 0.09757749744557649, G Loss: 22.46959114074707\n",
      "Epoch: 27, Batch: 104, D Loss: 0.1003965140304874, G Loss: 22.376605987548828\n",
      "Epoch: 27, Batch: 105, D Loss: 0.09464724373407227, G Loss: 22.02553367614746\n",
      "Epoch: 27, Batch: 106, D Loss: 0.09638018921450515, G Loss: 21.797164916992188\n",
      "Epoch: 27, Batch: 107, D Loss: 0.09891276077956865, G Loss: 21.872594833374023\n",
      "Epoch: 27, Batch: 108, D Loss: 0.1010792703721856, G Loss: 22.269332885742188\n",
      "Epoch: 27, Batch: 109, D Loss: 0.09382899116316193, G Loss: 22.249412536621094\n",
      "Epoch: 27, Batch: 110, D Loss: 0.09750874352393989, G Loss: 22.08360481262207\n",
      "Epoch: 27, Batch: 111, D Loss: 0.1032264755380066, G Loss: 22.204391479492188\n",
      "Epoch: 27, Batch: 112, D Loss: 0.10031227778230829, G Loss: 22.30861473083496\n",
      "Epoch: 27, Batch: 113, D Loss: 0.09931570301934742, G Loss: 22.277082443237305\n",
      "Epoch: 27, Batch: 114, D Loss: 0.10396297285771694, G Loss: 22.430578231811523\n",
      "Epoch: 27, Batch: 115, D Loss: 0.09741611043460119, G Loss: 22.28639793395996\n",
      "Epoch: 27, Batch: 116, D Loss: 0.09695258004055528, G Loss: 21.949886322021484\n",
      "Epoch: 27, Batch: 117, D Loss: 0.09586710499952006, G Loss: 21.654203414916992\n",
      "Epoch: 27, Batch: 118, D Loss: 0.09250263892016607, G Loss: 21.42360496520996\n",
      "Epoch: 27, Batch: 119, D Loss: 0.09596629463086868, G Loss: 21.626558303833008\n",
      "Epoch: 27, Batch: 120, D Loss: 0.10443028075910221, G Loss: 22.418712615966797\n",
      "Epoch: 27, Batch: 121, D Loss: 0.09365744897564478, G Loss: 22.502119064331055\n",
      "Epoch: 27, Batch: 122, D Loss: 0.10199603447687772, G Loss: 22.316003799438477\n",
      "Epoch: 27, Batch: 123, D Loss: 0.09953033938920877, G Loss: 21.600839614868164\n",
      "Epoch: 27, Batch: 124, D Loss: 0.09574413331811746, G Loss: 20.76691246032715\n",
      "Epoch: 27, Batch: 125, D Loss: 0.0957731611076435, G Loss: 20.18517303466797\n",
      "Epoch: 27, Batch: 126, D Loss: 0.10661366651064247, G Loss: 20.590961456298828\n",
      "Epoch: 27, Batch: 127, D Loss: 0.09333879552618357, G Loss: 20.768444061279297\n",
      "Epoch: 27, Batch: 128, D Loss: 0.09896323876124735, G Loss: 20.831743240356445\n",
      "Epoch: 27, Batch: 129, D Loss: 0.09897288727041126, G Loss: 20.745098114013672\n",
      "Epoch: 27, Batch: 130, D Loss: 0.0931921011910572, G Loss: 20.156219482421875\n",
      "Epoch: 27, Batch: 131, D Loss: 0.10171163181767495, G Loss: 19.924177169799805\n",
      "Epoch: 27, Batch: 132, D Loss: 0.10200187659407312, G Loss: 20.213394165039062\n",
      "Epoch: 27, Batch: 133, D Loss: 0.10137575186721987, G Loss: 20.62664031982422\n",
      "Epoch: 27, Batch: 134, D Loss: 0.09935967672691265, G Loss: 20.868633270263672\n",
      "Epoch: 27, Batch: 135, D Loss: 0.09809630411879539, G Loss: 20.682247161865234\n",
      "Epoch: 27, Batch: 136, D Loss: 0.10339104436328656, G Loss: 20.680875778198242\n",
      "Epoch: 27, Batch: 137, D Loss: 0.09466800156585425, G Loss: 20.324363708496094\n",
      "Epoch: 27, Batch: 138, D Loss: 0.0983758353216484, G Loss: 20.197093963623047\n",
      "Epoch: 27, Batch: 139, D Loss: 0.09816692845215663, G Loss: 20.409866333007812\n",
      "Epoch: 27, Batch: 140, D Loss: 0.09822084068386239, G Loss: 20.69975471496582\n",
      "Epoch: 27, Batch: 141, D Loss: 0.09439453534891229, G Loss: 20.660783767700195\n",
      "Epoch: 27, Batch: 142, D Loss: 0.10251146602583272, G Loss: 20.871841430664062\n",
      "Epoch: 27, Batch: 143, D Loss: 0.09883090894255275, G Loss: 20.987567901611328\n",
      "Epoch: 27, Batch: 144, D Loss: 0.10440123114321673, G Loss: 21.268421173095703\n",
      "Epoch: 27, Batch: 145, D Loss: 0.10333534356148197, G Loss: 21.473983764648438\n",
      "Epoch: 27, Batch: 146, D Loss: 0.09958299276451013, G Loss: 21.215532302856445\n",
      "Epoch: 27, Batch: 147, D Loss: 0.09715037089369574, G Loss: 20.634136199951172\n",
      "Epoch: 27, Batch: 148, D Loss: 0.09994585875917117, G Loss: 20.33985137939453\n",
      "Epoch: 27, Batch: 149, D Loss: 0.09683087543659735, G Loss: 20.285707473754883\n",
      "Epoch: 27, Batch: 150, D Loss: 0.10294663963622869, G Loss: 20.85036277770996\n",
      "Epoch: 27, Batch: 151, D Loss: 0.09934423897459504, G Loss: 21.3660945892334\n",
      "Epoch: 27, Batch: 152, D Loss: 0.09600155082349443, G Loss: 21.32794761657715\n",
      "Epoch: 27, Batch: 153, D Loss: 0.09976042838000376, G Loss: 21.093730926513672\n",
      "Epoch: 27, Batch: 154, D Loss: 0.09573510332002197, G Loss: 20.68425941467285\n",
      "Epoch: 27, Batch: 155, D Loss: 0.0929205126406138, G Loss: 20.174951553344727\n",
      "Epoch: 27, Batch: 156, D Loss: 0.0925165126844032, G Loss: 19.889741897583008\n",
      "Epoch: 27, Batch: 157, D Loss: 0.09317278972889287, G Loss: 19.961172103881836\n",
      "Epoch: 27, Batch: 158, D Loss: 0.10167110786052308, G Loss: 20.6449031829834\n",
      "Epoch: 27, Batch: 159, D Loss: 0.09576050237372108, G Loss: 20.98278045654297\n",
      "Epoch: 27, Batch: 160, D Loss: 0.09311573998824257, G Loss: 20.63239288330078\n",
      "Epoch: 27, Batch: 161, D Loss: 0.09968964821950926, G Loss: 20.265928268432617\n",
      "Epoch: 27, Batch: 162, D Loss: 0.0996645623496426, G Loss: 20.020639419555664\n",
      "Epoch: 27, Batch: 163, D Loss: 0.10144724049712295, G Loss: 20.080015182495117\n",
      "Epoch: 27, Batch: 164, D Loss: 0.10265785537364314, G Loss: 20.370473861694336\n",
      "Epoch: 27, Batch: 165, D Loss: 0.09885083955851875, G Loss: 20.35260009765625\n",
      "Epoch: 27, Batch: 166, D Loss: 0.09715552716680675, G Loss: 19.969491958618164\n",
      "Epoch: 27, Batch: 167, D Loss: 0.10292545073023718, G Loss: 19.869651794433594\n",
      "Epoch: 27, Batch: 168, D Loss: 0.09860514228927275, G Loss: 19.758480072021484\n",
      "Epoch: 27, Batch: 169, D Loss: 0.0918362307058388, G Loss: 19.22425651550293\n",
      "Epoch: 27, Batch: 170, D Loss: 0.09865717839375754, G Loss: 19.020591735839844\n",
      "Epoch: 27, Batch: 171, D Loss: 0.0971322010427742, G Loss: 19.177452087402344\n",
      "Epoch: 27, Batch: 172, D Loss: 0.1007827091761534, G Loss: 19.63761329650879\n",
      "Epoch: 27, Batch: 173, D Loss: 0.10411906348833022, G Loss: 20.264039993286133\n",
      "Epoch: 27, Batch: 174, D Loss: 0.09931670949981813, G Loss: 20.35121726989746\n",
      "Epoch: 27, Batch: 175, D Loss: 0.09685298899349393, G Loss: 19.76195526123047\n",
      "Epoch: 27, Batch: 176, D Loss: 0.09933339238507666, G Loss: 19.164306640625\n",
      "Epoch: 27, Batch: 177, D Loss: 0.0956380173092779, G Loss: 18.767351150512695\n",
      "Epoch: 27, Batch: 178, D Loss: 0.10569587615791831, G Loss: 19.31036376953125\n",
      "Epoch: 27, Batch: 179, D Loss: 0.10488763578545746, G Loss: 20.222810745239258\n",
      "Epoch: 27, Batch: 180, D Loss: 0.10010542043374587, G Loss: 20.593164443969727\n",
      "Epoch: 27, Batch: 181, D Loss: 0.10010805796933803, G Loss: 20.17748260498047\n",
      "Epoch: 27, Batch: 182, D Loss: 0.10513101629270893, G Loss: 19.697647094726562\n",
      "Epoch: 27, Batch: 183, D Loss: 0.09505585049789733, G Loss: 18.885984420776367\n",
      "Epoch: 27, Batch: 184, D Loss: 0.0990658886313045, G Loss: 18.58606719970703\n",
      "Epoch: 27, Batch: 185, D Loss: 0.0980378578060015, G Loss: 18.714658737182617\n",
      "Epoch: 27, Batch: 186, D Loss: 0.09415680511207736, G Loss: 18.885923385620117\n",
      "Epoch: 27, Batch: 187, D Loss: 0.09884239244039206, G Loss: 19.277013778686523\n",
      "Epoch: 27, Batch: 188, D Loss: 0.10010078722060811, G Loss: 19.67142105102539\n",
      "Epoch: 27, Batch: 189, D Loss: 0.10019861298220634, G Loss: 19.763010025024414\n",
      "Epoch: 27, Batch: 190, D Loss: 0.09610188169702294, G Loss: 19.350906372070312\n",
      "Epoch: 27, Batch: 191, D Loss: 0.10267681109367022, G Loss: 19.09467124938965\n",
      "Epoch: 27, Batch: 192, D Loss: 0.09854916014076598, G Loss: 18.946107864379883\n",
      "Epoch: 27, Batch: 193, D Loss: 0.09539365333733252, G Loss: 18.857097625732422\n",
      "Epoch: 27, Batch: 194, D Loss: 0.09851169138713245, G Loss: 19.016897201538086\n",
      "Epoch: 27, Batch: 195, D Loss: 0.09597759209382639, G Loss: 19.125036239624023\n",
      "Epoch: 27, Batch: 196, D Loss: 0.09718840062126821, G Loss: 19.200313568115234\n",
      "Epoch: 27, Batch: 197, D Loss: 0.10471423906101585, G Loss: 19.551532745361328\n",
      "Epoch: 27, Batch: 198, D Loss: 0.1003361359609447, G Loss: 19.657888412475586\n",
      "Epoch: 27, Batch: 199, D Loss: 0.09695132998433797, G Loss: 19.285615921020508\n",
      "Epoch: 27, Batch: 200, D Loss: 0.09674489775814177, G Loss: 18.761690139770508\n",
      "Epoch: 27, Batch: 201, D Loss: 0.09641814652507685, G Loss: 18.44625473022461\n",
      "Epoch: 27, Batch: 202, D Loss: 0.09592484419404324, G Loss: 18.473834991455078\n",
      "Epoch: 27, Batch: 203, D Loss: 0.096544858428389, G Loss: 18.76079559326172\n",
      "Epoch: 27, Batch: 204, D Loss: 0.10219497481275086, G Loss: 19.45086097717285\n",
      "Epoch: 27, Batch: 205, D Loss: 0.10278374087096886, G Loss: 20.0471134185791\n",
      "Epoch: 27, Batch: 206, D Loss: 0.10160689152951896, G Loss: 20.073102951049805\n",
      "Epoch: 27, Batch: 207, D Loss: 0.09914768613293834, G Loss: 19.55122947692871\n",
      "Epoch: 27, Batch: 208, D Loss: 0.09440304596252491, G Loss: 18.6651668548584\n",
      "Epoch: 27, Batch: 209, D Loss: 0.09489772268039731, G Loss: 18.043880462646484\n",
      "Epoch: 27, Batch: 210, D Loss: 0.10190213298067352, G Loss: 18.511682510375977\n",
      "Epoch: 27, Batch: 211, D Loss: 0.10510520885265251, G Loss: 19.66794776916504\n",
      "Epoch: 27, Batch: 212, D Loss: 0.09910528457823031, G Loss: 20.432313919067383\n",
      "Epoch: 27, Batch: 213, D Loss: 0.0972272611753266, G Loss: 20.333126068115234\n",
      "Epoch: 27, Batch: 214, D Loss: 0.10212893877502605, G Loss: 19.885944366455078\n",
      "Epoch: 27, Batch: 215, D Loss: 0.09867389651559255, G Loss: 19.372068405151367\n",
      "Epoch: 27, Batch: 216, D Loss: 0.09817154925817584, G Loss: 19.12381362915039\n",
      "Epoch: 27, Batch: 217, D Loss: 0.10442947040293982, G Loss: 19.63727569580078\n",
      "Epoch: 27, Batch: 218, D Loss: 0.09607682502284753, G Loss: 19.957786560058594\n",
      "Epoch: 27, Batch: 219, D Loss: 0.10373139468343051, G Loss: 20.361665725708008\n",
      "Epoch: 27, Batch: 220, D Loss: 0.0937228360158539, G Loss: 20.080156326293945\n",
      "Epoch: 27, Batch: 221, D Loss: 0.0987343352700063, G Loss: 19.705718994140625\n",
      "Epoch: 27, Batch: 222, D Loss: 0.09670617597146414, G Loss: 19.363401412963867\n",
      "Epoch: 27, Batch: 223, D Loss: 0.10055203917196343, G Loss: 19.500959396362305\n",
      "Epoch: 27, Batch: 224, D Loss: 0.10066260531396598, G Loss: 19.951541900634766\n",
      "Epoch: 27, Batch: 225, D Loss: 0.10188408276880007, G Loss: 20.503494262695312\n",
      "Epoch: 27, Batch: 226, D Loss: 0.09908734321245866, G Loss: 20.598989486694336\n",
      "Epoch: 27, Batch: 227, D Loss: 0.09392338323119331, G Loss: 20.013992309570312\n",
      "Epoch: 27, Batch: 228, D Loss: 0.10852719947835265, G Loss: 19.963037490844727\n",
      "Epoch: 27, Batch: 229, D Loss: 0.09611630560036455, G Loss: 19.740869522094727\n",
      "Epoch: 27, Batch: 230, D Loss: 0.10295421755388823, G Loss: 19.864057540893555\n",
      "Epoch: 27, Batch: 231, D Loss: 0.10207025066971598, G Loss: 20.083072662353516\n",
      "Epoch: 27, Batch: 232, D Loss: 0.0960480730236728, G Loss: 19.90314292907715\n",
      "Epoch: 27, Batch: 233, D Loss: 0.0998366040884302, G Loss: 19.674497604370117\n",
      "Epoch: 27, Batch: 234, D Loss: 0.09248931897033819, G Loss: 19.120988845825195\n",
      "Epoch: 27, Batch: 235, D Loss: 0.09959793350338542, G Loss: 19.03924560546875\n",
      "Epoch: 27, Batch: 236, D Loss: 0.09575374672824788, G Loss: 19.196060180664062\n",
      "Epoch: 27, Batch: 237, D Loss: 0.0956621488862297, G Loss: 19.391950607299805\n",
      "Epoch: 27, Batch: 238, D Loss: 0.09245541887642994, G Loss: 19.32929229736328\n",
      "Epoch: 27, Batch: 239, D Loss: 0.09878327885181837, G Loss: 19.466846466064453\n",
      "Epoch: 27, Batch: 240, D Loss: 0.09834660004311502, G Loss: 19.649606704711914\n",
      "Epoch: 27, Batch: 241, D Loss: 0.10007775707969235, G Loss: 19.831462860107422\n",
      "Epoch: 27, Batch: 242, D Loss: 0.1010632600996556, G Loss: 19.938457489013672\n",
      "Epoch: 27, Batch: 243, D Loss: 0.09850904465586541, G Loss: 19.766250610351562\n",
      "Epoch: 27, Batch: 244, D Loss: 0.09892255217924739, G Loss: 19.497337341308594\n",
      "Epoch: 27, Batch: 245, D Loss: 0.10327911544016077, G Loss: 19.53636932373047\n",
      "Epoch: 27, Batch: 246, D Loss: 0.0940371472917012, G Loss: 19.24138832092285\n",
      "Epoch: 27, Batch: 247, D Loss: 0.10683502440055792, G Loss: 19.591543197631836\n",
      "Epoch: 27, Batch: 248, D Loss: 0.09887680554349576, G Loss: 19.74667739868164\n",
      "Epoch: 27, Batch: 249, D Loss: 0.09892718634111719, G Loss: 19.645065307617188\n",
      "Epoch: 27, Batch: 250, D Loss: 0.10405463124812442, G Loss: 19.67832374572754\n",
      "Epoch: 27, Batch: 251, D Loss: 0.09785193360164446, G Loss: 19.512149810791016\n",
      "Epoch: 27, Batch: 252, D Loss: 0.10367155234739911, G Loss: 19.609010696411133\n",
      "Epoch: 27, Batch: 253, D Loss: 0.09664403064883131, G Loss: 19.4853572845459\n",
      "Epoch: 27, Batch: 254, D Loss: 0.09833131918539162, G Loss: 19.323144912719727\n",
      "Epoch: 27, Batch: 255, D Loss: 0.09580472340875468, G Loss: 19.09307861328125\n",
      "Epoch: 27, Batch: 256, D Loss: 0.10452230484514735, G Loss: 19.46725082397461\n",
      "Epoch: 27, Batch: 257, D Loss: 0.09766876849304496, G Loss: 19.745670318603516\n",
      "Epoch: 27, Batch: 258, D Loss: 0.10259893650327523, G Loss: 20.042278289794922\n",
      "Epoch: 27, Batch: 259, D Loss: 0.09946008871370882, G Loss: 20.025720596313477\n",
      "Epoch: 27, Batch: 260, D Loss: 0.1064929003056494, G Loss: 20.137842178344727\n",
      "Epoch: 27, Batch: 261, D Loss: 0.0973157297421452, G Loss: 19.791643142700195\n",
      "Epoch: 27, Batch: 262, D Loss: 0.09734472053741405, G Loss: 19.278268814086914\n",
      "Epoch: 27, Batch: 263, D Loss: 0.09802693371686, G Loss: 19.02151870727539\n",
      "Epoch: 27, Batch: 264, D Loss: 0.10148888329955752, G Loss: 19.209789276123047\n",
      "Epoch: 27, Batch: 265, D Loss: 0.09336063488614266, G Loss: 19.248689651489258\n",
      "Epoch: 27, Batch: 266, D Loss: 0.09625942481324468, G Loss: 19.22669792175293\n",
      "Epoch: 27, Batch: 267, D Loss: 0.09915039165395911, G Loss: 19.23950958251953\n",
      "Epoch: 27, Batch: 268, D Loss: 0.10131700542601285, G Loss: 19.37383270263672\n",
      "Epoch: 27, Batch: 269, D Loss: 0.09676689114778703, G Loss: 19.25684356689453\n",
      "Epoch: 27, Batch: 270, D Loss: 0.09883504599205617, G Loss: 19.07884979248047\n",
      "Epoch: 27, Batch: 271, D Loss: 0.1027660394360137, G Loss: 19.18748664855957\n",
      "Epoch: 27, Batch: 272, D Loss: 0.10032387293212386, G Loss: 19.332921981811523\n",
      "Epoch: 27, Batch: 273, D Loss: 0.10286886427682462, G Loss: 19.514816284179688\n",
      "Epoch: 27, Batch: 274, D Loss: 0.0897335582388834, G Loss: 18.891399383544922\n",
      "Epoch: 27, Batch: 275, D Loss: 0.09907175974593718, G Loss: 18.552282333374023\n",
      "Epoch: 27, Batch: 276, D Loss: 0.1099777849174357, G Loss: 19.185590744018555\n",
      "Epoch: 27, Batch: 277, D Loss: 0.09919175695315707, G Loss: 19.575611114501953\n",
      "Epoch: 27, Batch: 278, D Loss: 0.09908318682090411, G Loss: 19.51856803894043\n",
      "Epoch: 27, Batch: 279, D Loss: 0.09462592236527545, G Loss: 18.902767181396484\n",
      "Epoch: 27, Batch: 280, D Loss: 0.10106853020191475, G Loss: 18.56504249572754\n",
      "Epoch: 27, Batch: 281, D Loss: 0.09792950450755633, G Loss: 18.511228561401367\n",
      "Epoch: 27, Batch: 282, D Loss: 0.09732104529469199, G Loss: 18.601680755615234\n",
      "Epoch: 27, Batch: 283, D Loss: 0.09522758829615441, G Loss: 18.66126823425293\n",
      "Epoch: 27, Batch: 284, D Loss: 0.10159595636759833, G Loss: 19.019821166992188\n",
      "Epoch: 27, Batch: 285, D Loss: 0.09736158213179213, G Loss: 19.13099479675293\n",
      "Epoch: 27, Batch: 286, D Loss: 0.10166894883670374, G Loss: 19.185260772705078\n",
      "Epoch: 27, Batch: 287, D Loss: 0.09763439257799189, G Loss: 18.99141502380371\n",
      "Epoch: 27, Batch: 288, D Loss: 0.10046477914362106, G Loss: 18.890336990356445\n",
      "Epoch: 27, Batch: 289, D Loss: 0.09674422036826158, G Loss: 18.7403564453125\n",
      "Epoch: 27, Batch: 290, D Loss: 0.10509050190426428, G Loss: 19.11939239501953\n",
      "Epoch: 27, Batch: 291, D Loss: 0.09822390454200125, G Loss: 19.305767059326172\n",
      "Epoch: 27, Batch: 292, D Loss: 0.09696907767977692, G Loss: 19.204822540283203\n",
      "Epoch: 27, Batch: 293, D Loss: 0.10106720264337188, G Loss: 19.16010856628418\n",
      "Epoch: 27, Batch: 294, D Loss: 0.09050590858096652, G Loss: 18.64687156677246\n",
      "Epoch: 27, Batch: 295, D Loss: 0.10010181025669818, G Loss: 18.63003158569336\n",
      "Epoch: 27, Batch: 296, D Loss: 0.10631662133941266, G Loss: 19.392009735107422\n",
      "Epoch: 27, Batch: 297, D Loss: 0.107591622702076, G Loss: 20.380020141601562\n",
      "Epoch: 27, Batch: 298, D Loss: 0.10388194085181995, G Loss: 20.66697883605957\n",
      "Epoch: 27, Batch: 299, D Loss: 0.09830214158856981, G Loss: 19.985963821411133\n",
      "Epoch: 27, Batch: 300, D Loss: 0.09893110568983532, G Loss: 19.010623931884766\n",
      "Epoch: 27, Batch: 301, D Loss: 0.09586184880076098, G Loss: 18.277891159057617\n",
      "Epoch: 27, Batch: 302, D Loss: 0.09420995297026291, G Loss: 18.124082565307617\n",
      "Epoch: 27, Batch: 303, D Loss: 0.10331795052449078, G Loss: 18.964462280273438\n",
      "Epoch: 27, Batch: 304, D Loss: 0.10003186186979351, G Loss: 19.983135223388672\n",
      "Epoch: 27, Batch: 305, D Loss: 0.1014326818672851, G Loss: 20.535480499267578\n",
      "Epoch: 27, Batch: 306, D Loss: 0.10527875333026937, G Loss: 20.591196060180664\n",
      "Epoch: 27, Batch: 307, D Loss: 0.09925498151954015, G Loss: 19.863666534423828\n",
      "Epoch: 27, Batch: 308, D Loss: 0.10120107409339663, G Loss: 19.107738494873047\n",
      "Epoch: 27, Batch: 309, D Loss: 0.09966317120154167, G Loss: 18.7698917388916\n",
      "Epoch: 27, Batch: 310, D Loss: 0.09073719786383583, G Loss: 18.515581130981445\n",
      "Epoch: 27, Batch: 311, D Loss: 0.10248542907878866, G Loss: 19.122760772705078\n",
      "Epoch: 27, Batch: 312, D Loss: 0.09766812796498547, G Loss: 19.79570770263672\n",
      "Epoch: 27, Batch: 313, D Loss: 0.09307804824562282, G Loss: 19.882749557495117\n",
      "Epoch: 27, Batch: 314, D Loss: 0.09636363516336377, G Loss: 19.67685317993164\n",
      "Epoch: 27, Batch: 315, D Loss: 0.08931125157105524, G Loss: 19.015684127807617\n",
      "Epoch: 27, Batch: 316, D Loss: 0.09941676558986834, G Loss: 18.85959815979004\n",
      "Epoch: 27, Batch: 317, D Loss: 0.09400470853878917, G Loss: 19.005876541137695\n",
      "Epoch: 27, Batch: 318, D Loss: 0.0941743426593189, G Loss: 19.378490447998047\n",
      "Epoch: 27, Batch: 319, D Loss: 0.09286974540430903, G Loss: 19.610923767089844\n",
      "Epoch: 27, Batch: 320, D Loss: 0.09631358224552977, G Loss: 19.804119110107422\n",
      "Epoch: 27, Batch: 321, D Loss: 0.10357238450374451, G Loss: 20.2709903717041\n",
      "Epoch: 27, Batch: 322, D Loss: 0.10807513500787935, G Loss: 20.942630767822266\n",
      "Epoch: 27, Batch: 323, D Loss: 0.09802079987141998, G Loss: 20.887659072875977\n",
      "Epoch: 27, Batch: 324, D Loss: 0.09466151955036833, G Loss: 20.168216705322266\n",
      "Epoch: 27, Batch: 325, D Loss: 0.09612200535024518, G Loss: 19.468399047851562\n",
      "Epoch: 27, Batch: 326, D Loss: 0.09647007479954706, G Loss: 19.28452491760254\n",
      "Epoch: 27, Batch: 327, D Loss: 0.1003180757774087, G Loss: 19.868284225463867\n",
      "Epoch: 27, Batch: 328, D Loss: 0.10221494058413977, G Loss: 20.873374938964844\n",
      "Epoch: 27, Batch: 329, D Loss: 0.10304909972885679, G Loss: 21.66649627685547\n",
      "Epoch: 27, Batch: 330, D Loss: 0.09958255311052468, G Loss: 21.60912322998047\n",
      "Epoch: 27, Batch: 331, D Loss: 0.09583874080070628, G Loss: 20.700294494628906\n",
      "Epoch: 27, Batch: 332, D Loss: 0.09882769068234115, G Loss: 19.857973098754883\n",
      "Epoch: 27, Batch: 333, D Loss: 0.10293161987723176, G Loss: 19.861173629760742\n",
      "Epoch: 27, Batch: 334, D Loss: 0.09157241249576609, G Loss: 19.938875198364258\n",
      "Epoch: 27, Batch: 335, D Loss: 0.10426043046528444, G Loss: 20.72134017944336\n",
      "Epoch: 27, Batch: 336, D Loss: 0.10136254165809985, G Loss: 21.45781135559082\n",
      "Epoch: 27, Batch: 337, D Loss: 0.0978119152141696, G Loss: 21.507047653198242\n",
      "Epoch: 27, Batch: 338, D Loss: 0.0978243875521651, G Loss: 20.98984718322754\n",
      "Epoch: 27, Batch: 339, D Loss: 0.10133426685825148, G Loss: 20.507293701171875\n",
      "Epoch: 27, Batch: 340, D Loss: 0.10400663377188502, G Loss: 20.542505264282227\n",
      "Epoch: 27, Batch: 341, D Loss: 0.09978821928942355, G Loss: 20.695903778076172\n",
      "Epoch: 27, Batch: 342, D Loss: 0.09743782927435551, G Loss: 20.767013549804688\n",
      "Epoch: 27, Batch: 343, D Loss: 0.10118000998191048, G Loss: 20.935821533203125\n",
      "Epoch: 27, Batch: 344, D Loss: 0.0989597443734038, G Loss: 20.9716739654541\n",
      "Epoch: 27, Batch: 345, D Loss: 0.10315306520982595, G Loss: 21.10943603515625\n",
      "Epoch: 27, Batch: 346, D Loss: 0.09584812113877877, G Loss: 20.849058151245117\n",
      "Epoch: 27, Batch: 347, D Loss: 0.08809954740149212, G Loss: 20.049732208251953\n",
      "Epoch: 27, Batch: 348, D Loss: 0.10137866539643048, G Loss: 19.972156524658203\n",
      "Epoch: 27, Batch: 349, D Loss: 0.10279858188934171, G Loss: 20.588529586791992\n",
      "Epoch: 27, Batch: 350, D Loss: 0.10067712555407693, G Loss: 21.27735137939453\n",
      "Epoch: 27, Batch: 351, D Loss: 0.09727141287159621, G Loss: 21.462997436523438\n",
      "Epoch: 27, Batch: 352, D Loss: 0.0944854769203016, G Loss: 20.982587814331055\n",
      "Epoch: 27, Batch: 353, D Loss: 0.08685919712283624, G Loss: 19.851198196411133\n",
      "Epoch: 27, Batch: 354, D Loss: 0.0988780870504049, G Loss: 19.50343132019043\n",
      "Epoch: 27, Batch: 355, D Loss: 0.10580138227652591, G Loss: 20.312076568603516\n",
      "Epoch: 27, Batch: 356, D Loss: 0.096440330641135, G Loss: 21.117408752441406\n",
      "Epoch: 27, Batch: 357, D Loss: 0.09801100221627246, G Loss: 21.52729034423828\n",
      "Epoch: 27, Batch: 358, D Loss: 0.10224603138298786, G Loss: 21.57831573486328\n",
      "Epoch: 27, Batch: 359, D Loss: 0.10686084650495764, G Loss: 21.480430603027344\n",
      "Epoch: 27, Batch: 360, D Loss: 0.10515561726522146, G Loss: 21.23732566833496\n",
      "Epoch: 27, Batch: 361, D Loss: 0.09725821059614795, G Loss: 20.618810653686523\n",
      "Epoch: 27, Batch: 362, D Loss: 0.10361407759374297, G Loss: 20.40386962890625\n",
      "Epoch: 27, Batch: 363, D Loss: 0.09884867144469373, G Loss: 20.309127807617188\n",
      "Epoch: 27, Batch: 364, D Loss: 0.09916575324498095, G Loss: 20.417598724365234\n",
      "Epoch: 27, Batch: 365, D Loss: 0.09937628420582933, G Loss: 20.59096908569336\n",
      "Epoch: 27, Batch: 366, D Loss: 0.09542611300302206, G Loss: 20.529800415039062\n",
      "Epoch: 27, Batch: 367, D Loss: 0.10023924769134085, G Loss: 20.52755355834961\n",
      "Epoch: 27, Batch: 368, D Loss: 0.10345865840630569, G Loss: 20.73426628112793\n",
      "Epoch: 27, Batch: 369, D Loss: 0.09087668421757716, G Loss: 20.290096282958984\n",
      "Epoch: 27, Batch: 370, D Loss: 0.10090990449060366, G Loss: 20.116910934448242\n",
      "Epoch: 27, Batch: 371, D Loss: 0.09472213039404109, G Loss: 20.05630874633789\n",
      "Epoch: 27, Batch: 372, D Loss: 0.10660517286987264, G Loss: 20.650651931762695\n",
      "Epoch: 27, Batch: 373, D Loss: 0.09506209243925173, G Loss: 20.817340850830078\n",
      "Epoch: 27, Batch: 374, D Loss: 0.10699131376629667, G Loss: 21.219091415405273\n",
      "Epoch: 27, Batch: 375, D Loss: 0.09889435800814311, G Loss: 21.085201263427734\n",
      "Epoch: 27, Batch: 376, D Loss: 0.09456110796374839, G Loss: 20.369779586791992\n",
      "Epoch: 27, Batch: 377, D Loss: 0.08628469099841551, G Loss: 19.09146499633789\n",
      "Epoch: 27, Batch: 378, D Loss: 0.10395387078053453, G Loss: 19.041213989257812\n",
      "Epoch: 27, Batch: 379, D Loss: 0.10591281362319427, G Loss: 20.08183479309082\n",
      "Epoch: 27, Batch: 380, D Loss: 0.10184122675032903, G Loss: 21.185632705688477\n",
      "Epoch: 27, Batch: 381, D Loss: 0.09841649259762425, G Loss: 21.58919334411621\n",
      "Epoch: 27, Batch: 382, D Loss: 0.09554083673843825, G Loss: 21.013036727905273\n",
      "Epoch: 27, Batch: 383, D Loss: 0.09818027971589294, G Loss: 20.17774200439453\n",
      "Epoch: 27, Batch: 384, D Loss: 0.09299738092524046, G Loss: 19.363061904907227\n",
      "Epoch: 27, Batch: 385, D Loss: 0.10288926391628128, G Loss: 19.540956497192383\n",
      "Epoch: 27, Batch: 386, D Loss: 0.10314849119380887, G Loss: 20.4619083404541\n",
      "Epoch: 27, Batch: 387, D Loss: 0.10121603349989122, G Loss: 21.386024475097656\n",
      "Epoch: 27, Batch: 388, D Loss: 0.09569790238140738, G Loss: 21.53427505493164\n",
      "Epoch: 27, Batch: 389, D Loss: 0.10019646612056407, G Loss: 21.1601619720459\n",
      "Epoch: 27, Batch: 390, D Loss: 0.10447153488046995, G Loss: 20.80266761779785\n",
      "Epoch: 27, Batch: 391, D Loss: 0.09697343468340991, G Loss: 20.328125\n",
      "Epoch: 27, Batch: 392, D Loss: 0.09555902419832707, G Loss: 20.010549545288086\n",
      "Epoch: 27, Batch: 393, D Loss: 0.10374423943849087, G Loss: 20.41753578186035\n",
      "Epoch: 27, Batch: 394, D Loss: 0.09327904193503894, G Loss: 20.70015525817871\n",
      "Epoch: 27, Batch: 395, D Loss: 0.1004197452600317, G Loss: 21.117490768432617\n",
      "Epoch: 27, Batch: 396, D Loss: 0.09695802660662983, G Loss: 21.236621856689453\n",
      "Epoch: 27, Batch: 397, D Loss: 0.09768817605053243, G Loss: 21.153522491455078\n",
      "Epoch: 27, Batch: 398, D Loss: 0.10092030498708368, G Loss: 21.119853973388672\n",
      "Epoch: 27, Batch: 399, D Loss: 0.10203214021455573, G Loss: 21.231393814086914\n",
      "Epoch: 27, Batch: 400, D Loss: 0.09686985643042381, G Loss: 21.16681480407715\n",
      "Epoch: 27, Batch: 401, D Loss: 0.10290382832736497, G Loss: 21.27924156188965\n",
      "Epoch: 27, Batch: 402, D Loss: 0.09374348105208535, G Loss: 21.130779266357422\n",
      "Epoch: 27, Batch: 403, D Loss: 0.0993576202247268, G Loss: 21.07248306274414\n",
      "Epoch: 27, Batch: 404, D Loss: 0.09839671140717451, G Loss: 21.055604934692383\n",
      "Epoch: 27, Batch: 405, D Loss: 0.10235986146845463, G Loss: 21.1969051361084\n",
      "Epoch: 27, Batch: 406, D Loss: 0.10050490528316045, G Loss: 21.282272338867188\n",
      "Epoch: 27, Batch: 407, D Loss: 0.09413237904713842, G Loss: 20.89934539794922\n",
      "Epoch: 27, Batch: 408, D Loss: 0.09939488818936831, G Loss: 20.55158233642578\n",
      "Epoch: 27, Batch: 409, D Loss: 0.09545052869447151, G Loss: 20.163381576538086\n",
      "Epoch: 27, Batch: 410, D Loss: 0.10646611527004607, G Loss: 20.459699630737305\n",
      "Epoch: 27, Batch: 411, D Loss: 0.09634279519534755, G Loss: 20.62040138244629\n",
      "Epoch: 27, Batch: 412, D Loss: 0.09725614695733326, G Loss: 20.515119552612305\n",
      "Epoch: 27, Batch: 413, D Loss: 0.09415114003557773, G Loss: 20.075321197509766\n",
      "Epoch: 27, Batch: 414, D Loss: 0.0942866665417531, G Loss: 19.61037826538086\n",
      "Epoch: 27, Batch: 415, D Loss: 0.10258151732458332, G Loss: 19.748292922973633\n",
      "Epoch: 27, Batch: 416, D Loss: 0.09943436939108674, G Loss: 20.138643264770508\n",
      "Epoch: 27, Batch: 417, D Loss: 0.09833148196657499, G Loss: 20.484195709228516\n",
      "Epoch: 27, Batch: 418, D Loss: 0.0982815927442674, G Loss: 20.550241470336914\n",
      "Epoch: 27, Batch: 419, D Loss: 0.10213168024368424, G Loss: 20.566699981689453\n",
      "Epoch: 27, Batch: 420, D Loss: 0.0945546336347145, G Loss: 20.138723373413086\n",
      "Epoch: 27, Batch: 421, D Loss: 0.10165122995550424, G Loss: 19.95037269592285\n",
      "Epoch: 27, Batch: 422, D Loss: 0.1006945828901522, G Loss: 20.058399200439453\n",
      "Epoch: 27, Batch: 423, D Loss: 0.10145537636101393, G Loss: 20.408546447753906\n",
      "Epoch: 27, Batch: 424, D Loss: 0.08863964010808462, G Loss: 20.13784408569336\n",
      "Epoch: 27, Batch: 425, D Loss: 0.09739540616033993, G Loss: 19.95909309387207\n",
      "Epoch: 27, Batch: 426, D Loss: 0.10147602953523494, G Loss: 20.145681381225586\n",
      "Epoch: 27, Batch: 427, D Loss: 0.10544750903264732, G Loss: 20.77965545654297\n",
      "Epoch: 27, Batch: 428, D Loss: 0.09901778440129677, G Loss: 21.088010787963867\n",
      "Epoch: 27, Batch: 429, D Loss: 0.09936429596342503, G Loss: 21.011255264282227\n",
      "Epoch: 27, Batch: 430, D Loss: 0.0937939663946758, G Loss: 20.39396095275879\n",
      "Epoch: 27, Batch: 431, D Loss: 0.09683372171039067, G Loss: 19.885812759399414\n",
      "Epoch: 27, Batch: 432, D Loss: 0.10799120456160766, G Loss: 20.369596481323242\n",
      "Epoch: 27, Batch: 433, D Loss: 0.0985575025585314, G Loss: 20.94084930419922\n",
      "Epoch: 27, Batch: 434, D Loss: 0.09880435500258256, G Loss: 21.28885841369629\n",
      "Epoch: 27, Batch: 435, D Loss: 0.10042411860777306, G Loss: 21.401199340820312\n",
      "Epoch: 27, Batch: 436, D Loss: 0.092558205446585, G Loss: 20.966947555541992\n",
      "Epoch: 27, Batch: 437, D Loss: 0.09757140326008373, G Loss: 20.613628387451172\n",
      "Epoch: 27, Batch: 438, D Loss: 0.10710005506731132, G Loss: 21.040985107421875\n",
      "Epoch: 27, Batch: 439, D Loss: 0.10034485188819761, G Loss: 21.5715274810791\n",
      "Epoch: 27, Batch: 440, D Loss: 0.103396766054825, G Loss: 22.04096794128418\n",
      "Epoch: 27, Batch: 441, D Loss: 0.10580778133056584, G Loss: 22.39543914794922\n",
      "Epoch: 27, Batch: 442, D Loss: 0.09727463137409456, G Loss: 22.055932998657227\n",
      "Epoch: 27, Batch: 443, D Loss: 0.09337018450147994, G Loss: 21.26996421813965\n",
      "Epoch: 27, Batch: 444, D Loss: 0.10171560977449587, G Loss: 20.945932388305664\n",
      "Epoch: 27, Batch: 445, D Loss: 0.09528207074941406, G Loss: 20.89727783203125\n",
      "Epoch: 27, Batch: 446, D Loss: 0.10915734646074582, G Loss: 21.723217010498047\n",
      "Epoch: 27, Batch: 447, D Loss: 0.10033917440166427, G Loss: 22.36803436279297\n",
      "Epoch: 27, Batch: 448, D Loss: 0.09405580172878775, G Loss: 22.324504852294922\n",
      "Epoch: 27, Batch: 449, D Loss: 0.09543317570059243, G Loss: 21.74125862121582\n",
      "Epoch: 27, Batch: 450, D Loss: 0.09981928789816374, G Loss: 21.197425842285156\n",
      "Epoch: 27, Batch: 451, D Loss: 0.09949444267250768, G Loss: 21.093284606933594\n",
      "Epoch: 27, Batch: 452, D Loss: 0.0980338010290713, G Loss: 21.311758041381836\n",
      "Epoch: 27, Batch: 453, D Loss: 0.09618602717544963, G Loss: 21.55195426940918\n",
      "Epoch: 27, Batch: 454, D Loss: 0.09814088066087669, G Loss: 21.763025283813477\n",
      "Epoch: 27, Batch: 455, D Loss: 0.10069067791896662, G Loss: 21.989418029785156\n",
      "Epoch: 27, Batch: 456, D Loss: 0.10356777919366872, G Loss: 22.150785446166992\n",
      "Epoch: 27, Batch: 457, D Loss: 0.10023367417553218, G Loss: 22.05509376525879\n",
      "Epoch: 27, Batch: 458, D Loss: 0.09553235785821622, G Loss: 21.624774932861328\n",
      "Epoch: 27, Batch: 459, D Loss: 0.09461438683561998, G Loss: 21.032419204711914\n",
      "Epoch: 27, Batch: 460, D Loss: 0.10247836297787288, G Loss: 21.080284118652344\n",
      "Epoch: 27, Batch: 461, D Loss: 0.0899567085962002, G Loss: 21.114212036132812\n",
      "Epoch: 27, Batch: 462, D Loss: 0.10591162019591191, G Loss: 21.807750701904297\n",
      "Epoch: 27, Batch: 463, D Loss: 0.1020160914631163, G Loss: 22.51765251159668\n",
      "Epoch: 27, Batch: 464, D Loss: 0.11100306367765067, G Loss: 23.181737899780273\n",
      "Epoch: 27, Batch: 465, D Loss: 0.10026602451646455, G Loss: 23.038297653198242\n",
      "Epoch: 27, Batch: 466, D Loss: 0.10035885132415517, G Loss: 22.368167877197266\n",
      "Epoch: 27, Batch: 467, D Loss: 0.09841802730839849, G Loss: 21.58125877380371\n",
      "Epoch: 28, Batch: 0, D Loss: 0.10240632320468501, G Loss: 21.27867317199707\n",
      "Epoch: 28, Batch: 1, D Loss: 0.09786143926911187, G Loss: 21.329017639160156\n",
      "Epoch: 28, Batch: 2, D Loss: 0.09603972756940937, G Loss: 21.57901954650879\n",
      "Epoch: 28, Batch: 3, D Loss: 0.09942506271451292, G Loss: 21.922407150268555\n",
      "Epoch: 28, Batch: 4, D Loss: 0.09887067987229184, G Loss: 22.115549087524414\n",
      "Epoch: 28, Batch: 5, D Loss: 0.0974641816214912, G Loss: 21.906599044799805\n",
      "Epoch: 28, Batch: 6, D Loss: 0.10205498354511583, G Loss: 21.734455108642578\n",
      "Epoch: 28, Batch: 7, D Loss: 0.0967428611907412, G Loss: 21.391510009765625\n",
      "Epoch: 28, Batch: 8, D Loss: 0.09504041107975708, G Loss: 20.953670501708984\n",
      "Epoch: 28, Batch: 9, D Loss: 0.09293699311799958, G Loss: 20.622621536254883\n",
      "Epoch: 28, Batch: 10, D Loss: 0.10649916573058987, G Loss: 21.081518173217773\n",
      "Epoch: 28, Batch: 11, D Loss: 0.09905341294623662, G Loss: 21.569419860839844\n",
      "Epoch: 28, Batch: 12, D Loss: 0.10500377434336221, G Loss: 21.932035446166992\n",
      "Epoch: 28, Batch: 13, D Loss: 0.10068623738878543, G Loss: 21.64627456665039\n",
      "Epoch: 28, Batch: 14, D Loss: 0.09460814328800485, G Loss: 20.76365089416504\n",
      "Epoch: 28, Batch: 15, D Loss: 0.09843886716189543, G Loss: 19.979373931884766\n",
      "Epoch: 28, Batch: 16, D Loss: 0.09830034646467611, G Loss: 19.69541358947754\n",
      "Epoch: 28, Batch: 17, D Loss: 0.10219510013311428, G Loss: 20.088443756103516\n",
      "Epoch: 28, Batch: 18, D Loss: 0.09662431555402506, G Loss: 20.47710418701172\n",
      "Epoch: 28, Batch: 19, D Loss: 0.0988614192167151, G Loss: 20.756418228149414\n",
      "Epoch: 28, Batch: 20, D Loss: 0.10029884473763118, G Loss: 20.853435516357422\n",
      "Epoch: 28, Batch: 21, D Loss: 0.10379001541047539, G Loss: 20.901029586791992\n",
      "Epoch: 28, Batch: 22, D Loss: 0.10052204178661173, G Loss: 20.698305130004883\n",
      "Epoch: 28, Batch: 23, D Loss: 0.10281646307305098, G Loss: 20.543787002563477\n",
      "Epoch: 28, Batch: 24, D Loss: 0.09679541062818958, G Loss: 20.218229293823242\n",
      "Epoch: 28, Batch: 25, D Loss: 0.0984240928492437, G Loss: 20.032649993896484\n",
      "Epoch: 28, Batch: 26, D Loss: 0.10330379841820869, G Loss: 20.282255172729492\n",
      "Epoch: 28, Batch: 27, D Loss: 0.09867876837075223, G Loss: 20.510046005249023\n",
      "Epoch: 28, Batch: 28, D Loss: 0.10000177531992244, G Loss: 20.596281051635742\n",
      "Epoch: 28, Batch: 29, D Loss: 0.10047391860601701, G Loss: 20.539064407348633\n",
      "Epoch: 28, Batch: 30, D Loss: 0.10728196854580879, G Loss: 20.714580535888672\n",
      "Epoch: 28, Batch: 31, D Loss: 0.10096104494292057, G Loss: 20.686025619506836\n",
      "Epoch: 28, Batch: 32, D Loss: 0.10243456865620532, G Loss: 20.5795955657959\n",
      "Epoch: 28, Batch: 33, D Loss: 0.10061022703213574, G Loss: 20.386062622070312\n",
      "Epoch: 28, Batch: 34, D Loss: 0.10169435366132129, G Loss: 20.291839599609375\n",
      "Epoch: 28, Batch: 35, D Loss: 0.09607160176704438, G Loss: 20.0975284576416\n",
      "Epoch: 28, Batch: 36, D Loss: 0.09958226328304443, G Loss: 20.076576232910156\n",
      "Epoch: 28, Batch: 37, D Loss: 0.09735895785611837, G Loss: 20.14170265197754\n",
      "Epoch: 28, Batch: 38, D Loss: 0.09732578033657502, G Loss: 20.264501571655273\n",
      "Epoch: 28, Batch: 39, D Loss: 0.09458039780391514, G Loss: 20.258358001708984\n",
      "Epoch: 28, Batch: 40, D Loss: 0.10190995851925189, G Loss: 20.52198028564453\n",
      "Epoch: 28, Batch: 41, D Loss: 0.09648288844063502, G Loss: 20.634618759155273\n",
      "Epoch: 28, Batch: 42, D Loss: 0.09773263391511594, G Loss: 20.578899383544922\n",
      "Epoch: 28, Batch: 43, D Loss: 0.10098627266075133, G Loss: 20.62471580505371\n",
      "Epoch: 28, Batch: 44, D Loss: 0.09738629369375268, G Loss: 20.52902603149414\n",
      "Epoch: 28, Batch: 45, D Loss: 0.09240824804277037, G Loss: 20.126379013061523\n",
      "Epoch: 28, Batch: 46, D Loss: 0.10200521439734928, G Loss: 20.148603439331055\n",
      "Epoch: 28, Batch: 47, D Loss: 0.09671988421731931, G Loss: 20.267236709594727\n",
      "Epoch: 28, Batch: 48, D Loss: 0.09791388434227183, G Loss: 20.452892303466797\n",
      "Epoch: 28, Batch: 49, D Loss: 0.10535160503346042, G Loss: 20.920867919921875\n",
      "Epoch: 28, Batch: 50, D Loss: 0.10369530354667794, G Loss: 21.250896453857422\n",
      "Epoch: 28, Batch: 51, D Loss: 0.10358360438416739, G Loss: 21.30373764038086\n",
      "Epoch: 28, Batch: 52, D Loss: 0.10297783495683327, G Loss: 21.079490661621094\n",
      "Epoch: 28, Batch: 53, D Loss: 0.10085826409969414, G Loss: 20.69678497314453\n",
      "Epoch: 28, Batch: 54, D Loss: 0.10627514175030789, G Loss: 20.70597267150879\n",
      "Epoch: 28, Batch: 55, D Loss: 0.09606970902818757, G Loss: 20.518577575683594\n",
      "Epoch: 28, Batch: 56, D Loss: 0.1034602528551451, G Loss: 20.658832550048828\n",
      "Epoch: 28, Batch: 57, D Loss: 0.09967809963441093, G Loss: 20.86348533630371\n",
      "Epoch: 28, Batch: 58, D Loss: 0.09995240013441065, G Loss: 21.004005432128906\n",
      "Epoch: 28, Batch: 59, D Loss: 0.10365653073079686, G Loss: 21.145774841308594\n",
      "Epoch: 28, Batch: 60, D Loss: 0.10196239534148321, G Loss: 21.138111114501953\n",
      "Epoch: 28, Batch: 61, D Loss: 0.09768956192608413, G Loss: 20.870426177978516\n",
      "Epoch: 28, Batch: 62, D Loss: 0.09602552707518758, G Loss: 20.404264450073242\n",
      "Epoch: 28, Batch: 63, D Loss: 0.09658653371491299, G Loss: 20.061674118041992\n",
      "Epoch: 28, Batch: 64, D Loss: 0.09987145754947607, G Loss: 20.148334503173828\n",
      "Epoch: 28, Batch: 65, D Loss: 0.1039077572021258, G Loss: 20.615724563598633\n",
      "Epoch: 28, Batch: 66, D Loss: 0.09913961636775648, G Loss: 20.920001983642578\n",
      "Epoch: 28, Batch: 67, D Loss: 0.100312479250776, G Loss: 20.921878814697266\n",
      "Epoch: 28, Batch: 68, D Loss: 0.10389542624834658, G Loss: 20.73772430419922\n",
      "Epoch: 28, Batch: 69, D Loss: 0.09758558933468514, G Loss: 20.237947463989258\n",
      "Epoch: 28, Batch: 70, D Loss: 0.09993399036092265, G Loss: 19.8158016204834\n",
      "Epoch: 28, Batch: 71, D Loss: 0.10642373680433459, G Loss: 19.90094566345215\n",
      "Epoch: 28, Batch: 72, D Loss: 0.10945790344713763, G Loss: 20.48448371887207\n",
      "Epoch: 28, Batch: 73, D Loss: 0.09848096281231161, G Loss: 20.607067108154297\n",
      "Epoch: 28, Batch: 74, D Loss: 0.10289083483871042, G Loss: 20.40047264099121\n",
      "Epoch: 28, Batch: 75, D Loss: 0.09748627341289373, G Loss: 19.77689552307129\n",
      "Epoch: 28, Batch: 76, D Loss: 0.0995550545262216, G Loss: 19.240711212158203\n",
      "Epoch: 28, Batch: 77, D Loss: 0.09676237663351417, G Loss: 18.935802459716797\n",
      "Epoch: 28, Batch: 78, D Loss: 0.10017305880534422, G Loss: 19.14596176147461\n",
      "Epoch: 28, Batch: 79, D Loss: 0.09913474513044318, G Loss: 19.591720581054688\n",
      "Epoch: 28, Batch: 80, D Loss: 0.10070891058410092, G Loss: 19.999849319458008\n",
      "Epoch: 28, Batch: 81, D Loss: 0.10041420257542322, G Loss: 20.13983154296875\n",
      "Epoch: 28, Batch: 82, D Loss: 0.09198685858982203, G Loss: 19.530488967895508\n",
      "Epoch: 28, Batch: 83, D Loss: 0.09480764218780191, G Loss: 18.76344871520996\n",
      "Epoch: 28, Batch: 84, D Loss: 0.10252459714080087, G Loss: 18.706073760986328\n",
      "Epoch: 28, Batch: 85, D Loss: 0.10335192371987478, G Loss: 19.21729278564453\n",
      "Epoch: 28, Batch: 86, D Loss: 0.09448930075331075, G Loss: 19.454607009887695\n",
      "Epoch: 28, Batch: 87, D Loss: 0.1027327344332486, G Loss: 19.72820472717285\n",
      "Epoch: 28, Batch: 88, D Loss: 0.10380719727004184, G Loss: 19.881175994873047\n",
      "Epoch: 28, Batch: 89, D Loss: 0.09334556162240137, G Loss: 19.409069061279297\n",
      "Epoch: 28, Batch: 90, D Loss: 0.09561859330964628, G Loss: 18.77790069580078\n",
      "Epoch: 28, Batch: 91, D Loss: 0.09933095073419951, G Loss: 18.561800003051758\n",
      "Epoch: 28, Batch: 92, D Loss: 0.09778032095134837, G Loss: 18.779783248901367\n",
      "Epoch: 28, Batch: 93, D Loss: 0.0967372386126486, G Loss: 19.184043884277344\n",
      "Epoch: 28, Batch: 94, D Loss: 0.09592075093274532, G Loss: 19.550783157348633\n",
      "Epoch: 28, Batch: 95, D Loss: 0.10142813012436569, G Loss: 19.899545669555664\n",
      "Epoch: 28, Batch: 96, D Loss: 0.09289565808082323, G Loss: 19.715057373046875\n",
      "Epoch: 28, Batch: 97, D Loss: 0.09961709555551523, G Loss: 19.24838638305664\n",
      "Epoch: 28, Batch: 98, D Loss: 0.1000480229689591, G Loss: 19.006412506103516\n",
      "Epoch: 28, Batch: 99, D Loss: 0.10359027497416973, G Loss: 19.134397506713867\n",
      "Epoch: 28, Batch: 100, D Loss: 0.094694810691897, G Loss: 19.049360275268555\n",
      "Epoch: 28, Batch: 101, D Loss: 0.09094928543598013, G Loss: 18.600006103515625\n",
      "Epoch: 28, Batch: 102, D Loss: 0.10403353391236747, G Loss: 18.61774253845215\n",
      "Epoch: 28, Batch: 103, D Loss: 0.10294264915530316, G Loss: 18.869571685791016\n",
      "Epoch: 28, Batch: 104, D Loss: 0.09467433718177753, G Loss: 18.839027404785156\n",
      "Epoch: 28, Batch: 105, D Loss: 0.0979661902304172, G Loss: 18.711885452270508\n",
      "Epoch: 28, Batch: 106, D Loss: 0.09412898566249828, G Loss: 18.394901275634766\n",
      "Epoch: 28, Batch: 107, D Loss: 0.0956580847090609, G Loss: 18.131977081298828\n",
      "Epoch: 28, Batch: 108, D Loss: 0.09589458943710749, G Loss: 18.08806037902832\n",
      "Epoch: 28, Batch: 109, D Loss: 0.09721611323086288, G Loss: 18.2965145111084\n",
      "Epoch: 28, Batch: 110, D Loss: 0.10356812599935594, G Loss: 18.864990234375\n",
      "Epoch: 28, Batch: 111, D Loss: 0.09460348929629259, G Loss: 19.035905838012695\n",
      "Epoch: 28, Batch: 112, D Loss: 0.09661571970411731, G Loss: 18.913387298583984\n",
      "Epoch: 28, Batch: 113, D Loss: 0.09581491712087198, G Loss: 18.601369857788086\n",
      "Epoch: 28, Batch: 114, D Loss: 0.10409342153597434, G Loss: 18.683120727539062\n",
      "Epoch: 28, Batch: 115, D Loss: 0.09930515644506732, G Loss: 18.83951187133789\n",
      "Epoch: 28, Batch: 116, D Loss: 0.09796601839519581, G Loss: 18.98363494873047\n",
      "Epoch: 28, Batch: 117, D Loss: 0.10064418126568953, G Loss: 19.177099227905273\n",
      "Epoch: 28, Batch: 118, D Loss: 0.09657469632956195, G Loss: 19.129127502441406\n",
      "Epoch: 28, Batch: 119, D Loss: 0.10081658010840644, G Loss: 19.153507232666016\n",
      "Epoch: 28, Batch: 120, D Loss: 0.0988843539628852, G Loss: 19.150419235229492\n",
      "Epoch: 28, Batch: 121, D Loss: 0.10181205199871113, G Loss: 19.282705307006836\n",
      "Epoch: 28, Batch: 122, D Loss: 0.09853984622241496, G Loss: 19.326278686523438\n",
      "Epoch: 28, Batch: 123, D Loss: 0.1008214820725084, G Loss: 19.429580688476562\n",
      "Epoch: 28, Batch: 124, D Loss: 0.09788695166178041, G Loss: 19.36978530883789\n",
      "Epoch: 28, Batch: 125, D Loss: 0.09233898161063658, G Loss: 18.990755081176758\n",
      "Epoch: 28, Batch: 126, D Loss: 0.0939079406544463, G Loss: 18.732561111450195\n",
      "Epoch: 28, Batch: 127, D Loss: 0.10312939723304648, G Loss: 19.191781997680664\n",
      "Epoch: 28, Batch: 128, D Loss: 0.10250310755564407, G Loss: 19.943349838256836\n",
      "Epoch: 28, Batch: 129, D Loss: 0.0940999994548426, G Loss: 20.146657943725586\n",
      "Epoch: 28, Batch: 130, D Loss: 0.10000374257783129, G Loss: 20.134702682495117\n",
      "Epoch: 28, Batch: 131, D Loss: 0.10090263283327039, G Loss: 20.025924682617188\n",
      "Epoch: 28, Batch: 132, D Loss: 0.09726967776828921, G Loss: 19.782020568847656\n",
      "Epoch: 28, Batch: 133, D Loss: 0.09367782032317706, G Loss: 19.42499542236328\n",
      "Epoch: 28, Batch: 134, D Loss: 0.09604166640101508, G Loss: 19.33845329284668\n",
      "Epoch: 28, Batch: 135, D Loss: 0.08621908950273038, G Loss: 19.10700798034668\n",
      "Epoch: 28, Batch: 136, D Loss: 0.09704277136662576, G Loss: 19.38962745666504\n",
      "Epoch: 28, Batch: 137, D Loss: 0.09779274604565891, G Loss: 19.95594024658203\n",
      "Epoch: 28, Batch: 138, D Loss: 0.09488123741402005, G Loss: 20.382366180419922\n",
      "Epoch: 28, Batch: 139, D Loss: 0.10776437123737165, G Loss: 21.037168502807617\n",
      "Epoch: 28, Batch: 140, D Loss: 0.09615515955375323, G Loss: 20.970964431762695\n",
      "Epoch: 28, Batch: 141, D Loss: 0.10233523743245021, G Loss: 20.635038375854492\n",
      "Epoch: 28, Batch: 142, D Loss: 0.10376859519134107, G Loss: 20.369197845458984\n",
      "Epoch: 28, Batch: 143, D Loss: 0.10142524618448323, G Loss: 20.19750213623047\n",
      "Epoch: 28, Batch: 144, D Loss: 0.09280131861854757, G Loss: 19.79511833190918\n",
      "Epoch: 28, Batch: 145, D Loss: 0.09739051157973577, G Loss: 19.553762435913086\n",
      "Epoch: 28, Batch: 146, D Loss: 0.10053604983283948, G Loss: 19.793804168701172\n",
      "Epoch: 28, Batch: 147, D Loss: 0.10226547070435321, G Loss: 20.292455673217773\n",
      "Epoch: 28, Batch: 148, D Loss: 0.09835910866772629, G Loss: 20.48202896118164\n",
      "Epoch: 28, Batch: 149, D Loss: 0.09441509172874679, G Loss: 20.1691951751709\n",
      "Epoch: 28, Batch: 150, D Loss: 0.09816303952770544, G Loss: 19.839763641357422\n",
      "Epoch: 28, Batch: 151, D Loss: 0.10682840750873657, G Loss: 20.100154876708984\n",
      "Epoch: 28, Batch: 152, D Loss: 0.10183974431579013, G Loss: 20.48636245727539\n",
      "Epoch: 28, Batch: 153, D Loss: 0.09871640862083725, G Loss: 20.570528030395508\n",
      "Epoch: 28, Batch: 154, D Loss: 0.099344470219975, G Loss: 20.47380828857422\n",
      "Epoch: 28, Batch: 155, D Loss: 0.10540014569565415, G Loss: 20.474498748779297\n",
      "Epoch: 28, Batch: 156, D Loss: 0.10074864395378519, G Loss: 20.378787994384766\n",
      "Epoch: 28, Batch: 157, D Loss: 0.09980719612950562, G Loss: 20.228666305541992\n",
      "Epoch: 28, Batch: 158, D Loss: 0.09594087397591389, G Loss: 19.951902389526367\n",
      "Epoch: 28, Batch: 159, D Loss: 0.0985475193800801, G Loss: 19.87554359436035\n",
      "Epoch: 28, Batch: 160, D Loss: 0.09571489062252014, G Loss: 19.896087646484375\n",
      "Epoch: 28, Batch: 161, D Loss: 0.09423522762007508, G Loss: 19.957473754882812\n",
      "Epoch: 28, Batch: 162, D Loss: 0.09501932662930646, G Loss: 20.068235397338867\n",
      "Epoch: 28, Batch: 163, D Loss: 0.089186639631474, G Loss: 19.926790237426758\n",
      "Epoch: 28, Batch: 164, D Loss: 0.09942071235934735, G Loss: 20.19978141784668\n",
      "Epoch: 28, Batch: 165, D Loss: 0.09474363997264684, G Loss: 20.445791244506836\n",
      "Epoch: 28, Batch: 166, D Loss: 0.10140465247413671, G Loss: 21.071985244750977\n",
      "Epoch: 28, Batch: 167, D Loss: 0.10162621763028745, G Loss: 21.616226196289062\n",
      "Epoch: 28, Batch: 168, D Loss: 0.10085801799477914, G Loss: 21.73309326171875\n",
      "Epoch: 28, Batch: 169, D Loss: 0.10042759795572605, G Loss: 21.607860565185547\n",
      "Epoch: 28, Batch: 170, D Loss: 0.10325412474111664, G Loss: 21.496845245361328\n",
      "Epoch: 28, Batch: 171, D Loss: 0.09534828393336417, G Loss: 21.095592498779297\n",
      "Epoch: 28, Batch: 172, D Loss: 0.09389770821252358, G Loss: 20.578418731689453\n",
      "Epoch: 28, Batch: 173, D Loss: 0.09490505673400834, G Loss: 20.285083770751953\n",
      "Epoch: 28, Batch: 174, D Loss: 0.09920734975976869, G Loss: 20.654560089111328\n",
      "Epoch: 28, Batch: 175, D Loss: 0.10212225504941308, G Loss: 21.306711196899414\n",
      "Epoch: 28, Batch: 176, D Loss: 0.10186691602699735, G Loss: 21.891538619995117\n",
      "Epoch: 28, Batch: 177, D Loss: 0.10258662714678955, G Loss: 22.08732795715332\n",
      "Epoch: 28, Batch: 178, D Loss: 0.0973531605542855, G Loss: 21.511672973632812\n",
      "Epoch: 28, Batch: 179, D Loss: 0.1020832065088379, G Loss: 20.7896785736084\n",
      "Epoch: 28, Batch: 180, D Loss: 0.10352351575543017, G Loss: 20.347000122070312\n",
      "Epoch: 28, Batch: 181, D Loss: 0.09880984656197767, G Loss: 20.13142967224121\n",
      "Epoch: 28, Batch: 182, D Loss: 0.09902191996273951, G Loss: 20.15936851501465\n",
      "Epoch: 28, Batch: 183, D Loss: 0.0936038652346351, G Loss: 20.068532943725586\n",
      "Epoch: 28, Batch: 184, D Loss: 0.09913078790307861, G Loss: 20.097484588623047\n",
      "Epoch: 28, Batch: 185, D Loss: 0.10084039803768036, G Loss: 20.260374069213867\n",
      "Epoch: 28, Batch: 186, D Loss: 0.1003875963554714, G Loss: 20.341575622558594\n",
      "Epoch: 28, Batch: 187, D Loss: 0.09455914135694743, G Loss: 20.05162239074707\n",
      "Epoch: 28, Batch: 188, D Loss: 0.09635925414484481, G Loss: 19.641794204711914\n",
      "Epoch: 28, Batch: 189, D Loss: 0.10033250007316608, G Loss: 19.58294677734375\n",
      "Epoch: 28, Batch: 190, D Loss: 0.10032434902965925, G Loss: 19.77581024169922\n",
      "Epoch: 28, Batch: 191, D Loss: 0.09742350996753635, G Loss: 19.907697677612305\n",
      "Epoch: 28, Batch: 192, D Loss: 0.0990742083099656, G Loss: 20.02462387084961\n",
      "Epoch: 28, Batch: 193, D Loss: 0.09772132436107162, G Loss: 20.05547332763672\n",
      "Epoch: 28, Batch: 194, D Loss: 0.09919047456477093, G Loss: 19.993165969848633\n",
      "Epoch: 28, Batch: 195, D Loss: 0.0938504648635119, G Loss: 19.664079666137695\n",
      "Epoch: 28, Batch: 196, D Loss: 0.10487021638154292, G Loss: 19.829418182373047\n",
      "Epoch: 28, Batch: 197, D Loss: 0.10275158385215988, G Loss: 20.228515625\n",
      "Epoch: 28, Batch: 198, D Loss: 0.10477094417529009, G Loss: 20.6619873046875\n",
      "Epoch: 28, Batch: 199, D Loss: 0.10198894195427066, G Loss: 20.692916870117188\n",
      "Epoch: 28, Batch: 200, D Loss: 0.09385212583105945, G Loss: 20.04975128173828\n",
      "Epoch: 28, Batch: 201, D Loss: 0.10041701928045021, G Loss: 19.451717376708984\n",
      "Epoch: 28, Batch: 202, D Loss: 0.10332909411641877, G Loss: 19.382410049438477\n",
      "Epoch: 28, Batch: 203, D Loss: 0.10141626909625023, G Loss: 19.673532485961914\n",
      "Epoch: 28, Batch: 204, D Loss: 0.10391275689361557, G Loss: 20.264997482299805\n",
      "Epoch: 28, Batch: 205, D Loss: 0.0983800075690281, G Loss: 20.445899963378906\n",
      "Epoch: 28, Batch: 206, D Loss: 0.08975251856017635, G Loss: 19.81472396850586\n",
      "Epoch: 28, Batch: 207, D Loss: 0.10645429178879084, G Loss: 19.67106056213379\n",
      "Epoch: 28, Batch: 208, D Loss: 0.10198311636500268, G Loss: 19.874393463134766\n",
      "Epoch: 28, Batch: 209, D Loss: 0.10535208969420051, G Loss: 20.402557373046875\n",
      "Epoch: 28, Batch: 210, D Loss: 0.09415440335222075, G Loss: 20.271814346313477\n",
      "Epoch: 28, Batch: 211, D Loss: 0.10008517744131412, G Loss: 19.985082626342773\n",
      "Epoch: 28, Batch: 212, D Loss: 0.09584988786323356, G Loss: 19.53502655029297\n",
      "Epoch: 28, Batch: 213, D Loss: 0.1012678610992328, G Loss: 19.404884338378906\n",
      "Epoch: 28, Batch: 214, D Loss: 0.09702220006914186, G Loss: 19.348045349121094\n",
      "Epoch: 28, Batch: 215, D Loss: 0.10360768598015646, G Loss: 19.74544334411621\n",
      "Epoch: 28, Batch: 216, D Loss: 0.0994597386768723, G Loss: 20.04265022277832\n",
      "Epoch: 28, Batch: 217, D Loss: 0.09650081497359253, G Loss: 19.996702194213867\n",
      "Epoch: 28, Batch: 218, D Loss: 0.10500999636651465, G Loss: 20.12822914123535\n",
      "Epoch: 28, Batch: 219, D Loss: 0.11039708628295791, G Loss: 20.526081085205078\n",
      "Epoch: 28, Batch: 220, D Loss: 0.10021598700909728, G Loss: 20.438430786132812\n",
      "Epoch: 28, Batch: 221, D Loss: 0.10074101467128921, G Loss: 20.119096755981445\n",
      "Epoch: 28, Batch: 222, D Loss: 0.09517955160511082, G Loss: 19.51787757873535\n",
      "Epoch: 28, Batch: 223, D Loss: 0.09247924625003501, G Loss: 18.84938621520996\n",
      "Epoch: 28, Batch: 224, D Loss: 0.09836675541760198, G Loss: 18.917404174804688\n",
      "Epoch: 28, Batch: 225, D Loss: 0.10333828082800811, G Loss: 19.71772003173828\n",
      "Epoch: 28, Batch: 226, D Loss: 0.09878037960960956, G Loss: 20.489179611206055\n",
      "Epoch: 28, Batch: 227, D Loss: 0.09732070621981881, G Loss: 20.69385528564453\n",
      "Epoch: 28, Batch: 228, D Loss: 0.09849762975366472, G Loss: 20.442256927490234\n",
      "Epoch: 28, Batch: 229, D Loss: 0.09758451666373613, G Loss: 19.959733963012695\n",
      "Epoch: 28, Batch: 230, D Loss: 0.09894339869426516, G Loss: 19.608753204345703\n",
      "Epoch: 28, Batch: 231, D Loss: 0.0993039623201768, G Loss: 19.616249084472656\n",
      "Epoch: 28, Batch: 232, D Loss: 0.10148239259938774, G Loss: 19.99236488342285\n",
      "Epoch: 28, Batch: 233, D Loss: 0.10104543052908493, G Loss: 20.43571662902832\n",
      "Epoch: 28, Batch: 234, D Loss: 0.0944336734068032, G Loss: 20.397096633911133\n",
      "Epoch: 28, Batch: 235, D Loss: 0.09365980415968944, G Loss: 19.92515754699707\n",
      "Epoch: 28, Batch: 236, D Loss: 0.10113746052121719, G Loss: 19.712976455688477\n",
      "Epoch: 28, Batch: 237, D Loss: 0.0976480930664676, G Loss: 19.60900115966797\n",
      "Epoch: 28, Batch: 238, D Loss: 0.10238987340182826, G Loss: 19.872364044189453\n",
      "Epoch: 28, Batch: 239, D Loss: 0.10027088324177202, G Loss: 20.18663787841797\n",
      "Epoch: 28, Batch: 240, D Loss: 0.09598967521491103, G Loss: 20.12244415283203\n",
      "Epoch: 28, Batch: 241, D Loss: 0.10451783330108116, G Loss: 20.143016815185547\n",
      "Epoch: 28, Batch: 242, D Loss: 0.10455404306229299, G Loss: 20.25620460510254\n",
      "Epoch: 28, Batch: 243, D Loss: 0.09368416021111181, G Loss: 19.84290313720703\n",
      "Epoch: 28, Batch: 244, D Loss: 0.10528261338701239, G Loss: 19.788724899291992\n",
      "Epoch: 28, Batch: 245, D Loss: 0.10193267584111987, G Loss: 19.911211013793945\n",
      "Epoch: 28, Batch: 246, D Loss: 0.09964031094158632, G Loss: 19.905092239379883\n",
      "Epoch: 28, Batch: 247, D Loss: 0.10101669394413237, G Loss: 19.917407989501953\n",
      "Epoch: 28, Batch: 248, D Loss: 0.10120084996202805, G Loss: 19.87745475769043\n",
      "Epoch: 28, Batch: 249, D Loss: 0.10183163106862414, G Loss: 19.82889747619629\n",
      "Epoch: 28, Batch: 250, D Loss: 0.09030074049447079, G Loss: 19.2236270904541\n",
      "Epoch: 28, Batch: 251, D Loss: 0.09562243053497732, G Loss: 18.82171058654785\n",
      "Epoch: 28, Batch: 252, D Loss: 0.09708413073721589, G Loss: 18.814537048339844\n",
      "Epoch: 28, Batch: 253, D Loss: 0.09780502604310981, G Loss: 19.138751983642578\n",
      "Epoch: 28, Batch: 254, D Loss: 0.09922746751319289, G Loss: 19.692358016967773\n",
      "Epoch: 28, Batch: 255, D Loss: 0.09842247631267065, G Loss: 20.064205169677734\n",
      "Epoch: 28, Batch: 256, D Loss: 0.10641310441733076, G Loss: 20.478866577148438\n",
      "Epoch: 28, Batch: 257, D Loss: 0.10329547587168963, G Loss: 20.513671875\n",
      "Epoch: 28, Batch: 258, D Loss: 0.09836977801560798, G Loss: 19.98851203918457\n",
      "Epoch: 28, Batch: 259, D Loss: 0.10294531422808884, G Loss: 19.470256805419922\n",
      "Epoch: 28, Batch: 260, D Loss: 0.10948143316167669, G Loss: 19.622447967529297\n",
      "Epoch: 28, Batch: 261, D Loss: 0.0936108695097354, G Loss: 19.44607162475586\n",
      "Epoch: 28, Batch: 262, D Loss: 0.1076149582674889, G Loss: 19.82403564453125\n",
      "Epoch: 28, Batch: 263, D Loss: 0.08909887967942631, G Loss: 19.479572296142578\n",
      "Epoch: 28, Batch: 264, D Loss: 0.09993265757593983, G Loss: 19.325218200683594\n",
      "Epoch: 28, Batch: 265, D Loss: 0.10298560738267559, G Loss: 19.56631851196289\n",
      "Epoch: 28, Batch: 266, D Loss: 0.09583480806929923, G Loss: 19.669740676879883\n",
      "Epoch: 28, Batch: 267, D Loss: 0.0993035225398311, G Loss: 19.823522567749023\n",
      "Epoch: 28, Batch: 268, D Loss: 0.09264342617526689, G Loss: 19.7098388671875\n",
      "Epoch: 28, Batch: 269, D Loss: 0.10010560734556817, G Loss: 19.784385681152344\n",
      "Epoch: 28, Batch: 270, D Loss: 0.09675318132844801, G Loss: 19.75282859802246\n",
      "Epoch: 28, Batch: 271, D Loss: 0.09655453396491631, G Loss: 19.757532119750977\n",
      "Epoch: 28, Batch: 272, D Loss: 0.09827448553842788, G Loss: 19.835969924926758\n",
      "Epoch: 28, Batch: 273, D Loss: 0.0991424035638645, G Loss: 19.935684204101562\n",
      "Epoch: 28, Batch: 274, D Loss: 0.09816986425285834, G Loss: 20.06284523010254\n",
      "Epoch: 28, Batch: 275, D Loss: 0.10014169748051299, G Loss: 20.314010620117188\n",
      "Epoch: 28, Batch: 276, D Loss: 0.09625873788620065, G Loss: 20.349620819091797\n",
      "Epoch: 28, Batch: 277, D Loss: 0.0977767862359884, G Loss: 20.307865142822266\n",
      "Epoch: 28, Batch: 278, D Loss: 0.09645474034098528, G Loss: 20.277034759521484\n",
      "Epoch: 28, Batch: 279, D Loss: 0.10115642912172729, G Loss: 20.58291244506836\n",
      "Epoch: 28, Batch: 280, D Loss: 0.10382852747504784, G Loss: 21.08510398864746\n",
      "Epoch: 28, Batch: 281, D Loss: 0.09749391708013011, G Loss: 21.18657875061035\n",
      "Epoch: 28, Batch: 282, D Loss: 0.0968589711846255, G Loss: 20.911113739013672\n",
      "Epoch: 28, Batch: 283, D Loss: 0.10104465531106774, G Loss: 20.693086624145508\n",
      "Epoch: 28, Batch: 284, D Loss: 0.10141632011875185, G Loss: 20.713430404663086\n",
      "Epoch: 28, Batch: 285, D Loss: 0.10137830721481589, G Loss: 20.85715675354004\n",
      "Epoch: 28, Batch: 286, D Loss: 0.09552595807708247, G Loss: 20.876422882080078\n",
      "Epoch: 28, Batch: 287, D Loss: 0.0997871164620989, G Loss: 20.95685577392578\n",
      "Epoch: 28, Batch: 288, D Loss: 0.09954933114564185, G Loss: 21.061979293823242\n",
      "Epoch: 28, Batch: 289, D Loss: 0.09231276851445416, G Loss: 20.78286361694336\n",
      "Epoch: 28, Batch: 290, D Loss: 0.0986529295597206, G Loss: 20.700653076171875\n",
      "Epoch: 28, Batch: 291, D Loss: 0.10128440752817464, G Loss: 20.94879913330078\n",
      "Epoch: 28, Batch: 292, D Loss: 0.1060244741854264, G Loss: 21.622142791748047\n",
      "Epoch: 28, Batch: 293, D Loss: 0.10074165480447557, G Loss: 21.964263916015625\n",
      "Epoch: 28, Batch: 294, D Loss: 0.10220015063645235, G Loss: 21.937192916870117\n",
      "Epoch: 28, Batch: 295, D Loss: 0.09903681297617412, G Loss: 21.430009841918945\n",
      "Epoch: 28, Batch: 296, D Loss: 0.10188721152053701, G Loss: 20.953125\n",
      "Epoch: 28, Batch: 297, D Loss: 0.10728245265903152, G Loss: 21.06998634338379\n",
      "Epoch: 28, Batch: 298, D Loss: 0.10046266052487166, G Loss: 21.192943572998047\n",
      "Epoch: 28, Batch: 299, D Loss: 0.09471841191300523, G Loss: 20.988595962524414\n",
      "Epoch: 28, Batch: 300, D Loss: 0.09433038579235473, G Loss: 20.622577667236328\n",
      "Epoch: 28, Batch: 301, D Loss: 0.10110309030412218, G Loss: 20.618898391723633\n",
      "Epoch: 28, Batch: 302, D Loss: 0.10157370615657485, G Loss: 20.88203239440918\n",
      "Epoch: 28, Batch: 303, D Loss: 0.09770128915305737, G Loss: 21.036788940429688\n",
      "Epoch: 28, Batch: 304, D Loss: 0.10048194264717555, G Loss: 21.11313819885254\n",
      "Epoch: 28, Batch: 305, D Loss: 0.10417904736551054, G Loss: 21.236186981201172\n",
      "Epoch: 28, Batch: 306, D Loss: 0.10031949014802843, G Loss: 21.162260055541992\n",
      "Epoch: 28, Batch: 307, D Loss: 0.10032891518072201, G Loss: 20.955001831054688\n",
      "Epoch: 28, Batch: 308, D Loss: 0.10034813029925702, G Loss: 20.79857635498047\n",
      "Epoch: 28, Batch: 309, D Loss: 0.09604159793387895, G Loss: 20.6259822845459\n",
      "Epoch: 28, Batch: 310, D Loss: 0.10197249103879286, G Loss: 20.851171493530273\n",
      "Epoch: 28, Batch: 311, D Loss: 0.10015164352007205, G Loss: 21.21649932861328\n",
      "Epoch: 28, Batch: 312, D Loss: 0.09928154971901534, G Loss: 21.483959197998047\n",
      "Epoch: 28, Batch: 313, D Loss: 0.09799522184557861, G Loss: 21.508344650268555\n",
      "Epoch: 28, Batch: 314, D Loss: 0.09925366961417234, G Loss: 21.467607498168945\n",
      "Epoch: 28, Batch: 315, D Loss: 0.10170280956007195, G Loss: 21.560209274291992\n",
      "Epoch: 28, Batch: 316, D Loss: 0.09880944361943614, G Loss: 21.66253662109375\n",
      "Epoch: 28, Batch: 317, D Loss: 0.09830961396930356, G Loss: 21.572463989257812\n",
      "Epoch: 28, Batch: 318, D Loss: 0.10203267657005201, G Loss: 21.42728614807129\n",
      "Epoch: 28, Batch: 319, D Loss: 0.09332652432086277, G Loss: 20.417938232421875\n",
      "Epoch: 28, Batch: 320, D Loss: 0.09572488903770976, G Loss: 19.901592254638672\n",
      "Epoch: 28, Batch: 321, D Loss: 0.09931305162210657, G Loss: 19.979339599609375\n",
      "Epoch: 28, Batch: 322, D Loss: 0.10141135835177212, G Loss: 20.43161964416504\n",
      "Epoch: 28, Batch: 323, D Loss: 0.10125067887250488, G Loss: 20.72890281677246\n",
      "Epoch: 28, Batch: 324, D Loss: 0.10337780465088942, G Loss: 20.754690170288086\n",
      "Epoch: 28, Batch: 325, D Loss: 0.1014278090014673, G Loss: 20.357812881469727\n",
      "Epoch: 28, Batch: 326, D Loss: 0.09944962068370422, G Loss: 19.673633575439453\n",
      "Epoch: 28, Batch: 327, D Loss: 0.09868742724443269, G Loss: 19.046890258789062\n",
      "Epoch: 28, Batch: 328, D Loss: 0.10176822822075349, G Loss: 18.970903396606445\n",
      "Epoch: 28, Batch: 329, D Loss: 0.10138165456633175, G Loss: 19.23677635192871\n",
      "Epoch: 28, Batch: 330, D Loss: 0.10053102857168317, G Loss: 19.57716178894043\n",
      "Epoch: 28, Batch: 331, D Loss: 0.10101596409525104, G Loss: 19.753999710083008\n",
      "Epoch: 28, Batch: 332, D Loss: 0.09563875352669315, G Loss: 19.45670509338379\n",
      "Epoch: 28, Batch: 333, D Loss: 0.10137959778248828, G Loss: 19.152816772460938\n",
      "Epoch: 28, Batch: 334, D Loss: 0.0940996438518289, G Loss: 18.73320960998535\n",
      "Epoch: 28, Batch: 335, D Loss: 0.1001201457926959, G Loss: 18.72290802001953\n",
      "Epoch: 28, Batch: 336, D Loss: 0.09927552508862902, G Loss: 19.02910614013672\n",
      "Epoch: 28, Batch: 337, D Loss: 0.1057892386203858, G Loss: 19.717208862304688\n",
      "Epoch: 28, Batch: 338, D Loss: 0.09915328143278856, G Loss: 20.007749557495117\n",
      "Epoch: 28, Batch: 339, D Loss: 0.10016135983254315, G Loss: 19.8393611907959\n",
      "Epoch: 28, Batch: 340, D Loss: 0.10196265721427811, G Loss: 19.522127151489258\n",
      "Epoch: 28, Batch: 341, D Loss: 0.10000483899327728, G Loss: 19.102245330810547\n",
      "Epoch: 28, Batch: 342, D Loss: 0.09868926103979514, G Loss: 18.8197078704834\n",
      "Epoch: 28, Batch: 343, D Loss: 0.09860009283839188, G Loss: 18.86358642578125\n",
      "Epoch: 28, Batch: 344, D Loss: 0.09728558657378539, G Loss: 19.02384376525879\n",
      "Epoch: 28, Batch: 345, D Loss: 0.09850533542224849, G Loss: 19.311384201049805\n",
      "Epoch: 28, Batch: 346, D Loss: 0.09644818500598751, G Loss: 19.41521453857422\n",
      "Epoch: 28, Batch: 347, D Loss: 0.09817053556396726, G Loss: 19.482961654663086\n",
      "Epoch: 28, Batch: 348, D Loss: 0.0958507302195073, G Loss: 19.44365119934082\n",
      "Epoch: 28, Batch: 349, D Loss: 0.09550362275091762, G Loss: 19.294719696044922\n",
      "Epoch: 28, Batch: 350, D Loss: 0.09763404926896735, G Loss: 19.379405975341797\n",
      "Epoch: 28, Batch: 351, D Loss: 0.09811379177119317, G Loss: 19.7058162689209\n",
      "Epoch: 28, Batch: 352, D Loss: 0.10178311272413942, G Loss: 20.26225471496582\n",
      "Epoch: 28, Batch: 353, D Loss: 0.09940391099212648, G Loss: 20.631258010864258\n",
      "Epoch: 28, Batch: 354, D Loss: 0.10011945716297788, G Loss: 20.75400733947754\n",
      "Epoch: 28, Batch: 355, D Loss: 0.1035560225331214, G Loss: 20.753847122192383\n",
      "Epoch: 28, Batch: 356, D Loss: 0.0925269282068929, G Loss: 20.29766082763672\n",
      "Epoch: 28, Batch: 357, D Loss: 0.1024614580526983, G Loss: 20.21419906616211\n",
      "Epoch: 28, Batch: 358, D Loss: 0.09743423834604448, G Loss: 20.42080307006836\n",
      "Epoch: 28, Batch: 359, D Loss: 0.09367261894462858, G Loss: 20.427383422851562\n",
      "Epoch: 28, Batch: 360, D Loss: 0.08873065634243776, G Loss: 20.26524543762207\n",
      "Epoch: 28, Batch: 361, D Loss: 0.105075874005998, G Loss: 20.880123138427734\n",
      "Epoch: 28, Batch: 362, D Loss: 0.1001389178595036, G Loss: 21.5894775390625\n",
      "Epoch: 28, Batch: 363, D Loss: 0.10138861106469158, G Loss: 22.046659469604492\n",
      "Epoch: 28, Batch: 364, D Loss: 0.10457812261656592, G Loss: 22.24441146850586\n",
      "Epoch: 28, Batch: 365, D Loss: 0.10431909573179668, G Loss: 22.062366485595703\n",
      "Epoch: 28, Batch: 366, D Loss: 0.10221509650913367, G Loss: 21.7445125579834\n",
      "Epoch: 28, Batch: 367, D Loss: 0.09782269620487635, G Loss: 21.24407196044922\n",
      "Epoch: 28, Batch: 368, D Loss: 0.09944805537078094, G Loss: 20.97709846496582\n",
      "Epoch: 28, Batch: 369, D Loss: 0.09748774801353158, G Loss: 21.204416275024414\n",
      "Epoch: 28, Batch: 370, D Loss: 0.09568168243837531, G Loss: 21.944351196289062\n",
      "Epoch: 28, Batch: 371, D Loss: 0.09823095805438156, G Loss: 23.378204345703125\n",
      "Epoch: 28, Batch: 372, D Loss: 0.11334507914002395, G Loss: 24.85369110107422\n",
      "Epoch: 28, Batch: 373, D Loss: 0.1048034579290768, G Loss: 20.6364803314209\n",
      "Epoch: 28, Batch: 374, D Loss: 0.10548578893472849, G Loss: 15.826522827148438\n",
      "Epoch: 28, Batch: 375, D Loss: 0.09929198879018486, G Loss: 12.364013671875\n",
      "Epoch: 28, Batch: 376, D Loss: 0.09059141711168195, G Loss: 16.619735717773438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 11:32:22.535668: W tensorflow/core/data/root_dataset.cc:286] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Batch: 377, D Loss: 0.09982825827549055, G Loss: 27.27672576904297\n",
      "Epoch: 28, Batch: 378, D Loss: 0.1038041189312955, G Loss: 38.48646926879883\n",
      "Epoch: 28, Batch: 379, D Loss: 0.09252041578292848, G Loss: 38.44141387939453\n",
      "Epoch: 28, Batch: 380, D Loss: 0.10328055173158646, G Loss: 40.049583435058594\n",
      "Epoch: 28, Batch: 381, D Loss: 0.09618809819221497, G Loss: 39.49931335449219\n",
      "Epoch: 28, Batch: 382, D Loss: 0.10045073181390762, G Loss: 38.99408721923828\n",
      "Epoch: 28, Batch: 383, D Loss: 0.0991995856165886, G Loss: 38.39547348022461\n",
      "Epoch: 28, Batch: 384, D Loss: 0.09992722421884538, G Loss: 37.6920166015625\n",
      "Epoch: 28, Batch: 385, D Loss: 0.10430442541837694, G Loss: 37.98432540893555\n",
      "Epoch: 28, Batch: 386, D Loss: 0.09752085804939271, G Loss: 37.83204650878906\n",
      "Epoch: 28, Batch: 387, D Loss: 0.09535160660743716, G Loss: 37.45651626586914\n",
      "Epoch: 28, Batch: 388, D Loss: 0.1000340133905411, G Loss: 37.12709045410156\n",
      "Epoch: 28, Batch: 389, D Loss: 0.09797327220439916, G Loss: 36.419471740722656\n",
      "Epoch: 28, Batch: 390, D Loss: 0.09709039330482493, G Loss: 35.8310432434082\n",
      "Epoch: 28, Batch: 391, D Loss: 0.10210580378770841, G Loss: 35.93770980834961\n",
      "Epoch: 28, Batch: 392, D Loss: 0.10352353006601345, G Loss: 36.09318542480469\n",
      "Epoch: 28, Batch: 393, D Loss: 0.0991667434573176, G Loss: 34.43175506591797\n",
      "Epoch: 28, Batch: 394, D Loss: 0.09869460761547211, G Loss: 32.9288215637207\n",
      "Epoch: 28, Batch: 395, D Loss: 0.1021976992487934, G Loss: 32.81245422363281\n",
      "Epoch: 28, Batch: 396, D Loss: 0.09687708318233712, G Loss: 33.257049560546875\n",
      "Epoch: 28, Batch: 397, D Loss: 0.09744767099619076, G Loss: 33.430274963378906\n",
      "Epoch: 28, Batch: 398, D Loss: 0.10409242659807337, G Loss: 33.691871643066406\n",
      "Epoch: 28, Batch: 399, D Loss: 0.0997078865766543, G Loss: 32.89475631713867\n",
      "Epoch: 28, Batch: 400, D Loss: 0.0959078520536477, G Loss: 31.499401092529297\n",
      "Epoch: 28, Batch: 401, D Loss: 0.0995167046785494, G Loss: 30.952651977539062\n",
      "Epoch: 28, Batch: 402, D Loss: 0.09621597826482761, G Loss: 30.85970687866211\n",
      "Epoch: 28, Batch: 403, D Loss: 0.0978754162788542, G Loss: 31.376243591308594\n",
      "Epoch: 28, Batch: 404, D Loss: 0.09885264933110118, G Loss: 32.03404235839844\n",
      "Epoch: 28, Batch: 405, D Loss: 0.09660363942385262, G Loss: 32.26285171508789\n",
      "Epoch: 28, Batch: 406, D Loss: 0.1004306674003644, G Loss: 32.5036506652832\n",
      "Epoch: 28, Batch: 407, D Loss: 0.09365786612034277, G Loss: 32.2662353515625\n",
      "Epoch: 28, Batch: 408, D Loss: 0.10796470195055283, G Loss: 33.354190826416016\n",
      "Epoch: 28, Batch: 409, D Loss: 0.10102186352014646, G Loss: 34.21040725708008\n",
      "Epoch: 28, Batch: 410, D Loss: 0.09716800600290376, G Loss: 34.005733489990234\n",
      "Epoch: 28, Batch: 411, D Loss: 0.10096624493599032, G Loss: 33.798561096191406\n",
      "Epoch: 28, Batch: 412, D Loss: 0.10172897577285873, G Loss: 33.75431823730469\n",
      "Epoch: 28, Batch: 413, D Loss: 0.09941302239894984, G Loss: 33.645774841308594\n",
      "Epoch: 28, Batch: 414, D Loss: 0.1047615334391603, G Loss: 34.21204376220703\n",
      "Epoch: 28, Batch: 415, D Loss: 0.10556475818157239, G Loss: 35.099403381347656\n",
      "Epoch: 28, Batch: 416, D Loss: 0.10383917391300226, G Loss: 35.393165588378906\n",
      "Epoch: 28, Batch: 417, D Loss: 0.09516888856887855, G Loss: 34.27320861816406\n",
      "Epoch: 28, Batch: 418, D Loss: 0.10033820569515343, G Loss: 33.19267272949219\n",
      "Epoch: 28, Batch: 419, D Loss: 0.09565782546997331, G Loss: 32.61088562011719\n",
      "Epoch: 28, Batch: 420, D Loss: 0.09696610271931003, G Loss: 32.816707611083984\n",
      "Epoch: 28, Batch: 421, D Loss: 0.09991493076086261, G Loss: 33.304237365722656\n",
      "Epoch: 28, Batch: 422, D Loss: 0.09824749082327026, G Loss: 33.734249114990234\n",
      "Epoch: 28, Batch: 423, D Loss: 0.10236488282680618, G Loss: 33.819461822509766\n",
      "Epoch: 28, Batch: 424, D Loss: 0.10141934454441184, G Loss: 33.6182746887207\n",
      "Epoch: 28, Batch: 425, D Loss: 0.09483984112739795, G Loss: 32.452911376953125\n",
      "Epoch: 28, Batch: 426, D Loss: 0.10213584452868049, G Loss: 31.892431259155273\n",
      "Epoch: 28, Batch: 427, D Loss: 0.09605874866247946, G Loss: 31.729379653930664\n",
      "Epoch: 28, Batch: 428, D Loss: 0.0989713221788477, G Loss: 32.03646469116211\n",
      "Epoch: 28, Batch: 429, D Loss: 0.10109539330006147, G Loss: 32.409542083740234\n",
      "Epoch: 28, Batch: 430, D Loss: 0.10517922043800709, G Loss: 32.7280158996582\n",
      "Epoch: 28, Batch: 431, D Loss: 0.09838899970055029, G Loss: 32.205955505371094\n",
      "Epoch: 28, Batch: 432, D Loss: 0.1015359386801798, G Loss: 31.409753799438477\n",
      "Epoch: 28, Batch: 433, D Loss: 0.09634390473367621, G Loss: 30.505512237548828\n",
      "Epoch: 28, Batch: 434, D Loss: 0.09685771167282209, G Loss: 29.881084442138672\n",
      "Epoch: 28, Batch: 435, D Loss: 0.09874530136590082, G Loss: 30.040081024169922\n",
      "Epoch: 28, Batch: 436, D Loss: 0.09131897985939728, G Loss: 30.030731201171875\n",
      "Epoch: 28, Batch: 437, D Loss: 0.09481565654282155, G Loss: 30.10936737060547\n",
      "Epoch: 28, Batch: 438, D Loss: 0.10009548068050168, G Loss: 30.39971923828125\n",
      "Epoch: 28, Batch: 439, D Loss: 0.09901400655510896, G Loss: 30.579240798950195\n",
      "Epoch: 28, Batch: 440, D Loss: 0.09512858092787992, G Loss: 30.254270553588867\n",
      "Epoch: 28, Batch: 441, D Loss: 0.1014002263546394, G Loss: 30.050247192382812\n",
      "Epoch: 28, Batch: 442, D Loss: 0.09788019955163293, G Loss: 29.805870056152344\n",
      "Epoch: 28, Batch: 443, D Loss: 0.09470323473221515, G Loss: 29.575687408447266\n",
      "Epoch: 28, Batch: 444, D Loss: 0.10360424220567832, G Loss: 29.956077575683594\n",
      "Epoch: 28, Batch: 445, D Loss: 0.09738469123844655, G Loss: 30.189838409423828\n",
      "Epoch: 28, Batch: 446, D Loss: 0.10214100778106248, G Loss: 30.45009994506836\n",
      "Epoch: 28, Batch: 447, D Loss: 0.09970103204253544, G Loss: 30.311748504638672\n",
      "Epoch: 28, Batch: 448, D Loss: 0.09713012725119251, G Loss: 29.823978424072266\n",
      "Epoch: 28, Batch: 449, D Loss: 0.10932715237146304, G Loss: 29.800687789916992\n",
      "Epoch: 28, Batch: 450, D Loss: 0.09409242868430431, G Loss: 29.419689178466797\n",
      "Epoch: 28, Batch: 451, D Loss: 0.1014057844878167, G Loss: 29.22947120666504\n",
      "Epoch: 28, Batch: 452, D Loss: 0.10259548574695189, G Loss: 29.42141342163086\n",
      "Epoch: 28, Batch: 453, D Loss: 0.09718520194300313, G Loss: 29.44419288635254\n",
      "Epoch: 28, Batch: 454, D Loss: 0.10122959315784741, G Loss: 29.50104331970215\n",
      "Epoch: 28, Batch: 455, D Loss: 0.10538537800317627, G Loss: 30.112754821777344\n",
      "Epoch: 28, Batch: 456, D Loss: 0.09943434596065569, G Loss: 30.263355255126953\n",
      "Epoch: 28, Batch: 457, D Loss: 0.09908758103851026, G Loss: 30.302959442138672\n",
      "Epoch: 28, Batch: 458, D Loss: 0.09972977638247857, G Loss: 30.432950973510742\n",
      "Epoch: 28, Batch: 459, D Loss: 0.1011461764574359, G Loss: 30.403982162475586\n",
      "Epoch: 28, Batch: 460, D Loss: 0.09322962164882376, G Loss: 30.17101287841797\n",
      "Epoch: 28, Batch: 461, D Loss: 0.09469577670101406, G Loss: 30.117767333984375\n",
      "Epoch: 28, Batch: 462, D Loss: 0.10105963051321461, G Loss: 31.21441078186035\n",
      "Epoch: 28, Batch: 463, D Loss: 0.10017170757056025, G Loss: 32.405338287353516\n",
      "Epoch: 28, Batch: 464, D Loss: 0.09672914445400559, G Loss: 32.92578125\n",
      "Epoch: 28, Batch: 465, D Loss: 0.09312312304974037, G Loss: 31.888856887817383\n",
      "Epoch: 28, Batch: 466, D Loss: 0.10197760909796526, G Loss: 31.740793228149414\n",
      "Epoch: 28, Batch: 467, D Loss: 0.10073216259480225, G Loss: 32.03668975830078\n",
      "Epoch: 29, Batch: 0, D Loss: 0.0995338782668161, G Loss: 32.51982879638672\n",
      "Epoch: 29, Batch: 1, D Loss: 0.09822076559067149, G Loss: 32.522125244140625\n",
      "Epoch: 29, Batch: 2, D Loss: 0.10355244576931354, G Loss: 32.63906478881836\n",
      "Epoch: 29, Batch: 3, D Loss: 0.09892538934946508, G Loss: 32.085330963134766\n",
      "Epoch: 29, Batch: 4, D Loss: 0.10378137230873744, G Loss: 31.915668487548828\n",
      "Epoch: 29, Batch: 5, D Loss: 0.09902408719063586, G Loss: 31.675186157226562\n",
      "Epoch: 29, Batch: 6, D Loss: 0.09362265467645253, G Loss: 30.635881423950195\n",
      "Epoch: 29, Batch: 7, D Loss: 0.10094457119706356, G Loss: 30.23265266418457\n",
      "Epoch: 29, Batch: 8, D Loss: 0.09582471847537732, G Loss: 30.313732147216797\n",
      "Epoch: 29, Batch: 9, D Loss: 0.09177850186829026, G Loss: 29.910785675048828\n",
      "Epoch: 29, Batch: 10, D Loss: 0.09779167175297694, G Loss: 30.06141471862793\n",
      "Epoch: 29, Batch: 11, D Loss: 0.09705565124754197, G Loss: 30.214706420898438\n",
      "Epoch: 29, Batch: 12, D Loss: 0.10213705152276108, G Loss: 30.697179794311523\n",
      "Epoch: 29, Batch: 13, D Loss: 0.09503128379585896, G Loss: 30.53520393371582\n",
      "Epoch: 29, Batch: 14, D Loss: 0.0968704074621586, G Loss: 29.886642456054688\n",
      "Epoch: 29, Batch: 15, D Loss: 0.09522436559207634, G Loss: 29.243852615356445\n",
      "Epoch: 29, Batch: 16, D Loss: 0.09769012779008812, G Loss: 28.989965438842773\n",
      "Epoch: 29, Batch: 17, D Loss: 0.09822560846817316, G Loss: 29.16041374206543\n",
      "Epoch: 29, Batch: 18, D Loss: 0.09425786137591903, G Loss: 29.125850677490234\n",
      "Epoch: 29, Batch: 19, D Loss: 0.10207776725302081, G Loss: 29.366952896118164\n",
      "Epoch: 29, Batch: 20, D Loss: 0.09392687678347149, G Loss: 29.11664581298828\n",
      "Epoch: 29, Batch: 21, D Loss: 0.0949592068792915, G Loss: 28.54886817932129\n",
      "Epoch: 29, Batch: 22, D Loss: 0.1015222519638245, G Loss: 28.46152114868164\n",
      "Epoch: 29, Batch: 23, D Loss: 0.0986554771663715, G Loss: 28.666107177734375\n",
      "Epoch: 29, Batch: 24, D Loss: 0.09614944458024442, G Loss: 28.790971755981445\n",
      "Epoch: 29, Batch: 25, D Loss: 0.09677433222547971, G Loss: 28.788053512573242\n",
      "Epoch: 29, Batch: 26, D Loss: 0.0957552567126059, G Loss: 28.64802360534668\n",
      "Epoch: 29, Batch: 27, D Loss: 0.09492096304913933, G Loss: 28.41531753540039\n",
      "Epoch: 29, Batch: 28, D Loss: 0.09742042422316873, G Loss: 28.463056564331055\n",
      "Epoch: 29, Batch: 29, D Loss: 0.10111743956821805, G Loss: 28.873327255249023\n",
      "Epoch: 29, Batch: 30, D Loss: 0.09993334114563038, G Loss: 29.306108474731445\n",
      "Epoch: 29, Batch: 31, D Loss: 0.10088430345067077, G Loss: 29.460079193115234\n",
      "Epoch: 29, Batch: 32, D Loss: 0.09589535743007938, G Loss: 29.07776641845703\n",
      "Epoch: 29, Batch: 33, D Loss: 0.10322237014783836, G Loss: 28.840890884399414\n",
      "Epoch: 29, Batch: 34, D Loss: 0.09867672622220511, G Loss: 28.627443313598633\n",
      "Epoch: 29, Batch: 35, D Loss: 0.09908268600721214, G Loss: 28.57984733581543\n",
      "Epoch: 29, Batch: 36, D Loss: 0.10555577278151101, G Loss: 29.20936393737793\n",
      "Epoch: 29, Batch: 37, D Loss: 0.09571957588205957, G Loss: 29.23915672302246\n",
      "Epoch: 29, Batch: 38, D Loss: 0.09563638269914036, G Loss: 28.77784538269043\n",
      "Epoch: 29, Batch: 39, D Loss: 0.0979570448400607, G Loss: 28.323335647583008\n",
      "Epoch: 29, Batch: 40, D Loss: 0.0960037633779601, G Loss: 28.019121170043945\n",
      "Epoch: 29, Batch: 41, D Loss: 0.10606676340127978, G Loss: 28.610673904418945\n",
      "Epoch: 29, Batch: 42, D Loss: 0.10385423898709281, G Loss: 29.400005340576172\n",
      "Epoch: 29, Batch: 43, D Loss: 0.09884558618077087, G Loss: 29.430084228515625\n",
      "Epoch: 29, Batch: 44, D Loss: 0.09414935857070626, G Loss: 28.561267852783203\n",
      "Epoch: 29, Batch: 45, D Loss: 0.09869827330143237, G Loss: 27.713420867919922\n",
      "Epoch: 29, Batch: 46, D Loss: 0.09917514026217558, G Loss: 27.46192169189453\n",
      "Epoch: 29, Batch: 47, D Loss: 0.09043999016354619, G Loss: 27.152612686157227\n",
      "Epoch: 29, Batch: 48, D Loss: 0.10769034177113083, G Loss: 28.124605178833008\n",
      "Epoch: 29, Batch: 49, D Loss: 0.09888809919378623, G Loss: 28.80459976196289\n",
      "Epoch: 29, Batch: 50, D Loss: 0.09721834212557531, G Loss: 28.745441436767578\n",
      "Epoch: 29, Batch: 51, D Loss: 0.10515885055083789, G Loss: 28.503326416015625\n",
      "Epoch: 29, Batch: 52, D Loss: 0.10137980431344845, G Loss: 28.047189712524414\n",
      "Epoch: 29, Batch: 53, D Loss: 0.10238145291843642, G Loss: 27.75897979736328\n",
      "Epoch: 29, Batch: 54, D Loss: 0.10035762190865914, G Loss: 27.628156661987305\n",
      "Epoch: 29, Batch: 55, D Loss: 0.10149253159807277, G Loss: 27.79828453063965\n",
      "Epoch: 29, Batch: 56, D Loss: 0.09365455806302637, G Loss: 27.58595848083496\n",
      "Epoch: 29, Batch: 57, D Loss: 0.09920744597962948, G Loss: 27.629764556884766\n",
      "Epoch: 29, Batch: 58, D Loss: 0.09681959450294159, G Loss: 27.660676956176758\n",
      "Epoch: 29, Batch: 59, D Loss: 0.09679013490725834, G Loss: 27.64441680908203\n",
      "Epoch: 29, Batch: 60, D Loss: 0.10355200618545235, G Loss: 28.054258346557617\n",
      "Epoch: 29, Batch: 61, D Loss: 0.09950493276147294, G Loss: 28.347505569458008\n",
      "Epoch: 29, Batch: 62, D Loss: 0.09991392493272025, G Loss: 28.377609252929688\n",
      "Epoch: 29, Batch: 63, D Loss: 0.09888646006611541, G Loss: 28.10342788696289\n",
      "Epoch: 29, Batch: 64, D Loss: 0.10517294704944619, G Loss: 28.143415451049805\n",
      "Epoch: 29, Batch: 65, D Loss: 0.09189043939152722, G Loss: 27.636104583740234\n",
      "Epoch: 29, Batch: 66, D Loss: 0.10069993138362308, G Loss: 27.66421127319336\n",
      "Epoch: 29, Batch: 67, D Loss: 0.0943547189240661, G Loss: 27.610763549804688\n",
      "Epoch: 29, Batch: 68, D Loss: 0.09868198633229733, G Loss: 28.285688400268555\n",
      "Epoch: 29, Batch: 69, D Loss: 0.10153506696240436, G Loss: 29.17969512939453\n",
      "Epoch: 29, Batch: 70, D Loss: 0.10426519066101964, G Loss: 30.080303192138672\n",
      "Epoch: 29, Batch: 71, D Loss: 0.0992252454162027, G Loss: 30.307689666748047\n",
      "Epoch: 29, Batch: 72, D Loss: 0.09899856150154467, G Loss: 29.941925048828125\n",
      "Epoch: 29, Batch: 73, D Loss: 0.098177120089598, G Loss: 29.36711883544922\n",
      "Epoch: 29, Batch: 74, D Loss: 0.10535767674454341, G Loss: 29.495590209960938\n",
      "Epoch: 29, Batch: 75, D Loss: 0.1066009998322124, G Loss: 30.009780883789062\n",
      "Epoch: 29, Batch: 76, D Loss: 0.10367634892467473, G Loss: 30.391584396362305\n",
      "Epoch: 29, Batch: 77, D Loss: 0.09617958962921248, G Loss: 29.983272552490234\n",
      "Epoch: 29, Batch: 78, D Loss: 0.09649067372091141, G Loss: 29.122356414794922\n",
      "Epoch: 29, Batch: 79, D Loss: 0.0990227088333729, G Loss: 28.509798049926758\n",
      "Epoch: 29, Batch: 80, D Loss: 0.10205256938954206, G Loss: 28.59244728088379\n",
      "Epoch: 29, Batch: 81, D Loss: 0.10297932475819134, G Loss: 29.203617095947266\n",
      "Epoch: 29, Batch: 82, D Loss: 0.10100483149297601, G Loss: 29.81523895263672\n",
      "Epoch: 29, Batch: 83, D Loss: 0.10224106907849263, G Loss: 30.149616241455078\n",
      "Epoch: 29, Batch: 84, D Loss: 0.10237754881386125, G Loss: 30.099336624145508\n",
      "Epoch: 29, Batch: 85, D Loss: 0.09999687969690056, G Loss: 29.617965698242188\n",
      "Epoch: 29, Batch: 86, D Loss: 0.09987668693074832, G Loss: 29.0605525970459\n",
      "Epoch: 29, Batch: 87, D Loss: 0.10037936270250089, G Loss: 28.886219024658203\n",
      "Epoch: 29, Batch: 88, D Loss: 0.09532696008696409, G Loss: 28.898588180541992\n",
      "Epoch: 29, Batch: 89, D Loss: 0.1004734560848394, G Loss: 29.346660614013672\n",
      "Epoch: 29, Batch: 90, D Loss: 0.0982056558132904, G Loss: 29.736539840698242\n",
      "Epoch: 29, Batch: 91, D Loss: 0.09825842827564213, G Loss: 29.86335563659668\n",
      "Epoch: 29, Batch: 92, D Loss: 0.09386514127261424, G Loss: 29.37410545349121\n",
      "Epoch: 29, Batch: 93, D Loss: 0.10239176452170055, G Loss: 29.08745574951172\n",
      "Epoch: 29, Batch: 94, D Loss: 0.10139498114597904, G Loss: 29.027233123779297\n",
      "Epoch: 29, Batch: 95, D Loss: 0.09944345057023268, G Loss: 28.990550994873047\n",
      "Epoch: 29, Batch: 96, D Loss: 0.09961306303752729, G Loss: 28.940593719482422\n",
      "Epoch: 29, Batch: 97, D Loss: 0.10296058654797, G Loss: 29.188907623291016\n",
      "Epoch: 29, Batch: 98, D Loss: 0.09764372557413019, G Loss: 29.044130325317383\n",
      "Epoch: 29, Batch: 99, D Loss: 0.09784968197359908, G Loss: 28.753976821899414\n",
      "Epoch: 29, Batch: 100, D Loss: 0.09416885674020621, G Loss: 28.282878875732422\n",
      "Epoch: 29, Batch: 101, D Loss: 0.0985968708994829, G Loss: 28.128889083862305\n",
      "Epoch: 29, Batch: 102, D Loss: 0.10527454316638186, G Loss: 28.73053550720215\n",
      "Epoch: 29, Batch: 103, D Loss: 0.098906785249837, G Loss: 29.246129989624023\n",
      "Epoch: 29, Batch: 104, D Loss: 0.10001298040160704, G Loss: 29.412837982177734\n",
      "Epoch: 29, Batch: 105, D Loss: 0.09427911043178097, G Loss: 28.906299591064453\n",
      "Epoch: 29, Batch: 106, D Loss: 0.09692350029964632, G Loss: 28.29490089416504\n",
      "Epoch: 29, Batch: 107, D Loss: 0.09765564650325956, G Loss: 28.081554412841797\n",
      "Epoch: 29, Batch: 108, D Loss: 0.09810473024873413, G Loss: 28.307083129882812\n",
      "Epoch: 29, Batch: 109, D Loss: 0.10176008939760928, G Loss: 28.97490692138672\n",
      "Epoch: 29, Batch: 110, D Loss: 0.09919332712898998, G Loss: 29.426454544067383\n",
      "Epoch: 29, Batch: 111, D Loss: 0.10116998106248544, G Loss: 29.6663818359375\n",
      "Epoch: 29, Batch: 112, D Loss: 0.10388149321085577, G Loss: 29.727954864501953\n",
      "Epoch: 29, Batch: 113, D Loss: 0.1022095680237475, G Loss: 29.59510612487793\n",
      "Epoch: 29, Batch: 114, D Loss: 0.09550437331208973, G Loss: 29.052297592163086\n",
      "Epoch: 29, Batch: 115, D Loss: 0.09313236176984616, G Loss: 28.400222778320312\n",
      "Epoch: 29, Batch: 116, D Loss: 0.10724506527203398, G Loss: 28.883563995361328\n",
      "Epoch: 29, Batch: 117, D Loss: 0.1062322035432668, G Loss: 29.968347549438477\n",
      "Epoch: 29, Batch: 118, D Loss: 0.10171251744034719, G Loss: 30.994449615478516\n",
      "Epoch: 29, Batch: 119, D Loss: 0.09987686574460633, G Loss: 31.196147918701172\n",
      "Epoch: 29, Batch: 120, D Loss: 0.10003989934923004, G Loss: 30.803232192993164\n",
      "Epoch: 29, Batch: 121, D Loss: 0.09924078732731613, G Loss: 30.35211753845215\n",
      "Epoch: 29, Batch: 122, D Loss: 0.10524737834933386, G Loss: 30.54937744140625\n",
      "Epoch: 29, Batch: 123, D Loss: 0.09634294360878497, G Loss: 30.763330459594727\n",
      "Epoch: 29, Batch: 124, D Loss: 0.09982817620040829, G Loss: 31.082725524902344\n",
      "Epoch: 29, Batch: 125, D Loss: 0.10372520983220519, G Loss: 31.35519790649414\n",
      "Epoch: 29, Batch: 126, D Loss: 0.1057787612080679, G Loss: 31.621112823486328\n",
      "Epoch: 29, Batch: 127, D Loss: 0.10086502879859054, G Loss: 31.403827667236328\n",
      "Epoch: 29, Batch: 128, D Loss: 0.10508719831706391, G Loss: 31.172555923461914\n",
      "Epoch: 29, Batch: 129, D Loss: 0.09223316609861855, G Loss: 30.219655990600586\n",
      "Epoch: 29, Batch: 130, D Loss: 0.09451860189443607, G Loss: 29.411373138427734\n",
      "Epoch: 29, Batch: 131, D Loss: 0.0960621982813828, G Loss: 29.1910400390625\n",
      "Epoch: 29, Batch: 132, D Loss: 0.09698477387436417, G Loss: 29.67699432373047\n",
      "Epoch: 29, Batch: 133, D Loss: 0.11308002471927028, G Loss: 31.005979537963867\n",
      "Epoch: 29, Batch: 134, D Loss: 0.10108273476363229, G Loss: 32.02406311035156\n",
      "Epoch: 29, Batch: 135, D Loss: 0.09625446796418198, G Loss: 31.184480667114258\n",
      "Epoch: 29, Batch: 136, D Loss: 0.10235574096443996, G Loss: 29.957151412963867\n",
      "Epoch: 29, Batch: 137, D Loss: 0.10629123449332588, G Loss: 29.26521873474121\n",
      "Epoch: 29, Batch: 138, D Loss: 0.10540467500696453, G Loss: 29.25518035888672\n",
      "Epoch: 29, Batch: 139, D Loss: 0.10151626914748124, G Loss: 29.532129287719727\n",
      "Epoch: 29, Batch: 140, D Loss: 0.0979255437851695, G Loss: 29.542804718017578\n",
      "Epoch: 29, Batch: 141, D Loss: 0.09361387044200789, G Loss: 29.079654693603516\n",
      "Epoch: 29, Batch: 142, D Loss: 0.09757733345046501, G Loss: 28.64458656311035\n",
      "Epoch: 29, Batch: 143, D Loss: 0.10512941330687298, G Loss: 28.88503074645996\n",
      "Epoch: 29, Batch: 144, D Loss: 0.09967099130165682, G Loss: 29.2093563079834\n",
      "Epoch: 29, Batch: 145, D Loss: 0.10751873254783441, G Loss: 29.82940673828125\n",
      "Epoch: 29, Batch: 146, D Loss: 0.10091570764785349, G Loss: 29.9154052734375\n",
      "Epoch: 29, Batch: 147, D Loss: 0.10003533214337278, G Loss: 29.42050552368164\n",
      "Epoch: 29, Batch: 148, D Loss: 0.09614609181894153, G Loss: 28.548616409301758\n",
      "Epoch: 29, Batch: 149, D Loss: 0.08695214241780604, G Loss: 27.342554092407227\n",
      "Epoch: 29, Batch: 150, D Loss: 0.09704103320917265, G Loss: 26.99151611328125\n",
      "Epoch: 29, Batch: 151, D Loss: 0.09398439526635996, G Loss: 27.359519958496094\n",
      "Epoch: 29, Batch: 152, D Loss: 0.09726853668730084, G Loss: 28.277862548828125\n",
      "Epoch: 29, Batch: 153, D Loss: 0.10245869308724662, G Loss: 29.38932228088379\n",
      "Epoch: 29, Batch: 154, D Loss: 0.10294295102363811, G Loss: 30.093053817749023\n",
      "Epoch: 29, Batch: 155, D Loss: 0.09601961076264903, G Loss: 29.68238639831543\n",
      "Epoch: 29, Batch: 156, D Loss: 0.10067476332197345, G Loss: 28.899953842163086\n",
      "Epoch: 29, Batch: 157, D Loss: 0.10232640802878522, G Loss: 28.401596069335938\n",
      "Epoch: 29, Batch: 158, D Loss: 0.10041351616404758, G Loss: 28.483766555786133\n",
      "Epoch: 29, Batch: 159, D Loss: 0.0971542820336252, G Loss: 28.78377914428711\n",
      "Epoch: 29, Batch: 160, D Loss: 0.09406840801252789, G Loss: 29.042911529541016\n",
      "Epoch: 29, Batch: 161, D Loss: 0.1048896163702838, G Loss: 29.77867317199707\n",
      "Epoch: 29, Batch: 162, D Loss: 0.10130751132969272, G Loss: 30.411029815673828\n",
      "Epoch: 29, Batch: 163, D Loss: 0.09656554460528669, G Loss: 30.378381729125977\n",
      "Epoch: 29, Batch: 164, D Loss: 0.09801343083385576, G Loss: 29.993276596069336\n",
      "Epoch: 29, Batch: 165, D Loss: 0.10512038320307622, G Loss: 30.014036178588867\n",
      "Epoch: 29, Batch: 166, D Loss: 0.09727015346293247, G Loss: 30.034055709838867\n",
      "Epoch: 29, Batch: 167, D Loss: 0.0950547829270765, G Loss: 30.256975173950195\n",
      "Epoch: 29, Batch: 168, D Loss: 0.10000154376032913, G Loss: 30.64859390258789\n",
      "Epoch: 29, Batch: 169, D Loss: 0.09885483980180686, G Loss: 31.176347732543945\n",
      "Epoch: 29, Batch: 170, D Loss: 0.0958974733948841, G Loss: 31.326126098632812\n",
      "Epoch: 29, Batch: 171, D Loss: 0.10092075914145632, G Loss: 31.530780792236328\n",
      "Epoch: 29, Batch: 172, D Loss: 0.09690628945828487, G Loss: 31.54899787902832\n",
      "Epoch: 29, Batch: 173, D Loss: 0.10640364885330975, G Loss: 32.02251434326172\n",
      "Epoch: 29, Batch: 174, D Loss: 0.10465750098228938, G Loss: 32.493980407714844\n",
      "Epoch: 29, Batch: 175, D Loss: 0.09732000529766507, G Loss: 32.31476974487305\n",
      "Epoch: 29, Batch: 176, D Loss: 0.10119699686766233, G Loss: 31.94472312927246\n",
      "Epoch: 29, Batch: 177, D Loss: 0.08870045840741071, G Loss: 31.448381423950195\n",
      "Epoch: 29, Batch: 178, D Loss: 0.09495801478625489, G Loss: 31.37097930908203\n",
      "Epoch: 29, Batch: 179, D Loss: 0.09860126674176127, G Loss: 31.973798751831055\n",
      "Epoch: 29, Batch: 180, D Loss: 0.10137040913105361, G Loss: 33.14765167236328\n",
      "Epoch: 29, Batch: 181, D Loss: 0.09856637567281816, G Loss: 34.634857177734375\n",
      "Epoch: 29, Batch: 182, D Loss: 0.10328993201255819, G Loss: 36.14093017578125\n",
      "Epoch: 29, Batch: 183, D Loss: 0.1015507876873017, G Loss: 36.92688751220703\n",
      "Epoch: 29, Batch: 184, D Loss: 0.10023453831672674, G Loss: 36.808013916015625\n",
      "Epoch: 29, Batch: 185, D Loss: 0.10035327076911932, G Loss: 36.92556381225586\n",
      "Epoch: 29, Batch: 186, D Loss: 0.09922611713409427, G Loss: 38.00466537475586\n",
      "Epoch: 29, Batch: 187, D Loss: 0.10110102593898773, G Loss: 41.78853988647461\n",
      "Epoch: 29, Batch: 188, D Loss: 0.10261330008506775, G Loss: 50.72715759277344\n",
      "Epoch: 29, Batch: 189, D Loss: 0.09983621537685394, G Loss: 51.16432571411133\n",
      "Epoch: 29, Batch: 190, D Loss: 0.09419865906238556, G Loss: 42.28634262084961\n",
      "Epoch: 29, Batch: 191, D Loss: 0.10162976384162903, G Loss: 36.457393646240234\n",
      "Epoch: 29, Batch: 192, D Loss: 0.10208246111869895, G Loss: 31.874080657958984\n",
      "Epoch: 29, Batch: 193, D Loss: 0.09640707075600036, G Loss: 28.529441833496094\n",
      "Epoch: 29, Batch: 194, D Loss: 0.09465185552944266, G Loss: 25.344482421875\n",
      "Epoch: 29, Batch: 195, D Loss: 0.09665517510992128, G Loss: 22.67196273803711\n",
      "Epoch: 29, Batch: 196, D Loss: 0.09966421146924677, G Loss: 20.75083351135254\n",
      "Epoch: 29, Batch: 197, D Loss: 0.10392044570322123, G Loss: 19.676084518432617\n",
      "Epoch: 29, Batch: 198, D Loss: 0.09225751754140532, G Loss: 18.29707145690918\n",
      "Epoch: 29, Batch: 199, D Loss: 0.09831238843008894, G Loss: 17.13437843322754\n",
      "Epoch: 29, Batch: 200, D Loss: 0.09505871469968596, G Loss: 15.916574478149414\n",
      "Epoch: 29, Batch: 201, D Loss: 0.09736290429489713, G Loss: 15.343141555786133\n",
      "Epoch: 29, Batch: 202, D Loss: 0.09435375749620789, G Loss: 15.101841926574707\n",
      "Epoch: 29, Batch: 203, D Loss: 0.10219635268375526, G Loss: 15.717288970947266\n",
      "Epoch: 29, Batch: 204, D Loss: 0.09826453515706746, G Loss: 16.54912567138672\n",
      "Epoch: 29, Batch: 205, D Loss: 0.09724194211042914, G Loss: 16.9761905670166\n",
      "Epoch: 29, Batch: 206, D Loss: 0.09689497009504677, G Loss: 17.069564819335938\n",
      "Epoch: 29, Batch: 207, D Loss: 0.09918822606714706, G Loss: 17.277179718017578\n",
      "Epoch: 29, Batch: 208, D Loss: 0.09314094625557523, G Loss: 17.220182418823242\n",
      "Epoch: 29, Batch: 209, D Loss: 0.09537344884737742, G Loss: 16.937667846679688\n",
      "Epoch: 29, Batch: 210, D Loss: 0.0980937235240269, G Loss: 17.131006240844727\n",
      "Epoch: 29, Batch: 211, D Loss: 0.09997059967014277, G Loss: 17.769245147705078\n",
      "Epoch: 29, Batch: 212, D Loss: 0.09930177018692188, G Loss: 18.29339599609375\n",
      "Epoch: 29, Batch: 213, D Loss: 0.10115022719393396, G Loss: 18.513671875\n",
      "Epoch: 29, Batch: 214, D Loss: 0.09771179191585588, G Loss: 18.236034393310547\n",
      "Epoch: 29, Batch: 215, D Loss: 0.09703071463294144, G Loss: 17.718820571899414\n",
      "Epoch: 29, Batch: 216, D Loss: 0.09853796503384782, G Loss: 17.204437255859375\n",
      "Epoch: 29, Batch: 217, D Loss: 0.09582829934949011, G Loss: 16.951580047607422\n",
      "Epoch: 29, Batch: 218, D Loss: 0.10481186490896555, G Loss: 17.360517501831055\n",
      "Epoch: 29, Batch: 219, D Loss: 0.09628169680318788, G Loss: 17.745569229125977\n",
      "Epoch: 29, Batch: 220, D Loss: 0.10151323009652646, G Loss: 18.08907127380371\n",
      "Epoch: 29, Batch: 221, D Loss: 0.0932877438074673, G Loss: 17.924402236938477\n",
      "Epoch: 29, Batch: 222, D Loss: 0.10021930328881012, G Loss: 17.790132522583008\n",
      "Epoch: 29, Batch: 223, D Loss: 0.09767396241607518, G Loss: 17.713638305664062\n",
      "Epoch: 29, Batch: 224, D Loss: 0.09909214967593272, G Loss: 17.975435256958008\n",
      "Epoch: 29, Batch: 225, D Loss: 0.09560521620467943, G Loss: 18.263200759887695\n",
      "Epoch: 29, Batch: 226, D Loss: 0.10563866443815728, G Loss: 19.014678955078125\n",
      "Epoch: 29, Batch: 227, D Loss: 0.10108798952970721, G Loss: 19.530303955078125\n",
      "Epoch: 29, Batch: 228, D Loss: 0.09674603663078918, G Loss: 19.461841583251953\n",
      "Epoch: 29, Batch: 229, D Loss: 0.09813619616943248, G Loss: 19.11623191833496\n",
      "Epoch: 29, Batch: 230, D Loss: 0.10018263302717667, G Loss: 18.8288516998291\n",
      "Epoch: 29, Batch: 231, D Loss: 0.0973816772951619, G Loss: 18.71237564086914\n",
      "Epoch: 29, Batch: 232, D Loss: 0.09269173806750164, G Loss: 18.768474578857422\n",
      "Epoch: 29, Batch: 233, D Loss: 0.1009890611227322, G Loss: 19.420019149780273\n",
      "Epoch: 29, Batch: 234, D Loss: 0.10068020347565787, G Loss: 20.18657112121582\n",
      "Epoch: 29, Batch: 235, D Loss: 0.09962823306899404, G Loss: 20.70977210998535\n",
      "Epoch: 29, Batch: 236, D Loss: 0.09540110139159746, G Loss: 20.462682723999023\n",
      "Epoch: 29, Batch: 237, D Loss: 0.10644595390923256, G Loss: 20.433029174804688\n",
      "Epoch: 29, Batch: 238, D Loss: 0.09368170879708937, G Loss: 20.04738426208496\n",
      "Epoch: 29, Batch: 239, D Loss: 0.10302207708575978, G Loss: 20.223796844482422\n",
      "Epoch: 29, Batch: 240, D Loss: 0.09285941804999376, G Loss: 20.16570281982422\n",
      "Epoch: 29, Batch: 241, D Loss: 0.09649576329379722, G Loss: 20.271352767944336\n",
      "Epoch: 29, Batch: 242, D Loss: 0.10247566607619135, G Loss: 20.892879486083984\n",
      "Epoch: 29, Batch: 243, D Loss: 0.09837307815059612, G Loss: 21.299192428588867\n",
      "Epoch: 29, Batch: 244, D Loss: 0.09417359563097202, G Loss: 21.04294776916504\n",
      "Epoch: 29, Batch: 245, D Loss: 0.09762702180731994, G Loss: 20.70029640197754\n",
      "Epoch: 29, Batch: 246, D Loss: 0.09505352437060621, G Loss: 20.424312591552734\n",
      "Epoch: 29, Batch: 247, D Loss: 0.09563440151520358, G Loss: 20.435192108154297\n",
      "Epoch: 29, Batch: 248, D Loss: 0.09396803440777707, G Loss: 20.583267211914062\n",
      "Epoch: 29, Batch: 249, D Loss: 0.10297381915802356, G Loss: 21.37507438659668\n",
      "Epoch: 29, Batch: 250, D Loss: 0.09976157564306956, G Loss: 22.049428939819336\n",
      "Epoch: 29, Batch: 251, D Loss: 0.09760716569915319, G Loss: 22.177146911621094\n",
      "Epoch: 29, Batch: 252, D Loss: 0.09712311639344631, G Loss: 21.851797103881836\n",
      "Epoch: 29, Batch: 253, D Loss: 0.09608218096740054, G Loss: 21.191049575805664\n",
      "Epoch: 29, Batch: 254, D Loss: 0.09587226851243816, G Loss: 20.580820083618164\n",
      "Epoch: 29, Batch: 255, D Loss: 0.10111677705186572, G Loss: 20.552156448364258\n",
      "Epoch: 29, Batch: 256, D Loss: 0.0991212507060617, G Loss: 20.900798797607422\n",
      "Epoch: 29, Batch: 257, D Loss: 0.10242770644440266, G Loss: 21.398975372314453\n",
      "Epoch: 29, Batch: 258, D Loss: 0.09948597870819006, G Loss: 21.64048957824707\n",
      "Epoch: 29, Batch: 259, D Loss: 0.10249002298566334, G Loss: 21.572160720825195\n",
      "Epoch: 29, Batch: 260, D Loss: 0.1007947626257942, G Loss: 21.254690170288086\n",
      "Epoch: 29, Batch: 261, D Loss: 0.09822317251238041, G Loss: 20.744977951049805\n",
      "Epoch: 29, Batch: 262, D Loss: 0.09970744014168581, G Loss: 20.357906341552734\n",
      "Epoch: 29, Batch: 263, D Loss: 0.10008268129828962, G Loss: 20.372610092163086\n",
      "Epoch: 29, Batch: 264, D Loss: 0.09980654028965685, G Loss: 20.77265739440918\n",
      "Epoch: 29, Batch: 265, D Loss: 0.10041007436061711, G Loss: 21.276636123657227\n",
      "Epoch: 29, Batch: 266, D Loss: 0.09847755755572979, G Loss: 21.510726928710938\n",
      "Epoch: 29, Batch: 267, D Loss: 0.0999494122912809, G Loss: 21.382444381713867\n",
      "Epoch: 29, Batch: 268, D Loss: 0.10382287231541096, G Loss: 21.281753540039062\n",
      "Epoch: 29, Batch: 269, D Loss: 0.10559108134074019, G Loss: 21.478670120239258\n",
      "Epoch: 29, Batch: 270, D Loss: 0.09972238564606781, G Loss: 21.441638946533203\n",
      "Epoch: 29, Batch: 271, D Loss: 0.1043558123079534, G Loss: 21.5098934173584\n",
      "Epoch: 29, Batch: 272, D Loss: 0.09969380521054551, G Loss: 21.480907440185547\n",
      "Epoch: 29, Batch: 273, D Loss: 0.09474708171503052, G Loss: 20.912620544433594\n",
      "Epoch: 29, Batch: 274, D Loss: 0.09672447349062269, G Loss: 20.369613647460938\n",
      "Epoch: 29, Batch: 275, D Loss: 0.10125853193721002, G Loss: 20.337968826293945\n",
      "Epoch: 29, Batch: 276, D Loss: 0.10057514966118186, G Loss: 20.718021392822266\n",
      "Epoch: 29, Batch: 277, D Loss: 0.08957055269247549, G Loss: 20.440582275390625\n",
      "Epoch: 29, Batch: 278, D Loss: 0.1027333519310038, G Loss: 20.502548217773438\n",
      "Epoch: 29, Batch: 279, D Loss: 0.09825336250917172, G Loss: 20.48838233947754\n",
      "Epoch: 29, Batch: 280, D Loss: 0.09859820520654333, G Loss: 20.426982879638672\n",
      "Epoch: 29, Batch: 281, D Loss: 0.09734231309619096, G Loss: 20.194637298583984\n",
      "Epoch: 29, Batch: 282, D Loss: 0.09880581590812076, G Loss: 20.027799606323242\n",
      "Epoch: 29, Batch: 283, D Loss: 0.09926274520169331, G Loss: 20.008155822753906\n",
      "Epoch: 29, Batch: 284, D Loss: 0.09632731333880917, G Loss: 19.96182632446289\n",
      "Epoch: 29, Batch: 285, D Loss: 0.09826616303677427, G Loss: 19.984825134277344\n",
      "Epoch: 29, Batch: 286, D Loss: 0.09944950885351034, G Loss: 20.14690589904785\n",
      "Epoch: 29, Batch: 287, D Loss: 0.10096928558094764, G Loss: 20.33082389831543\n",
      "Epoch: 29, Batch: 288, D Loss: 0.09609161400053312, G Loss: 20.12120819091797\n",
      "Epoch: 29, Batch: 289, D Loss: 0.0964574377548797, G Loss: 19.813308715820312\n",
      "Epoch: 29, Batch: 290, D Loss: 0.09656614204623815, G Loss: 19.59488868713379\n",
      "Epoch: 29, Batch: 291, D Loss: 0.09903808830229999, G Loss: 19.69068717956543\n",
      "Epoch: 29, Batch: 292, D Loss: 0.09523091602601441, G Loss: 19.73412322998047\n",
      "Epoch: 29, Batch: 293, D Loss: 0.09816654154443671, G Loss: 19.829980850219727\n",
      "Epoch: 29, Batch: 294, D Loss: 0.10105086222903936, G Loss: 20.119956970214844\n",
      "Epoch: 29, Batch: 295, D Loss: 0.09986390253780852, G Loss: 20.36585807800293\n",
      "Epoch: 29, Batch: 296, D Loss: 0.10207760397264903, G Loss: 20.59903907775879\n",
      "Epoch: 29, Batch: 297, D Loss: 0.09756806555525588, G Loss: 20.40494728088379\n",
      "Epoch: 29, Batch: 298, D Loss: 0.09254695571892668, G Loss: 19.754302978515625\n",
      "Epoch: 29, Batch: 299, D Loss: 0.10108016582906931, G Loss: 19.48978614807129\n",
      "Epoch: 29, Batch: 300, D Loss: 0.10166341959382375, G Loss: 19.773555755615234\n",
      "Epoch: 29, Batch: 301, D Loss: 0.10074877838672813, G Loss: 20.266748428344727\n",
      "Epoch: 29, Batch: 302, D Loss: 0.10053417153361621, G Loss: 20.585256576538086\n",
      "Epoch: 29, Batch: 303, D Loss: 0.09769869666078956, G Loss: 20.200422286987305\n",
      "Epoch: 29, Batch: 304, D Loss: 0.10144545244123937, G Loss: 19.762773513793945\n",
      "Epoch: 29, Batch: 305, D Loss: 0.09442661894881565, G Loss: 19.029916763305664\n",
      "Epoch: 29, Batch: 306, D Loss: 0.10009427678046245, G Loss: 18.78428077697754\n",
      "Epoch: 29, Batch: 307, D Loss: 0.10061499788038897, G Loss: 18.995643615722656\n",
      "Epoch: 29, Batch: 308, D Loss: 0.09778712185733984, G Loss: 19.29324722290039\n",
      "Epoch: 29, Batch: 309, D Loss: 0.10187555268670467, G Loss: 19.753002166748047\n",
      "Epoch: 29, Batch: 310, D Loss: 0.0972988991452951, G Loss: 19.72165870666504\n",
      "Epoch: 29, Batch: 311, D Loss: 0.10526712371478453, G Loss: 19.771963119506836\n",
      "Epoch: 29, Batch: 312, D Loss: 0.09985503691455377, G Loss: 19.664369583129883\n",
      "Epoch: 29, Batch: 313, D Loss: 0.10468151557747196, G Loss: 19.757492065429688\n",
      "Epoch: 29, Batch: 314, D Loss: 0.10223938651139197, G Loss: 19.83011245727539\n",
      "Epoch: 29, Batch: 315, D Loss: 0.10305288547530334, G Loss: 19.97091293334961\n",
      "Epoch: 29, Batch: 316, D Loss: 0.09782021613115777, G Loss: 19.73200225830078\n",
      "Epoch: 29, Batch: 317, D Loss: 0.09553184522593483, G Loss: 19.379362106323242\n",
      "Epoch: 29, Batch: 318, D Loss: 0.09835230764352842, G Loss: 19.252126693725586\n",
      "Epoch: 29, Batch: 319, D Loss: 0.10033200876595605, G Loss: 19.460073471069336\n",
      "Epoch: 29, Batch: 320, D Loss: 0.10061765607490858, G Loss: 19.83418846130371\n",
      "Epoch: 29, Batch: 321, D Loss: 0.09741523230400828, G Loss: 19.965984344482422\n",
      "Epoch: 29, Batch: 322, D Loss: 0.09798107410935364, G Loss: 19.828609466552734\n",
      "Epoch: 29, Batch: 323, D Loss: 0.09759272776343875, G Loss: 19.555410385131836\n",
      "Epoch: 29, Batch: 324, D Loss: 0.09714628206264742, G Loss: 19.187856674194336\n",
      "Epoch: 29, Batch: 325, D Loss: 0.100184822863296, G Loss: 19.23273468017578\n",
      "Epoch: 29, Batch: 326, D Loss: 0.10264486247135551, G Loss: 19.711505889892578\n",
      "Epoch: 29, Batch: 327, D Loss: 0.102282763559573, G Loss: 20.257518768310547\n",
      "Epoch: 29, Batch: 328, D Loss: 0.10137020869212576, G Loss: 20.432697296142578\n",
      "Epoch: 29, Batch: 329, D Loss: 0.10021038428197804, G Loss: 20.221332550048828\n",
      "Epoch: 29, Batch: 330, D Loss: 0.09377533324717557, G Loss: 19.398670196533203\n",
      "Epoch: 29, Batch: 331, D Loss: 0.10390199940660771, G Loss: 19.10457992553711\n",
      "Epoch: 29, Batch: 332, D Loss: 0.10154114902496181, G Loss: 19.211458206176758\n",
      "Epoch: 29, Batch: 333, D Loss: 0.09250134465332516, G Loss: 19.141143798828125\n",
      "Epoch: 29, Batch: 334, D Loss: 0.09424360351977668, G Loss: 19.05099105834961\n",
      "Epoch: 29, Batch: 335, D Loss: 0.10602948268504941, G Loss: 19.606225967407227\n",
      "Epoch: 29, Batch: 336, D Loss: 0.09997805331120302, G Loss: 20.01710319519043\n",
      "Epoch: 29, Batch: 337, D Loss: 0.09670724086364102, G Loss: 19.833654403686523\n",
      "Epoch: 29, Batch: 338, D Loss: 0.10143441104386386, G Loss: 19.53487777709961\n",
      "Epoch: 29, Batch: 339, D Loss: 0.10245873210545264, G Loss: 19.398080825805664\n",
      "Epoch: 29, Batch: 340, D Loss: 0.09870573335064714, G Loss: 19.267141342163086\n",
      "Epoch: 29, Batch: 341, D Loss: 0.10055416281294427, G Loss: 19.36560821533203\n",
      "Epoch: 29, Batch: 342, D Loss: 0.09922718439918099, G Loss: 19.480199813842773\n",
      "Epoch: 29, Batch: 343, D Loss: 0.09778116810343007, G Loss: 19.553834915161133\n",
      "Epoch: 29, Batch: 344, D Loss: 0.10093777030630957, G Loss: 19.703866958618164\n",
      "Epoch: 29, Batch: 345, D Loss: 0.09766288239692167, G Loss: 19.71331787109375\n",
      "Epoch: 29, Batch: 346, D Loss: 0.09587384163757351, G Loss: 19.56658363342285\n",
      "Epoch: 29, Batch: 347, D Loss: 0.09005648113053288, G Loss: 18.991539001464844\n",
      "Epoch: 29, Batch: 348, D Loss: 0.09409456288659146, G Loss: 18.679271697998047\n",
      "Epoch: 29, Batch: 349, D Loss: 0.09385566775205811, G Loss: 18.80735969543457\n",
      "Epoch: 29, Batch: 350, D Loss: 0.10045111396980055, G Loss: 19.65419578552246\n",
      "Epoch: 29, Batch: 351, D Loss: 0.10499461074152588, G Loss: 20.814939498901367\n",
      "Epoch: 29, Batch: 352, D Loss: 0.0928327147463496, G Loss: 20.940641403198242\n",
      "Epoch: 29, Batch: 353, D Loss: 0.09814528428312735, G Loss: 20.4366455078125\n",
      "Epoch: 29, Batch: 354, D Loss: 0.09686781566606761, G Loss: 19.65233039855957\n",
      "Epoch: 29, Batch: 355, D Loss: 0.10122998228844526, G Loss: 19.363283157348633\n",
      "Epoch: 29, Batch: 356, D Loss: 0.10093086385182681, G Loss: 19.598676681518555\n",
      "Epoch: 29, Batch: 357, D Loss: 0.10052495570547826, G Loss: 20.060863494873047\n",
      "Epoch: 29, Batch: 358, D Loss: 0.1007808231063056, G Loss: 20.50045394897461\n",
      "Epoch: 29, Batch: 359, D Loss: 0.09887277400750072, G Loss: 20.40229034423828\n",
      "Epoch: 29, Batch: 360, D Loss: 0.09430787071675995, G Loss: 19.613611221313477\n",
      "Epoch: 29, Batch: 361, D Loss: 0.09287859751757499, G Loss: 18.6478214263916\n",
      "Epoch: 29, Batch: 362, D Loss: 0.09939396851480753, G Loss: 18.340417861938477\n",
      "Epoch: 29, Batch: 363, D Loss: 0.10329577749953467, G Loss: 18.81517791748047\n",
      "Epoch: 29, Batch: 364, D Loss: 0.09574030622692642, G Loss: 19.15038299560547\n",
      "Epoch: 29, Batch: 365, D Loss: 0.09918098372320494, G Loss: 19.32099723815918\n",
      "Epoch: 29, Batch: 366, D Loss: 0.10391335376243682, G Loss: 19.48235511779785\n",
      "Epoch: 29, Batch: 367, D Loss: 0.10019780891635555, G Loss: 19.24507713317871\n",
      "Epoch: 29, Batch: 368, D Loss: 0.0974270433838571, G Loss: 18.623851776123047\n",
      "Epoch: 29, Batch: 369, D Loss: 0.093038908253817, G Loss: 17.7286319732666\n",
      "Epoch: 29, Batch: 370, D Loss: 0.09826079440569657, G Loss: 17.435836791992188\n",
      "Epoch: 29, Batch: 371, D Loss: 0.0984710344431754, G Loss: 17.772401809692383\n",
      "Epoch: 29, Batch: 372, D Loss: 0.10330945107994749, G Loss: 18.666269302368164\n",
      "Epoch: 29, Batch: 373, D Loss: 0.09615803070009243, G Loss: 19.14167594909668\n",
      "Epoch: 29, Batch: 374, D Loss: 0.09884684772142682, G Loss: 19.17531394958496\n",
      "Epoch: 29, Batch: 375, D Loss: 0.09722988603690164, G Loss: 18.739458084106445\n",
      "Epoch: 29, Batch: 376, D Loss: 0.0942787730352066, G Loss: 18.018291473388672\n",
      "Epoch: 29, Batch: 377, D Loss: 0.09963352350405952, G Loss: 17.758453369140625\n",
      "Epoch: 29, Batch: 378, D Loss: 0.10466290987334803, G Loss: 18.327102661132812\n",
      "Epoch: 29, Batch: 379, D Loss: 0.10145030537275379, G Loss: 19.100482940673828\n",
      "Epoch: 29, Batch: 380, D Loss: 0.10480530731861115, G Loss: 19.839271545410156\n",
      "Epoch: 29, Batch: 381, D Loss: 0.10317713127279482, G Loss: 20.10980796813965\n",
      "Epoch: 29, Batch: 382, D Loss: 0.10227522363183883, G Loss: 19.792179107666016\n",
      "Epoch: 29, Batch: 383, D Loss: 0.09860650636919144, G Loss: 19.058700561523438\n",
      "Epoch: 29, Batch: 384, D Loss: 0.09349631941810799, G Loss: 18.163898468017578\n",
      "Epoch: 29, Batch: 385, D Loss: 0.10274734236666294, G Loss: 18.21024513244629\n",
      "Epoch: 29, Batch: 386, D Loss: 0.10462005819897735, G Loss: 19.11744499206543\n",
      "Epoch: 29, Batch: 387, D Loss: 0.09386466617550793, G Loss: 19.803375244140625\n",
      "Epoch: 29, Batch: 388, D Loss: 0.10101171678398291, G Loss: 20.323537826538086\n",
      "Epoch: 29, Batch: 389, D Loss: 0.09858437699911965, G Loss: 20.381759643554688\n",
      "Epoch: 29, Batch: 390, D Loss: 0.09624673518222343, G Loss: 19.870908737182617\n",
      "Epoch: 29, Batch: 391, D Loss: 0.09875004138192556, G Loss: 19.473217010498047\n",
      "Epoch: 29, Batch: 392, D Loss: 0.09772432776262918, G Loss: 19.408802032470703\n",
      "Epoch: 29, Batch: 393, D Loss: 0.10008237672636666, G Loss: 19.677980422973633\n",
      "Epoch: 29, Batch: 394, D Loss: 0.09413126983225129, G Loss: 19.892858505249023\n",
      "Epoch: 29, Batch: 395, D Loss: 0.09632474277364778, G Loss: 20.286123275756836\n",
      "Epoch: 29, Batch: 396, D Loss: 0.09557657012487264, G Loss: 20.514272689819336\n",
      "Epoch: 29, Batch: 397, D Loss: 0.09911384487734454, G Loss: 20.757999420166016\n",
      "Epoch: 29, Batch: 398, D Loss: 0.09360608511812335, G Loss: 20.571449279785156\n",
      "Epoch: 29, Batch: 399, D Loss: 0.1009687339425745, G Loss: 20.81312370300293\n",
      "Epoch: 29, Batch: 400, D Loss: 0.09827613869042695, G Loss: 21.140653610229492\n",
      "Epoch: 29, Batch: 401, D Loss: 0.09571822017597731, G Loss: 21.32063865661621\n",
      "Epoch: 29, Batch: 402, D Loss: 0.0996446462858524, G Loss: 21.602035522460938\n",
      "Epoch: 29, Batch: 403, D Loss: 0.0962869526950834, G Loss: 21.678279876708984\n",
      "Epoch: 29, Batch: 404, D Loss: 0.09543930761241312, G Loss: 21.417098999023438\n",
      "Epoch: 29, Batch: 405, D Loss: 0.09467712818650278, G Loss: 21.142093658447266\n",
      "Epoch: 29, Batch: 406, D Loss: 0.09419883818541538, G Loss: 21.260520935058594\n",
      "Epoch: 29, Batch: 407, D Loss: 0.10187955221320003, G Loss: 21.91996192932129\n",
      "Epoch: 29, Batch: 408, D Loss: 0.10585591950654222, G Loss: 22.992765426635742\n",
      "Epoch: 29, Batch: 409, D Loss: 0.09745420519094114, G Loss: 23.702754974365234\n",
      "Epoch: 29, Batch: 410, D Loss: 0.09796552362734354, G Loss: 23.603702545166016\n",
      "Epoch: 29, Batch: 411, D Loss: 0.09928521516974187, G Loss: 23.453332901000977\n",
      "Epoch: 29, Batch: 412, D Loss: 0.09651805464586678, G Loss: 23.001750946044922\n",
      "Epoch: 29, Batch: 413, D Loss: 0.1074782833882837, G Loss: 23.352310180664062\n",
      "Epoch: 29, Batch: 414, D Loss: 0.10084412995037519, G Loss: 23.67863655090332\n",
      "Epoch: 29, Batch: 415, D Loss: 0.09754502031482651, G Loss: 23.253406524658203\n",
      "Epoch: 29, Batch: 416, D Loss: 0.10538677875268404, G Loss: 23.225479125976562\n",
      "Epoch: 29, Batch: 417, D Loss: 0.09763932978949676, G Loss: 22.562829971313477\n",
      "Epoch: 29, Batch: 418, D Loss: 0.09773926447919207, G Loss: 21.94062042236328\n",
      "Epoch: 29, Batch: 419, D Loss: 0.09646078965930441, G Loss: 21.210895538330078\n",
      "Epoch: 29, Batch: 420, D Loss: 0.10090559004739588, G Loss: 21.332719802856445\n",
      "Epoch: 29, Batch: 421, D Loss: 0.09962964824912628, G Loss: 21.740478515625\n",
      "Epoch: 29, Batch: 422, D Loss: 0.09897393002425513, G Loss: 22.196456909179688\n",
      "Epoch: 29, Batch: 423, D Loss: 0.09836349646621473, G Loss: 22.398351669311523\n",
      "Epoch: 29, Batch: 424, D Loss: 0.09300313899696482, G Loss: 22.32805061340332\n",
      "Epoch: 29, Batch: 425, D Loss: 0.10259871937696627, G Loss: 22.806203842163086\n",
      "Epoch: 29, Batch: 426, D Loss: 0.101818144378562, G Loss: 22.970638275146484\n",
      "Epoch: 29, Batch: 427, D Loss: 0.09611961251312645, G Loss: 22.801536560058594\n",
      "Epoch: 29, Batch: 428, D Loss: 0.10673086351393489, G Loss: 22.819406509399414\n",
      "Epoch: 29, Batch: 429, D Loss: 0.10036870844145036, G Loss: 22.590490341186523\n",
      "Epoch: 29, Batch: 430, D Loss: 0.10377718517177881, G Loss: 22.31487464904785\n",
      "Epoch: 29, Batch: 431, D Loss: 0.09460803883686814, G Loss: 21.306318283081055\n",
      "Epoch: 29, Batch: 432, D Loss: 0.099447705274476, G Loss: 20.51673698425293\n",
      "Epoch: 29, Batch: 433, D Loss: 0.09837979166498922, G Loss: 19.83280372619629\n",
      "Epoch: 29, Batch: 434, D Loss: 0.09544785482272466, G Loss: 19.2989501953125\n",
      "Epoch: 29, Batch: 435, D Loss: 0.10176034480184204, G Loss: 19.294864654541016\n",
      "Epoch: 29, Batch: 436, D Loss: 0.09562234792912405, G Loss: 19.26360321044922\n",
      "Epoch: 29, Batch: 437, D Loss: 0.10419286975447783, G Loss: 19.523391723632812\n",
      "Epoch: 29, Batch: 438, D Loss: 0.09905338462718061, G Loss: 19.421449661254883\n",
      "Epoch: 29, Batch: 439, D Loss: 0.09751203927461716, G Loss: 18.685251235961914\n",
      "Epoch: 29, Batch: 440, D Loss: 0.10062050611521212, G Loss: 18.053367614746094\n",
      "Epoch: 29, Batch: 441, D Loss: 0.09932641090181793, G Loss: 17.656837463378906\n",
      "Epoch: 29, Batch: 442, D Loss: 0.10850203901932698, G Loss: 18.078611373901367\n",
      "Epoch: 29, Batch: 443, D Loss: 0.10159459564536721, G Loss: 18.393220901489258\n",
      "Epoch: 29, Batch: 444, D Loss: 0.10164306077352014, G Loss: 18.41641616821289\n",
      "Epoch: 29, Batch: 445, D Loss: 0.0994836900360796, G Loss: 17.985687255859375\n",
      "Epoch: 29, Batch: 446, D Loss: 0.1058859762615798, G Loss: 17.782957077026367\n",
      "Epoch: 29, Batch: 447, D Loss: 0.09887872244782869, G Loss: 17.514205932617188\n",
      "Epoch: 29, Batch: 448, D Loss: 0.1031027852702362, G Loss: 17.61499786376953\n",
      "Epoch: 29, Batch: 449, D Loss: 0.10277373559059377, G Loss: 17.9190731048584\n",
      "Epoch: 29, Batch: 450, D Loss: 0.09844738984259704, G Loss: 18.139734268188477\n",
      "Epoch: 29, Batch: 451, D Loss: 0.09810663644802675, G Loss: 18.24301528930664\n",
      "Epoch: 29, Batch: 452, D Loss: 0.09397040251916922, G Loss: 17.97953224182129\n",
      "Epoch: 29, Batch: 453, D Loss: 0.0973490413414746, G Loss: 17.803428649902344\n",
      "Epoch: 29, Batch: 454, D Loss: 0.10853302381445706, G Loss: 18.49275016784668\n",
      "Epoch: 29, Batch: 455, D Loss: 0.10322992831616018, G Loss: 19.16152572631836\n",
      "Epoch: 29, Batch: 456, D Loss: 0.10003814317103998, G Loss: 19.352752685546875\n",
      "Epoch: 29, Batch: 457, D Loss: 0.09558161619097061, G Loss: 18.748170852661133\n",
      "Epoch: 29, Batch: 458, D Loss: 0.09671867427035652, G Loss: 18.01015853881836\n",
      "Epoch: 29, Batch: 459, D Loss: 0.0951408469133268, G Loss: 17.528514862060547\n",
      "Epoch: 29, Batch: 460, D Loss: 0.09767219062294341, G Loss: 17.693979263305664\n",
      "Epoch: 29, Batch: 461, D Loss: 0.0948666862928711, G Loss: 18.15239906311035\n",
      "Epoch: 29, Batch: 462, D Loss: 0.09556658319204336, G Loss: 18.675416946411133\n",
      "Epoch: 29, Batch: 463, D Loss: 0.10390045021094862, G Loss: 19.35118865966797\n",
      "Epoch: 29, Batch: 464, D Loss: 0.09961323603490879, G Loss: 19.71015167236328\n",
      "Epoch: 29, Batch: 465, D Loss: 0.09854048648267899, G Loss: 19.454174041748047\n",
      "Epoch: 29, Batch: 466, D Loss: 0.1004445576200721, G Loss: 18.937883377075195\n",
      "Epoch: 29, Batch: 467, D Loss: 0.09864338890139157, G Loss: 18.37175178527832\n",
      "Epoch: 30, Batch: 0, D Loss: 0.10482070320792003, G Loss: 18.585847854614258\n",
      "Epoch: 30, Batch: 1, D Loss: 0.0969744883128556, G Loss: 18.854415893554688\n",
      "Epoch: 30, Batch: 2, D Loss: 0.09792074847359045, G Loss: 19.094390869140625\n",
      "Epoch: 30, Batch: 3, D Loss: 0.0981632792737046, G Loss: 19.242008209228516\n",
      "Epoch: 30, Batch: 4, D Loss: 0.10174131591620927, G Loss: 19.44268226623535\n",
      "Epoch: 30, Batch: 5, D Loss: 0.10218172679295612, G Loss: 19.68130111694336\n",
      "Epoch: 30, Batch: 6, D Loss: 0.0979855298393405, G Loss: 19.666770935058594\n",
      "Epoch: 30, Batch: 7, D Loss: 0.09821020971232797, G Loss: 19.472986221313477\n",
      "Epoch: 30, Batch: 8, D Loss: 0.10414074522732941, G Loss: 19.62433433532715\n",
      "Epoch: 30, Batch: 9, D Loss: 0.09712726030234586, G Loss: 19.596126556396484\n",
      "Epoch: 30, Batch: 10, D Loss: 0.10223687586055652, G Loss: 19.705177307128906\n",
      "Epoch: 30, Batch: 11, D Loss: 0.1005321829037632, G Loss: 19.764562606811523\n",
      "Epoch: 30, Batch: 12, D Loss: 0.09760102770897316, G Loss: 19.61520004272461\n",
      "Epoch: 30, Batch: 13, D Loss: 0.10219861720349399, G Loss: 19.59377670288086\n",
      "Epoch: 30, Batch: 14, D Loss: 0.10042436579470726, G Loss: 19.549480438232422\n",
      "Epoch: 30, Batch: 15, D Loss: 0.10144621295278233, G Loss: 19.554698944091797\n",
      "Epoch: 30, Batch: 16, D Loss: 0.09507357519229709, G Loss: 19.24003791809082\n",
      "Epoch: 30, Batch: 17, D Loss: 0.09896681694588039, G Loss: 19.106721878051758\n",
      "Epoch: 30, Batch: 18, D Loss: 0.10545408942691226, G Loss: 19.394182205200195\n",
      "Epoch: 30, Batch: 19, D Loss: 0.10718161749929622, G Loss: 20.002933502197266\n",
      "Epoch: 30, Batch: 20, D Loss: 0.09719741445216579, G Loss: 20.04159164428711\n",
      "Epoch: 30, Batch: 21, D Loss: 0.0982328069411621, G Loss: 19.65535545349121\n",
      "Epoch: 30, Batch: 22, D Loss: 0.09830950396644123, G Loss: 19.092100143432617\n",
      "Epoch: 30, Batch: 23, D Loss: 0.10465459800176169, G Loss: 18.959184646606445\n",
      "Epoch: 30, Batch: 24, D Loss: 0.10201950629350676, G Loss: 19.196186065673828\n",
      "Epoch: 30, Batch: 25, D Loss: 0.10116990854731278, G Loss: 19.475263595581055\n",
      "Epoch: 30, Batch: 26, D Loss: 0.09685242366259894, G Loss: 19.310779571533203\n",
      "Epoch: 30, Batch: 27, D Loss: 0.09852849945426678, G Loss: 18.916748046875\n",
      "Epoch: 30, Batch: 28, D Loss: 0.09938482542892624, G Loss: 18.66917610168457\n",
      "Epoch: 30, Batch: 29, D Loss: 0.10043900840988762, G Loss: 18.719318389892578\n",
      "Epoch: 30, Batch: 30, D Loss: 0.09401504344941225, G Loss: 18.607641220092773\n",
      "Epoch: 30, Batch: 31, D Loss: 0.09988619023138234, G Loss: 18.774450302124023\n",
      "Epoch: 30, Batch: 32, D Loss: 0.09873491844678517, G Loss: 18.960840225219727\n",
      "Epoch: 30, Batch: 33, D Loss: 0.10106903557647073, G Loss: 19.308578491210938\n",
      "Epoch: 30, Batch: 34, D Loss: 0.09831536002593966, G Loss: 19.499494552612305\n",
      "Epoch: 30, Batch: 35, D Loss: 0.10077871540378947, G Loss: 19.63937759399414\n",
      "Epoch: 30, Batch: 36, D Loss: 0.09922102240427233, G Loss: 19.655502319335938\n",
      "Epoch: 30, Batch: 37, D Loss: 0.09507322474453994, G Loss: 19.44176483154297\n",
      "Epoch: 30, Batch: 38, D Loss: 0.10161527417814364, G Loss: 19.536558151245117\n",
      "Epoch: 30, Batch: 39, D Loss: 0.09480748488217772, G Loss: 19.552804946899414\n",
      "Epoch: 30, Batch: 40, D Loss: 0.0961172297742603, G Loss: 19.685977935791016\n",
      "Epoch: 30, Batch: 41, D Loss: 0.09584233300293865, G Loss: 19.764657974243164\n",
      "Epoch: 30, Batch: 42, D Loss: 0.10356754160663872, G Loss: 20.345523834228516\n",
      "Epoch: 30, Batch: 43, D Loss: 0.09884634673349318, G Loss: 20.737937927246094\n",
      "Epoch: 30, Batch: 44, D Loss: 0.1011807177954959, G Loss: 20.92601776123047\n",
      "Epoch: 30, Batch: 45, D Loss: 0.09537152994751691, G Loss: 20.588825225830078\n",
      "Epoch: 30, Batch: 46, D Loss: 0.10013575173168171, G Loss: 20.308528900146484\n",
      "Epoch: 30, Batch: 47, D Loss: 0.10204945577759544, G Loss: 20.37623405456543\n",
      "Epoch: 30, Batch: 48, D Loss: 0.10320319296421676, G Loss: 20.655364990234375\n",
      "Epoch: 30, Batch: 49, D Loss: 0.09829611381926517, G Loss: 20.75859832763672\n",
      "Epoch: 30, Batch: 50, D Loss: 0.09798902323620706, G Loss: 20.675405502319336\n",
      "Epoch: 30, Batch: 51, D Loss: 0.09072671907380908, G Loss: 19.952533721923828\n",
      "Epoch: 30, Batch: 52, D Loss: 0.09579121463797347, G Loss: 19.431156158447266\n",
      "Epoch: 30, Batch: 53, D Loss: 0.10496715598794859, G Loss: 19.89763069152832\n",
      "Epoch: 30, Batch: 54, D Loss: 0.10200579543021426, G Loss: 20.606809616088867\n",
      "Epoch: 30, Batch: 55, D Loss: 0.09837332415393779, G Loss: 20.925935745239258\n",
      "Epoch: 30, Batch: 56, D Loss: 0.09763742283270443, G Loss: 20.74211883544922\n",
      "Epoch: 30, Batch: 57, D Loss: 0.11209873898968875, G Loss: 20.956125259399414\n",
      "Epoch: 30, Batch: 58, D Loss: 0.09091215639974154, G Loss: 20.189674377441406\n",
      "Epoch: 30, Batch: 59, D Loss: 0.0966228185134711, G Loss: 19.399202346801758\n",
      "Epoch: 30, Batch: 60, D Loss: 0.0945581371566242, G Loss: 18.874176025390625\n",
      "Epoch: 30, Batch: 61, D Loss: 0.0925289204361821, G Loss: 18.67369270324707\n",
      "Epoch: 30, Batch: 62, D Loss: 0.09864190528221739, G Loss: 19.121307373046875\n",
      "Epoch: 30, Batch: 63, D Loss: 0.10652003566765034, G Loss: 20.360794067382812\n",
      "Epoch: 30, Batch: 64, D Loss: 0.09614180081613632, G Loss: 20.932571411132812\n",
      "Epoch: 30, Batch: 65, D Loss: 0.097768351896737, G Loss: 20.689403533935547\n",
      "Epoch: 30, Batch: 66, D Loss: 0.10086934338391346, G Loss: 20.116634368896484\n",
      "Epoch: 30, Batch: 67, D Loss: 0.09802343080234543, G Loss: 19.471595764160156\n",
      "Epoch: 30, Batch: 68, D Loss: 0.09703271303445171, G Loss: 19.103803634643555\n",
      "Epoch: 30, Batch: 69, D Loss: 0.09783691388092208, G Loss: 19.366971969604492\n",
      "Epoch: 30, Batch: 70, D Loss: 0.0983785851523088, G Loss: 20.039648056030273\n",
      "Epoch: 30, Batch: 71, D Loss: 0.09841090508067984, G Loss: 20.773757934570312\n",
      "Epoch: 30, Batch: 72, D Loss: 0.10348053310858094, G Loss: 21.3928165435791\n",
      "Epoch: 30, Batch: 73, D Loss: 0.09775632645463017, G Loss: 21.392616271972656\n",
      "Epoch: 30, Batch: 74, D Loss: 0.09418553895816645, G Loss: 20.70108413696289\n",
      "Epoch: 30, Batch: 75, D Loss: 0.1053753798782156, G Loss: 20.548179626464844\n",
      "Epoch: 30, Batch: 76, D Loss: 0.09293222496756848, G Loss: 20.258928298950195\n",
      "Epoch: 30, Batch: 77, D Loss: 0.09512654027132106, G Loss: 20.24334716796875\n",
      "Epoch: 30, Batch: 78, D Loss: 0.10357336740850395, G Loss: 21.5353946685791\n",
      "Epoch: 30, Batch: 79, D Loss: 0.09509670005045454, G Loss: 22.193241119384766\n",
      "Epoch: 30, Batch: 80, D Loss: 0.1016051620962577, G Loss: 23.08973503112793\n",
      "Epoch: 30, Batch: 81, D Loss: 0.10534049573431349, G Loss: 24.02402687072754\n",
      "Epoch: 30, Batch: 82, D Loss: 0.0990530998092409, G Loss: 21.85647201538086\n",
      "Epoch: 30, Batch: 83, D Loss: 0.10534361037250214, G Loss: 20.531829833984375\n",
      "Epoch: 30, Batch: 84, D Loss: 0.09976721650410492, G Loss: 19.672117233276367\n",
      "Epoch: 30, Batch: 85, D Loss: 0.0961328914365267, G Loss: 18.996688842773438\n",
      "Epoch: 30, Batch: 86, D Loss: 0.09813581034849816, G Loss: 18.46687889099121\n",
      "Epoch: 30, Batch: 87, D Loss: 0.09976323557903521, G Loss: 18.014760971069336\n",
      "Epoch: 30, Batch: 88, D Loss: 0.09867800194585641, G Loss: 17.671924591064453\n",
      "Epoch: 30, Batch: 89, D Loss: 0.10278880350752662, G Loss: 17.38148307800293\n",
      "Epoch: 30, Batch: 90, D Loss: 0.10575027794615721, G Loss: 17.266578674316406\n",
      "Epoch: 30, Batch: 91, D Loss: 0.09909050650098372, G Loss: 16.880931854248047\n",
      "Epoch: 30, Batch: 92, D Loss: 0.09640883422846258, G Loss: 16.1784610748291\n",
      "Epoch: 30, Batch: 93, D Loss: 0.09877786369563779, G Loss: 15.723915100097656\n",
      "Epoch: 30, Batch: 94, D Loss: 0.09626338118364686, G Loss: 15.7705659866333\n",
      "Epoch: 30, Batch: 95, D Loss: 0.10045895393666271, G Loss: 16.29326629638672\n",
      "Epoch: 30, Batch: 96, D Loss: 0.10418287071597199, G Loss: 17.400419235229492\n",
      "Epoch: 30, Batch: 97, D Loss: 0.09796273936132405, G Loss: 18.08985137939453\n",
      "Epoch: 30, Batch: 98, D Loss: 0.09568352173495853, G Loss: 18.18315887451172\n",
      "Epoch: 30, Batch: 99, D Loss: 0.101768321185844, G Loss: 18.190834045410156\n",
      "Epoch: 30, Batch: 100, D Loss: 0.10404368301337819, G Loss: 18.433242797851562\n",
      "Epoch: 30, Batch: 101, D Loss: 0.09530208007696839, G Loss: 18.44402503967285\n",
      "Epoch: 30, Batch: 102, D Loss: 0.09869800237566073, G Loss: 18.50617218017578\n",
      "Epoch: 30, Batch: 103, D Loss: 0.10158884172653515, G Loss: 18.810258865356445\n",
      "Epoch: 30, Batch: 104, D Loss: 0.10664043061819539, G Loss: 19.53496551513672\n",
      "Epoch: 30, Batch: 105, D Loss: 0.10056211192645625, G Loss: 19.86146354675293\n",
      "Epoch: 30, Batch: 106, D Loss: 0.09227178410371839, G Loss: 19.235733032226562\n",
      "Epoch: 30, Batch: 107, D Loss: 0.10075488978157177, G Loss: 18.7153377532959\n",
      "Epoch: 30, Batch: 108, D Loss: 0.10595938909765934, G Loss: 18.858224868774414\n",
      "Epoch: 30, Batch: 109, D Loss: 0.10372939958751037, G Loss: 19.325424194335938\n",
      "Epoch: 30, Batch: 110, D Loss: 0.10316868285000325, G Loss: 19.789945602416992\n",
      "Epoch: 30, Batch: 111, D Loss: 0.09523645187296459, G Loss: 19.556535720825195\n",
      "Epoch: 30, Batch: 112, D Loss: 0.09660834292965115, G Loss: 18.967802047729492\n",
      "Epoch: 30, Batch: 113, D Loss: 0.09948300154289269, G Loss: 18.727890014648438\n",
      "Epoch: 30, Batch: 114, D Loss: 0.0969269388753955, G Loss: 18.642879486083984\n",
      "Epoch: 30, Batch: 115, D Loss: 0.09412494708476782, G Loss: 18.619762420654297\n",
      "Epoch: 30, Batch: 116, D Loss: 0.09396195063340462, G Loss: 18.687572479248047\n",
      "Epoch: 30, Batch: 117, D Loss: 0.10384868350709042, G Loss: 19.387605667114258\n",
      "Epoch: 30, Batch: 118, D Loss: 0.09958146663920153, G Loss: 19.821823120117188\n",
      "Epoch: 30, Batch: 119, D Loss: 0.09732701010435652, G Loss: 19.779069900512695\n",
      "Epoch: 30, Batch: 120, D Loss: 0.09455220578538137, G Loss: 19.169231414794922\n",
      "Epoch: 30, Batch: 121, D Loss: 0.09313942113728291, G Loss: 18.34254264831543\n",
      "Epoch: 30, Batch: 122, D Loss: 0.09826972223964692, G Loss: 18.05144500732422\n",
      "Epoch: 30, Batch: 123, D Loss: 0.10166693298357066, G Loss: 18.530670166015625\n",
      "Epoch: 30, Batch: 124, D Loss: 0.09474239112099059, G Loss: 18.958600997924805\n",
      "Epoch: 30, Batch: 125, D Loss: 0.09832254305505783, G Loss: 19.232152938842773\n",
      "Epoch: 30, Batch: 126, D Loss: 0.10147834025958336, G Loss: 19.417234420776367\n",
      "Epoch: 30, Batch: 127, D Loss: 0.09275707102828057, G Loss: 18.878070831298828\n",
      "Epoch: 30, Batch: 128, D Loss: 0.10148748379080086, G Loss: 18.594636917114258\n",
      "Epoch: 30, Batch: 129, D Loss: 0.09835915723355182, G Loss: 18.446903228759766\n",
      "Epoch: 30, Batch: 130, D Loss: 0.0995085064179051, G Loss: 18.471168518066406\n",
      "Epoch: 30, Batch: 131, D Loss: 0.09783858530076683, G Loss: 18.503463745117188\n",
      "Epoch: 30, Batch: 132, D Loss: 0.10585475331295702, G Loss: 18.958572387695312\n",
      "Epoch: 30, Batch: 133, D Loss: 0.10922613200452758, G Loss: 19.627731323242188\n",
      "Epoch: 30, Batch: 134, D Loss: 0.10299547154959898, G Loss: 19.77783966064453\n",
      "Epoch: 30, Batch: 135, D Loss: 0.10099980400710651, G Loss: 19.30063819885254\n",
      "Epoch: 30, Batch: 136, D Loss: 0.10282329015456271, G Loss: 18.6643123626709\n",
      "Epoch: 30, Batch: 137, D Loss: 0.10178139555090437, G Loss: 18.23040008544922\n",
      "Epoch: 30, Batch: 138, D Loss: 0.09820350920881804, G Loss: 18.071319580078125\n",
      "Epoch: 30, Batch: 139, D Loss: 0.09323171529357221, G Loss: 17.981416702270508\n",
      "Epoch: 30, Batch: 140, D Loss: 0.10036863277050534, G Loss: 18.370641708374023\n",
      "Epoch: 30, Batch: 141, D Loss: 0.10467733027770376, G Loss: 19.257246017456055\n",
      "Epoch: 30, Batch: 142, D Loss: 0.10054823917949551, G Loss: 19.814302444458008\n",
      "Epoch: 30, Batch: 143, D Loss: 0.09597765791875168, G Loss: 19.620607376098633\n",
      "Epoch: 30, Batch: 144, D Loss: 0.09661327516569207, G Loss: 18.9560546875\n",
      "Epoch: 30, Batch: 145, D Loss: 0.10478431375177655, G Loss: 18.42315673828125\n",
      "Epoch: 30, Batch: 146, D Loss: 0.10601901766593347, G Loss: 18.411226272583008\n",
      "Epoch: 30, Batch: 147, D Loss: 0.09163498032295969, G Loss: 17.95887565612793\n",
      "Epoch: 30, Batch: 148, D Loss: 0.09992686840201959, G Loss: 17.68720245361328\n",
      "Epoch: 30, Batch: 149, D Loss: 0.10513799770376675, G Loss: 18.026456832885742\n",
      "Epoch: 30, Batch: 150, D Loss: 0.10704787610431055, G Loss: 18.655363082885742\n",
      "Epoch: 30, Batch: 151, D Loss: 0.0969444552567933, G Loss: 18.67576026916504\n",
      "Epoch: 30, Batch: 152, D Loss: 0.09670012204728762, G Loss: 18.17717742919922\n",
      "Epoch: 30, Batch: 153, D Loss: 0.09675552815658417, G Loss: 17.614301681518555\n",
      "Epoch: 30, Batch: 154, D Loss: 0.09382447513316805, G Loss: 17.205734252929688\n",
      "Epoch: 30, Batch: 155, D Loss: 0.0998235344658358, G Loss: 17.465017318725586\n",
      "Epoch: 30, Batch: 156, D Loss: 0.09977004082042207, G Loss: 18.18865203857422\n",
      "Epoch: 30, Batch: 157, D Loss: 0.1011549199469175, G Loss: 19.079980850219727\n",
      "Epoch: 30, Batch: 158, D Loss: 0.10545061699191838, G Loss: 19.872716903686523\n",
      "Epoch: 30, Batch: 159, D Loss: 0.09950655065526304, G Loss: 19.961505889892578\n",
      "Epoch: 30, Batch: 160, D Loss: 0.10299958412257681, G Loss: 19.690935134887695\n",
      "Epoch: 30, Batch: 161, D Loss: 0.10031518524202776, G Loss: 19.177589416503906\n",
      "Epoch: 30, Batch: 162, D Loss: 0.09404293042717748, G Loss: 18.478313446044922\n",
      "Epoch: 30, Batch: 163, D Loss: 0.10647051438563748, G Loss: 18.788898468017578\n",
      "Epoch: 30, Batch: 164, D Loss: 0.09583756603228566, G Loss: 19.22686767578125\n",
      "Epoch: 30, Batch: 165, D Loss: 0.09975300894679773, G Loss: 19.797414779663086\n",
      "Epoch: 30, Batch: 166, D Loss: 0.10028760977822404, G Loss: 20.287307739257812\n",
      "Epoch: 30, Batch: 167, D Loss: 0.09827711507412368, G Loss: 20.365798950195312\n",
      "Epoch: 30, Batch: 168, D Loss: 0.0982560523246116, G Loss: 20.190773010253906\n",
      "Epoch: 30, Batch: 169, D Loss: 0.09730281035404054, G Loss: 19.892181396484375\n",
      "Epoch: 30, Batch: 170, D Loss: 0.09666432571312122, G Loss: 19.642501831054688\n",
      "Epoch: 30, Batch: 171, D Loss: 0.10118701437553468, G Loss: 19.90330696105957\n",
      "Epoch: 30, Batch: 172, D Loss: 0.09567214644817934, G Loss: 20.21886444091797\n",
      "Epoch: 30, Batch: 173, D Loss: 0.09469830319852446, G Loss: 20.40624237060547\n",
      "Epoch: 30, Batch: 174, D Loss: 0.10050736423765938, G Loss: 20.790891647338867\n",
      "Epoch: 30, Batch: 175, D Loss: 0.10120043941433995, G Loss: 21.192119598388672\n",
      "Epoch: 30, Batch: 176, D Loss: 0.1015691461880174, G Loss: 21.471607208251953\n",
      "Epoch: 30, Batch: 177, D Loss: 0.10398431144063332, G Loss: 21.630847930908203\n",
      "Epoch: 30, Batch: 178, D Loss: 0.09507677730783451, G Loss: 21.09897804260254\n",
      "Epoch: 30, Batch: 179, D Loss: 0.10553844316200012, G Loss: 20.666563034057617\n",
      "Epoch: 30, Batch: 180, D Loss: 0.1024293905456789, G Loss: 20.454126358032227\n",
      "Epoch: 30, Batch: 181, D Loss: 0.09973783117913637, G Loss: 20.276260375976562\n",
      "Epoch: 30, Batch: 182, D Loss: 0.10057472521486521, G Loss: 20.14421844482422\n",
      "Epoch: 30, Batch: 183, D Loss: 0.0985492477705251, G Loss: 19.962549209594727\n",
      "Epoch: 30, Batch: 184, D Loss: 0.0952971739839954, G Loss: 19.567758560180664\n",
      "Epoch: 30, Batch: 185, D Loss: 0.09712129279513149, G Loss: 19.19730567932129\n",
      "Epoch: 30, Batch: 186, D Loss: 0.10061910976057531, G Loss: 19.220958709716797\n",
      "Epoch: 30, Batch: 187, D Loss: 0.10796684918338739, G Loss: 20.03611946105957\n",
      "Epoch: 30, Batch: 188, D Loss: 0.0974055164270971, G Loss: 20.41240119934082\n",
      "Epoch: 30, Batch: 189, D Loss: 0.10299500884688267, G Loss: 20.605377197265625\n",
      "Epoch: 30, Batch: 190, D Loss: 0.0996328449780145, G Loss: 20.33382797241211\n",
      "Epoch: 30, Batch: 191, D Loss: 0.10311466539251768, G Loss: 20.093830108642578\n",
      "Epoch: 30, Batch: 192, D Loss: 0.1030188138039616, G Loss: 20.034671783447266\n",
      "Epoch: 30, Batch: 193, D Loss: 0.0965730260354718, G Loss: 19.940353393554688\n",
      "Epoch: 30, Batch: 194, D Loss: 0.10487862021522854, G Loss: 20.308643341064453\n",
      "Epoch: 30, Batch: 195, D Loss: 0.09702901613274056, G Loss: 20.429025650024414\n",
      "Epoch: 30, Batch: 196, D Loss: 0.09287043740689593, G Loss: 20.10044288635254\n",
      "Epoch: 30, Batch: 197, D Loss: 0.09858100218408572, G Loss: 19.928081512451172\n",
      "Epoch: 30, Batch: 198, D Loss: 0.10154031313517975, G Loss: 20.193748474121094\n",
      "Epoch: 30, Batch: 199, D Loss: 0.09832727241155348, G Loss: 20.377548217773438\n",
      "Epoch: 30, Batch: 200, D Loss: 0.10580493562567134, G Loss: 20.930620193481445\n",
      "Epoch: 30, Batch: 201, D Loss: 0.10048937834227051, G Loss: 21.125764846801758\n",
      "Epoch: 30, Batch: 202, D Loss: 0.10059698706849657, G Loss: 20.99907112121582\n",
      "Epoch: 30, Batch: 203, D Loss: 0.10111255985676437, G Loss: 20.81031036376953\n",
      "Epoch: 30, Batch: 204, D Loss: 0.10293360103539112, G Loss: 20.68218231201172\n",
      "Epoch: 30, Batch: 205, D Loss: 0.10275295426139985, G Loss: 20.785507202148438\n",
      "Epoch: 30, Batch: 206, D Loss: 0.10095556870266117, G Loss: 20.87384796142578\n",
      "Epoch: 30, Batch: 207, D Loss: 0.09840372248506596, G Loss: 20.843202590942383\n",
      "Epoch: 30, Batch: 208, D Loss: 0.09145608602877509, G Loss: 20.316190719604492\n",
      "Epoch: 30, Batch: 209, D Loss: 0.10628953643553246, G Loss: 20.521455764770508\n",
      "Epoch: 30, Batch: 210, D Loss: 0.0964729195420867, G Loss: 20.70815658569336\n",
      "Epoch: 30, Batch: 211, D Loss: 0.10189662916867936, G Loss: 21.018596649169922\n",
      "Epoch: 30, Batch: 212, D Loss: 0.1045921298991043, G Loss: 21.359256744384766\n",
      "Epoch: 30, Batch: 213, D Loss: 0.10294198269273047, G Loss: 21.50947380065918\n",
      "Epoch: 30, Batch: 214, D Loss: 0.10119483645530708, G Loss: 21.287673950195312\n",
      "Epoch: 30, Batch: 215, D Loss: 0.10226176712612345, G Loss: 20.976707458496094\n",
      "Epoch: 30, Batch: 216, D Loss: 0.09982995738399197, G Loss: 20.515302658081055\n",
      "Epoch: 30, Batch: 217, D Loss: 0.1009926355623812, G Loss: 20.355670928955078\n",
      "Epoch: 30, Batch: 218, D Loss: 0.0970982171565713, G Loss: 20.305011749267578\n",
      "Epoch: 30, Batch: 219, D Loss: 0.10461410941074556, G Loss: 20.723018646240234\n",
      "Epoch: 30, Batch: 220, D Loss: 0.1038679856884426, G Loss: 21.242277145385742\n",
      "Epoch: 30, Batch: 221, D Loss: 0.0980663898682102, G Loss: 21.180255889892578\n",
      "Epoch: 30, Batch: 222, D Loss: 0.10543547603425218, G Loss: 21.11819839477539\n",
      "Epoch: 30, Batch: 223, D Loss: 0.09871797305387742, G Loss: 20.709102630615234\n",
      "Epoch: 30, Batch: 224, D Loss: 0.09502087604404319, G Loss: 20.07160758972168\n",
      "Epoch: 30, Batch: 225, D Loss: 0.10465398527580971, G Loss: 20.057092666625977\n",
      "Epoch: 30, Batch: 226, D Loss: 0.10186822792812589, G Loss: 20.42160415649414\n",
      "Epoch: 30, Batch: 227, D Loss: 0.09551844065637344, G Loss: 20.50261116027832\n",
      "Epoch: 30, Batch: 228, D Loss: 0.10649398765225465, G Loss: 20.887367248535156\n",
      "Epoch: 30, Batch: 229, D Loss: 0.09222106687188658, G Loss: 20.515331268310547\n",
      "Epoch: 30, Batch: 230, D Loss: 0.09206630381209174, G Loss: 19.7586612701416\n",
      "Epoch: 30, Batch: 231, D Loss: 0.10534818596410489, G Loss: 19.838542938232422\n",
      "Epoch: 30, Batch: 232, D Loss: 0.0926474419032085, G Loss: 19.90353775024414\n",
      "Epoch: 30, Batch: 233, D Loss: 0.10111498174545774, G Loss: 20.411874771118164\n",
      "Epoch: 30, Batch: 234, D Loss: 0.09492597045488554, G Loss: 20.608747482299805\n",
      "Epoch: 30, Batch: 235, D Loss: 0.09697737601380757, G Loss: 20.591556549072266\n",
      "Epoch: 30, Batch: 236, D Loss: 0.10649166303512286, G Loss: 20.94583511352539\n",
      "Epoch: 30, Batch: 237, D Loss: 0.10143575853776995, G Loss: 21.125041961669922\n",
      "Epoch: 30, Batch: 238, D Loss: 0.09909629859207733, G Loss: 20.91229820251465\n",
      "Epoch: 30, Batch: 239, D Loss: 0.09781831558790421, G Loss: 20.341190338134766\n",
      "Epoch: 30, Batch: 240, D Loss: 0.10283017241487602, G Loss: 20.10591697692871\n",
      "Epoch: 30, Batch: 241, D Loss: 0.10590352194968194, G Loss: 20.46063232421875\n",
      "Epoch: 30, Batch: 242, D Loss: 0.09936213552328987, G Loss: 20.646699905395508\n",
      "Epoch: 30, Batch: 243, D Loss: 0.0980989193839712, G Loss: 20.483869552612305\n",
      "Epoch: 30, Batch: 244, D Loss: 0.10144445368854743, G Loss: 20.3347225189209\n",
      "Epoch: 30, Batch: 245, D Loss: 0.0932713980351153, G Loss: 19.79345703125\n",
      "Epoch: 30, Batch: 246, D Loss: 0.100729340182798, G Loss: 19.663877487182617\n",
      "Epoch: 30, Batch: 247, D Loss: 0.09696751973683126, G Loss: 19.713184356689453\n",
      "Epoch: 30, Batch: 248, D Loss: 0.10422429546256218, G Loss: 20.244644165039062\n",
      "Epoch: 30, Batch: 249, D Loss: 0.09967233304419948, G Loss: 20.691022872924805\n",
      "Epoch: 30, Batch: 250, D Loss: 0.09368826507063577, G Loss: 20.466167449951172\n",
      "Epoch: 30, Batch: 251, D Loss: 0.10137573701343777, G Loss: 20.270164489746094\n",
      "Epoch: 30, Batch: 252, D Loss: 0.0970184439717347, G Loss: 19.966121673583984\n",
      "Epoch: 30, Batch: 253, D Loss: 0.09841272351570562, G Loss: 19.796958923339844\n",
      "Epoch: 30, Batch: 254, D Loss: 0.10320493682836052, G Loss: 20.168411254882812\n",
      "Epoch: 30, Batch: 255, D Loss: 0.09900923147668267, G Loss: 20.46929359436035\n",
      "Epoch: 30, Batch: 256, D Loss: 0.09622372007620422, G Loss: 20.430814743041992\n",
      "Epoch: 30, Batch: 257, D Loss: 0.1037401786796443, G Loss: 20.545316696166992\n",
      "Epoch: 30, Batch: 258, D Loss: 0.09956954480298569, G Loss: 20.51649284362793\n",
      "Epoch: 30, Batch: 259, D Loss: 0.10036607151903815, G Loss: 20.404844284057617\n",
      "Epoch: 30, Batch: 260, D Loss: 0.10369979658691664, G Loss: 20.412500381469727\n",
      "Epoch: 30, Batch: 261, D Loss: 0.10029978377699539, G Loss: 20.295644760131836\n",
      "Epoch: 30, Batch: 262, D Loss: 0.10663717310880466, G Loss: 20.448780059814453\n",
      "Epoch: 30, Batch: 263, D Loss: 0.10604532864695676, G Loss: 20.73340606689453\n",
      "Epoch: 30, Batch: 264, D Loss: 0.09568671941506107, G Loss: 20.38796615600586\n",
      "Epoch: 30, Batch: 265, D Loss: 0.09728290237558956, G Loss: 19.770689010620117\n",
      "Epoch: 30, Batch: 266, D Loss: 0.09455675072952008, G Loss: 19.08378791809082\n",
      "Epoch: 30, Batch: 267, D Loss: 0.10521891194302935, G Loss: 19.334630966186523\n",
      "Epoch: 30, Batch: 268, D Loss: 0.10458517950268975, G Loss: 20.1451358795166\n",
      "Epoch: 30, Batch: 269, D Loss: 0.09528931305520377, G Loss: 20.46929359436035\n",
      "Epoch: 30, Batch: 270, D Loss: 0.10297457189429321, G Loss: 20.585460662841797\n",
      "Epoch: 30, Batch: 271, D Loss: 0.10283701180854199, G Loss: 20.532312393188477\n",
      "Epoch: 30, Batch: 272, D Loss: 0.0923758605011028, G Loss: 19.81830406188965\n",
      "Epoch: 30, Batch: 273, D Loss: 0.0953782516814331, G Loss: 19.107852935791016\n",
      "Epoch: 30, Batch: 274, D Loss: 0.10008003077903993, G Loss: 19.047273635864258\n",
      "Epoch: 30, Batch: 275, D Loss: 0.09496040130109829, G Loss: 19.31230926513672\n",
      "Epoch: 30, Batch: 276, D Loss: 0.10334094003576921, G Loss: 20.10886001586914\n",
      "Epoch: 30, Batch: 277, D Loss: 0.10456934630767423, G Loss: 20.942787170410156\n",
      "Epoch: 30, Batch: 278, D Loss: 0.09637850562870834, G Loss: 20.956256866455078\n",
      "Epoch: 30, Batch: 279, D Loss: 0.10462102339372364, G Loss: 20.697294235229492\n",
      "Epoch: 30, Batch: 280, D Loss: 0.09870302749022358, G Loss: 20.0585994720459\n",
      "Epoch: 30, Batch: 281, D Loss: 0.09612992542217969, G Loss: 19.41586685180664\n",
      "Epoch: 30, Batch: 282, D Loss: 0.10100607743186663, G Loss: 19.586694717407227\n",
      "Epoch: 30, Batch: 283, D Loss: 0.09679972504617851, G Loss: 20.01932716369629\n",
      "Epoch: 30, Batch: 284, D Loss: 0.10087596690968731, G Loss: 20.832956314086914\n",
      "Epoch: 30, Batch: 285, D Loss: 0.0974379483191076, G Loss: 21.40982437133789\n",
      "Epoch: 30, Batch: 286, D Loss: 0.10293700566451833, G Loss: 21.806045532226562\n",
      "Epoch: 30, Batch: 287, D Loss: 0.09553393740764154, G Loss: 21.568439483642578\n",
      "Epoch: 30, Batch: 288, D Loss: 0.10001239951748778, G Loss: 21.194215774536133\n",
      "Epoch: 30, Batch: 289, D Loss: 0.0974311385388559, G Loss: 20.81631851196289\n",
      "Epoch: 30, Batch: 290, D Loss: 0.0969816600218828, G Loss: 20.67753028869629\n",
      "Epoch: 30, Batch: 291, D Loss: 0.09797796654622914, G Loss: 20.858510971069336\n",
      "Epoch: 30, Batch: 292, D Loss: 0.10574567344110969, G Loss: 21.834901809692383\n",
      "Epoch: 30, Batch: 293, D Loss: 0.10331688831971447, G Loss: 22.658143997192383\n",
      "Epoch: 30, Batch: 294, D Loss: 0.09964426614035156, G Loss: 22.67958641052246\n",
      "Epoch: 30, Batch: 295, D Loss: 0.10782752938875917, G Loss: 22.502988815307617\n",
      "Epoch: 30, Batch: 296, D Loss: 0.10121139894855163, G Loss: 22.02195167541504\n",
      "Epoch: 30, Batch: 297, D Loss: 0.1004941986887051, G Loss: 21.413551330566406\n",
      "Epoch: 30, Batch: 298, D Loss: 0.09820205750827762, G Loss: 20.919950485229492\n",
      "Epoch: 30, Batch: 299, D Loss: 0.10485392845908639, G Loss: 21.170486450195312\n",
      "Epoch: 30, Batch: 300, D Loss: 0.10163089657113081, G Loss: 21.704648971557617\n",
      "Epoch: 30, Batch: 301, D Loss: 0.10179860158809767, G Loss: 22.264530181884766\n",
      "Epoch: 30, Batch: 302, D Loss: 0.10387743273421421, G Loss: 22.597393035888672\n",
      "Epoch: 30, Batch: 303, D Loss: 0.09631257513753887, G Loss: 22.1839656829834\n",
      "Epoch: 30, Batch: 304, D Loss: 0.09416379796874752, G Loss: 21.420488357543945\n",
      "Epoch: 30, Batch: 305, D Loss: 0.10009551080175677, G Loss: 20.94975471496582\n",
      "Epoch: 30, Batch: 306, D Loss: 0.0991940799969109, G Loss: 21.147506713867188\n",
      "Epoch: 30, Batch: 307, D Loss: 0.09234376284719853, G Loss: 21.130264282226562\n",
      "Epoch: 30, Batch: 308, D Loss: 0.1012880581151121, G Loss: 21.663087844848633\n",
      "Epoch: 30, Batch: 309, D Loss: 0.09120947142723829, G Loss: 21.69646644592285\n",
      "Epoch: 30, Batch: 310, D Loss: 0.10290712134490484, G Loss: 21.971973419189453\n",
      "Epoch: 30, Batch: 311, D Loss: 0.10174305749724034, G Loss: 22.20258903503418\n",
      "Epoch: 30, Batch: 312, D Loss: 0.09900227946011897, G Loss: 22.121116638183594\n",
      "Epoch: 30, Batch: 313, D Loss: 0.09620776787545825, G Loss: 21.745723724365234\n",
      "Epoch: 30, Batch: 314, D Loss: 0.09162382807640743, G Loss: 21.03608512878418\n",
      "Epoch: 30, Batch: 315, D Loss: 0.10069587863719817, G Loss: 21.01496696472168\n",
      "Epoch: 30, Batch: 316, D Loss: 0.10105790226542455, G Loss: 21.516925811767578\n",
      "Epoch: 30, Batch: 317, D Loss: 0.10716249062113971, G Loss: 22.50449562072754\n",
      "Epoch: 30, Batch: 318, D Loss: 0.09891340143408497, G Loss: 22.88827133178711\n",
      "Epoch: 30, Batch: 319, D Loss: 0.10493552690692777, G Loss: 22.83245086669922\n",
      "Epoch: 30, Batch: 320, D Loss: 0.0953232944976518, G Loss: 21.946369171142578\n",
      "Epoch: 30, Batch: 321, D Loss: 0.0949986505130162, G Loss: 20.864492416381836\n",
      "Epoch: 30, Batch: 322, D Loss: 0.09877367377048551, G Loss: 20.269325256347656\n",
      "Epoch: 30, Batch: 323, D Loss: 0.09448386067590281, G Loss: 20.1502628326416\n",
      "Epoch: 30, Batch: 324, D Loss: 0.09758797351548248, G Loss: 20.780540466308594\n",
      "Epoch: 30, Batch: 325, D Loss: 0.09983235626827641, G Loss: 21.69558334350586\n",
      "Epoch: 30, Batch: 326, D Loss: 0.10055856419473924, G Loss: 22.43730354309082\n",
      "Epoch: 30, Batch: 327, D Loss: 0.09558414677284806, G Loss: 22.348115921020508\n",
      "Epoch: 30, Batch: 328, D Loss: 0.09862326097995538, G Loss: 21.905004501342773\n",
      "Epoch: 30, Batch: 329, D Loss: 0.10022096354627312, G Loss: 21.52268409729004\n",
      "Epoch: 30, Batch: 330, D Loss: 0.10336208364971317, G Loss: 21.610837936401367\n",
      "Epoch: 30, Batch: 331, D Loss: 0.09310108444094016, G Loss: 21.58565330505371\n",
      "Epoch: 30, Batch: 332, D Loss: 0.09328770659045367, G Loss: 21.54801368713379\n",
      "Epoch: 30, Batch: 333, D Loss: 0.09746561963789194, G Loss: 21.789552688598633\n",
      "Epoch: 30, Batch: 334, D Loss: 0.08975631016076295, G Loss: 21.76240348815918\n",
      "Epoch: 30, Batch: 335, D Loss: 0.09423521923071562, G Loss: 21.845516204833984\n",
      "Epoch: 30, Batch: 336, D Loss: 0.09889254732047759, G Loss: 22.267799377441406\n",
      "Epoch: 30, Batch: 337, D Loss: 0.10721880203687569, G Loss: 23.305652618408203\n",
      "Epoch: 30, Batch: 338, D Loss: 0.09497223052680556, G Loss: 23.576059341430664\n",
      "Epoch: 30, Batch: 339, D Loss: 0.10212426635612838, G Loss: 23.5202579498291\n",
      "Epoch: 30, Batch: 340, D Loss: 0.09791749719702508, G Loss: 23.053455352783203\n",
      "Epoch: 30, Batch: 341, D Loss: 0.1079036966442411, G Loss: 23.093839645385742\n",
      "Epoch: 30, Batch: 342, D Loss: 0.10226647560181089, G Loss: 23.228023529052734\n",
      "Epoch: 30, Batch: 343, D Loss: 0.09637924288482486, G Loss: 22.945472717285156\n",
      "Epoch: 30, Batch: 344, D Loss: 0.10293605929806407, G Loss: 22.70379638671875\n",
      "Epoch: 30, Batch: 345, D Loss: 0.09728673108950193, G Loss: 22.312273025512695\n",
      "Epoch: 30, Batch: 346, D Loss: 0.10852126786582872, G Loss: 22.46613883972168\n",
      "Epoch: 30, Batch: 347, D Loss: 0.09274840366034792, G Loss: 22.011598587036133\n",
      "Epoch: 30, Batch: 348, D Loss: 0.09440295418265436, G Loss: 21.301334381103516\n",
      "Epoch: 30, Batch: 349, D Loss: 0.09287171852195958, G Loss: 20.56459617614746\n",
      "Epoch: 30, Batch: 350, D Loss: 0.09698200292236248, G Loss: 20.328174591064453\n",
      "Epoch: 30, Batch: 351, D Loss: 0.10022540451865464, G Loss: 20.690013885498047\n",
      "Epoch: 30, Batch: 352, D Loss: 0.10613682897592727, G Loss: 21.629533767700195\n",
      "Epoch: 30, Batch: 353, D Loss: 0.1075147987663795, G Loss: 22.534393310546875\n",
      "Epoch: 30, Batch: 354, D Loss: 0.10427658267517725, G Loss: 22.657377243041992\n",
      "Epoch: 30, Batch: 355, D Loss: 0.09973955165651308, G Loss: 21.817243576049805\n",
      "Epoch: 30, Batch: 356, D Loss: 0.09522286837951166, G Loss: 20.388517379760742\n",
      "Epoch: 30, Batch: 357, D Loss: 0.10201132406973157, G Loss: 19.536203384399414\n",
      "Epoch: 30, Batch: 358, D Loss: 0.10234591521610492, G Loss: 19.623598098754883\n",
      "Epoch: 30, Batch: 359, D Loss: 0.09570887060924504, G Loss: 20.033050537109375\n",
      "Epoch: 30, Batch: 360, D Loss: 0.09509325107974687, G Loss: 20.44051170349121\n",
      "Epoch: 30, Batch: 361, D Loss: 0.10670609816433804, G Loss: 21.21039390563965\n",
      "Epoch: 30, Batch: 362, D Loss: 0.09770822553447644, G Loss: 21.358543395996094\n",
      "Epoch: 30, Batch: 363, D Loss: 0.10191145569865784, G Loss: 21.08592414855957\n",
      "Epoch: 30, Batch: 364, D Loss: 0.09771448422602835, G Loss: 20.442590713500977\n",
      "Epoch: 30, Batch: 365, D Loss: 0.0941510210456713, G Loss: 19.66195297241211\n",
      "Epoch: 30, Batch: 366, D Loss: 0.10355089004618678, G Loss: 19.6606502532959\n",
      "Epoch: 30, Batch: 367, D Loss: 0.10164989645734912, G Loss: 20.101530075073242\n",
      "Epoch: 30, Batch: 368, D Loss: 0.09918891711617689, G Loss: 20.563764572143555\n",
      "Epoch: 30, Batch: 369, D Loss: 0.1011357684912837, G Loss: 20.886756896972656\n",
      "Epoch: 30, Batch: 370, D Loss: 0.10030908927171192, G Loss: 20.7961368560791\n",
      "Epoch: 30, Batch: 371, D Loss: 0.09900055881887643, G Loss: 20.436983108520508\n",
      "Epoch: 30, Batch: 372, D Loss: 0.0995627947516719, G Loss: 20.13353157043457\n",
      "Epoch: 30, Batch: 373, D Loss: 0.09586519109346991, G Loss: 19.820152282714844\n",
      "Epoch: 30, Batch: 374, D Loss: 0.09685922542265757, G Loss: 19.749492645263672\n",
      "Epoch: 30, Batch: 375, D Loss: 0.0992501985175942, G Loss: 20.091520309448242\n",
      "Epoch: 30, Batch: 376, D Loss: 0.10242893612630577, G Loss: 20.773578643798828\n",
      "Epoch: 30, Batch: 377, D Loss: 0.09277364657360643, G Loss: 20.848318099975586\n",
      "Epoch: 30, Batch: 378, D Loss: 0.1044910404979924, G Loss: 21.09613037109375\n",
      "Epoch: 30, Batch: 379, D Loss: 0.10360915991371641, G Loss: 21.207378387451172\n",
      "Epoch: 30, Batch: 380, D Loss: 0.09680273420339369, G Loss: 20.886789321899414\n",
      "Epoch: 30, Batch: 381, D Loss: 0.09712585860034156, G Loss: 20.45990562438965\n",
      "Epoch: 30, Batch: 382, D Loss: 0.09843038093701811, G Loss: 20.2902889251709\n",
      "Epoch: 30, Batch: 383, D Loss: 0.09941497516674891, G Loss: 20.432985305786133\n",
      "Epoch: 30, Batch: 384, D Loss: 0.09792892693426047, G Loss: 20.685964584350586\n",
      "Epoch: 30, Batch: 385, D Loss: 0.10205699544313387, G Loss: 21.139297485351562\n",
      "Epoch: 30, Batch: 386, D Loss: 0.10125958946258148, G Loss: 21.5387020111084\n",
      "Epoch: 30, Batch: 387, D Loss: 0.10573808122101704, G Loss: 21.89897918701172\n",
      "Epoch: 30, Batch: 388, D Loss: 0.10140929387047304, G Loss: 21.838809967041016\n",
      "Epoch: 30, Batch: 389, D Loss: 0.10523292439415521, G Loss: 21.75586700439453\n",
      "Epoch: 30, Batch: 390, D Loss: 0.096572436623776, G Loss: 21.255956649780273\n",
      "Epoch: 30, Batch: 391, D Loss: 0.09807890691547336, G Loss: 20.768823623657227\n",
      "Epoch: 30, Batch: 392, D Loss: 0.09827819515972147, G Loss: 20.70672035217285\n",
      "Epoch: 30, Batch: 393, D Loss: 0.09835697757326384, G Loss: 20.864810943603516\n",
      "Epoch: 30, Batch: 394, D Loss: 0.102174505913811, G Loss: 21.42955780029297\n",
      "Epoch: 30, Batch: 395, D Loss: 0.09761092086556189, G Loss: 21.84786605834961\n",
      "Epoch: 30, Batch: 396, D Loss: 0.0993947909784184, G Loss: 21.99654769897461\n",
      "Epoch: 30, Batch: 397, D Loss: 0.10277406885380429, G Loss: 21.987892150878906\n",
      "Epoch: 30, Batch: 398, D Loss: 0.09735344367979736, G Loss: 21.562902450561523\n",
      "Epoch: 30, Batch: 399, D Loss: 0.09693956405550205, G Loss: 20.910852432250977\n",
      "Epoch: 30, Batch: 400, D Loss: 0.09882548502030264, G Loss: 20.533117294311523\n",
      "Epoch: 30, Batch: 401, D Loss: 0.09362050958556878, G Loss: 20.321638107299805\n",
      "Epoch: 30, Batch: 402, D Loss: 0.10616080516771209, G Loss: 20.945758819580078\n",
      "Epoch: 30, Batch: 403, D Loss: 0.10707673453927885, G Loss: 21.953428268432617\n",
      "Epoch: 30, Batch: 404, D Loss: 0.10478959243160736, G Loss: 22.563438415527344\n",
      "Epoch: 30, Batch: 405, D Loss: 0.09007389855704816, G Loss: 21.73714256286621\n",
      "Epoch: 30, Batch: 406, D Loss: 0.09803356262975499, G Loss: 20.614728927612305\n",
      "Epoch: 30, Batch: 407, D Loss: 0.09601280180512789, G Loss: 19.76091194152832\n",
      "Epoch: 30, Batch: 408, D Loss: 0.10106919831490968, G Loss: 19.84152603149414\n",
      "Epoch: 30, Batch: 409, D Loss: 0.10512632204676986, G Loss: 20.794212341308594\n",
      "Epoch: 30, Batch: 410, D Loss: 0.09806428879254567, G Loss: 21.65620231628418\n",
      "Epoch: 30, Batch: 411, D Loss: 0.1004202516704063, G Loss: 21.806554794311523\n",
      "Epoch: 30, Batch: 412, D Loss: 0.10179118086669435, G Loss: 21.5237979888916\n",
      "Epoch: 30, Batch: 413, D Loss: 0.09849419478705573, G Loss: 20.738502502441406\n",
      "Epoch: 30, Batch: 414, D Loss: 0.0990664072449357, G Loss: 19.926475524902344\n",
      "Epoch: 30, Batch: 415, D Loss: 0.10006316893365697, G Loss: 19.45783805847168\n",
      "Epoch: 30, Batch: 416, D Loss: 0.10276827384050191, G Loss: 19.56380271911621\n",
      "Epoch: 30, Batch: 417, D Loss: 0.10527131076306417, G Loss: 20.18909454345703\n",
      "Epoch: 30, Batch: 418, D Loss: 0.09956298837699845, G Loss: 20.58803367614746\n",
      "Epoch: 30, Batch: 419, D Loss: 0.09567021644810247, G Loss: 20.3111515045166\n",
      "Epoch: 30, Batch: 420, D Loss: 0.09572848787943589, G Loss: 19.595121383666992\n",
      "Epoch: 30, Batch: 421, D Loss: 0.08796885882025274, G Loss: 18.523725509643555\n",
      "Epoch: 30, Batch: 422, D Loss: 0.1028217871176289, G Loss: 18.381420135498047\n",
      "Epoch: 30, Batch: 423, D Loss: 0.10205471134266664, G Loss: 19.06926727294922\n",
      "Epoch: 30, Batch: 424, D Loss: 0.09947519166621299, G Loss: 19.97638511657715\n",
      "Epoch: 30, Batch: 425, D Loss: 0.09237441514286637, G Loss: 20.20452117919922\n",
      "Epoch: 30, Batch: 426, D Loss: 0.09729637297310223, G Loss: 20.040185928344727\n",
      "Epoch: 30, Batch: 427, D Loss: 0.10077346972550649, G Loss: 19.82159423828125\n",
      "Epoch: 30, Batch: 428, D Loss: 0.10481256366654657, G Loss: 19.872465133666992\n",
      "Epoch: 30, Batch: 429, D Loss: 0.10110753142860363, G Loss: 19.937498092651367\n",
      "Epoch: 30, Batch: 430, D Loss: 0.09799209359462646, G Loss: 19.732418060302734\n",
      "Epoch: 30, Batch: 431, D Loss: 0.10785180446486431, G Loss: 20.014928817749023\n",
      "Epoch: 30, Batch: 432, D Loss: 0.09975680803740761, G Loss: 20.146202087402344\n",
      "Epoch: 30, Batch: 433, D Loss: 0.09113078683050124, G Loss: 19.60254669189453\n",
      "Epoch: 30, Batch: 434, D Loss: 0.0997050795690666, G Loss: 19.237895965576172\n",
      "Epoch: 30, Batch: 435, D Loss: 0.10130720796994841, G Loss: 19.325075149536133\n",
      "Epoch: 30, Batch: 436, D Loss: 0.09981168972984522, G Loss: 19.699878692626953\n",
      "Epoch: 30, Batch: 437, D Loss: 0.09953209127041229, G Loss: 20.07558250427246\n",
      "Epoch: 30, Batch: 438, D Loss: 0.0980077767427987, G Loss: 20.191959381103516\n",
      "Epoch: 30, Batch: 439, D Loss: 0.094073259372214, G Loss: 19.82666015625\n",
      "Epoch: 30, Batch: 440, D Loss: 0.1000721766635243, G Loss: 19.57769203186035\n",
      "Epoch: 30, Batch: 441, D Loss: 0.10087452986475554, G Loss: 19.576370239257812\n",
      "Epoch: 30, Batch: 442, D Loss: 0.09583310946991219, G Loss: 19.501033782958984\n",
      "Epoch: 30, Batch: 443, D Loss: 0.09528953019636155, G Loss: 19.365564346313477\n",
      "Epoch: 30, Batch: 444, D Loss: 0.09914338776861542, G Loss: 19.431241989135742\n",
      "Epoch: 30, Batch: 445, D Loss: 0.09942184552560784, G Loss: 19.63335609436035\n",
      "Epoch: 30, Batch: 446, D Loss: 0.10287279015228701, G Loss: 19.97127342224121\n",
      "Epoch: 30, Batch: 447, D Loss: 0.09629692246582411, G Loss: 19.91566276550293\n",
      "Epoch: 30, Batch: 448, D Loss: 0.10174171743712912, G Loss: 19.834903717041016\n",
      "Epoch: 30, Batch: 449, D Loss: 0.09654786584035902, G Loss: 19.485740661621094\n",
      "Epoch: 30, Batch: 450, D Loss: 0.09416388941619647, G Loss: 19.015161514282227\n",
      "Epoch: 30, Batch: 451, D Loss: 0.10346973192903475, G Loss: 19.204479217529297\n",
      "Epoch: 30, Batch: 452, D Loss: 0.10025502922425467, G Loss: 19.64836883544922\n",
      "Epoch: 30, Batch: 453, D Loss: 0.1028745706628339, G Loss: 20.250341415405273\n",
      "Epoch: 30, Batch: 454, D Loss: 0.10043032536542118, G Loss: 20.53478240966797\n",
      "Epoch: 30, Batch: 455, D Loss: 0.0938310332868803, G Loss: 20.068937301635742\n",
      "Epoch: 30, Batch: 456, D Loss: 0.09912781544642435, G Loss: 19.538663864135742\n",
      "Epoch: 30, Batch: 457, D Loss: 0.09963712282784942, G Loss: 19.29120445251465\n",
      "Epoch: 30, Batch: 458, D Loss: 0.09685613423563244, G Loss: 19.302631378173828\n",
      "Epoch: 30, Batch: 459, D Loss: 0.09716513941685578, G Loss: 19.481796264648438\n",
      "Epoch: 30, Batch: 460, D Loss: 0.1065613341270677, G Loss: 20.200698852539062\n",
      "Epoch: 30, Batch: 461, D Loss: 0.095471516978686, G Loss: 20.48436164855957\n",
      "Epoch: 30, Batch: 462, D Loss: 0.10187675866207668, G Loss: 20.52144432067871\n",
      "Epoch: 30, Batch: 463, D Loss: 0.10330402917152037, G Loss: 20.377357482910156\n",
      "Epoch: 30, Batch: 464, D Loss: 0.09829649419967362, G Loss: 19.903539657592773\n",
      "Epoch: 30, Batch: 465, D Loss: 0.10354667277711505, G Loss: 19.787776947021484\n",
      "Epoch: 30, Batch: 466, D Loss: 0.09913803024277423, G Loss: 19.71902847290039\n",
      "Epoch: 30, Batch: 467, D Loss: 0.10587508344395113, G Loss: 20.0802059173584\n",
      "Epoch: 31, Batch: 0, D Loss: 0.10729225793731068, G Loss: 20.697633743286133\n",
      "Epoch: 31, Batch: 1, D Loss: 0.0945336973113976, G Loss: 20.5986328125\n",
      "Epoch: 31, Batch: 2, D Loss: 0.09549175278578653, G Loss: 20.04930877685547\n",
      "Epoch: 31, Batch: 3, D Loss: 0.09797538199572098, G Loss: 19.549962997436523\n",
      "Epoch: 31, Batch: 4, D Loss: 0.0961572397586985, G Loss: 19.275291442871094\n",
      "Epoch: 31, Batch: 5, D Loss: 0.10199286226578774, G Loss: 19.565662384033203\n",
      "Epoch: 31, Batch: 6, D Loss: 0.10179478042062984, G Loss: 20.234214782714844\n",
      "Epoch: 31, Batch: 7, D Loss: 0.09985922337994024, G Loss: 20.786012649536133\n",
      "Epoch: 31, Batch: 8, D Loss: 0.09451027264637174, G Loss: 20.663597106933594\n",
      "Epoch: 31, Batch: 9, D Loss: 0.09576918255355948, G Loss: 20.124805450439453\n",
      "Epoch: 31, Batch: 10, D Loss: 0.09971889964454439, G Loss: 19.748811721801758\n",
      "Epoch: 31, Batch: 11, D Loss: 0.1042120319594736, G Loss: 19.953641891479492\n",
      "Epoch: 31, Batch: 12, D Loss: 0.09624238410374208, G Loss: 20.13690948486328\n",
      "Epoch: 31, Batch: 13, D Loss: 0.0987466209025139, G Loss: 20.398160934448242\n",
      "Epoch: 31, Batch: 14, D Loss: 0.0992896935575977, G Loss: 20.61104965209961\n",
      "Epoch: 31, Batch: 15, D Loss: 0.09916918034601419, G Loss: 20.648399353027344\n",
      "Epoch: 31, Batch: 16, D Loss: 0.10037238950061433, G Loss: 20.63969612121582\n",
      "Epoch: 31, Batch: 17, D Loss: 0.10591096478324524, G Loss: 20.90460968017578\n",
      "Epoch: 31, Batch: 18, D Loss: 0.10333369709812515, G Loss: 21.106740951538086\n",
      "Epoch: 31, Batch: 19, D Loss: 0.09458154482152098, G Loss: 20.69955062866211\n",
      "Epoch: 31, Batch: 20, D Loss: 0.09989786209143642, G Loss: 20.36731719970703\n",
      "Epoch: 31, Batch: 21, D Loss: 0.09949833230507454, G Loss: 20.253917694091797\n",
      "Epoch: 31, Batch: 22, D Loss: 0.10113732589545782, G Loss: 20.433956146240234\n",
      "Epoch: 31, Batch: 23, D Loss: 0.10156129353765542, G Loss: 20.86886978149414\n",
      "Epoch: 31, Batch: 24, D Loss: 0.09456118983641806, G Loss: 20.909391403198242\n",
      "Epoch: 31, Batch: 25, D Loss: 0.10338211099506056, G Loss: 20.983566284179688\n",
      "Epoch: 31, Batch: 26, D Loss: 0.1037331152599423, G Loss: 21.10464859008789\n",
      "Epoch: 31, Batch: 27, D Loss: 0.09687847683383932, G Loss: 20.838523864746094\n",
      "Epoch: 31, Batch: 28, D Loss: 0.09558048160062271, G Loss: 20.25119400024414\n",
      "Epoch: 31, Batch: 29, D Loss: 0.10586403390378663, G Loss: 20.254974365234375\n",
      "Epoch: 31, Batch: 30, D Loss: 0.09844696600050601, G Loss: 20.294397354125977\n",
      "Epoch: 31, Batch: 31, D Loss: 0.10099242696903982, G Loss: 20.49230194091797\n",
      "Epoch: 31, Batch: 32, D Loss: 0.09748474571048876, G Loss: 20.5078125\n",
      "Epoch: 31, Batch: 33, D Loss: 0.09983462904688867, G Loss: 20.438600540161133\n",
      "Epoch: 31, Batch: 34, D Loss: 0.10141295261253286, G Loss: 20.435457229614258\n",
      "Epoch: 31, Batch: 35, D Loss: 0.10089422083630567, G Loss: 20.44781494140625\n",
      "Epoch: 31, Batch: 36, D Loss: 0.09668262376747705, G Loss: 20.232168197631836\n",
      "Epoch: 31, Batch: 37, D Loss: 0.09843176693252242, G Loss: 20.05162811279297\n",
      "Epoch: 31, Batch: 38, D Loss: 0.09474633746753114, G Loss: 19.78643035888672\n",
      "Epoch: 31, Batch: 39, D Loss: 0.10731428961581024, G Loss: 20.251928329467773\n",
      "Epoch: 31, Batch: 40, D Loss: 0.09911764478347523, G Loss: 20.64518928527832\n",
      "Epoch: 31, Batch: 41, D Loss: 0.10233244345103085, G Loss: 20.984867095947266\n",
      "Epoch: 31, Batch: 42, D Loss: 0.09814277331564153, G Loss: 20.89983367919922\n",
      "Epoch: 31, Batch: 43, D Loss: 0.09734369865901432, G Loss: 20.508028030395508\n",
      "Epoch: 31, Batch: 44, D Loss: 0.09987685156386444, G Loss: 20.224851608276367\n",
      "Epoch: 31, Batch: 45, D Loss: 0.10330949799444439, G Loss: 20.384849548339844\n",
      "Epoch: 31, Batch: 46, D Loss: 0.0991247377021256, G Loss: 20.626935958862305\n",
      "Epoch: 31, Batch: 47, D Loss: 0.0995766674381065, G Loss: 20.861112594604492\n",
      "Epoch: 31, Batch: 48, D Loss: 0.09732388003485926, G Loss: 20.86354637145996\n",
      "Epoch: 31, Batch: 49, D Loss: 0.09715604086205631, G Loss: 20.629867553710938\n",
      "Epoch: 31, Batch: 50, D Loss: 0.09415084191849221, G Loss: 20.218978881835938\n",
      "Epoch: 31, Batch: 51, D Loss: 0.10509335324257674, G Loss: 20.418642044067383\n",
      "Epoch: 31, Batch: 52, D Loss: 0.10560920881838998, G Loss: 21.103181838989258\n",
      "Epoch: 31, Batch: 53, D Loss: 0.10063463476803536, G Loss: 21.529279708862305\n",
      "Epoch: 31, Batch: 54, D Loss: 0.10238474629110997, G Loss: 21.58933448791504\n",
      "Epoch: 31, Batch: 55, D Loss: 0.10110256100252124, G Loss: 21.307723999023438\n",
      "Epoch: 31, Batch: 56, D Loss: 0.09703924545685563, G Loss: 20.67896270751953\n",
      "Epoch: 31, Batch: 57, D Loss: 0.09841302850780292, G Loss: 20.168115615844727\n",
      "Epoch: 31, Batch: 58, D Loss: 0.0974366450864298, G Loss: 20.00638198852539\n",
      "Epoch: 31, Batch: 59, D Loss: 0.10357953688446686, G Loss: 20.466983795166016\n",
      "Epoch: 31, Batch: 60, D Loss: 0.09331724103721928, G Loss: 20.738224029541016\n",
      "Epoch: 31, Batch: 61, D Loss: 0.0960925226086295, G Loss: 20.851402282714844\n",
      "Epoch: 31, Batch: 62, D Loss: 0.09329423357809458, G Loss: 20.630290985107422\n",
      "Epoch: 31, Batch: 63, D Loss: 0.10366185059204819, G Loss: 20.81854248046875\n",
      "Epoch: 31, Batch: 64, D Loss: 0.1024221930654477, G Loss: 21.196327209472656\n",
      "Epoch: 31, Batch: 65, D Loss: 0.104428723702879, G Loss: 21.625301361083984\n",
      "Epoch: 31, Batch: 66, D Loss: 0.09780187926534599, G Loss: 21.49785041809082\n",
      "Epoch: 31, Batch: 67, D Loss: 0.09823896020624981, G Loss: 21.01027488708496\n",
      "Epoch: 31, Batch: 68, D Loss: 0.10354455602789084, G Loss: 20.78141212463379\n",
      "Epoch: 31, Batch: 69, D Loss: 0.09588545616581429, G Loss: 20.46526336669922\n",
      "Epoch: 31, Batch: 70, D Loss: 0.10177625778326121, G Loss: 20.530080795288086\n",
      "Epoch: 31, Batch: 71, D Loss: 0.09740179835443713, G Loss: 20.606739044189453\n",
      "Epoch: 31, Batch: 72, D Loss: 0.09272626104732667, G Loss: 20.4095401763916\n",
      "Epoch: 31, Batch: 73, D Loss: 0.10238696696247457, G Loss: 20.614295959472656\n",
      "Epoch: 31, Batch: 74, D Loss: 0.10417205138679769, G Loss: 21.090702056884766\n",
      "Epoch: 31, Batch: 75, D Loss: 0.10443000523031928, G Loss: 21.520610809326172\n",
      "Epoch: 31, Batch: 76, D Loss: 0.10370669534478688, G Loss: 21.69659996032715\n",
      "Epoch: 31, Batch: 77, D Loss: 0.10377298315871476, G Loss: 21.5534725189209\n",
      "Epoch: 31, Batch: 78, D Loss: 0.09853373496128928, G Loss: 21.062381744384766\n",
      "Epoch: 31, Batch: 79, D Loss: 0.10250332994669759, G Loss: 20.699926376342773\n",
      "Epoch: 31, Batch: 80, D Loss: 0.10290027462963863, G Loss: 20.628751754760742\n",
      "Epoch: 31, Batch: 81, D Loss: 0.09935685300192848, G Loss: 20.69852066040039\n",
      "Epoch: 31, Batch: 82, D Loss: 0.09973311470916496, G Loss: 20.877777099609375\n",
      "Epoch: 31, Batch: 83, D Loss: 0.10373210942392155, G Loss: 21.23938751220703\n",
      "Epoch: 31, Batch: 84, D Loss: 0.09643058510013944, G Loss: 21.156679153442383\n",
      "Epoch: 31, Batch: 85, D Loss: 0.0978795591825403, G Loss: 20.850736618041992\n",
      "Epoch: 31, Batch: 86, D Loss: 0.10142314482546244, G Loss: 20.667667388916016\n",
      "Epoch: 31, Batch: 87, D Loss: 0.10284306159751216, G Loss: 20.74431610107422\n",
      "Epoch: 31, Batch: 88, D Loss: 0.10293389900169972, G Loss: 20.976125717163086\n",
      "Epoch: 31, Batch: 89, D Loss: 0.10486011239270457, G Loss: 21.33385467529297\n",
      "Epoch: 31, Batch: 90, D Loss: 0.09917036471829663, G Loss: 21.28413200378418\n",
      "Epoch: 31, Batch: 91, D Loss: 0.10421322316300136, G Loss: 21.178916931152344\n",
      "Epoch: 31, Batch: 92, D Loss: 0.09525927943707926, G Loss: 20.625160217285156\n",
      "Epoch: 31, Batch: 93, D Loss: 0.09929293462679756, G Loss: 20.211902618408203\n",
      "Epoch: 31, Batch: 94, D Loss: 0.09858918277080014, G Loss: 20.131418228149414\n",
      "Epoch: 31, Batch: 95, D Loss: 0.09630003658033431, G Loss: 20.216022491455078\n",
      "Epoch: 31, Batch: 96, D Loss: 0.09276475094073006, G Loss: 20.247112274169922\n",
      "Epoch: 31, Batch: 97, D Loss: 0.10571889637966009, G Loss: 20.84847640991211\n",
      "Epoch: 31, Batch: 98, D Loss: 0.10229645701882958, G Loss: 21.43536949157715\n",
      "Epoch: 31, Batch: 99, D Loss: 0.0993410500212008, G Loss: 21.551597595214844\n",
      "Epoch: 31, Batch: 100, D Loss: 0.09865404691718985, G Loss: 21.202316284179688\n",
      "Epoch: 31, Batch: 101, D Loss: 0.09494987175698485, G Loss: 20.468400955200195\n",
      "Epoch: 31, Batch: 102, D Loss: 0.0994395025580962, G Loss: 20.071231842041016\n",
      "Epoch: 31, Batch: 103, D Loss: 0.09547833454257137, G Loss: 19.97699737548828\n",
      "Epoch: 31, Batch: 104, D Loss: 0.10080209463498802, G Loss: 20.299928665161133\n",
      "Epoch: 31, Batch: 105, D Loss: 0.09771353812217182, G Loss: 20.734058380126953\n",
      "Epoch: 31, Batch: 106, D Loss: 0.09914259654678759, G Loss: 21.042171478271484\n",
      "Epoch: 31, Batch: 107, D Loss: 0.09960391407832733, G Loss: 21.093727111816406\n",
      "Epoch: 31, Batch: 108, D Loss: 0.09382610067655656, G Loss: 20.607149124145508\n",
      "Epoch: 31, Batch: 109, D Loss: 0.10086558081318392, G Loss: 20.268125534057617\n",
      "Epoch: 31, Batch: 110, D Loss: 0.09503720796244486, G Loss: 19.904949188232422\n",
      "Epoch: 31, Batch: 111, D Loss: 0.09856384361949044, G Loss: 19.889772415161133\n",
      "Epoch: 31, Batch: 112, D Loss: 0.09646832301715891, G Loss: 20.087751388549805\n",
      "Epoch: 31, Batch: 113, D Loss: 0.1007951579838034, G Loss: 20.577415466308594\n",
      "Epoch: 31, Batch: 114, D Loss: 0.09901918518476821, G Loss: 20.950138092041016\n",
      "Epoch: 31, Batch: 115, D Loss: 0.10033403374259817, G Loss: 21.078857421875\n",
      "Epoch: 31, Batch: 116, D Loss: 0.10003589130363225, G Loss: 20.99275016784668\n",
      "Epoch: 31, Batch: 117, D Loss: 0.09538754869713384, G Loss: 20.52623748779297\n",
      "Epoch: 31, Batch: 118, D Loss: 0.10021519730988199, G Loss: 20.2615909576416\n",
      "Epoch: 31, Batch: 119, D Loss: 0.10381934115845537, G Loss: 20.525632858276367\n",
      "Epoch: 31, Batch: 120, D Loss: 0.09659710581578901, G Loss: 20.717456817626953\n",
      "Epoch: 31, Batch: 121, D Loss: 0.10089822901692347, G Loss: 21.01214599609375\n",
      "Epoch: 31, Batch: 122, D Loss: 0.10368230969706768, G Loss: 21.384033203125\n",
      "Epoch: 31, Batch: 123, D Loss: 0.10062013591282334, G Loss: 21.46231460571289\n",
      "Epoch: 31, Batch: 124, D Loss: 0.09480282695224426, G Loss: 20.970056533813477\n",
      "Epoch: 31, Batch: 125, D Loss: 0.10334564044244013, G Loss: 20.75119400024414\n",
      "Epoch: 31, Batch: 126, D Loss: 0.09526993389688554, G Loss: 20.504472732543945\n",
      "Epoch: 31, Batch: 127, D Loss: 0.10308454985530668, G Loss: 20.74909019470215\n",
      "Epoch: 31, Batch: 128, D Loss: 0.1015066508260144, G Loss: 21.23241424560547\n",
      "Epoch: 31, Batch: 129, D Loss: 0.094803728448904, G Loss: 21.32938003540039\n",
      "Epoch: 31, Batch: 130, D Loss: 0.09522873195048426, G Loss: 21.036623001098633\n",
      "Epoch: 31, Batch: 131, D Loss: 0.10121727028589372, G Loss: 20.921846389770508\n",
      "Epoch: 31, Batch: 132, D Loss: 0.1017228368843178, G Loss: 21.018165588378906\n",
      "Epoch: 31, Batch: 133, D Loss: 0.09760583229961595, G Loss: 20.987668991088867\n",
      "Epoch: 31, Batch: 134, D Loss: 0.10711532862971138, G Loss: 21.346864700317383\n",
      "Epoch: 31, Batch: 135, D Loss: 0.09660875825357279, G Loss: 21.25851058959961\n",
      "Epoch: 31, Batch: 136, D Loss: 0.1018132198001068, G Loss: 21.1356258392334\n",
      "Epoch: 31, Batch: 137, D Loss: 0.09272541896140737, G Loss: 20.53985595703125\n",
      "Epoch: 31, Batch: 138, D Loss: 0.10157635130905612, G Loss: 20.30632781982422\n",
      "Epoch: 31, Batch: 139, D Loss: 0.09100435022006398, G Loss: 19.924793243408203\n",
      "Epoch: 31, Batch: 140, D Loss: 0.10103210910418814, G Loss: 20.061553955078125\n",
      "Epoch: 31, Batch: 141, D Loss: 0.09887009939638647, G Loss: 20.414304733276367\n",
      "Epoch: 31, Batch: 142, D Loss: 0.09271270105222884, G Loss: 20.404165267944336\n",
      "Epoch: 31, Batch: 143, D Loss: 0.09538253472871039, G Loss: 20.213659286499023\n",
      "Epoch: 31, Batch: 144, D Loss: 0.09882246054070165, G Loss: 19.940475463867188\n",
      "Epoch: 31, Batch: 145, D Loss: 0.09691307057911758, G Loss: 19.945430755615234\n",
      "Epoch: 31, Batch: 146, D Loss: 0.09867823973844403, G Loss: 20.01883316040039\n",
      "Epoch: 31, Batch: 147, D Loss: 0.1086461402338938, G Loss: 20.6354923248291\n",
      "Epoch: 31, Batch: 148, D Loss: 0.0989185203973949, G Loss: 20.86806297302246\n",
      "Epoch: 31, Batch: 149, D Loss: 0.10304505421054602, G Loss: 20.878496170043945\n",
      "Epoch: 31, Batch: 150, D Loss: 0.10161310484264585, G Loss: 20.587406158447266\n",
      "Epoch: 31, Batch: 151, D Loss: 0.10034355596201527, G Loss: 20.07624626159668\n",
      "Epoch: 31, Batch: 152, D Loss: 0.09679597744220114, G Loss: 19.5242862701416\n",
      "Epoch: 31, Batch: 153, D Loss: 0.09227930229399539, G Loss: 18.991485595703125\n",
      "Epoch: 31, Batch: 154, D Loss: 0.09942457348325284, G Loss: 19.095317840576172\n",
      "Epoch: 31, Batch: 155, D Loss: 0.10109559628504206, G Loss: 19.737844467163086\n",
      "Epoch: 31, Batch: 156, D Loss: 0.10040577590005145, G Loss: 20.517597198486328\n",
      "Epoch: 31, Batch: 157, D Loss: 0.1010978077800948, G Loss: 20.940025329589844\n",
      "Epoch: 31, Batch: 158, D Loss: 0.09621446626657482, G Loss: 20.648120880126953\n",
      "Epoch: 31, Batch: 159, D Loss: 0.09742521577836588, G Loss: 19.823898315429688\n",
      "Epoch: 31, Batch: 160, D Loss: 0.1030990199196955, G Loss: 19.34604263305664\n",
      "Epoch: 31, Batch: 161, D Loss: 0.09804310878260747, G Loss: 19.080163955688477\n",
      "Epoch: 31, Batch: 162, D Loss: 0.0907866838234701, G Loss: 18.656660079956055\n",
      "Epoch: 31, Batch: 163, D Loss: 0.09619343696864746, G Loss: 18.567670822143555\n",
      "Epoch: 31, Batch: 164, D Loss: 0.09576549035585469, G Loss: 18.723888397216797\n",
      "Epoch: 31, Batch: 165, D Loss: 0.10264297096513086, G Loss: 19.34676742553711\n",
      "Epoch: 31, Batch: 166, D Loss: 0.09597300906510586, G Loss: 19.65900421142578\n",
      "Epoch: 31, Batch: 167, D Loss: 0.10197382554727585, G Loss: 19.805362701416016\n",
      "Epoch: 31, Batch: 168, D Loss: 0.09923008218130824, G Loss: 19.681964874267578\n",
      "Epoch: 31, Batch: 169, D Loss: 0.1003741637856903, G Loss: 19.45406150817871\n",
      "Epoch: 31, Batch: 170, D Loss: 0.09739212163464694, G Loss: 19.0722599029541\n",
      "Epoch: 31, Batch: 171, D Loss: 0.09785914711855725, G Loss: 18.87117576599121\n",
      "Epoch: 31, Batch: 172, D Loss: 0.09697897310096648, G Loss: 18.85415267944336\n",
      "Epoch: 31, Batch: 173, D Loss: 0.09661914699469021, G Loss: 19.064552307128906\n",
      "Epoch: 31, Batch: 174, D Loss: 0.09921173213099554, G Loss: 19.524383544921875\n",
      "Epoch: 31, Batch: 175, D Loss: 0.09559212026235442, G Loss: 19.766456604003906\n",
      "Epoch: 31, Batch: 176, D Loss: 0.10374899312774033, G Loss: 20.191049575805664\n",
      "Epoch: 31, Batch: 177, D Loss: 0.09787257098775937, G Loss: 20.239810943603516\n",
      "Epoch: 31, Batch: 178, D Loss: 0.10033519651328271, G Loss: 20.146228790283203\n",
      "Epoch: 31, Batch: 179, D Loss: 0.10396368891049906, G Loss: 20.1396484375\n",
      "Epoch: 31, Batch: 180, D Loss: 0.09853449561145089, G Loss: 19.98590850830078\n",
      "Epoch: 31, Batch: 181, D Loss: 0.10225778177861311, G Loss: 19.983688354492188\n",
      "Epoch: 31, Batch: 182, D Loss: 0.09556055188346924, G Loss: 19.738231658935547\n",
      "Epoch: 31, Batch: 183, D Loss: 0.10309707498192056, G Loss: 19.874942779541016\n",
      "Epoch: 31, Batch: 184, D Loss: 0.09975634619148499, G Loss: 20.100427627563477\n",
      "Epoch: 31, Batch: 185, D Loss: 0.09551764376475691, G Loss: 20.02967071533203\n",
      "Epoch: 31, Batch: 186, D Loss: 0.09982891485433565, G Loss: 19.9469051361084\n",
      "Epoch: 31, Batch: 187, D Loss: 0.0963196021490974, G Loss: 19.74677276611328\n",
      "Epoch: 31, Batch: 188, D Loss: 0.09601779424751544, G Loss: 19.6141357421875\n",
      "Epoch: 31, Batch: 189, D Loss: 0.09238267115854537, G Loss: 19.389673233032227\n",
      "Epoch: 31, Batch: 190, D Loss: 0.10289524650649273, G Loss: 19.777942657470703\n",
      "Epoch: 31, Batch: 191, D Loss: 0.09909010032746068, G Loss: 20.273046493530273\n",
      "Epoch: 31, Batch: 192, D Loss: 0.10104933443504394, G Loss: 20.708053588867188\n",
      "Epoch: 31, Batch: 193, D Loss: 0.10357250315484903, G Loss: 21.059003829956055\n",
      "Epoch: 31, Batch: 194, D Loss: 0.09730048518056103, G Loss: 20.828086853027344\n",
      "Epoch: 31, Batch: 195, D Loss: 0.10136377120082907, G Loss: 20.493955612182617\n",
      "Epoch: 31, Batch: 196, D Loss: 0.09659107111232185, G Loss: 19.995834350585938\n",
      "Epoch: 31, Batch: 197, D Loss: 0.1033515493864241, G Loss: 19.93109130859375\n",
      "Epoch: 31, Batch: 198, D Loss: 0.09773969755045842, G Loss: 20.03331756591797\n",
      "Epoch: 31, Batch: 199, D Loss: 0.1006202035513189, G Loss: 20.380638122558594\n",
      "Epoch: 31, Batch: 200, D Loss: 0.09009172845683944, G Loss: 20.181726455688477\n",
      "Epoch: 31, Batch: 201, D Loss: 0.10075807653532792, G Loss: 20.270095825195312\n",
      "Epoch: 31, Batch: 202, D Loss: 0.10167506401663834, G Loss: 20.648820877075195\n",
      "Epoch: 31, Batch: 203, D Loss: 0.09894453778778617, G Loss: 21.007728576660156\n",
      "Epoch: 31, Batch: 204, D Loss: 0.09687270263070663, G Loss: 20.941436767578125\n",
      "Epoch: 31, Batch: 205, D Loss: 0.09832090927919312, G Loss: 20.793703079223633\n",
      "Epoch: 31, Batch: 206, D Loss: 0.10267347887827219, G Loss: 20.845645904541016\n",
      "Epoch: 31, Batch: 207, D Loss: 0.10301795638809053, G Loss: 21.18785285949707\n",
      "Epoch: 31, Batch: 208, D Loss: 0.09878519206714409, G Loss: 21.323020935058594\n",
      "Epoch: 31, Batch: 209, D Loss: 0.09790796072341182, G Loss: 21.102577209472656\n",
      "Epoch: 31, Batch: 210, D Loss: 0.10322912071329157, G Loss: 21.117950439453125\n",
      "Epoch: 31, Batch: 211, D Loss: 0.10041353884664736, G Loss: 21.152177810668945\n",
      "Epoch: 31, Batch: 212, D Loss: 0.10151168734850968, G Loss: 21.25760269165039\n",
      "Epoch: 31, Batch: 213, D Loss: 0.0954721945757731, G Loss: 21.083677291870117\n",
      "Epoch: 31, Batch: 214, D Loss: 0.10064636950150802, G Loss: 21.11985969543457\n",
      "Epoch: 31, Batch: 215, D Loss: 0.09877555104459285, G Loss: 21.206401824951172\n",
      "Epoch: 31, Batch: 216, D Loss: 0.09674828529785193, G Loss: 21.245365142822266\n",
      "Epoch: 31, Batch: 217, D Loss: 0.10171970750675483, G Loss: 21.52469825744629\n",
      "Epoch: 31, Batch: 218, D Loss: 0.09888029118636674, G Loss: 21.731245040893555\n",
      "Epoch: 31, Batch: 219, D Loss: 0.1010536478645198, G Loss: 21.893856048583984\n",
      "Epoch: 31, Batch: 220, D Loss: 0.09997242704427607, G Loss: 21.92073631286621\n",
      "Epoch: 31, Batch: 221, D Loss: 0.10356415823006133, G Loss: 21.957576751708984\n",
      "Epoch: 31, Batch: 222, D Loss: 0.09973153487972321, G Loss: 21.773330688476562\n",
      "Epoch: 31, Batch: 223, D Loss: 0.09966632743863749, G Loss: 21.513965606689453\n",
      "Epoch: 31, Batch: 224, D Loss: 0.10432730636977125, G Loss: 21.586034774780273\n",
      "Epoch: 31, Batch: 225, D Loss: 0.0981014820116854, G Loss: 21.538795471191406\n",
      "Epoch: 31, Batch: 226, D Loss: 0.10372640212733332, G Loss: 21.709447860717773\n",
      "Epoch: 31, Batch: 227, D Loss: 0.09318415843198025, G Loss: 21.34345817565918\n",
      "Epoch: 31, Batch: 228, D Loss: 0.10514979090840351, G Loss: 21.381044387817383\n",
      "Epoch: 31, Batch: 229, D Loss: 0.0945353659963267, G Loss: 21.130517959594727\n",
      "Epoch: 31, Batch: 230, D Loss: 0.0971123207293389, G Loss: 20.95163917541504\n",
      "Epoch: 31, Batch: 231, D Loss: 0.09699533920764203, G Loss: 20.895498275756836\n",
      "Epoch: 31, Batch: 232, D Loss: 0.10348024996913446, G Loss: 21.384727478027344\n",
      "Epoch: 31, Batch: 233, D Loss: 0.10341770965035575, G Loss: 22.055442810058594\n",
      "Epoch: 31, Batch: 234, D Loss: 0.10102197539033173, G Loss: 22.375797271728516\n",
      "Epoch: 31, Batch: 235, D Loss: 0.09384614986053723, G Loss: 21.978498458862305\n",
      "Epoch: 31, Batch: 236, D Loss: 0.09841182102425476, G Loss: 21.37599754333496\n",
      "Epoch: 31, Batch: 237, D Loss: 0.09814160346720724, G Loss: 21.136363983154297\n",
      "Epoch: 31, Batch: 238, D Loss: 0.10105226961600419, G Loss: 21.4782657623291\n",
      "Epoch: 31, Batch: 239, D Loss: 0.100999593900131, G Loss: 22.143171310424805\n",
      "Epoch: 31, Batch: 240, D Loss: 0.09928275653895023, G Loss: 22.675495147705078\n",
      "Epoch: 31, Batch: 241, D Loss: 0.09902152425609478, G Loss: 22.837278366088867\n",
      "Epoch: 31, Batch: 242, D Loss: 0.09912468499652215, G Loss: 22.648752212524414\n",
      "Epoch: 31, Batch: 243, D Loss: 0.09896631547372074, G Loss: 22.352581024169922\n",
      "Epoch: 31, Batch: 244, D Loss: 0.09842177491565204, G Loss: 22.115541458129883\n",
      "Epoch: 31, Batch: 245, D Loss: 0.09719761474243697, G Loss: 21.997196197509766\n",
      "Epoch: 31, Batch: 246, D Loss: 0.09449887289524048, G Loss: 22.019216537475586\n",
      "Epoch: 31, Batch: 247, D Loss: 0.10192060481394469, G Loss: 22.465829849243164\n",
      "Epoch: 31, Batch: 248, D Loss: 0.10485932981864252, G Loss: 23.22040557861328\n",
      "Epoch: 31, Batch: 249, D Loss: 0.09643432501773584, G Loss: 23.374624252319336\n",
      "Epoch: 31, Batch: 250, D Loss: 0.09513886277346538, G Loss: 22.937469482421875\n",
      "Epoch: 31, Batch: 251, D Loss: 0.09744632251463219, G Loss: 22.36159324645996\n",
      "Epoch: 31, Batch: 252, D Loss: 0.10426291088582831, G Loss: 22.259363174438477\n",
      "Epoch: 31, Batch: 253, D Loss: 0.10490389177118181, G Loss: 22.620586395263672\n",
      "Epoch: 31, Batch: 254, D Loss: 0.09501202411904608, G Loss: 22.644472122192383\n",
      "Epoch: 31, Batch: 255, D Loss: 0.09232562044719018, G Loss: 22.167428970336914\n",
      "Epoch: 31, Batch: 256, D Loss: 0.09547604635685883, G Loss: 21.680824279785156\n",
      "Epoch: 31, Batch: 257, D Loss: 0.09474825881631949, G Loss: 21.374492645263672\n",
      "Epoch: 31, Batch: 258, D Loss: 0.09433589156809857, G Loss: 21.36794662475586\n",
      "Epoch: 31, Batch: 259, D Loss: 0.10200112332166504, G Loss: 21.971385955810547\n",
      "Epoch: 31, Batch: 260, D Loss: 0.09502103191367173, G Loss: 22.36102867126465\n",
      "Epoch: 31, Batch: 261, D Loss: 0.10410983868171074, G Loss: 22.80723762512207\n",
      "Epoch: 31, Batch: 262, D Loss: 0.10047389572655971, G Loss: 22.95470428466797\n",
      "Epoch: 31, Batch: 263, D Loss: 0.09977427876062808, G Loss: 22.734676361083984\n",
      "Epoch: 31, Batch: 264, D Loss: 0.10415967561005773, G Loss: 22.60732078552246\n",
      "Epoch: 31, Batch: 265, D Loss: 0.10129950948946614, G Loss: 22.43103790283203\n",
      "Epoch: 31, Batch: 266, D Loss: 0.10007121423715501, G Loss: 22.288681030273438\n",
      "Epoch: 31, Batch: 267, D Loss: 0.09895879041215155, G Loss: 22.19338035583496\n",
      "Epoch: 31, Batch: 268, D Loss: 0.09747750323848588, G Loss: 22.150598526000977\n",
      "Epoch: 31, Batch: 269, D Loss: 0.09927536558745044, G Loss: 22.221370697021484\n",
      "Epoch: 31, Batch: 270, D Loss: 0.09621368359588323, G Loss: 22.253929138183594\n",
      "Epoch: 31, Batch: 271, D Loss: 0.1025884897450838, G Loss: 22.533002853393555\n",
      "Epoch: 31, Batch: 272, D Loss: 0.10151025659663564, G Loss: 22.890262603759766\n",
      "Epoch: 31, Batch: 273, D Loss: 0.10043022041722646, G Loss: 23.084468841552734\n",
      "Epoch: 31, Batch: 274, D Loss: 0.10546568040536514, G Loss: 23.191650390625\n",
      "Epoch: 31, Batch: 275, D Loss: 0.10010069613070706, G Loss: 23.12715721130371\n",
      "Epoch: 31, Batch: 276, D Loss: 0.09585404401860101, G Loss: 22.64897918701172\n",
      "Epoch: 31, Batch: 277, D Loss: 0.09169525663398548, G Loss: 21.980417251586914\n",
      "Epoch: 31, Batch: 278, D Loss: 0.0999976546990877, G Loss: 21.98578643798828\n",
      "Epoch: 31, Batch: 279, D Loss: 0.1010919139775541, G Loss: 22.664857864379883\n",
      "Epoch: 31, Batch: 280, D Loss: 0.10387028013190255, G Loss: 23.549468994140625\n",
      "Epoch: 31, Batch: 281, D Loss: 0.10272075982944394, G Loss: 24.2545166015625\n",
      "Epoch: 31, Batch: 282, D Loss: 0.09952500464077163, G Loss: 24.151287078857422\n",
      "Epoch: 31, Batch: 283, D Loss: 0.09762902560181697, G Loss: 23.46102523803711\n",
      "Epoch: 31, Batch: 284, D Loss: 0.09729339932212196, G Loss: 22.71649169921875\n",
      "Epoch: 31, Batch: 285, D Loss: 0.10479946441452823, G Loss: 22.67741584777832\n",
      "Epoch: 31, Batch: 286, D Loss: 0.09636983282012132, G Loss: 22.812530517578125\n",
      "Epoch: 31, Batch: 287, D Loss: 0.10163307939791505, G Loss: 23.298124313354492\n",
      "Epoch: 31, Batch: 288, D Loss: 0.10052867236735763, G Loss: 23.762008666992188\n",
      "Epoch: 31, Batch: 289, D Loss: 0.10719932617672157, G Loss: 24.186006546020508\n",
      "Epoch: 31, Batch: 290, D Loss: 0.09447186442105286, G Loss: 23.844112396240234\n",
      "Epoch: 31, Batch: 291, D Loss: 0.09321544322961689, G Loss: 22.924148559570312\n",
      "Epoch: 31, Batch: 292, D Loss: 0.10121458031377309, G Loss: 22.321744918823242\n",
      "Epoch: 31, Batch: 293, D Loss: 0.09448388231184664, G Loss: 21.95014762878418\n",
      "Epoch: 31, Batch: 294, D Loss: 0.0905282871585442, G Loss: 21.72490692138672\n",
      "Epoch: 31, Batch: 295, D Loss: 0.10278213038198897, G Loss: 22.230939865112305\n",
      "Epoch: 31, Batch: 296, D Loss: 0.09917466350629364, G Loss: 22.803382873535156\n",
      "Epoch: 31, Batch: 297, D Loss: 0.0970005244575, G Loss: 23.016080856323242\n",
      "Epoch: 31, Batch: 298, D Loss: 0.09962978964556207, G Loss: 22.86311149597168\n",
      "Epoch: 31, Batch: 299, D Loss: 0.09909605242374617, G Loss: 22.39716911315918\n",
      "Epoch: 31, Batch: 300, D Loss: 0.09757848096931863, G Loss: 21.78097152709961\n",
      "Epoch: 31, Batch: 301, D Loss: 0.09967781623425562, G Loss: 21.50413703918457\n",
      "Epoch: 31, Batch: 302, D Loss: 0.10332086702408716, G Loss: 21.75343132019043\n",
      "Epoch: 31, Batch: 303, D Loss: 0.10514976841861116, G Loss: 22.417556762695312\n",
      "Epoch: 31, Batch: 304, D Loss: 0.10523095733540191, G Loss: 23.051403045654297\n",
      "Epoch: 31, Batch: 305, D Loss: 0.09805911039211525, G Loss: 23.05463409423828\n",
      "Epoch: 31, Batch: 306, D Loss: 0.10191344475730514, G Loss: 22.670188903808594\n",
      "Epoch: 31, Batch: 307, D Loss: 0.09761061529604506, G Loss: 21.985010147094727\n",
      "Epoch: 31, Batch: 308, D Loss: 0.0982644187254427, G Loss: 21.49875831604004\n",
      "Epoch: 31, Batch: 309, D Loss: 0.10272333046865358, G Loss: 21.680204391479492\n",
      "Epoch: 31, Batch: 310, D Loss: 0.10130822673283893, G Loss: 22.183237075805664\n",
      "Epoch: 31, Batch: 311, D Loss: 0.09518325339348105, G Loss: 22.37063217163086\n",
      "Epoch: 31, Batch: 312, D Loss: 0.09618418673876666, G Loss: 22.27311134338379\n",
      "Epoch: 31, Batch: 313, D Loss: 0.09856474411064459, G Loss: 22.121110916137695\n",
      "Epoch: 31, Batch: 314, D Loss: 0.1000770927783307, G Loss: 22.01365089416504\n",
      "Epoch: 31, Batch: 315, D Loss: 0.09847997143381021, G Loss: 21.925121307373047\n",
      "Epoch: 31, Batch: 316, D Loss: 0.10219890638203091, G Loss: 22.07176399230957\n",
      "Epoch: 31, Batch: 317, D Loss: 0.09623269004971054, G Loss: 22.031455993652344\n",
      "Epoch: 31, Batch: 318, D Loss: 0.1009733156673588, G Loss: 22.100130081176758\n",
      "Epoch: 31, Batch: 319, D Loss: 0.09779204441297917, G Loss: 22.029054641723633\n",
      "Epoch: 31, Batch: 320, D Loss: 0.10198763770848308, G Loss: 22.12189483642578\n",
      "Epoch: 31, Batch: 321, D Loss: 0.09964069736249984, G Loss: 22.150123596191406\n",
      "Epoch: 31, Batch: 322, D Loss: 0.10110659164370048, G Loss: 22.135066986083984\n",
      "Epoch: 31, Batch: 323, D Loss: 0.10188195121838749, G Loss: 22.091297149658203\n",
      "Epoch: 31, Batch: 324, D Loss: 0.09812723114406303, G Loss: 21.881179809570312\n",
      "Epoch: 31, Batch: 325, D Loss: 0.1024860219779652, G Loss: 21.831933975219727\n",
      "Epoch: 31, Batch: 326, D Loss: 0.10445058360635938, G Loss: 22.033573150634766\n",
      "Epoch: 31, Batch: 327, D Loss: 0.10125385237739269, G Loss: 22.115495681762695\n",
      "Epoch: 31, Batch: 328, D Loss: 0.10100463045427123, G Loss: 22.073749542236328\n",
      "Epoch: 31, Batch: 329, D Loss: 0.09060500580528885, G Loss: 21.415800094604492\n",
      "Epoch: 31, Batch: 330, D Loss: 0.10114597558850677, G Loss: 21.091432571411133\n",
      "Epoch: 31, Batch: 331, D Loss: 0.09664962477005981, G Loss: 21.002553939819336\n",
      "Epoch: 31, Batch: 332, D Loss: 0.10357563971676992, G Loss: 21.506446838378906\n",
      "Epoch: 31, Batch: 333, D Loss: 0.10081267373812534, G Loss: 22.075838088989258\n",
      "Epoch: 31, Batch: 334, D Loss: 0.09270195676623282, G Loss: 21.973352432250977\n",
      "Epoch: 31, Batch: 335, D Loss: 0.10168627664948261, G Loss: 21.835750579833984\n",
      "Epoch: 31, Batch: 336, D Loss: 0.09963789600362533, G Loss: 21.652732849121094\n",
      "Epoch: 31, Batch: 337, D Loss: 0.10382884759666774, G Loss: 21.742341995239258\n",
      "Epoch: 31, Batch: 338, D Loss: 0.1022915841787276, G Loss: 21.92647933959961\n",
      "Epoch: 31, Batch: 339, D Loss: 0.09969444587521946, G Loss: 21.98017692565918\n",
      "Epoch: 31, Batch: 340, D Loss: 0.09843037292833458, G Loss: 21.83327293395996\n",
      "Epoch: 31, Batch: 341, D Loss: 0.09645321239449585, G Loss: 21.535327911376953\n",
      "Epoch: 31, Batch: 342, D Loss: 0.09672170903248939, G Loss: 21.250595092773438\n",
      "Epoch: 31, Batch: 343, D Loss: 0.09879946737502326, G Loss: 21.296123504638672\n",
      "Epoch: 31, Batch: 344, D Loss: 0.10510946831169976, G Loss: 21.864057540893555\n",
      "Epoch: 31, Batch: 345, D Loss: 0.09471534207257706, G Loss: 22.023466110229492\n",
      "Epoch: 31, Batch: 346, D Loss: 0.09723347440079315, G Loss: 21.88992691040039\n",
      "Epoch: 31, Batch: 347, D Loss: 0.09590129573156347, G Loss: 21.524824142456055\n",
      "Epoch: 31, Batch: 348, D Loss: 0.09994370514258932, G Loss: 21.401309967041016\n",
      "Epoch: 31, Batch: 349, D Loss: 0.09766882683106023, G Loss: 21.423099517822266\n",
      "Epoch: 31, Batch: 350, D Loss: 0.10086603483978325, G Loss: 21.716796875\n",
      "Epoch: 31, Batch: 351, D Loss: 0.09878890232408592, G Loss: 21.988691329956055\n",
      "Epoch: 31, Batch: 352, D Loss: 0.0986570270222484, G Loss: 22.06779670715332\n",
      "Epoch: 31, Batch: 353, D Loss: 0.09624007359030043, G Loss: 21.828611373901367\n",
      "Epoch: 31, Batch: 354, D Loss: 0.09135223202917815, G Loss: 21.214853286743164\n",
      "Epoch: 31, Batch: 355, D Loss: 0.10023129019499705, G Loss: 21.063079833984375\n",
      "Epoch: 31, Batch: 356, D Loss: 0.0986163619304144, G Loss: 21.31206512451172\n",
      "Epoch: 31, Batch: 357, D Loss: 0.10588102805699055, G Loss: 22.139423370361328\n",
      "Epoch: 31, Batch: 358, D Loss: 0.10367681839405929, G Loss: 22.86121940612793\n",
      "Epoch: 31, Batch: 359, D Loss: 0.10359492903276799, G Loss: 23.067163467407227\n",
      "Epoch: 31, Batch: 360, D Loss: 0.09931035346050118, G Loss: 22.572641372680664\n",
      "Epoch: 31, Batch: 361, D Loss: 0.09643667948892035, G Loss: 21.683513641357422\n",
      "Epoch: 31, Batch: 362, D Loss: 0.10046274985586176, G Loss: 21.132789611816406\n",
      "Epoch: 31, Batch: 363, D Loss: 0.09051917535352325, G Loss: 20.686290740966797\n",
      "Epoch: 31, Batch: 364, D Loss: 0.09763005423421595, G Loss: 20.852954864501953\n",
      "Epoch: 31, Batch: 365, D Loss: 0.09771008821612881, G Loss: 21.44993782043457\n",
      "Epoch: 31, Batch: 366, D Loss: 0.1003913732025697, G Loss: 22.184680938720703\n",
      "Epoch: 31, Batch: 367, D Loss: 0.10095988223289577, G Loss: 22.60751724243164\n",
      "Epoch: 31, Batch: 368, D Loss: 0.09880828865896206, G Loss: 22.400005340576172\n",
      "Epoch: 31, Batch: 369, D Loss: 0.09524689629135179, G Loss: 21.580659866333008\n",
      "Epoch: 31, Batch: 370, D Loss: 0.10061939835140382, G Loss: 20.96068572998047\n",
      "Epoch: 31, Batch: 371, D Loss: 0.10281756561354125, G Loss: 20.884042739868164\n",
      "Epoch: 31, Batch: 372, D Loss: 0.09556433598027084, G Loss: 21.024629592895508\n",
      "Epoch: 31, Batch: 373, D Loss: 0.09152734318048139, G Loss: 20.95393180847168\n",
      "Epoch: 31, Batch: 374, D Loss: 0.10208909991013332, G Loss: 21.339950561523438\n",
      "Epoch: 31, Batch: 375, D Loss: 0.09133980449810578, G Loss: 21.36829948425293\n",
      "Epoch: 31, Batch: 376, D Loss: 0.10198558145293923, G Loss: 21.58924102783203\n",
      "Epoch: 31, Batch: 377, D Loss: 0.10294640081948175, G Loss: 21.915409088134766\n",
      "Epoch: 31, Batch: 378, D Loss: 0.09798625126686851, G Loss: 21.924827575683594\n",
      "Epoch: 31, Batch: 379, D Loss: 0.10347645744571664, G Loss: 21.956378936767578\n",
      "Epoch: 31, Batch: 380, D Loss: 0.1026148946540216, G Loss: 21.969745635986328\n",
      "Epoch: 31, Batch: 381, D Loss: 0.10033522562044776, G Loss: 21.79567527770996\n",
      "Epoch: 31, Batch: 382, D Loss: 0.10030671972756344, G Loss: 21.63739013671875\n",
      "Epoch: 31, Batch: 383, D Loss: 0.10132578780308371, G Loss: 21.649612426757812\n",
      "Epoch: 31, Batch: 384, D Loss: 0.11289954196597743, G Loss: 22.74391746520996\n",
      "Epoch: 31, Batch: 385, D Loss: 0.09682604677161083, G Loss: 22.74226188659668\n",
      "Epoch: 31, Batch: 386, D Loss: 0.100562281992081, G Loss: 22.26272964477539\n",
      "Epoch: 31, Batch: 387, D Loss: 0.1008994729741338, G Loss: 21.737899780273438\n",
      "Epoch: 31, Batch: 388, D Loss: 0.09126582024910404, G Loss: 20.89345359802246\n",
      "Epoch: 31, Batch: 389, D Loss: 0.09429870600136686, G Loss: 20.413894653320312\n",
      "Epoch: 31, Batch: 390, D Loss: 0.09861344157919727, G Loss: 20.691165924072266\n",
      "Epoch: 31, Batch: 391, D Loss: 0.09689301291601773, G Loss: 21.21274185180664\n",
      "Epoch: 31, Batch: 392, D Loss: 0.10152060560342156, G Loss: 21.837980270385742\n",
      "Epoch: 31, Batch: 393, D Loss: 0.09882488116659598, G Loss: 22.015827178955078\n",
      "Epoch: 31, Batch: 394, D Loss: 0.1040356682136, G Loss: 21.999313354492188\n",
      "Epoch: 31, Batch: 395, D Loss: 0.09663497675406116, G Loss: 21.429004669189453\n",
      "Epoch: 31, Batch: 396, D Loss: 0.09748218988678026, G Loss: 20.761993408203125\n",
      "Epoch: 31, Batch: 397, D Loss: 0.10469082792019041, G Loss: 20.72487449645996\n",
      "Epoch: 31, Batch: 398, D Loss: 0.09474578551215412, G Loss: 20.670196533203125\n",
      "Epoch: 31, Batch: 399, D Loss: 0.09791536679979673, G Loss: 20.74323844909668\n",
      "Epoch: 31, Batch: 400, D Loss: 0.0990689177817912, G Loss: 20.9164981842041\n",
      "Epoch: 31, Batch: 401, D Loss: 0.10136455332586308, G Loss: 21.221656799316406\n",
      "Epoch: 31, Batch: 402, D Loss: 0.09827123611074376, G Loss: 21.32929039001465\n",
      "Epoch: 31, Batch: 403, D Loss: 0.09502445193567749, G Loss: 21.01290512084961\n",
      "Epoch: 31, Batch: 404, D Loss: 0.09767881826336741, G Loss: 20.643810272216797\n",
      "Epoch: 31, Batch: 405, D Loss: 0.10021956322442216, G Loss: 20.53205108642578\n",
      "Epoch: 31, Batch: 406, D Loss: 0.09619195820498438, G Loss: 20.513185501098633\n",
      "Epoch: 31, Batch: 407, D Loss: 0.09820745941843434, G Loss: 20.68289566040039\n",
      "Epoch: 31, Batch: 408, D Loss: 0.09794043801536007, G Loss: 20.687816619873047\n",
      "Epoch: 31, Batch: 409, D Loss: 0.09896856598165638, G Loss: 20.690893173217773\n",
      "Epoch: 31, Batch: 410, D Loss: 0.10209545542690052, G Loss: 20.770565032958984\n",
      "Epoch: 31, Batch: 411, D Loss: 0.10288053051938725, G Loss: 20.840564727783203\n",
      "Epoch: 31, Batch: 412, D Loss: 0.09767057055610906, G Loss: 20.47243309020996\n",
      "Epoch: 31, Batch: 413, D Loss: 0.10250839666399897, G Loss: 20.17144012451172\n",
      "Epoch: 31, Batch: 414, D Loss: 0.09720054374542642, G Loss: 19.800540924072266\n",
      "Epoch: 31, Batch: 415, D Loss: 0.09900696715651647, G Loss: 19.60172462463379\n",
      "Epoch: 31, Batch: 416, D Loss: 0.0981663480981827, G Loss: 19.590185165405273\n",
      "Epoch: 31, Batch: 417, D Loss: 0.09526577749578591, G Loss: 19.565818786621094\n",
      "Epoch: 31, Batch: 418, D Loss: 0.10653363282705497, G Loss: 20.194061279296875\n",
      "Epoch: 31, Batch: 419, D Loss: 0.09431640883454834, G Loss: 20.317689895629883\n",
      "Epoch: 31, Batch: 420, D Loss: 0.10134953334012953, G Loss: 20.35630226135254\n",
      "Epoch: 31, Batch: 421, D Loss: 0.09643948163569382, G Loss: 20.03851890563965\n",
      "Epoch: 31, Batch: 422, D Loss: 0.10129775215675108, G Loss: 19.866249084472656\n",
      "Epoch: 31, Batch: 423, D Loss: 0.10026915489830279, G Loss: 19.860307693481445\n",
      "Epoch: 31, Batch: 424, D Loss: 0.10000173855206351, G Loss: 20.0460205078125\n",
      "Epoch: 31, Batch: 425, D Loss: 0.08937995253289055, G Loss: 19.712688446044922\n",
      "Epoch: 31, Batch: 426, D Loss: 0.09751205295092713, G Loss: 19.565080642700195\n",
      "Epoch: 31, Batch: 427, D Loss: 0.09924242042680309, G Loss: 19.783342361450195\n",
      "Epoch: 31, Batch: 428, D Loss: 0.09384355070028394, G Loss: 19.89346694946289\n",
      "Epoch: 31, Batch: 429, D Loss: 0.0946847658738057, G Loss: 19.92296600341797\n",
      "Epoch: 31, Batch: 430, D Loss: 0.09977471928604198, G Loss: 20.127077102661133\n",
      "Epoch: 31, Batch: 431, D Loss: 0.0998762257797059, G Loss: 20.405132293701172\n",
      "Epoch: 31, Batch: 432, D Loss: 0.10643824241502653, G Loss: 20.952735900878906\n",
      "Epoch: 31, Batch: 433, D Loss: 0.09768403361260061, G Loss: 20.953638076782227\n",
      "Epoch: 31, Batch: 434, D Loss: 0.09961535827890189, G Loss: 20.666017532348633\n",
      "Epoch: 31, Batch: 435, D Loss: 0.09856651788450493, G Loss: 20.275732040405273\n",
      "Epoch: 31, Batch: 436, D Loss: 0.09864841489825649, G Loss: 20.049224853515625\n",
      "Epoch: 31, Batch: 437, D Loss: 0.09669385207868508, G Loss: 19.969371795654297\n",
      "Epoch: 31, Batch: 438, D Loss: 0.0945977728304318, G Loss: 19.965757369995117\n",
      "Epoch: 31, Batch: 439, D Loss: 0.09937496572812632, G Loss: 20.301815032958984\n",
      "Epoch: 31, Batch: 440, D Loss: 0.09806081713902065, G Loss: 20.717182159423828\n",
      "Epoch: 31, Batch: 441, D Loss: 0.10450321473044646, G Loss: 21.298728942871094\n",
      "Epoch: 31, Batch: 442, D Loss: 0.09630950568998733, G Loss: 21.261348724365234\n",
      "Epoch: 31, Batch: 443, D Loss: 0.09307555150503882, G Loss: 20.606792449951172\n",
      "Epoch: 31, Batch: 444, D Loss: 0.09524133883226044, G Loss: 19.89473533630371\n",
      "Epoch: 31, Batch: 445, D Loss: 0.09414969525363714, G Loss: 19.508413314819336\n",
      "Epoch: 31, Batch: 446, D Loss: 0.0994929014562641, G Loss: 19.88909912109375\n",
      "Epoch: 31, Batch: 447, D Loss: 0.09479972061562736, G Loss: 20.43543243408203\n",
      "Epoch: 31, Batch: 448, D Loss: 0.09756650079482987, G Loss: 21.024612426757812\n",
      "Epoch: 31, Batch: 449, D Loss: 0.09521937403779673, G Loss: 21.213844299316406\n",
      "Epoch: 31, Batch: 450, D Loss: 0.09895188393478524, G Loss: 21.125965118408203\n",
      "Epoch: 31, Batch: 451, D Loss: 0.09979220516136236, G Loss: 20.964582443237305\n",
      "Epoch: 31, Batch: 452, D Loss: 0.10198952297257943, G Loss: 20.949241638183594\n",
      "Epoch: 31, Batch: 453, D Loss: 0.09829061519450435, G Loss: 20.894878387451172\n",
      "Epoch: 31, Batch: 454, D Loss: 0.0997178856739544, G Loss: 20.90993881225586\n",
      "Epoch: 31, Batch: 455, D Loss: 0.09357936726316973, G Loss: 20.715017318725586\n",
      "Epoch: 31, Batch: 456, D Loss: 0.09879988482547009, G Loss: 20.709108352661133\n",
      "Epoch: 31, Batch: 457, D Loss: 0.09933935151681861, G Loss: 20.900802612304688\n",
      "Epoch: 31, Batch: 458, D Loss: 0.10743862418157296, G Loss: 21.68076515197754\n",
      "Epoch: 31, Batch: 459, D Loss: 0.09860705603544172, G Loss: 21.674898147583008\n",
      "Epoch: 31, Batch: 460, D Loss: 0.1027731897570631, G Loss: 21.494762420654297\n",
      "Epoch: 31, Batch: 461, D Loss: 0.10511375988164282, G Loss: 21.406864166259766\n",
      "Epoch: 31, Batch: 462, D Loss: 0.09685755553569816, G Loss: 20.92682456970215\n",
      "Epoch: 31, Batch: 463, D Loss: 0.09770393424063761, G Loss: 20.441139221191406\n",
      "Epoch: 31, Batch: 464, D Loss: 0.09596665281381, G Loss: 20.13918685913086\n",
      "Epoch: 31, Batch: 465, D Loss: 0.09520234261037608, G Loss: 20.063499450683594\n",
      "Epoch: 31, Batch: 466, D Loss: 0.10546095733837718, G Loss: 20.824302673339844\n",
      "Epoch: 31, Batch: 467, D Loss: 0.10373076825251087, G Loss: 21.68417739868164\n",
      "Epoch: 32, Batch: 0, D Loss: 0.10177996770261995, G Loss: 22.069791793823242\n",
      "Epoch: 32, Batch: 1, D Loss: 0.09680707769054127, G Loss: 21.635284423828125\n",
      "Epoch: 32, Batch: 2, D Loss: 0.09938979923265628, G Loss: 20.913318634033203\n",
      "Epoch: 32, Batch: 3, D Loss: 0.1069014226098074, G Loss: 20.683971405029297\n",
      "Epoch: 32, Batch: 4, D Loss: 0.09509155960150123, G Loss: 20.38678550720215\n",
      "Epoch: 32, Batch: 5, D Loss: 0.10190990631024716, G Loss: 20.564565658569336\n",
      "Epoch: 32, Batch: 6, D Loss: 0.09752070955706282, G Loss: 20.795822143554688\n",
      "Epoch: 32, Batch: 7, D Loss: 0.09362299788247247, G Loss: 20.739742279052734\n",
      "Epoch: 32, Batch: 8, D Loss: 0.09753175875738129, G Loss: 20.677730560302734\n",
      "Epoch: 32, Batch: 9, D Loss: 0.10504075928169199, G Loss: 21.03655433654785\n",
      "Epoch: 32, Batch: 10, D Loss: 0.10142621428712509, G Loss: 21.366376876831055\n",
      "Epoch: 32, Batch: 11, D Loss: 0.09413531452701598, G Loss: 21.110166549682617\n",
      "Epoch: 32, Batch: 12, D Loss: 0.09937740158318753, G Loss: 20.75278091430664\n",
      "Epoch: 32, Batch: 13, D Loss: 0.10198107412114465, G Loss: 20.686189651489258\n",
      "Epoch: 32, Batch: 14, D Loss: 0.10035388221193209, G Loss: 20.776594161987305\n",
      "Epoch: 32, Batch: 15, D Loss: 0.10290063212724884, G Loss: 21.09288787841797\n",
      "Epoch: 32, Batch: 16, D Loss: 0.10052190752288812, G Loss: 21.284914016723633\n",
      "Epoch: 32, Batch: 17, D Loss: 0.09963090002272126, G Loss: 21.218870162963867\n",
      "Epoch: 32, Batch: 18, D Loss: 0.09808657354017292, G Loss: 20.919830322265625\n",
      "Epoch: 32, Batch: 19, D Loss: 0.09406695568340284, G Loss: 20.421480178833008\n",
      "Epoch: 32, Batch: 20, D Loss: 0.09697800952655528, G Loss: 20.15357780456543\n",
      "Epoch: 32, Batch: 21, D Loss: 0.09431115629060072, G Loss: 20.097530364990234\n",
      "Epoch: 32, Batch: 22, D Loss: 0.09435207482361307, G Loss: 20.267362594604492\n",
      "Epoch: 32, Batch: 23, D Loss: 0.09304887125847211, G Loss: 20.510305404663086\n",
      "Epoch: 32, Batch: 24, D Loss: 0.09770728696632186, G Loss: 20.957622528076172\n",
      "Epoch: 32, Batch: 25, D Loss: 0.10399284985314897, G Loss: 21.721643447875977\n",
      "Epoch: 32, Batch: 26, D Loss: 0.0997178779518195, G Loss: 22.15644645690918\n",
      "Epoch: 32, Batch: 27, D Loss: 0.10186296713432821, G Loss: 22.145044326782227\n",
      "Epoch: 32, Batch: 28, D Loss: 0.10426712049937316, G Loss: 21.889320373535156\n",
      "Epoch: 32, Batch: 29, D Loss: 0.09974685332226867, G Loss: 21.328990936279297\n",
      "Epoch: 32, Batch: 30, D Loss: 0.09901378339305489, G Loss: 20.827320098876953\n",
      "Epoch: 32, Batch: 31, D Loss: 0.0972550367510665, G Loss: 20.570512771606445\n",
      "Epoch: 32, Batch: 32, D Loss: 0.09892945046926649, G Loss: 20.66986656188965\n",
      "Epoch: 32, Batch: 33, D Loss: 0.09997235282084549, G Loss: 21.035633087158203\n",
      "Epoch: 32, Batch: 34, D Loss: 0.0940986577127943, G Loss: 21.15834617614746\n",
      "Epoch: 32, Batch: 35, D Loss: 0.10032879590730498, G Loss: 21.332996368408203\n",
      "Epoch: 32, Batch: 36, D Loss: 0.10118386919890723, G Loss: 21.460237503051758\n",
      "Epoch: 32, Batch: 37, D Loss: 0.10173030965850326, G Loss: 21.52198600769043\n",
      "Epoch: 32, Batch: 38, D Loss: 0.09490226236571891, G Loss: 21.14844512939453\n",
      "Epoch: 32, Batch: 39, D Loss: 0.0927412067406532, G Loss: 20.531410217285156\n",
      "Epoch: 32, Batch: 40, D Loss: 0.0949558548551564, G Loss: 20.160131454467773\n",
      "Epoch: 32, Batch: 41, D Loss: 0.09729274440943303, G Loss: 20.37286376953125\n",
      "Epoch: 32, Batch: 42, D Loss: 0.1004507695634882, G Loss: 21.051998138427734\n",
      "Epoch: 32, Batch: 43, D Loss: 0.09492345182459724, G Loss: 21.518125534057617\n",
      "Epoch: 32, Batch: 44, D Loss: 0.10077608395632436, G Loss: 21.85748291015625\n",
      "Epoch: 32, Batch: 45, D Loss: 0.09463868308625974, G Loss: 21.598112106323242\n",
      "Epoch: 32, Batch: 46, D Loss: 0.10119812214599419, G Loss: 21.326908111572266\n",
      "Epoch: 32, Batch: 47, D Loss: 0.10275346069020203, G Loss: 21.26271629333496\n",
      "Epoch: 32, Batch: 48, D Loss: 0.09558995101316137, G Loss: 21.014286041259766\n",
      "Epoch: 32, Batch: 49, D Loss: 0.10148423946809484, G Loss: 21.05182456970215\n",
      "Epoch: 32, Batch: 50, D Loss: 0.09953555497897706, G Loss: 21.209354400634766\n",
      "Epoch: 32, Batch: 51, D Loss: 0.1035918521431124, G Loss: 21.58064079284668\n",
      "Epoch: 32, Batch: 52, D Loss: 0.09465667627444477, G Loss: 21.50867462158203\n",
      "Epoch: 32, Batch: 53, D Loss: 0.09763555999808007, G Loss: 21.256011962890625\n",
      "Epoch: 32, Batch: 54, D Loss: 0.09782746468235201, G Loss: 20.976123809814453\n",
      "Epoch: 32, Batch: 55, D Loss: 0.09734198492168433, G Loss: 20.868295669555664\n",
      "Epoch: 32, Batch: 56, D Loss: 0.10127213634871687, G Loss: 21.136768341064453\n",
      "Epoch: 32, Batch: 57, D Loss: 0.09998136785239634, G Loss: 21.561315536499023\n",
      "Epoch: 32, Batch: 58, D Loss: 0.09905514139951818, G Loss: 21.818130493164062\n",
      "Epoch: 32, Batch: 59, D Loss: 0.09860079007193123, G Loss: 21.818241119384766\n",
      "Epoch: 32, Batch: 60, D Loss: 0.09880705941448618, G Loss: 21.61600685119629\n",
      "Epoch: 32, Batch: 61, D Loss: 0.09912659250726302, G Loss: 21.40593910217285\n",
      "Epoch: 32, Batch: 62, D Loss: 0.10241584503796353, G Loss: 21.505281448364258\n",
      "Epoch: 32, Batch: 63, D Loss: 0.09744983933388167, G Loss: 21.591381072998047\n",
      "Epoch: 32, Batch: 64, D Loss: 0.09784968217447226, G Loss: 21.674041748046875\n",
      "Epoch: 32, Batch: 65, D Loss: 0.09374184927694837, G Loss: 21.497346878051758\n",
      "Epoch: 32, Batch: 66, D Loss: 0.09979408257420005, G Loss: 21.49770164489746\n",
      "Epoch: 32, Batch: 67, D Loss: 0.10166884233812726, G Loss: 21.755666732788086\n",
      "Epoch: 32, Batch: 68, D Loss: 0.09889596716882626, G Loss: 21.933984756469727\n",
      "Epoch: 32, Batch: 69, D Loss: 0.09787320360684225, G Loss: 21.916135787963867\n",
      "Epoch: 32, Batch: 70, D Loss: 0.10010987535730784, G Loss: 21.87381362915039\n",
      "Epoch: 32, Batch: 71, D Loss: 0.10381444558250291, G Loss: 22.020479202270508\n",
      "Epoch: 32, Batch: 72, D Loss: 0.10058888806494944, G Loss: 22.043563842773438\n",
      "Epoch: 32, Batch: 73, D Loss: 0.09548313931882572, G Loss: 21.6814022064209\n",
      "Epoch: 32, Batch: 74, D Loss: 0.09812231384729589, G Loss: 21.3486270904541\n",
      "Epoch: 32, Batch: 75, D Loss: 0.10218223954979203, G Loss: 21.435150146484375\n",
      "Epoch: 32, Batch: 76, D Loss: 0.09897463045051313, G Loss: 21.69684410095215\n",
      "Epoch: 32, Batch: 77, D Loss: 0.09679609554878119, G Loss: 21.815061569213867\n",
      "Epoch: 32, Batch: 78, D Loss: 0.09345975539491183, G Loss: 21.364173889160156\n",
      "Epoch: 32, Batch: 79, D Loss: 0.09959001868720235, G Loss: 21.14610481262207\n",
      "Epoch: 32, Batch: 80, D Loss: 0.09783220327967895, G Loss: 20.92502212524414\n",
      "Epoch: 32, Batch: 81, D Loss: 0.10018403870247619, G Loss: 20.870073318481445\n",
      "Epoch: 32, Batch: 82, D Loss: 0.09069757219471541, G Loss: 20.380815505981445\n",
      "Epoch: 32, Batch: 83, D Loss: 0.10257166695788594, G Loss: 20.34859275817871\n",
      "Epoch: 32, Batch: 84, D Loss: 0.10328190091174139, G Loss: 20.63902473449707\n",
      "Epoch: 32, Batch: 85, D Loss: 0.10016164232113589, G Loss: 20.858797073364258\n",
      "Epoch: 32, Batch: 86, D Loss: 0.10283370357861499, G Loss: 20.941261291503906\n",
      "Epoch: 32, Batch: 87, D Loss: 0.10689771212966567, G Loss: 21.07085418701172\n",
      "Epoch: 32, Batch: 88, D Loss: 0.10127762001093074, G Loss: 20.785316467285156\n",
      "Epoch: 32, Batch: 89, D Loss: 0.09709514000282332, G Loss: 20.093290328979492\n",
      "Epoch: 32, Batch: 90, D Loss: 0.09070068014283983, G Loss: 19.06955909729004\n",
      "Epoch: 32, Batch: 91, D Loss: 0.09945069549191365, G Loss: 18.84453582763672\n",
      "Epoch: 32, Batch: 92, D Loss: 0.10234056641623601, G Loss: 19.535207748413086\n",
      "Epoch: 32, Batch: 93, D Loss: 0.09792606638219092, G Loss: 20.37354850769043\n",
      "Epoch: 32, Batch: 94, D Loss: 0.10593458307335693, G Loss: 21.360443115234375\n",
      "Epoch: 32, Batch: 95, D Loss: 0.10049267136616075, G Loss: 21.592679977416992\n",
      "Epoch: 32, Batch: 96, D Loss: 0.09687280684113253, G Loss: 20.96172332763672\n",
      "Epoch: 32, Batch: 97, D Loss: 0.09049701023146783, G Loss: 19.679105758666992\n",
      "Epoch: 32, Batch: 98, D Loss: 0.10124594162431166, G Loss: 19.140628814697266\n",
      "Epoch: 32, Batch: 99, D Loss: 0.09732540921672261, G Loss: 19.299480438232422\n",
      "Epoch: 32, Batch: 100, D Loss: 0.10153511295348616, G Loss: 20.213607788085938\n",
      "Epoch: 32, Batch: 101, D Loss: 0.09300501702720515, G Loss: 20.901002883911133\n",
      "Epoch: 32, Batch: 102, D Loss: 0.10004647108092068, G Loss: 21.41448974609375\n",
      "Epoch: 32, Batch: 103, D Loss: 0.10055042826584085, G Loss: 21.5531005859375\n",
      "Epoch: 32, Batch: 104, D Loss: 0.0956055822776635, G Loss: 21.0859432220459\n",
      "Epoch: 32, Batch: 105, D Loss: 0.1006548111112043, G Loss: 20.623048782348633\n",
      "Epoch: 32, Batch: 106, D Loss: 0.10506007129642614, G Loss: 20.657564163208008\n",
      "Epoch: 32, Batch: 107, D Loss: 0.0986396079405778, G Loss: 20.742637634277344\n",
      "Epoch: 32, Batch: 108, D Loss: 0.09584726443809644, G Loss: 20.685434341430664\n",
      "Epoch: 32, Batch: 109, D Loss: 0.09628561940126129, G Loss: 20.546125411987305\n",
      "Epoch: 32, Batch: 110, D Loss: 0.10168933923644491, G Loss: 20.69622039794922\n",
      "Epoch: 32, Batch: 111, D Loss: 0.098329395529198, G Loss: 20.853084564208984\n",
      "Epoch: 32, Batch: 112, D Loss: 0.09730136437510184, G Loss: 20.894142150878906\n",
      "Epoch: 32, Batch: 113, D Loss: 0.1048357192282143, G Loss: 21.20530128479004\n",
      "Epoch: 32, Batch: 114, D Loss: 0.10206281421681906, G Loss: 21.397994995117188\n",
      "Epoch: 32, Batch: 115, D Loss: 0.09665422915738836, G Loss: 21.1439266204834\n",
      "Epoch: 32, Batch: 116, D Loss: 0.10311503743156639, G Loss: 21.03477668762207\n",
      "Epoch: 32, Batch: 117, D Loss: 0.10066644140437278, G Loss: 20.96061134338379\n",
      "Epoch: 32, Batch: 118, D Loss: 0.10047593753213269, G Loss: 20.91593360900879\n",
      "Epoch: 32, Batch: 119, D Loss: 0.1019452218123193, G Loss: 21.032184600830078\n",
      "Epoch: 32, Batch: 120, D Loss: 0.09714408257308965, G Loss: 20.945751190185547\n",
      "Epoch: 32, Batch: 121, D Loss: 0.09829305901851601, G Loss: 20.748958587646484\n",
      "Epoch: 32, Batch: 122, D Loss: 0.10182551341525875, G Loss: 20.821002960205078\n",
      "Epoch: 32, Batch: 123, D Loss: 0.10004347606137193, G Loss: 20.908201217651367\n",
      "Epoch: 32, Batch: 124, D Loss: 0.09538599894485453, G Loss: 20.7280330657959\n",
      "Epoch: 32, Batch: 125, D Loss: 0.09825366044999118, G Loss: 20.553688049316406\n",
      "Epoch: 32, Batch: 126, D Loss: 0.09742033544125339, G Loss: 20.453344345092773\n",
      "Epoch: 32, Batch: 127, D Loss: 0.09363886042385189, G Loss: 20.23773956298828\n",
      "Epoch: 32, Batch: 128, D Loss: 0.10110387278320315, G Loss: 20.463594436645508\n",
      "Epoch: 32, Batch: 129, D Loss: 0.10145107707503198, G Loss: 20.93124771118164\n",
      "Epoch: 32, Batch: 130, D Loss: 0.09976985339058911, G Loss: 21.296531677246094\n",
      "Epoch: 32, Batch: 131, D Loss: 0.10125473167581384, G Loss: 21.457231521606445\n",
      "Epoch: 32, Batch: 132, D Loss: 0.09710713503680157, G Loss: 21.18424415588379\n",
      "Epoch: 32, Batch: 133, D Loss: 0.10060144997560033, G Loss: 20.898090362548828\n",
      "Epoch: 32, Batch: 134, D Loss: 0.097353041659343, G Loss: 20.617504119873047\n",
      "Epoch: 32, Batch: 135, D Loss: 0.10087717377204258, G Loss: 20.720535278320312\n",
      "Epoch: 32, Batch: 136, D Loss: 0.10704733465782382, G Loss: 21.434804916381836\n",
      "Epoch: 32, Batch: 137, D Loss: 0.09820044806366005, G Loss: 21.76573371887207\n",
      "Epoch: 32, Batch: 138, D Loss: 0.10250748710871793, G Loss: 21.843387603759766\n",
      "Epoch: 32, Batch: 139, D Loss: 0.09907996674127958, G Loss: 21.49308967590332\n",
      "Epoch: 32, Batch: 140, D Loss: 0.09595859083461925, G Loss: 20.837432861328125\n",
      "Epoch: 32, Batch: 141, D Loss: 0.10127887925237072, G Loss: 20.60816192626953\n",
      "Epoch: 32, Batch: 142, D Loss: 0.09958481094597071, G Loss: 20.79119300842285\n",
      "Epoch: 32, Batch: 143, D Loss: 0.10268028115345379, G Loss: 21.347240447998047\n",
      "Epoch: 32, Batch: 144, D Loss: 0.09464036698624573, G Loss: 21.45573616027832\n",
      "Epoch: 32, Batch: 145, D Loss: 0.10376819992263561, G Loss: 21.456279754638672\n",
      "Epoch: 32, Batch: 146, D Loss: 0.10269427324659924, G Loss: 21.36931610107422\n",
      "Epoch: 32, Batch: 147, D Loss: 0.09498200601020881, G Loss: 20.797571182250977\n",
      "Epoch: 32, Batch: 148, D Loss: 0.09594959087248406, G Loss: 20.114870071411133\n",
      "Epoch: 32, Batch: 149, D Loss: 0.10733989709954822, G Loss: 20.293231964111328\n",
      "Epoch: 32, Batch: 150, D Loss: 0.10185168744604978, G Loss: 20.732023239135742\n",
      "Epoch: 32, Batch: 151, D Loss: 0.10209061990891455, G Loss: 21.12139892578125\n",
      "Epoch: 32, Batch: 152, D Loss: 0.10161084713446922, G Loss: 21.231996536254883\n",
      "Epoch: 32, Batch: 153, D Loss: 0.10349346728859041, G Loss: 21.142663955688477\n",
      "Epoch: 32, Batch: 154, D Loss: 0.10015991370285202, G Loss: 20.765378952026367\n",
      "Epoch: 32, Batch: 155, D Loss: 0.1036436414223858, G Loss: 20.51797866821289\n",
      "Epoch: 32, Batch: 156, D Loss: 0.09630917831591168, G Loss: 20.169593811035156\n",
      "Epoch: 32, Batch: 157, D Loss: 0.08870618165550859, G Loss: 19.55923843383789\n",
      "Epoch: 32, Batch: 158, D Loss: 0.10140124107558812, G Loss: 19.763797760009766\n",
      "Epoch: 32, Batch: 159, D Loss: 0.09790648613699326, G Loss: 20.399076461791992\n",
      "Epoch: 32, Batch: 160, D Loss: 0.09800963151361719, G Loss: 21.112110137939453\n",
      "Epoch: 32, Batch: 161, D Loss: 0.09683619468275934, G Loss: 21.429767608642578\n",
      "Epoch: 32, Batch: 162, D Loss: 0.093436837486914, G Loss: 21.118459701538086\n",
      "Epoch: 32, Batch: 163, D Loss: 0.09816247265211997, G Loss: 20.775249481201172\n",
      "Epoch: 32, Batch: 164, D Loss: 0.09579373206783676, G Loss: 20.472515106201172\n",
      "Epoch: 32, Batch: 165, D Loss: 0.10137085674510182, G Loss: 20.67171287536621\n",
      "Epoch: 32, Batch: 166, D Loss: 0.10643672233217893, G Loss: 21.44298553466797\n",
      "Epoch: 32, Batch: 167, D Loss: 0.09904994089391837, G Loss: 21.928199768066406\n",
      "Epoch: 32, Batch: 168, D Loss: 0.099665977208236, G Loss: 21.95968246459961\n",
      "Epoch: 32, Batch: 169, D Loss: 0.10196530835201353, G Loss: 21.744998931884766\n",
      "Epoch: 32, Batch: 170, D Loss: 0.10198035111603426, G Loss: 21.503692626953125\n",
      "Epoch: 32, Batch: 171, D Loss: 0.09918224837724479, G Loss: 21.251575469970703\n",
      "Epoch: 32, Batch: 172, D Loss: 0.09643973447501156, G Loss: 20.803903579711914\n",
      "Epoch: 32, Batch: 173, D Loss: 0.09835990569407976, G Loss: 20.612112045288086\n",
      "Epoch: 32, Batch: 174, D Loss: 0.0980333020577589, G Loss: 20.7308406829834\n",
      "Epoch: 32, Batch: 175, D Loss: 0.10204850920740938, G Loss: 21.218778610229492\n",
      "Epoch: 32, Batch: 176, D Loss: 0.10008667433533525, G Loss: 21.662137985229492\n",
      "Epoch: 32, Batch: 177, D Loss: 0.09882707912692124, G Loss: 21.73313331604004\n",
      "Epoch: 32, Batch: 178, D Loss: 0.10040192325799357, G Loss: 21.57917022705078\n",
      "Epoch: 32, Batch: 179, D Loss: 0.0918685498939778, G Loss: 20.87006378173828\n",
      "Epoch: 32, Batch: 180, D Loss: 0.10015234404221252, G Loss: 20.479717254638672\n",
      "Epoch: 32, Batch: 181, D Loss: 0.1067303126202444, G Loss: 20.901758193969727\n",
      "Epoch: 32, Batch: 182, D Loss: 0.09764045510758415, G Loss: 21.30699348449707\n",
      "Epoch: 32, Batch: 183, D Loss: 0.09499599812915624, G Loss: 21.280258178710938\n",
      "Epoch: 32, Batch: 184, D Loss: 0.09931688041020492, G Loss: 21.173004150390625\n",
      "Epoch: 32, Batch: 185, D Loss: 0.09433899859794206, G Loss: 20.747276306152344\n",
      "Epoch: 32, Batch: 186, D Loss: 0.09426359894558506, G Loss: 20.286422729492188\n",
      "Epoch: 32, Batch: 187, D Loss: 0.10191521121293962, G Loss: 20.406755447387695\n",
      "Epoch: 32, Batch: 188, D Loss: 0.0951864874556888, G Loss: 20.615819931030273\n",
      "Epoch: 32, Batch: 189, D Loss: 0.1041107032666432, G Loss: 21.273815155029297\n",
      "Epoch: 32, Batch: 190, D Loss: 0.0983343871872166, G Loss: 21.603225708007812\n",
      "Epoch: 32, Batch: 191, D Loss: 0.10028147718371996, G Loss: 21.58733558654785\n",
      "Epoch: 32, Batch: 192, D Loss: 0.09499670593213289, G Loss: 21.040790557861328\n",
      "Epoch: 32, Batch: 193, D Loss: 0.10131646735251568, G Loss: 20.747753143310547\n",
      "Epoch: 32, Batch: 194, D Loss: 0.10108302581784567, G Loss: 20.774452209472656\n",
      "Epoch: 32, Batch: 195, D Loss: 0.10631933098452725, G Loss: 21.347963333129883\n",
      "Epoch: 32, Batch: 196, D Loss: 0.10528863985427935, G Loss: 22.00234603881836\n",
      "Epoch: 32, Batch: 197, D Loss: 0.10234986257792736, G Loss: 22.258752822875977\n",
      "Epoch: 32, Batch: 198, D Loss: 0.09784465296754769, G Loss: 21.815053939819336\n",
      "Epoch: 32, Batch: 199, D Loss: 0.09597007212119332, G Loss: 20.917362213134766\n",
      "Epoch: 32, Batch: 200, D Loss: 0.10009120458640425, G Loss: 20.406658172607422\n",
      "Epoch: 32, Batch: 201, D Loss: 0.11218246863745912, G Loss: 21.16169548034668\n",
      "Epoch: 32, Batch: 202, D Loss: 0.09748357558305373, G Loss: 21.73103141784668\n",
      "Epoch: 32, Batch: 203, D Loss: 0.09968494639466471, G Loss: 22.033832550048828\n",
      "Epoch: 32, Batch: 204, D Loss: 0.10326685024102188, G Loss: 22.14571189880371\n",
      "Epoch: 32, Batch: 205, D Loss: 0.09852056219934847, G Loss: 21.77407455444336\n",
      "Epoch: 32, Batch: 206, D Loss: 0.09580069806731503, G Loss: 20.993122100830078\n",
      "Epoch: 32, Batch: 207, D Loss: 0.09521365964640621, G Loss: 20.34009552001953\n",
      "Epoch: 32, Batch: 208, D Loss: 0.09818506318840586, G Loss: 20.226476669311523\n",
      "Epoch: 32, Batch: 209, D Loss: 0.10696258448368479, G Loss: 21.080310821533203\n",
      "Epoch: 32, Batch: 210, D Loss: 0.09772095109279619, G Loss: 21.711631774902344\n",
      "Epoch: 32, Batch: 211, D Loss: 0.0948963837709383, G Loss: 21.69915199279785\n",
      "Epoch: 32, Batch: 212, D Loss: 0.09814456128495826, G Loss: 21.298078536987305\n",
      "Epoch: 32, Batch: 213, D Loss: 0.10126300189595164, G Loss: 20.97001075744629\n",
      "Epoch: 32, Batch: 214, D Loss: 0.09532491911138469, G Loss: 20.565792083740234\n",
      "Epoch: 32, Batch: 215, D Loss: 0.10397269630326023, G Loss: 20.737201690673828\n",
      "Epoch: 32, Batch: 216, D Loss: 0.09174340271074288, G Loss: 20.61039924621582\n",
      "Epoch: 32, Batch: 217, D Loss: 0.10286035436546165, G Loss: 20.910594940185547\n",
      "Epoch: 32, Batch: 218, D Loss: 0.09710896052145956, G Loss: 21.129287719726562\n",
      "Epoch: 32, Batch: 219, D Loss: 0.10287265507305388, G Loss: 21.479061126708984\n",
      "Epoch: 32, Batch: 220, D Loss: 0.10140944293344155, G Loss: 21.686311721801758\n",
      "Epoch: 32, Batch: 221, D Loss: 0.0979098828811449, G Loss: 21.44763946533203\n",
      "Epoch: 32, Batch: 222, D Loss: 0.09718519480499802, G Loss: 20.965702056884766\n",
      "Epoch: 32, Batch: 223, D Loss: 0.09346543308743793, G Loss: 20.28340721130371\n",
      "Epoch: 32, Batch: 224, D Loss: 0.09543167893477977, G Loss: 19.927852630615234\n",
      "Epoch: 32, Batch: 225, D Loss: 0.10648397434652213, G Loss: 20.589214324951172\n",
      "Epoch: 32, Batch: 226, D Loss: 0.09354836538343139, G Loss: 21.061914443969727\n",
      "Epoch: 32, Batch: 227, D Loss: 0.10193657902389966, G Loss: 21.568069458007812\n",
      "Epoch: 32, Batch: 228, D Loss: 0.10084565002829445, G Loss: 21.803607940673828\n",
      "Epoch: 32, Batch: 229, D Loss: 0.10236573236393726, G Loss: 21.790864944458008\n",
      "Epoch: 32, Batch: 230, D Loss: 0.096496448143415, G Loss: 21.29861068725586\n",
      "Epoch: 32, Batch: 231, D Loss: 0.10252559218039808, G Loss: 20.995058059692383\n",
      "Epoch: 32, Batch: 232, D Loss: 0.09657077534876443, G Loss: 20.740636825561523\n",
      "Epoch: 32, Batch: 233, D Loss: 0.09855210828864436, G Loss: 20.79642105102539\n",
      "Epoch: 32, Batch: 234, D Loss: 0.09870496431064679, G Loss: 21.14006805419922\n",
      "Epoch: 32, Batch: 235, D Loss: 0.10054964597009527, G Loss: 21.682239532470703\n",
      "Epoch: 32, Batch: 236, D Loss: 0.10169526948888201, G Loss: 22.242820739746094\n",
      "Epoch: 32, Batch: 237, D Loss: 0.1025582403899907, G Loss: 22.500659942626953\n",
      "Epoch: 32, Batch: 238, D Loss: 0.10425122835745058, G Loss: 22.501073837280273\n",
      "Epoch: 32, Batch: 239, D Loss: 0.09458450985853299, G Loss: 21.70779800415039\n",
      "Epoch: 32, Batch: 240, D Loss: 0.10223180825762102, G Loss: 21.150331497192383\n",
      "Epoch: 32, Batch: 241, D Loss: 0.10311823370925896, G Loss: 21.149625778198242\n",
      "Epoch: 32, Batch: 242, D Loss: 0.1018272342988053, G Loss: 21.518526077270508\n",
      "Epoch: 32, Batch: 243, D Loss: 0.10142936575353817, G Loss: 21.96661376953125\n",
      "Epoch: 32, Batch: 244, D Loss: 0.10595794777914079, G Loss: 22.520648956298828\n",
      "Epoch: 32, Batch: 245, D Loss: 0.09922225036754606, G Loss: 22.477632522583008\n",
      "Epoch: 32, Batch: 246, D Loss: 0.10093110810529483, G Loss: 22.066635131835938\n",
      "Epoch: 32, Batch: 247, D Loss: 0.10932664586734951, G Loss: 21.99661636352539\n",
      "Epoch: 32, Batch: 248, D Loss: 0.09542292373761618, G Loss: 21.595853805541992\n",
      "Epoch: 32, Batch: 249, D Loss: 0.10142699651848218, G Loss: 21.433393478393555\n",
      "Epoch: 32, Batch: 250, D Loss: 0.09703180219479834, G Loss: 21.35870361328125\n",
      "Epoch: 32, Batch: 251, D Loss: 0.10011452461024997, G Loss: 21.501718521118164\n",
      "Epoch: 32, Batch: 252, D Loss: 0.10100077111803085, G Loss: 21.846399307250977\n",
      "Epoch: 32, Batch: 253, D Loss: 0.09908829644013854, G Loss: 22.052776336669922\n",
      "Epoch: 32, Batch: 254, D Loss: 0.10354880255896304, G Loss: 22.182994842529297\n",
      "Epoch: 32, Batch: 255, D Loss: 0.10213699948566346, G Loss: 22.169710159301758\n",
      "Epoch: 32, Batch: 256, D Loss: 0.10240532470655817, G Loss: 22.006757736206055\n",
      "Epoch: 32, Batch: 257, D Loss: 0.09015172740951709, G Loss: 21.21711540222168\n",
      "Epoch: 32, Batch: 258, D Loss: 0.09497803493088364, G Loss: 20.546106338500977\n",
      "Epoch: 32, Batch: 259, D Loss: 0.1012845715516435, G Loss: 20.67097282409668\n",
      "Epoch: 32, Batch: 260, D Loss: 0.10430389676519192, G Loss: 21.513763427734375\n",
      "Epoch: 32, Batch: 261, D Loss: 0.0976386071866397, G Loss: 22.157108306884766\n",
      "Epoch: 32, Batch: 262, D Loss: 0.09701339166596126, G Loss: 22.28261947631836\n",
      "Epoch: 32, Batch: 263, D Loss: 0.10190399747290435, G Loss: 22.17572784423828\n",
      "Epoch: 32, Batch: 264, D Loss: 0.09959771498175386, G Loss: 21.829532623291016\n",
      "Epoch: 32, Batch: 265, D Loss: 0.09987513740876511, G Loss: 21.480451583862305\n",
      "Epoch: 32, Batch: 266, D Loss: 0.0983118194016733, G Loss: 21.245147705078125\n",
      "Epoch: 32, Batch: 267, D Loss: 0.09769719869433166, G Loss: 21.204177856445312\n",
      "Epoch: 32, Batch: 268, D Loss: 0.09655153781505094, G Loss: 21.253976821899414\n",
      "Epoch: 32, Batch: 269, D Loss: 0.10194659256583219, G Loss: 21.682941436767578\n",
      "Epoch: 32, Batch: 270, D Loss: 0.10211808994530445, G Loss: 22.143728256225586\n",
      "Epoch: 32, Batch: 271, D Loss: 0.09510666145076854, G Loss: 21.989667892456055\n",
      "Epoch: 32, Batch: 272, D Loss: 0.09897278265855414, G Loss: 21.67875862121582\n",
      "Epoch: 32, Batch: 273, D Loss: 0.09684979939329916, G Loss: 21.282350540161133\n",
      "Epoch: 32, Batch: 274, D Loss: 0.09932360083661276, G Loss: 21.154264450073242\n",
      "Epoch: 32, Batch: 275, D Loss: 0.09472550484874157, G Loss: 21.119417190551758\n",
      "Epoch: 32, Batch: 276, D Loss: 0.09934209315984446, G Loss: 21.414670944213867\n",
      "Epoch: 32, Batch: 277, D Loss: 0.10076858122126156, G Loss: 21.957176208496094\n",
      "Epoch: 32, Batch: 278, D Loss: 0.09970053297301511, G Loss: 22.333810806274414\n",
      "Epoch: 32, Batch: 279, D Loss: 0.09437665354156777, G Loss: 22.173202514648438\n",
      "Epoch: 32, Batch: 280, D Loss: 0.09303489342688055, G Loss: 21.672943115234375\n",
      "Epoch: 32, Batch: 281, D Loss: 0.10798746363656232, G Loss: 22.00796127319336\n",
      "Epoch: 32, Batch: 282, D Loss: 0.10065943013413486, G Loss: 22.49329376220703\n",
      "Epoch: 32, Batch: 283, D Loss: 0.10497964924695569, G Loss: 23.132694244384766\n",
      "Epoch: 32, Batch: 284, D Loss: 0.10191036764373013, G Loss: 23.57199478149414\n",
      "Epoch: 32, Batch: 285, D Loss: 0.10247729721482365, G Loss: 23.637962341308594\n",
      "Epoch: 32, Batch: 286, D Loss: 0.09362781796635573, G Loss: 23.018413543701172\n",
      "Epoch: 32, Batch: 287, D Loss: 0.09920796758361315, G Loss: 22.5666446685791\n",
      "Epoch: 32, Batch: 288, D Loss: 0.09711551674723241, G Loss: 22.438426971435547\n",
      "Epoch: 32, Batch: 289, D Loss: 0.10589194304164926, G Loss: 23.09086799621582\n",
      "Epoch: 32, Batch: 290, D Loss: 0.10034729543552018, G Loss: 23.812387466430664\n",
      "Epoch: 32, Batch: 291, D Loss: 0.09686818720942905, G Loss: 24.028244018554688\n",
      "Epoch: 32, Batch: 292, D Loss: 0.09695030750840007, G Loss: 23.868328094482422\n",
      "Epoch: 32, Batch: 293, D Loss: 0.10570843519850684, G Loss: 23.943025588989258\n",
      "Epoch: 32, Batch: 294, D Loss: 0.0943195522027078, G Loss: 23.983678817749023\n",
      "Epoch: 32, Batch: 295, D Loss: 0.09576617183152454, G Loss: 24.051345825195312\n",
      "Epoch: 32, Batch: 296, D Loss: 0.10009747745255616, G Loss: 24.210525512695312\n",
      "Epoch: 32, Batch: 297, D Loss: 0.09977874161084019, G Loss: 24.561599731445312\n",
      "Epoch: 32, Batch: 298, D Loss: 0.09353660047926333, G Loss: 24.961753845214844\n",
      "Epoch: 32, Batch: 299, D Loss: 0.09720316529728518, G Loss: 25.843271255493164\n",
      "Epoch: 32, Batch: 300, D Loss: 0.09759736061240303, G Loss: 27.228839874267578\n",
      "Epoch: 32, Batch: 301, D Loss: 0.09981501847550393, G Loss: 28.201072692871094\n",
      "Epoch: 32, Batch: 302, D Loss: 0.09915046393895116, G Loss: 28.527742385864258\n",
      "Epoch: 32, Batch: 303, D Loss: 0.10153612494507533, G Loss: 27.30286407470703\n",
      "Epoch: 32, Batch: 304, D Loss: 0.10228105634571089, G Loss: 26.259662628173828\n",
      "Epoch: 32, Batch: 305, D Loss: 0.09566012770317343, G Loss: 25.018077850341797\n",
      "Epoch: 32, Batch: 306, D Loss: 0.10357455165202306, G Loss: 24.27497100830078\n",
      "Epoch: 32, Batch: 307, D Loss: 0.10327148439202077, G Loss: 23.948970794677734\n",
      "Epoch: 32, Batch: 308, D Loss: 0.096863597658022, G Loss: 23.396339416503906\n",
      "Epoch: 32, Batch: 309, D Loss: 0.09868063781973871, G Loss: 22.983938217163086\n",
      "Epoch: 32, Batch: 310, D Loss: 0.09880767023828041, G Loss: 22.64733123779297\n",
      "Epoch: 32, Batch: 311, D Loss: 0.10053978868549943, G Loss: 22.43343162536621\n",
      "Epoch: 32, Batch: 312, D Loss: 0.09804765889844841, G Loss: 22.29300880432129\n",
      "Epoch: 32, Batch: 313, D Loss: 0.10252692559657905, G Loss: 22.519445419311523\n",
      "Epoch: 32, Batch: 314, D Loss: 0.10490400351336801, G Loss: 22.787826538085938\n",
      "Epoch: 32, Batch: 315, D Loss: 0.09216461338897294, G Loss: 22.289657592773438\n",
      "Epoch: 32, Batch: 316, D Loss: 0.09585072860311192, G Loss: 21.590328216552734\n",
      "Epoch: 32, Batch: 317, D Loss: 0.09090738775103538, G Loss: 20.820241928100586\n",
      "Epoch: 32, Batch: 318, D Loss: 0.10408752452243378, G Loss: 21.031482696533203\n",
      "Epoch: 32, Batch: 319, D Loss: 0.10345262309724221, G Loss: 22.124765396118164\n",
      "Epoch: 32, Batch: 320, D Loss: 0.10603401071285713, G Loss: 23.361690521240234\n",
      "Epoch: 32, Batch: 321, D Loss: 0.09793066236634129, G Loss: 23.54941749572754\n",
      "Epoch: 32, Batch: 322, D Loss: 0.10193689171965167, G Loss: 22.76909637451172\n",
      "Epoch: 32, Batch: 323, D Loss: 0.100174978488898, G Loss: 21.69889259338379\n",
      "Epoch: 32, Batch: 324, D Loss: 0.10265916613973369, G Loss: 20.943634033203125\n",
      "Epoch: 32, Batch: 325, D Loss: 0.09705396794214582, G Loss: 20.433115005493164\n",
      "Epoch: 32, Batch: 326, D Loss: 0.0993915653158326, G Loss: 20.67587661743164\n",
      "Epoch: 32, Batch: 327, D Loss: 0.09702418787453168, G Loss: 21.058900833129883\n",
      "Epoch: 32, Batch: 328, D Loss: 0.10675540589813518, G Loss: 21.867877960205078\n",
      "Epoch: 32, Batch: 329, D Loss: 0.10076877487111097, G Loss: 22.35382652282715\n",
      "Epoch: 32, Batch: 330, D Loss: 0.09634310018256796, G Loss: 22.10520362854004\n",
      "Epoch: 32, Batch: 331, D Loss: 0.0969575943879208, G Loss: 20.944568634033203\n",
      "Epoch: 32, Batch: 332, D Loss: 0.10090050158567193, G Loss: 20.27033042907715\n",
      "Epoch: 32, Batch: 333, D Loss: 0.09216323602875587, G Loss: 19.67374038696289\n",
      "Epoch: 32, Batch: 334, D Loss: 0.09161159571859534, G Loss: 19.287851333618164\n",
      "Epoch: 32, Batch: 335, D Loss: 0.10083104092074957, G Loss: 19.72979736328125\n",
      "Epoch: 32, Batch: 336, D Loss: 0.09690977729578731, G Loss: 20.372968673706055\n",
      "Epoch: 32, Batch: 337, D Loss: 0.09845063144335514, G Loss: 20.89403533935547\n",
      "Epoch: 32, Batch: 338, D Loss: 0.10334222053468872, G Loss: 21.26211166381836\n",
      "Epoch: 32, Batch: 339, D Loss: 0.10176215350930379, G Loss: 21.20357894897461\n",
      "Epoch: 32, Batch: 340, D Loss: 0.09872532677087908, G Loss: 20.660320281982422\n",
      "Epoch: 32, Batch: 341, D Loss: 0.09813541249113694, G Loss: 20.010473251342773\n",
      "Epoch: 32, Batch: 342, D Loss: 0.09602669016496324, G Loss: 19.481510162353516\n",
      "Epoch: 32, Batch: 343, D Loss: 0.09964577275707809, G Loss: 19.555824279785156\n",
      "Epoch: 32, Batch: 344, D Loss: 0.0931923627701533, G Loss: 19.72509765625\n",
      "Epoch: 32, Batch: 345, D Loss: 0.10298425054834437, G Loss: 20.39509391784668\n",
      "Epoch: 32, Batch: 346, D Loss: 0.09658382888697087, G Loss: 20.816957473754883\n",
      "Epoch: 32, Batch: 347, D Loss: 0.09736315950673863, G Loss: 20.857023239135742\n",
      "Epoch: 32, Batch: 348, D Loss: 0.09964335011996678, G Loss: 20.712602615356445\n",
      "Epoch: 32, Batch: 349, D Loss: 0.09891234395770387, G Loss: 20.47134780883789\n",
      "Epoch: 32, Batch: 350, D Loss: 0.10615450201528248, G Loss: 20.68079948425293\n",
      "Epoch: 32, Batch: 351, D Loss: 0.10314190430201789, G Loss: 21.072975158691406\n",
      "Epoch: 32, Batch: 352, D Loss: 0.09885279868246091, G Loss: 21.144182205200195\n",
      "Epoch: 32, Batch: 353, D Loss: 0.1049436333505373, G Loss: 21.5093994140625\n",
      "Epoch: 32, Batch: 354, D Loss: 0.09572469467213895, G Loss: 21.400672912597656\n",
      "Epoch: 32, Batch: 355, D Loss: 0.10150855805311043, G Loss: 21.381929397583008\n",
      "Epoch: 32, Batch: 356, D Loss: 0.10050215596221326, G Loss: 21.518009185791016\n",
      "Epoch: 32, Batch: 357, D Loss: 0.10026116687221633, G Loss: 21.945241928100586\n",
      "Epoch: 32, Batch: 358, D Loss: 0.09237722321938041, G Loss: 21.9768123626709\n",
      "Epoch: 32, Batch: 359, D Loss: 0.09859173013450144, G Loss: 22.07069969177246\n",
      "Epoch: 32, Batch: 360, D Loss: 0.10153234760614849, G Loss: 22.461429595947266\n",
      "Epoch: 32, Batch: 361, D Loss: 0.10189429677985283, G Loss: 22.78562355041504\n",
      "Epoch: 32, Batch: 362, D Loss: 0.10570866619029329, G Loss: 23.463518142700195\n",
      "Epoch: 32, Batch: 363, D Loss: 0.10142372551416041, G Loss: 23.709550857543945\n",
      "Epoch: 32, Batch: 364, D Loss: 0.09975087646155299, G Loss: 23.095609664916992\n",
      "Epoch: 32, Batch: 365, D Loss: 0.10052269704693823, G Loss: 22.191020965576172\n",
      "Epoch: 32, Batch: 366, D Loss: 0.10151855663440551, G Loss: 21.58354949951172\n",
      "Epoch: 32, Batch: 367, D Loss: 0.09092298182352046, G Loss: 20.78325080871582\n",
      "Epoch: 32, Batch: 368, D Loss: 0.09959705227494886, G Loss: 20.542251586914062\n",
      "Epoch: 32, Batch: 369, D Loss: 0.09662385341690577, G Loss: 20.646738052368164\n",
      "Epoch: 32, Batch: 370, D Loss: 0.08789329291569631, G Loss: 20.42481803894043\n",
      "Epoch: 32, Batch: 371, D Loss: 0.10256923047079897, G Loss: 20.74622917175293\n",
      "Epoch: 32, Batch: 372, D Loss: 0.09925800601686471, G Loss: 21.140138626098633\n",
      "Epoch: 32, Batch: 373, D Loss: 0.09660469027760632, G Loss: 21.18627166748047\n",
      "Epoch: 32, Batch: 374, D Loss: 0.10153369637683424, G Loss: 21.149333953857422\n",
      "Epoch: 32, Batch: 375, D Loss: 0.09179748639055196, G Loss: 20.57316017150879\n",
      "Epoch: 32, Batch: 376, D Loss: 0.10206089980814453, G Loss: 20.307090759277344\n",
      "Epoch: 32, Batch: 377, D Loss: 0.09626516790358547, G Loss: 19.973100662231445\n",
      "Epoch: 32, Batch: 378, D Loss: 0.10007107361517598, G Loss: 20.017547607421875\n",
      "Epoch: 32, Batch: 379, D Loss: 0.10031709163769253, G Loss: 20.271068572998047\n",
      "Epoch: 32, Batch: 380, D Loss: 0.09986794809019306, G Loss: 20.521240234375\n",
      "Epoch: 32, Batch: 381, D Loss: 0.09718389871945948, G Loss: 20.47444725036621\n",
      "Epoch: 32, Batch: 382, D Loss: 0.09730757848812255, G Loss: 20.158655166625977\n",
      "Epoch: 32, Batch: 383, D Loss: 0.10633640077848461, G Loss: 20.192514419555664\n",
      "Epoch: 32, Batch: 384, D Loss: 0.10058215342818022, G Loss: 20.257612228393555\n",
      "Epoch: 32, Batch: 385, D Loss: 0.09729375030006865, G Loss: 20.14154815673828\n",
      "Epoch: 32, Batch: 386, D Loss: 0.09890586979045668, G Loss: 20.007455825805664\n",
      "Epoch: 32, Batch: 387, D Loss: 0.09691521635506406, G Loss: 19.872295379638672\n",
      "Epoch: 32, Batch: 388, D Loss: 0.10257534785063738, G Loss: 20.133325576782227\n",
      "Epoch: 32, Batch: 389, D Loss: 0.10221962695821585, G Loss: 20.759597778320312\n",
      "Epoch: 32, Batch: 390, D Loss: 0.10124476290332943, G Loss: 21.297786712646484\n",
      "Epoch: 32, Batch: 391, D Loss: 0.1011873784167481, G Loss: 21.53476905822754\n",
      "Epoch: 32, Batch: 392, D Loss: 0.09641984875528103, G Loss: 21.283432006835938\n",
      "Epoch: 32, Batch: 393, D Loss: 0.09962426158818441, G Loss: 21.01959228515625\n",
      "Epoch: 32, Batch: 394, D Loss: 0.10102827883893192, G Loss: 21.035964965820312\n",
      "Epoch: 32, Batch: 395, D Loss: 0.1014930161892644, G Loss: 21.388931274414062\n",
      "Epoch: 32, Batch: 396, D Loss: 0.09952064626571612, G Loss: 21.6001033782959\n",
      "Epoch: 32, Batch: 397, D Loss: 0.10024777819100719, G Loss: 21.747913360595703\n",
      "Epoch: 32, Batch: 398, D Loss: 0.09748544563767172, G Loss: 21.56334114074707\n",
      "Epoch: 32, Batch: 399, D Loss: 0.09832854594405424, G Loss: 21.251445770263672\n",
      "Epoch: 32, Batch: 400, D Loss: 0.0962556604174975, G Loss: 20.870561599731445\n",
      "Epoch: 32, Batch: 401, D Loss: 0.10160142226071717, G Loss: 20.889610290527344\n",
      "Epoch: 32, Batch: 402, D Loss: 0.09869037607458572, G Loss: 21.05279541015625\n",
      "Epoch: 32, Batch: 403, D Loss: 0.10888876790192412, G Loss: 21.803503036499023\n",
      "Epoch: 32, Batch: 404, D Loss: 0.09353140758545056, G Loss: 21.806293487548828\n",
      "Epoch: 32, Batch: 405, D Loss: 0.09915375729337812, G Loss: 21.509721755981445\n",
      "Epoch: 32, Batch: 406, D Loss: 0.09842136531727813, G Loss: 21.020017623901367\n",
      "Epoch: 32, Batch: 407, D Loss: 0.10120774846577651, G Loss: 20.8336238861084\n",
      "Epoch: 32, Batch: 408, D Loss: 0.09598146427107107, G Loss: 20.70003890991211\n",
      "Epoch: 32, Batch: 409, D Loss: 0.10206973596176155, G Loss: 21.012439727783203\n",
      "Epoch: 32, Batch: 410, D Loss: 0.10391210791980673, G Loss: 21.6101016998291\n",
      "Epoch: 32, Batch: 411, D Loss: 0.09300674519255996, G Loss: 21.558629989624023\n",
      "Epoch: 32, Batch: 412, D Loss: 0.10222459607193658, G Loss: 21.471214294433594\n",
      "Epoch: 32, Batch: 413, D Loss: 0.09400133818428907, G Loss: 21.03047752380371\n",
      "Epoch: 32, Batch: 414, D Loss: 0.10204763749379447, G Loss: 20.92645835876465\n",
      "Epoch: 32, Batch: 415, D Loss: 0.09721008729581118, G Loss: 20.902406692504883\n",
      "Epoch: 32, Batch: 416, D Loss: 0.09783300797390224, G Loss: 20.988758087158203\n",
      "Epoch: 32, Batch: 417, D Loss: 0.09869714116388531, G Loss: 21.158212661743164\n",
      "Epoch: 32, Batch: 418, D Loss: 0.0998665693354259, G Loss: 21.347026824951172\n",
      "Epoch: 32, Batch: 419, D Loss: 0.09844814263629817, G Loss: 21.663633346557617\n",
      "Epoch: 32, Batch: 420, D Loss: 0.10103064047501151, G Loss: 21.91730499267578\n",
      "Epoch: 32, Batch: 421, D Loss: 0.10211268080825757, G Loss: 22.14200782775879\n",
      "Epoch: 32, Batch: 422, D Loss: 0.10045037430151926, G Loss: 22.231491088867188\n",
      "Epoch: 32, Batch: 423, D Loss: 0.09587636602659207, G Loss: 21.977216720581055\n",
      "Epoch: 32, Batch: 424, D Loss: 0.09578785317306246, G Loss: 21.638174057006836\n",
      "Epoch: 32, Batch: 425, D Loss: 0.09407970331981154, G Loss: 21.399038314819336\n",
      "Epoch: 32, Batch: 426, D Loss: 0.09737478965547064, G Loss: 21.52123260498047\n",
      "Epoch: 32, Batch: 427, D Loss: 0.10250439511070246, G Loss: 22.14278221130371\n",
      "Epoch: 32, Batch: 428, D Loss: 0.09904938945271019, G Loss: 22.695703506469727\n",
      "Epoch: 32, Batch: 429, D Loss: 0.09874073422266412, G Loss: 22.892620086669922\n",
      "Epoch: 32, Batch: 430, D Loss: 0.09779681271916227, G Loss: 22.629344940185547\n",
      "Epoch: 32, Batch: 431, D Loss: 0.09696228812013606, G Loss: 22.101993560791016\n",
      "Epoch: 32, Batch: 432, D Loss: 0.10500327510793502, G Loss: 22.0318603515625\n",
      "Epoch: 32, Batch: 433, D Loss: 0.09892040507058425, G Loss: 21.716609954833984\n",
      "Epoch: 32, Batch: 434, D Loss: 0.09850930441790909, G Loss: 21.644119262695312\n",
      "Epoch: 32, Batch: 435, D Loss: 0.10146331806780191, G Loss: 21.682477951049805\n",
      "Epoch: 32, Batch: 436, D Loss: 0.10121375340746265, G Loss: 21.759708404541016\n",
      "Epoch: 32, Batch: 437, D Loss: 0.10327610390342676, G Loss: 21.858308792114258\n",
      "Epoch: 32, Batch: 438, D Loss: 0.10053874569352536, G Loss: 21.740816116333008\n",
      "Epoch: 32, Batch: 439, D Loss: 0.10002513251076378, G Loss: 21.435834884643555\n",
      "Epoch: 32, Batch: 440, D Loss: 0.09901239752850324, G Loss: 21.061769485473633\n",
      "Epoch: 32, Batch: 441, D Loss: 0.09748487217673096, G Loss: 20.701440811157227\n",
      "Epoch: 32, Batch: 442, D Loss: 0.097575165877131, G Loss: 20.57903480529785\n",
      "Epoch: 32, Batch: 443, D Loss: 0.09855562502393944, G Loss: 20.713205337524414\n",
      "Epoch: 32, Batch: 444, D Loss: 0.10150763432694701, G Loss: 21.147884368896484\n",
      "Epoch: 32, Batch: 445, D Loss: 0.10248699808917414, G Loss: 21.686716079711914\n",
      "Epoch: 32, Batch: 446, D Loss: 0.09440170993642265, G Loss: 21.588281631469727\n",
      "Epoch: 32, Batch: 447, D Loss: 0.09877070809510649, G Loss: 21.26702880859375\n",
      "Epoch: 32, Batch: 448, D Loss: 0.10460352926808986, G Loss: 21.25948143005371\n",
      "Epoch: 32, Batch: 449, D Loss: 0.10280583826057155, G Loss: 21.400667190551758\n",
      "Epoch: 32, Batch: 450, D Loss: 0.09913097347636421, G Loss: 21.38314437866211\n",
      "Epoch: 32, Batch: 451, D Loss: 0.09746407746637695, G Loss: 21.155107498168945\n",
      "Epoch: 32, Batch: 452, D Loss: 0.10220985148427464, G Loss: 21.077146530151367\n",
      "Epoch: 32, Batch: 453, D Loss: 0.09578299561277054, G Loss: 20.885812759399414\n",
      "Epoch: 32, Batch: 454, D Loss: 0.09317398118092535, G Loss: 20.704484939575195\n",
      "Epoch: 32, Batch: 455, D Loss: 0.10039331809691229, G Loss: 20.912960052490234\n",
      "Epoch: 32, Batch: 456, D Loss: 0.09919427369164052, G Loss: 21.2939510345459\n",
      "Epoch: 32, Batch: 457, D Loss: 0.10049002639512473, G Loss: 21.77809715270996\n",
      "Epoch: 32, Batch: 458, D Loss: 0.09318166243930556, G Loss: 21.739084243774414\n",
      "Epoch: 32, Batch: 459, D Loss: 0.09753500690194619, G Loss: 21.55076789855957\n",
      "Epoch: 32, Batch: 460, D Loss: 0.11048202978655493, G Loss: 22.03186798095703\n",
      "Epoch: 32, Batch: 461, D Loss: 0.10420804481260551, G Loss: 22.516342163085938\n",
      "Epoch: 32, Batch: 462, D Loss: 0.092190653192408, G Loss: 22.046464920043945\n",
      "Epoch: 32, Batch: 463, D Loss: 0.09851828238800393, G Loss: 21.155271530151367\n",
      "Epoch: 32, Batch: 464, D Loss: 0.10245160800521133, G Loss: 20.667207717895508\n",
      "Epoch: 32, Batch: 465, D Loss: 0.098394498752924, G Loss: 20.687496185302734\n",
      "Epoch: 32, Batch: 466, D Loss: 0.10361514280399844, G Loss: 21.186328887939453\n",
      "Epoch: 32, Batch: 467, D Loss: 0.09542377320225115, G Loss: 21.471710205078125\n",
      "Epoch: 33, Batch: 0, D Loss: 0.0943763407620849, G Loss: 21.34119415283203\n",
      "Epoch: 33, Batch: 1, D Loss: 0.10168544229676083, G Loss: 21.36516761779785\n",
      "Epoch: 33, Batch: 2, D Loss: 0.10193185534075364, G Loss: 21.40223503112793\n",
      "Epoch: 33, Batch: 3, D Loss: 0.09798365857910762, G Loss: 21.3172664642334\n",
      "Epoch: 33, Batch: 4, D Loss: 0.09935354470599228, G Loss: 21.21234703063965\n",
      "Epoch: 33, Batch: 5, D Loss: 0.09280587026002055, G Loss: 20.79177474975586\n",
      "Epoch: 33, Batch: 6, D Loss: 0.10299802616827525, G Loss: 20.851736068725586\n",
      "Epoch: 33, Batch: 7, D Loss: 0.10083337166227638, G Loss: 21.126483917236328\n",
      "Epoch: 33, Batch: 8, D Loss: 0.09785951705361617, G Loss: 21.247852325439453\n",
      "Epoch: 33, Batch: 9, D Loss: 0.09645454617930074, G Loss: 21.078929901123047\n",
      "Epoch: 33, Batch: 10, D Loss: 0.09825409987991096, G Loss: 20.86847686767578\n",
      "Epoch: 33, Batch: 11, D Loss: 0.0966132362590969, G Loss: 20.64318084716797\n",
      "Epoch: 33, Batch: 12, D Loss: 0.10202339341303462, G Loss: 20.808048248291016\n",
      "Epoch: 33, Batch: 13, D Loss: 0.10002861956892906, G Loss: 21.07792854309082\n",
      "Epoch: 33, Batch: 14, D Loss: 0.09876395793829887, G Loss: 21.26219367980957\n",
      "Epoch: 33, Batch: 15, D Loss: 0.10214549329445538, G Loss: 21.454200744628906\n",
      "Epoch: 33, Batch: 16, D Loss: 0.0995473268097675, G Loss: 21.42216682434082\n",
      "Epoch: 33, Batch: 17, D Loss: 0.09747579723246355, G Loss: 21.103673934936523\n",
      "Epoch: 33, Batch: 18, D Loss: 0.09995663949236602, G Loss: 20.896705627441406\n",
      "Epoch: 33, Batch: 19, D Loss: 0.10024132620778156, G Loss: 20.936416625976562\n",
      "Epoch: 33, Batch: 20, D Loss: 0.0961047862012204, G Loss: 20.951534271240234\n",
      "Epoch: 33, Batch: 21, D Loss: 0.10180133615134393, G Loss: 21.25307273864746\n",
      "Epoch: 33, Batch: 22, D Loss: 0.09464345901486529, G Loss: 21.277462005615234\n",
      "Epoch: 33, Batch: 23, D Loss: 0.094983749408803, G Loss: 21.09067153930664\n",
      "Epoch: 33, Batch: 24, D Loss: 0.0952311907128274, G Loss: 20.8713436126709\n",
      "Epoch: 33, Batch: 25, D Loss: 0.10053709188629137, G Loss: 21.05098533630371\n",
      "Epoch: 33, Batch: 26, D Loss: 0.09821556540221582, G Loss: 21.296232223510742\n",
      "Epoch: 33, Batch: 27, D Loss: 0.10140486829243317, G Loss: 21.716604232788086\n",
      "Epoch: 33, Batch: 28, D Loss: 0.09268244375671866, G Loss: 21.594589233398438\n",
      "Epoch: 33, Batch: 29, D Loss: 0.09750179973502082, G Loss: 21.105300903320312\n",
      "Epoch: 33, Batch: 30, D Loss: 0.0993863497178466, G Loss: 20.817514419555664\n",
      "Epoch: 33, Batch: 31, D Loss: 0.10380418637667727, G Loss: 21.114013671875\n",
      "Epoch: 33, Batch: 32, D Loss: 0.09847271473045743, G Loss: 21.304040908813477\n",
      "Epoch: 33, Batch: 33, D Loss: 0.09923340407449671, G Loss: 21.354646682739258\n",
      "Epoch: 33, Batch: 34, D Loss: 0.09919992117730358, G Loss: 21.227235794067383\n",
      "Epoch: 33, Batch: 35, D Loss: 0.09995682569943065, G Loss: 21.09598731994629\n",
      "Epoch: 33, Batch: 36, D Loss: 0.10495752872658312, G Loss: 21.271564483642578\n",
      "Epoch: 33, Batch: 37, D Loss: 0.09978578267520824, G Loss: 21.343650817871094\n",
      "Epoch: 33, Batch: 38, D Loss: 0.0906792733458329, G Loss: 20.916423797607422\n",
      "Epoch: 33, Batch: 39, D Loss: 0.10476823935116802, G Loss: 21.026086807250977\n",
      "Epoch: 33, Batch: 40, D Loss: 0.10228177935482705, G Loss: 21.39678955078125\n",
      "Epoch: 33, Batch: 41, D Loss: 0.09836442791349086, G Loss: 21.612287521362305\n",
      "Epoch: 33, Batch: 42, D Loss: 0.09687849900467749, G Loss: 21.554262161254883\n",
      "Epoch: 33, Batch: 43, D Loss: 0.10351286848961912, G Loss: 21.6756534576416\n",
      "Epoch: 33, Batch: 44, D Loss: 0.0988873245292118, G Loss: 21.646244049072266\n",
      "Epoch: 33, Batch: 45, D Loss: 0.10583803075465845, G Loss: 21.856338500976562\n",
      "Epoch: 33, Batch: 46, D Loss: 0.0952792840037251, G Loss: 21.6229190826416\n",
      "Epoch: 33, Batch: 47, D Loss: 0.09805256152004185, G Loss: 21.333166122436523\n",
      "Epoch: 33, Batch: 48, D Loss: 0.0980124700608192, G Loss: 20.843355178833008\n",
      "Epoch: 33, Batch: 49, D Loss: 0.09809296627831232, G Loss: 20.63091278076172\n",
      "Epoch: 33, Batch: 50, D Loss: 0.09760014023473068, G Loss: 20.60342788696289\n",
      "Epoch: 33, Batch: 51, D Loss: 0.10431464061745063, G Loss: 21.021041870117188\n",
      "Epoch: 33, Batch: 52, D Loss: 0.10073694619262147, G Loss: 21.274761199951172\n",
      "Epoch: 33, Batch: 53, D Loss: 0.0981018993461173, G Loss: 21.08658218383789\n",
      "Epoch: 33, Batch: 54, D Loss: 0.1017999056982414, G Loss: 20.831207275390625\n",
      "Epoch: 33, Batch: 55, D Loss: 0.10433590459454078, G Loss: 20.7333984375\n",
      "Epoch: 33, Batch: 56, D Loss: 0.10109068504996749, G Loss: 20.653886795043945\n",
      "Epoch: 33, Batch: 57, D Loss: 0.10899165316604001, G Loss: 21.03446388244629\n",
      "Epoch: 33, Batch: 58, D Loss: 0.10040012036751239, G Loss: 21.13577651977539\n",
      "Epoch: 33, Batch: 59, D Loss: 0.09499973101673195, G Loss: 20.640398025512695\n",
      "Epoch: 33, Batch: 60, D Loss: 0.0955573328075503, G Loss: 19.98656463623047\n",
      "Epoch: 33, Batch: 61, D Loss: 0.10045893605685852, G Loss: 19.80348777770996\n",
      "Epoch: 33, Batch: 62, D Loss: 0.10063708680187078, G Loss: 20.11778450012207\n",
      "Epoch: 33, Batch: 63, D Loss: 0.09408710979997853, G Loss: 20.308839797973633\n",
      "Epoch: 33, Batch: 64, D Loss: 0.10010198567787248, G Loss: 20.62891960144043\n",
      "Epoch: 33, Batch: 65, D Loss: 0.0973509257351029, G Loss: 20.707515716552734\n",
      "Epoch: 33, Batch: 66, D Loss: 0.09729315393995486, G Loss: 20.61243438720703\n",
      "Epoch: 33, Batch: 67, D Loss: 0.10086628853440127, G Loss: 20.518945693969727\n",
      "Epoch: 33, Batch: 68, D Loss: 0.09822759100315248, G Loss: 20.324838638305664\n",
      "Epoch: 33, Batch: 69, D Loss: 0.09623811479067629, G Loss: 20.075740814208984\n",
      "Epoch: 33, Batch: 70, D Loss: 0.09553216504112072, G Loss: 19.877416610717773\n",
      "Epoch: 33, Batch: 71, D Loss: 0.10000397371437308, G Loss: 20.05382537841797\n",
      "Epoch: 33, Batch: 72, D Loss: 0.10721449617833456, G Loss: 20.866241455078125\n",
      "Epoch: 33, Batch: 73, D Loss: 0.10399469763595923, G Loss: 21.54345703125\n",
      "Epoch: 33, Batch: 74, D Loss: 0.10106150827525712, G Loss: 21.583105087280273\n",
      "Epoch: 33, Batch: 75, D Loss: 0.0976691025558662, G Loss: 20.892850875854492\n",
      "Epoch: 33, Batch: 76, D Loss: 0.10508538092579206, G Loss: 20.391050338745117\n",
      "Epoch: 33, Batch: 77, D Loss: 0.09168815715642498, G Loss: 19.655620574951172\n",
      "Epoch: 33, Batch: 78, D Loss: 0.10045960695325262, G Loss: 19.60730743408203\n",
      "Epoch: 33, Batch: 79, D Loss: 0.09770454593331823, G Loss: 19.963088989257812\n",
      "Epoch: 33, Batch: 80, D Loss: 0.10348354362502854, G Loss: 20.45869255065918\n",
      "Epoch: 33, Batch: 81, D Loss: 0.09885710534209635, G Loss: 20.736404418945312\n",
      "Epoch: 33, Batch: 82, D Loss: 0.10122843137615273, G Loss: 20.680374145507812\n",
      "Epoch: 33, Batch: 83, D Loss: 0.10741949880770796, G Loss: 20.608457565307617\n",
      "Epoch: 33, Batch: 84, D Loss: 0.09462832743432059, G Loss: 19.846548080444336\n",
      "Epoch: 33, Batch: 85, D Loss: 0.0975600797336289, G Loss: 19.05725860595703\n",
      "Epoch: 33, Batch: 86, D Loss: 0.09492287397048327, G Loss: 18.50423812866211\n",
      "Epoch: 33, Batch: 87, D Loss: 0.10300185167282594, G Loss: 18.882038116455078\n",
      "Epoch: 33, Batch: 88, D Loss: 0.10176190186421641, G Loss: 19.77849578857422\n",
      "Epoch: 33, Batch: 89, D Loss: 0.09400310469305073, G Loss: 20.223772048950195\n",
      "Epoch: 33, Batch: 90, D Loss: 0.1009082652537523, G Loss: 20.442861557006836\n",
      "Epoch: 33, Batch: 91, D Loss: 0.10672822652963654, G Loss: 20.68617820739746\n",
      "Epoch: 33, Batch: 92, D Loss: 0.09875537513753402, G Loss: 20.45566749572754\n",
      "Epoch: 33, Batch: 93, D Loss: 0.09768528577390517, G Loss: 19.93256187438965\n",
      "Epoch: 33, Batch: 94, D Loss: 0.10241492959751675, G Loss: 19.745027542114258\n",
      "Epoch: 33, Batch: 95, D Loss: 0.09936019910734128, G Loss: 19.75934410095215\n",
      "Epoch: 33, Batch: 96, D Loss: 0.09448845819800433, G Loss: 19.70699119567871\n",
      "Epoch: 33, Batch: 97, D Loss: 0.09573137896135198, G Loss: 19.7443904876709\n",
      "Epoch: 33, Batch: 98, D Loss: 0.10111768652892505, G Loss: 20.12614631652832\n",
      "Epoch: 33, Batch: 99, D Loss: 0.10106759588593561, G Loss: 20.617748260498047\n",
      "Epoch: 33, Batch: 100, D Loss: 0.10450145644669334, G Loss: 21.132802963256836\n",
      "Epoch: 33, Batch: 101, D Loss: 0.10648056892847757, G Loss: 21.450315475463867\n",
      "Epoch: 33, Batch: 102, D Loss: 0.0991450923573039, G Loss: 21.12361717224121\n",
      "Epoch: 33, Batch: 103, D Loss: 0.09477440320019515, G Loss: 20.28338623046875\n",
      "Epoch: 33, Batch: 104, D Loss: 0.1020241985755388, G Loss: 19.812335968017578\n",
      "Epoch: 33, Batch: 105, D Loss: 0.0985587102921609, G Loss: 19.783662796020508\n",
      "Epoch: 33, Batch: 106, D Loss: 0.10158269205911441, G Loss: 20.28412628173828\n",
      "Epoch: 33, Batch: 107, D Loss: 0.09979570713519736, G Loss: 20.88713264465332\n",
      "Epoch: 33, Batch: 108, D Loss: 0.0941885564723969, G Loss: 21.014793395996094\n",
      "Epoch: 33, Batch: 109, D Loss: 0.10125083513562813, G Loss: 21.021862030029297\n",
      "Epoch: 33, Batch: 110, D Loss: 0.10211966222891888, G Loss: 21.073816299438477\n",
      "Epoch: 33, Batch: 111, D Loss: 0.09774521031968653, G Loss: 20.89519691467285\n",
      "Epoch: 33, Batch: 112, D Loss: 0.09791241633571562, G Loss: 20.673709869384766\n",
      "Epoch: 33, Batch: 113, D Loss: 0.09899017268552646, G Loss: 20.632190704345703\n",
      "Epoch: 33, Batch: 114, D Loss: 0.09750074946475057, G Loss: 20.68891716003418\n",
      "Epoch: 33, Batch: 115, D Loss: 0.09301341378175798, G Loss: 20.641653060913086\n",
      "Epoch: 33, Batch: 116, D Loss: 0.10500930290224017, G Loss: 21.19934844970703\n",
      "Epoch: 33, Batch: 117, D Loss: 0.10066012316884937, G Loss: 21.7093448638916\n",
      "Epoch: 33, Batch: 118, D Loss: 0.09996095316808491, G Loss: 21.876686096191406\n",
      "Epoch: 33, Batch: 119, D Loss: 0.09217150530630815, G Loss: 21.310178756713867\n",
      "Epoch: 33, Batch: 120, D Loss: 0.10119280997714758, G Loss: 20.953401565551758\n",
      "Epoch: 33, Batch: 121, D Loss: 0.10279478170177861, G Loss: 21.06761932373047\n",
      "Epoch: 33, Batch: 122, D Loss: 0.09995728761342823, G Loss: 21.373645782470703\n",
      "Epoch: 33, Batch: 123, D Loss: 0.10694921034915268, G Loss: 22.056472778320312\n",
      "Epoch: 33, Batch: 124, D Loss: 0.10228732239363414, G Loss: 22.386072158813477\n",
      "Epoch: 33, Batch: 125, D Loss: 0.10516189047968183, G Loss: 22.44062042236328\n",
      "Epoch: 33, Batch: 126, D Loss: 0.09732136887602075, G Loss: 21.855693817138672\n",
      "Epoch: 33, Batch: 127, D Loss: 0.09722615802803314, G Loss: 21.07497215270996\n",
      "Epoch: 33, Batch: 128, D Loss: 0.096207283915337, G Loss: 20.49294662475586\n",
      "Epoch: 33, Batch: 129, D Loss: 0.10007389693624502, G Loss: 20.62657356262207\n",
      "Epoch: 33, Batch: 130, D Loss: 0.1019666198738522, G Loss: 21.32219123840332\n",
      "Epoch: 33, Batch: 131, D Loss: 0.09750583789720135, G Loss: 21.761398315429688\n",
      "Epoch: 33, Batch: 132, D Loss: 0.09490428883115776, G Loss: 21.71424102783203\n",
      "Epoch: 33, Batch: 133, D Loss: 0.0910014587287625, G Loss: 21.057762145996094\n",
      "Epoch: 33, Batch: 134, D Loss: 0.10513752735950532, G Loss: 20.99370574951172\n",
      "Epoch: 33, Batch: 135, D Loss: 0.09857966042603142, G Loss: 21.064239501953125\n",
      "Epoch: 33, Batch: 136, D Loss: 0.09963080318913373, G Loss: 21.269954681396484\n",
      "Epoch: 33, Batch: 137, D Loss: 0.09531798988375492, G Loss: 21.229175567626953\n",
      "Epoch: 33, Batch: 138, D Loss: 0.10201303689099567, G Loss: 21.355594635009766\n",
      "Epoch: 33, Batch: 139, D Loss: 0.09637971250319471, G Loss: 21.26287078857422\n",
      "Epoch: 33, Batch: 140, D Loss: 0.09914595664550335, G Loss: 21.159536361694336\n",
      "Epoch: 33, Batch: 141, D Loss: 0.09782512519971184, G Loss: 21.06581687927246\n",
      "Epoch: 33, Batch: 142, D Loss: 0.0980789366952822, G Loss: 21.05782127380371\n",
      "Epoch: 33, Batch: 143, D Loss: 0.10758280780863741, G Loss: 21.61200714111328\n",
      "Epoch: 33, Batch: 144, D Loss: 0.0935137422953928, G Loss: 21.608266830444336\n",
      "Epoch: 33, Batch: 145, D Loss: 0.09450272498591078, G Loss: 21.039480209350586\n",
      "Epoch: 33, Batch: 146, D Loss: 0.09447132846902573, G Loss: 20.407644271850586\n",
      "Epoch: 33, Batch: 147, D Loss: 0.09699478827278235, G Loss: 20.07604217529297\n",
      "Epoch: 33, Batch: 148, D Loss: 0.10285654745986961, G Loss: 20.37137794494629\n",
      "Epoch: 33, Batch: 149, D Loss: 0.1005330910828725, G Loss: 20.856828689575195\n",
      "Epoch: 33, Batch: 150, D Loss: 0.09450703156258186, G Loss: 20.93730354309082\n",
      "Epoch: 33, Batch: 151, D Loss: 0.09721528037969124, G Loss: 20.76345443725586\n",
      "Epoch: 33, Batch: 152, D Loss: 0.0947227931140977, G Loss: 20.31884002685547\n",
      "Epoch: 33, Batch: 153, D Loss: 0.09675683918401312, G Loss: 19.929330825805664\n",
      "Epoch: 33, Batch: 154, D Loss: 0.10299711030208614, G Loss: 20.111005783081055\n",
      "Epoch: 33, Batch: 155, D Loss: 0.09649619541694077, G Loss: 20.348424911499023\n",
      "Epoch: 33, Batch: 156, D Loss: 0.09830178386997307, G Loss: 20.519697189331055\n",
      "Epoch: 33, Batch: 157, D Loss: 0.09836518077697765, G Loss: 20.619279861450195\n",
      "Epoch: 33, Batch: 158, D Loss: 0.09839020726584163, G Loss: 20.56697654724121\n",
      "Epoch: 33, Batch: 159, D Loss: 0.09923070729668959, G Loss: 20.505598068237305\n",
      "Epoch: 33, Batch: 160, D Loss: 0.10466668809850643, G Loss: 20.740182876586914\n",
      "Epoch: 33, Batch: 161, D Loss: 0.10171480520809353, G Loss: 20.955337524414062\n",
      "Epoch: 33, Batch: 162, D Loss: 0.09664461060818846, G Loss: 20.752519607543945\n",
      "Epoch: 33, Batch: 163, D Loss: 0.09567671330667432, G Loss: 20.307199478149414\n",
      "Epoch: 33, Batch: 164, D Loss: 0.10200668205825941, G Loss: 20.2215633392334\n",
      "Epoch: 33, Batch: 165, D Loss: 0.10171973032481663, G Loss: 20.479534149169922\n",
      "Epoch: 33, Batch: 166, D Loss: 0.10588014916567307, G Loss: 21.11751365661621\n",
      "Epoch: 33, Batch: 167, D Loss: 0.09157808160446843, G Loss: 21.024999618530273\n",
      "Epoch: 33, Batch: 168, D Loss: 0.10133811125391176, G Loss: 20.9271240234375\n",
      "Epoch: 33, Batch: 169, D Loss: 0.10053808283829974, G Loss: 20.88490104675293\n",
      "Epoch: 33, Batch: 170, D Loss: 0.09709872351439616, G Loss: 20.736848831176758\n",
      "Epoch: 33, Batch: 171, D Loss: 0.09994507629334032, G Loss: 20.77800750732422\n",
      "Epoch: 33, Batch: 172, D Loss: 0.09625449824320387, G Loss: 20.767324447631836\n",
      "Epoch: 33, Batch: 173, D Loss: 0.09768214123628888, G Loss: 20.80907440185547\n",
      "Epoch: 33, Batch: 174, D Loss: 0.10013283830440128, G Loss: 21.012361526489258\n",
      "Epoch: 33, Batch: 175, D Loss: 0.09763269162556659, G Loss: 21.081871032714844\n",
      "Epoch: 33, Batch: 176, D Loss: 0.10109390351548553, G Loss: 21.183000564575195\n",
      "Epoch: 33, Batch: 177, D Loss: 0.10334078995759582, G Loss: 21.401025772094727\n",
      "Epoch: 33, Batch: 178, D Loss: 0.09817798462720051, G Loss: 21.283540725708008\n",
      "Epoch: 33, Batch: 179, D Loss: 0.0923656676136953, G Loss: 20.69475555419922\n",
      "Epoch: 33, Batch: 180, D Loss: 0.10212080982202765, G Loss: 20.519906997680664\n",
      "Epoch: 33, Batch: 181, D Loss: 0.1030404870863803, G Loss: 20.862401962280273\n",
      "Epoch: 33, Batch: 182, D Loss: 0.10194151880682831, G Loss: 21.44089126586914\n",
      "Epoch: 33, Batch: 183, D Loss: 0.09562356793310535, G Loss: 21.531864166259766\n",
      "Epoch: 33, Batch: 184, D Loss: 0.09443274167469676, G Loss: 21.161649703979492\n",
      "Epoch: 33, Batch: 185, D Loss: 0.09525943588735206, G Loss: 20.696792602539062\n",
      "Epoch: 33, Batch: 186, D Loss: 0.09478938640355533, G Loss: 20.3787841796875\n",
      "Epoch: 33, Batch: 187, D Loss: 0.10374561008153027, G Loss: 20.8220272064209\n",
      "Epoch: 33, Batch: 188, D Loss: 0.09461722559449354, G Loss: 21.23543930053711\n",
      "Epoch: 33, Batch: 189, D Loss: 0.10729034264374351, G Loss: 22.066843032836914\n",
      "Epoch: 33, Batch: 190, D Loss: 0.10275416086005243, G Loss: 22.6085205078125\n",
      "Epoch: 33, Batch: 191, D Loss: 0.09296703348793642, G Loss: 22.054128646850586\n",
      "Epoch: 33, Batch: 192, D Loss: 0.09677723070956643, G Loss: 21.190763473510742\n",
      "Epoch: 33, Batch: 193, D Loss: 0.10443164444055258, G Loss: 20.93611717224121\n",
      "Epoch: 33, Batch: 194, D Loss: 0.0995146486905647, G Loss: 21.09394073486328\n",
      "Epoch: 33, Batch: 195, D Loss: 0.09447012128232629, G Loss: 21.26407241821289\n",
      "Epoch: 33, Batch: 196, D Loss: 0.10223633073277727, G Loss: 21.7689151763916\n",
      "Epoch: 33, Batch: 197, D Loss: 0.09938521697436326, G Loss: 22.17173194885254\n",
      "Epoch: 33, Batch: 198, D Loss: 0.10126534114815423, G Loss: 22.391191482543945\n",
      "Epoch: 33, Batch: 199, D Loss: 0.100469604234044, G Loss: 22.29041862487793\n",
      "Epoch: 33, Batch: 200, D Loss: 0.0961732791254601, G Loss: 21.758087158203125\n",
      "Epoch: 33, Batch: 201, D Loss: 0.10055810234627899, G Loss: 21.394248962402344\n",
      "Epoch: 33, Batch: 202, D Loss: 0.09437830776612444, G Loss: 21.062904357910156\n",
      "Epoch: 33, Batch: 203, D Loss: 0.09276522735979334, G Loss: 20.846364974975586\n",
      "Epoch: 33, Batch: 204, D Loss: 0.09670145849685385, G Loss: 21.037830352783203\n",
      "Epoch: 33, Batch: 205, D Loss: 0.10064359035338474, G Loss: 21.679075241088867\n",
      "Epoch: 33, Batch: 206, D Loss: 0.09800834221226551, G Loss: 22.497350692749023\n",
      "Epoch: 33, Batch: 207, D Loss: 0.09504357732706505, G Loss: 22.777219772338867\n",
      "Epoch: 33, Batch: 208, D Loss: 0.10094471281782298, G Loss: 22.911190032958984\n",
      "Epoch: 33, Batch: 209, D Loss: 0.09289645410396434, G Loss: 22.55339813232422\n",
      "Epoch: 33, Batch: 210, D Loss: 0.09978248932724706, G Loss: 22.397302627563477\n",
      "Epoch: 33, Batch: 211, D Loss: 0.08848316979149023, G Loss: 21.982473373413086\n",
      "Epoch: 33, Batch: 212, D Loss: 0.09720000638187595, G Loss: 22.07423973083496\n",
      "Epoch: 33, Batch: 213, D Loss: 0.09789454201741357, G Loss: 22.600313186645508\n",
      "Epoch: 33, Batch: 214, D Loss: 0.10073575382533852, G Loss: 23.385549545288086\n",
      "Epoch: 33, Batch: 215, D Loss: 0.09744654598652071, G Loss: 23.803590774536133\n",
      "Epoch: 33, Batch: 216, D Loss: 0.0955246016637671, G Loss: 23.608991622924805\n",
      "Epoch: 33, Batch: 217, D Loss: 0.09820580485963894, G Loss: 23.18873405456543\n",
      "Epoch: 33, Batch: 218, D Loss: 0.1000036597746635, G Loss: 22.90083122253418\n",
      "Epoch: 33, Batch: 219, D Loss: 0.10239269589801953, G Loss: 22.99786949157715\n",
      "Epoch: 33, Batch: 220, D Loss: 0.10122288767931836, G Loss: 23.290678024291992\n",
      "Epoch: 33, Batch: 221, D Loss: 0.09791995588582042, G Loss: 23.402801513671875\n",
      "Epoch: 33, Batch: 222, D Loss: 0.08892273162740705, G Loss: 22.725597381591797\n",
      "Epoch: 33, Batch: 223, D Loss: 0.09744381913146317, G Loss: 22.278139114379883\n",
      "Epoch: 33, Batch: 224, D Loss: 0.10041043172736819, G Loss: 22.309600830078125\n",
      "Epoch: 33, Batch: 225, D Loss: 0.09777945289270014, G Loss: 22.513425827026367\n",
      "Epoch: 33, Batch: 226, D Loss: 0.09961359209917185, G Loss: 22.83292007446289\n",
      "Epoch: 33, Batch: 227, D Loss: 0.10279487823360596, G Loss: 23.246458053588867\n",
      "Epoch: 33, Batch: 228, D Loss: 0.10177509490355409, G Loss: 23.409809112548828\n",
      "Epoch: 33, Batch: 229, D Loss: 0.09368550036950232, G Loss: 22.850440979003906\n",
      "Epoch: 33, Batch: 230, D Loss: 0.09334421167083508, G Loss: 22.014280319213867\n",
      "Epoch: 33, Batch: 231, D Loss: 0.10227157190696683, G Loss: 21.83065414428711\n",
      "Epoch: 33, Batch: 232, D Loss: 0.10002545281429157, G Loss: 22.13780975341797\n",
      "Epoch: 33, Batch: 233, D Loss: 0.09780543307163322, G Loss: 22.579195022583008\n",
      "Epoch: 33, Batch: 234, D Loss: 0.102439090667479, G Loss: 23.150127410888672\n",
      "Epoch: 33, Batch: 235, D Loss: 0.09843139354558184, G Loss: 23.271034240722656\n",
      "Epoch: 33, Batch: 236, D Loss: 0.0956435800069135, G Loss: 22.92113494873047\n",
      "Epoch: 33, Batch: 237, D Loss: 0.10120863473918439, G Loss: 22.632469177246094\n",
      "Epoch: 33, Batch: 238, D Loss: 0.10231508322257332, G Loss: 22.57286262512207\n",
      "Epoch: 33, Batch: 239, D Loss: 0.09564171740270624, G Loss: 22.360082626342773\n",
      "Epoch: 33, Batch: 240, D Loss: 0.1021836102902354, G Loss: 22.522443771362305\n",
      "Epoch: 33, Batch: 241, D Loss: 0.09570240982723768, G Loss: 22.517087936401367\n",
      "Epoch: 33, Batch: 242, D Loss: 0.1003804729198842, G Loss: 22.567527770996094\n",
      "Epoch: 33, Batch: 243, D Loss: 0.09980238981719619, G Loss: 22.636978149414062\n",
      "Epoch: 33, Batch: 244, D Loss: 0.10109528906367057, G Loss: 22.690311431884766\n",
      "Epoch: 33, Batch: 245, D Loss: 0.09872768826840708, G Loss: 22.555696487426758\n",
      "Epoch: 33, Batch: 246, D Loss: 0.09702511886063245, G Loss: 22.28219223022461\n",
      "Epoch: 33, Batch: 247, D Loss: 0.09432083381466809, G Loss: 21.86014175415039\n",
      "Epoch: 33, Batch: 248, D Loss: 0.10702968402110566, G Loss: 22.217660903930664\n",
      "Epoch: 33, Batch: 249, D Loss: 0.09775665411862952, G Loss: 22.544029235839844\n",
      "Epoch: 33, Batch: 250, D Loss: 0.09919452674692765, G Loss: 22.700599670410156\n",
      "Epoch: 33, Batch: 251, D Loss: 0.09960451729212358, G Loss: 22.661502838134766\n",
      "Epoch: 33, Batch: 252, D Loss: 0.10550893104739673, G Loss: 22.81987762451172\n",
      "Epoch: 33, Batch: 253, D Loss: 0.09555304057701505, G Loss: 22.503772735595703\n",
      "Epoch: 33, Batch: 254, D Loss: 0.09910250465793032, G Loss: 22.059499740600586\n",
      "Epoch: 33, Batch: 255, D Loss: 0.10321906222356561, G Loss: 22.02837562561035\n",
      "Epoch: 33, Batch: 256, D Loss: 0.1000472308498449, G Loss: 22.119260787963867\n",
      "Epoch: 33, Batch: 257, D Loss: 0.09879194212293937, G Loss: 22.139188766479492\n",
      "Epoch: 33, Batch: 258, D Loss: 0.09888266039375813, G Loss: 22.098596572875977\n",
      "Epoch: 33, Batch: 259, D Loss: 0.1009195895285277, G Loss: 22.071687698364258\n",
      "Epoch: 33, Batch: 260, D Loss: 0.10301665974581274, G Loss: 22.093643188476562\n",
      "Epoch: 33, Batch: 261, D Loss: 0.10378437501275, G Loss: 22.20159339904785\n",
      "Epoch: 33, Batch: 262, D Loss: 0.09567281617369017, G Loss: 21.875934600830078\n",
      "Epoch: 33, Batch: 263, D Loss: 0.09504096230644453, G Loss: 21.36737060546875\n",
      "Epoch: 33, Batch: 264, D Loss: 0.09587485374496763, G Loss: 21.0357723236084\n",
      "Epoch: 33, Batch: 265, D Loss: 0.09930945967061741, G Loss: 21.165592193603516\n",
      "Epoch: 33, Batch: 266, D Loss: 0.09938972468980814, G Loss: 21.595508575439453\n",
      "Epoch: 33, Batch: 267, D Loss: 0.09727149473943049, G Loss: 21.96624755859375\n",
      "Epoch: 33, Batch: 268, D Loss: 0.09520067288855885, G Loss: 21.985788345336914\n",
      "Epoch: 33, Batch: 269, D Loss: 0.09465245919347474, G Loss: 21.659029006958008\n",
      "Epoch: 33, Batch: 270, D Loss: 0.10396474619029482, G Loss: 21.701690673828125\n",
      "Epoch: 33, Batch: 271, D Loss: 0.10342253015150012, G Loss: 22.056791305541992\n",
      "Epoch: 33, Batch: 272, D Loss: 0.09803262365167166, G Loss: 22.200265884399414\n",
      "Epoch: 33, Batch: 273, D Loss: 0.09513305140548425, G Loss: 21.96605110168457\n",
      "Epoch: 33, Batch: 274, D Loss: 0.09745377319028195, G Loss: 21.671178817749023\n",
      "Epoch: 33, Batch: 275, D Loss: 0.09303870820947857, G Loss: 21.282299041748047\n",
      "Epoch: 33, Batch: 276, D Loss: 0.09740041225953389, G Loss: 21.217456817626953\n",
      "Epoch: 33, Batch: 277, D Loss: 0.10056595529947707, G Loss: 21.54692268371582\n",
      "Epoch: 33, Batch: 278, D Loss: 0.09930385666388333, G Loss: 22.01183319091797\n",
      "Epoch: 33, Batch: 279, D Loss: 0.09558866186055608, G Loss: 22.120168685913086\n",
      "Epoch: 33, Batch: 280, D Loss: 0.10253445815783357, G Loss: 22.23225212097168\n",
      "Epoch: 33, Batch: 281, D Loss: 0.10441169153061351, G Loss: 22.360599517822266\n",
      "Epoch: 33, Batch: 282, D Loss: 0.09927847989795366, G Loss: 22.652488708496094\n",
      "Epoch: 33, Batch: 283, D Loss: 0.09936444468487753, G Loss: 22.685693740844727\n",
      "Epoch: 33, Batch: 284, D Loss: 0.09169473507585271, G Loss: 22.3179988861084\n",
      "Epoch: 33, Batch: 285, D Loss: 0.0961965621598464, G Loss: 22.198745727539062\n",
      "Epoch: 33, Batch: 286, D Loss: 0.10358932622547729, G Loss: 22.825605392456055\n",
      "Epoch: 33, Batch: 287, D Loss: 0.10399881008868556, G Loss: 23.846872329711914\n",
      "Epoch: 33, Batch: 288, D Loss: 0.1005261391550606, G Loss: 24.584199905395508\n",
      "Epoch: 33, Batch: 289, D Loss: 0.09806643427447323, G Loss: 24.626989364624023\n",
      "Epoch: 33, Batch: 290, D Loss: 0.10418538750328188, G Loss: 24.444063186645508\n",
      "Epoch: 33, Batch: 291, D Loss: 0.10041373969604936, G Loss: 24.063661575317383\n",
      "Epoch: 33, Batch: 292, D Loss: 0.09857716414358832, G Loss: 23.062807083129883\n",
      "Epoch: 33, Batch: 293, D Loss: 0.09259904929036962, G Loss: 22.103357315063477\n",
      "Epoch: 33, Batch: 294, D Loss: 0.09936824455951627, G Loss: 21.770174026489258\n",
      "Epoch: 33, Batch: 295, D Loss: 0.10032183692533114, G Loss: 21.997638702392578\n",
      "Epoch: 33, Batch: 296, D Loss: 0.09887869667596788, G Loss: 22.367155075073242\n",
      "Epoch: 33, Batch: 297, D Loss: 0.09929031887294146, G Loss: 22.592557907104492\n",
      "Epoch: 33, Batch: 298, D Loss: 0.10030999787891917, G Loss: 22.478591918945312\n",
      "Epoch: 33, Batch: 299, D Loss: 0.09474642586919392, G Loss: 21.83955955505371\n",
      "Epoch: 33, Batch: 300, D Loss: 0.09224472966192149, G Loss: 20.94329261779785\n",
      "Epoch: 33, Batch: 301, D Loss: 0.09921422649065548, G Loss: 20.593013763427734\n",
      "Epoch: 33, Batch: 302, D Loss: 0.09605991895819471, G Loss: 20.647281646728516\n",
      "Epoch: 33, Batch: 303, D Loss: 0.09590295746053165, G Loss: 21.04421043395996\n",
      "Epoch: 33, Batch: 304, D Loss: 0.09635340450865204, G Loss: 21.50530242919922\n",
      "Epoch: 33, Batch: 305, D Loss: 0.09121724240974394, G Loss: 21.50920295715332\n",
      "Epoch: 33, Batch: 306, D Loss: 0.09975534699776069, G Loss: 21.55402183532715\n",
      "Epoch: 33, Batch: 307, D Loss: 0.09115265336134404, G Loss: 21.195798873901367\n",
      "Epoch: 33, Batch: 308, D Loss: 0.09688127074012445, G Loss: 21.0808048248291\n",
      "Epoch: 33, Batch: 309, D Loss: 0.09988962889622621, G Loss: 21.329118728637695\n",
      "Epoch: 33, Batch: 310, D Loss: 0.0977504181136524, G Loss: 21.69354248046875\n",
      "Epoch: 33, Batch: 311, D Loss: 0.10117488369506203, G Loss: 22.131757736206055\n",
      "Epoch: 33, Batch: 312, D Loss: 0.099224120488974, G Loss: 22.324932098388672\n",
      "Epoch: 33, Batch: 313, D Loss: 0.09393718851047428, G Loss: 21.93810272216797\n",
      "Epoch: 33, Batch: 314, D Loss: 0.09632454832040048, G Loss: 21.421207427978516\n",
      "Epoch: 33, Batch: 315, D Loss: 0.09683340817077893, G Loss: 21.118894577026367\n",
      "Epoch: 33, Batch: 316, D Loss: 0.10080215365468531, G Loss: 21.303552627563477\n",
      "Epoch: 33, Batch: 317, D Loss: 0.09532207275256532, G Loss: 21.545026779174805\n",
      "Epoch: 33, Batch: 318, D Loss: 0.10186305659097233, G Loss: 22.04053497314453\n",
      "Epoch: 33, Batch: 319, D Loss: 0.10157090436155189, G Loss: 22.47386932373047\n",
      "Epoch: 33, Batch: 320, D Loss: 0.09962151953041834, G Loss: 22.536449432373047\n",
      "Epoch: 33, Batch: 321, D Loss: 0.09821158657482613, G Loss: 22.15996742248535\n",
      "Epoch: 33, Batch: 322, D Loss: 0.09784600154897041, G Loss: 21.57188606262207\n",
      "Epoch: 33, Batch: 323, D Loss: 0.09004121306671878, G Loss: 20.7525577545166\n",
      "Epoch: 33, Batch: 324, D Loss: 0.10601858093388841, G Loss: 20.953094482421875\n",
      "Epoch: 33, Batch: 325, D Loss: 0.10331551010995715, G Loss: 21.80118751525879\n",
      "Epoch: 33, Batch: 326, D Loss: 0.09317956878643918, G Loss: 22.19916534423828\n",
      "Epoch: 33, Batch: 327, D Loss: 0.0963969529826673, G Loss: 22.185497283935547\n",
      "Epoch: 33, Batch: 328, D Loss: 0.09688219441661376, G Loss: 21.8818416595459\n",
      "Epoch: 33, Batch: 329, D Loss: 0.09408376386882894, G Loss: 21.33295249938965\n",
      "Epoch: 33, Batch: 330, D Loss: 0.09848991812663127, G Loss: 21.073034286499023\n",
      "Epoch: 33, Batch: 331, D Loss: 0.10113628983621309, G Loss: 21.385400772094727\n",
      "Epoch: 33, Batch: 332, D Loss: 0.09772171103238368, G Loss: 21.593517303466797\n",
      "Epoch: 33, Batch: 333, D Loss: 0.10518154518176781, G Loss: 22.07758140563965\n",
      "Epoch: 33, Batch: 334, D Loss: 0.1046428830510677, G Loss: 22.41788673400879\n",
      "Epoch: 33, Batch: 335, D Loss: 0.104746803737081, G Loss: 22.338924407958984\n",
      "Epoch: 33, Batch: 336, D Loss: 0.1065990777029321, G Loss: 21.972171783447266\n",
      "Epoch: 33, Batch: 337, D Loss: 0.0938160496504517, G Loss: 20.896879196166992\n",
      "Epoch: 33, Batch: 338, D Loss: 0.10358761310415687, G Loss: 20.240991592407227\n",
      "Epoch: 33, Batch: 339, D Loss: 0.09895955862528222, G Loss: 20.018810272216797\n",
      "Epoch: 33, Batch: 340, D Loss: 0.09645929282851384, G Loss: 20.137767791748047\n",
      "Epoch: 33, Batch: 341, D Loss: 0.095457331120686, G Loss: 20.423585891723633\n",
      "Epoch: 33, Batch: 342, D Loss: 0.09763531442422163, G Loss: 20.795717239379883\n",
      "Epoch: 33, Batch: 343, D Loss: 0.09844457398009654, G Loss: 21.08981704711914\n",
      "Epoch: 33, Batch: 344, D Loss: 0.10464271931345581, G Loss: 21.476016998291016\n",
      "Epoch: 33, Batch: 345, D Loss: 0.10459314307415489, G Loss: 21.72203826904297\n",
      "Epoch: 33, Batch: 346, D Loss: 0.10184752960994652, G Loss: 21.57959747314453\n",
      "Epoch: 33, Batch: 347, D Loss: 0.09825989631843976, G Loss: 21.066539764404297\n",
      "Epoch: 33, Batch: 348, D Loss: 0.10262698721951713, G Loss: 20.75699234008789\n",
      "Epoch: 33, Batch: 349, D Loss: 0.09952944568870259, G Loss: 20.63149642944336\n",
      "Epoch: 33, Batch: 350, D Loss: 0.10071760466516033, G Loss: 20.790882110595703\n",
      "Epoch: 33, Batch: 351, D Loss: 0.1040584374051251, G Loss: 21.310579299926758\n",
      "Epoch: 33, Batch: 352, D Loss: 0.10190274589018766, G Loss: 21.705636978149414\n",
      "Epoch: 33, Batch: 353, D Loss: 0.09797687847946805, G Loss: 21.638626098632812\n",
      "Epoch: 33, Batch: 354, D Loss: 0.10061702155148233, G Loss: 21.383102416992188\n",
      "Epoch: 33, Batch: 355, D Loss: 0.10014568299551996, G Loss: 21.082786560058594\n",
      "Epoch: 33, Batch: 356, D Loss: 0.09970261194837862, G Loss: 20.90912437438965\n",
      "Epoch: 33, Batch: 357, D Loss: 0.09928508143924186, G Loss: 20.934419631958008\n",
      "Epoch: 33, Batch: 358, D Loss: 0.09944286979215727, G Loss: 21.120988845825195\n",
      "Epoch: 33, Batch: 359, D Loss: 0.10095092683041607, G Loss: 21.41437530517578\n",
      "Epoch: 33, Batch: 360, D Loss: 0.09918303810493252, G Loss: 21.59605598449707\n",
      "Epoch: 33, Batch: 361, D Loss: 0.0995853917854248, G Loss: 21.639198303222656\n",
      "Epoch: 33, Batch: 362, D Loss: 0.1068834068148956, G Loss: 21.886037826538086\n",
      "Epoch: 33, Batch: 363, D Loss: 0.09743562357994043, G Loss: 21.69898796081543\n",
      "Epoch: 33, Batch: 364, D Loss: 0.1018964650301164, G Loss: 21.53677749633789\n",
      "Epoch: 33, Batch: 365, D Loss: 0.09297299414837301, G Loss: 20.977081298828125\n",
      "Epoch: 33, Batch: 366, D Loss: 0.09810239121896255, G Loss: 20.68597412109375\n",
      "Epoch: 33, Batch: 367, D Loss: 0.10118329570954832, G Loss: 20.9199275970459\n",
      "Epoch: 33, Batch: 368, D Loss: 0.10681076374206058, G Loss: 21.761465072631836\n",
      "Epoch: 33, Batch: 369, D Loss: 0.09455351547123095, G Loss: 22.000761032104492\n",
      "Epoch: 33, Batch: 370, D Loss: 0.09374444204413311, G Loss: 21.546417236328125\n",
      "Epoch: 33, Batch: 371, D Loss: 0.09707251965578409, G Loss: 20.99345588684082\n",
      "Epoch: 33, Batch: 372, D Loss: 0.10304252842505407, G Loss: 20.9461669921875\n",
      "Epoch: 33, Batch: 373, D Loss: 0.0973218832169816, G Loss: 21.081443786621094\n",
      "Epoch: 33, Batch: 374, D Loss: 0.09990260779974475, G Loss: 21.37851905822754\n",
      "Epoch: 33, Batch: 375, D Loss: 0.0945726188516948, G Loss: 21.467618942260742\n",
      "Epoch: 33, Batch: 376, D Loss: 0.10484630634025469, G Loss: 21.84351348876953\n",
      "Epoch: 33, Batch: 377, D Loss: 0.0987739042964618, G Loss: 21.98222541809082\n",
      "Epoch: 33, Batch: 378, D Loss: 0.09548159705332558, G Loss: 21.684730529785156\n",
      "Epoch: 33, Batch: 379, D Loss: 0.09770542406775276, G Loss: 21.287059783935547\n",
      "Epoch: 33, Batch: 380, D Loss: 0.09646119955493968, G Loss: 21.000974655151367\n",
      "Epoch: 33, Batch: 381, D Loss: 0.1011578518619892, G Loss: 21.181676864624023\n",
      "Epoch: 33, Batch: 382, D Loss: 0.10381677769171185, G Loss: 21.837249755859375\n",
      "Epoch: 33, Batch: 383, D Loss: 0.09300078467243905, G Loss: 21.933557510375977\n",
      "Epoch: 33, Batch: 384, D Loss: 0.09261134285196945, G Loss: 21.541019439697266\n",
      "Epoch: 33, Batch: 385, D Loss: 0.09160492599603681, G Loss: 20.931903839111328\n",
      "Epoch: 33, Batch: 386, D Loss: 0.09561000811442466, G Loss: 20.653093338012695\n",
      "Epoch: 33, Batch: 387, D Loss: 0.09872584090281486, G Loss: 20.974979400634766\n",
      "Epoch: 33, Batch: 388, D Loss: 0.0944581630853478, G Loss: 21.463191986083984\n",
      "Epoch: 33, Batch: 389, D Loss: 0.0975474418607118, G Loss: 22.486312866210938\n",
      "Epoch: 33, Batch: 390, D Loss: 0.10216310625461392, G Loss: 23.45699691772461\n",
      "Epoch: 33, Batch: 391, D Loss: 0.1088382229405208, G Loss: 24.414531707763672\n",
      "Epoch: 33, Batch: 392, D Loss: 0.09631344677300527, G Loss: 24.360687255859375\n",
      "Epoch: 33, Batch: 393, D Loss: 0.10392975808729636, G Loss: 24.0620059967041\n",
      "Epoch: 33, Batch: 394, D Loss: 0.09362246098764965, G Loss: 23.313255310058594\n",
      "Epoch: 33, Batch: 395, D Loss: 0.09446628396815068, G Loss: 22.738996505737305\n",
      "Epoch: 33, Batch: 396, D Loss: 0.10092200344342231, G Loss: 23.102773666381836\n",
      "Epoch: 33, Batch: 397, D Loss: 0.09435114267922186, G Loss: 23.671016693115234\n",
      "Epoch: 33, Batch: 398, D Loss: 0.09996660800473656, G Loss: 24.51023292541504\n",
      "Epoch: 33, Batch: 399, D Loss: 0.0969357416104868, G Loss: 25.39527702331543\n",
      "Epoch: 33, Batch: 400, D Loss: 0.09620171785742593, G Loss: 25.750333786010742\n",
      "Epoch: 33, Batch: 401, D Loss: 0.10161382705255363, G Loss: 26.035924911499023\n",
      "Epoch: 33, Batch: 402, D Loss: 0.09988445043802734, G Loss: 26.094940185546875\n",
      "Epoch: 33, Batch: 403, D Loss: 0.10106514394505127, G Loss: 26.18266487121582\n",
      "Epoch: 33, Batch: 404, D Loss: 0.09979994595248438, G Loss: 26.32329559326172\n",
      "Epoch: 33, Batch: 405, D Loss: 0.09664277732553757, G Loss: 26.35866928100586\n",
      "Epoch: 33, Batch: 406, D Loss: 0.1009885147225596, G Loss: 27.167469024658203\n",
      "Epoch: 33, Batch: 407, D Loss: 0.09859551489422588, G Loss: 27.425085067749023\n",
      "Epoch: 33, Batch: 408, D Loss: 0.09841112792542889, G Loss: 27.77967643737793\n",
      "Epoch: 33, Batch: 409, D Loss: 0.10444739460961157, G Loss: 29.657941818237305\n",
      "Epoch: 33, Batch: 410, D Loss: 0.09726354479792482, G Loss: 31.31907081604004\n",
      "Epoch: 33, Batch: 411, D Loss: 0.09697005152703247, G Loss: 31.91084861755371\n",
      "Epoch: 33, Batch: 412, D Loss: 0.09561119228601933, G Loss: 32.61619186401367\n",
      "Epoch: 33, Batch: 413, D Loss: 0.10704781860113202, G Loss: 35.99983596801758\n",
      "Epoch: 33, Batch: 414, D Loss: 0.09912617504596712, G Loss: 40.93748474121094\n",
      "Epoch: 33, Batch: 415, D Loss: 0.09797517955303192, G Loss: 39.773094177246094\n",
      "Epoch: 33, Batch: 416, D Loss: 0.10043390840291978, G Loss: 37.09843444824219\n",
      "Epoch: 33, Batch: 417, D Loss: 0.09605503082275449, G Loss: 31.933977127075195\n",
      "Epoch: 33, Batch: 418, D Loss: 0.10258748382334594, G Loss: 28.268949508666992\n",
      "Epoch: 33, Batch: 419, D Loss: 0.09644133597738117, G Loss: 25.30792808532715\n",
      "Epoch: 33, Batch: 420, D Loss: 0.09451839329728463, G Loss: 22.801040649414062\n",
      "Epoch: 33, Batch: 421, D Loss: 0.09803824888335774, G Loss: 20.959386825561523\n",
      "Epoch: 33, Batch: 422, D Loss: 0.09874954896573773, G Loss: 19.697540283203125\n",
      "Epoch: 33, Batch: 423, D Loss: 0.10599917362219591, G Loss: 19.132516860961914\n",
      "Epoch: 33, Batch: 424, D Loss: 0.10024222329816457, G Loss: 18.515684127807617\n",
      "Epoch: 33, Batch: 425, D Loss: 0.09579546795985472, G Loss: 17.511381149291992\n",
      "Epoch: 33, Batch: 426, D Loss: 0.10390019778449755, G Loss: 16.867069244384766\n",
      "Epoch: 33, Batch: 427, D Loss: 0.10867513924839045, G Loss: 16.95734405517578\n",
      "Epoch: 33, Batch: 428, D Loss: 0.09698259044314916, G Loss: 17.066152572631836\n",
      "Epoch: 33, Batch: 429, D Loss: 0.09615610302860667, G Loss: 17.13473129272461\n",
      "Epoch: 33, Batch: 430, D Loss: 0.09905924765688034, G Loss: 17.46242904663086\n",
      "Epoch: 33, Batch: 431, D Loss: 0.09901165444400917, G Loss: 18.08293914794922\n",
      "Epoch: 33, Batch: 432, D Loss: 0.09872024243173483, G Loss: 18.826513290405273\n",
      "Epoch: 33, Batch: 433, D Loss: 0.10173453643270647, G Loss: 19.36832046508789\n",
      "Epoch: 33, Batch: 434, D Loss: 0.10114336927700884, G Loss: 19.641000747680664\n",
      "Epoch: 33, Batch: 435, D Loss: 0.09382022344823804, G Loss: 19.354345321655273\n",
      "Epoch: 33, Batch: 436, D Loss: 0.10284614776811818, G Loss: 19.208375930786133\n",
      "Epoch: 33, Batch: 437, D Loss: 0.1010320061118899, G Loss: 19.160558700561523\n",
      "Epoch: 33, Batch: 438, D Loss: 0.09468177232619301, G Loss: 18.93169403076172\n",
      "Epoch: 33, Batch: 439, D Loss: 0.10671767845461289, G Loss: 19.271488189697266\n",
      "Epoch: 33, Batch: 440, D Loss: 0.0992508772596229, G Loss: 19.560123443603516\n",
      "Epoch: 33, Batch: 441, D Loss: 0.09842153047701807, G Loss: 19.64108657836914\n",
      "Epoch: 33, Batch: 442, D Loss: 0.10400262605696264, G Loss: 19.88050651550293\n",
      "Epoch: 33, Batch: 443, D Loss: 0.1019320796800206, G Loss: 20.025638580322266\n",
      "Epoch: 33, Batch: 444, D Loss: 0.09136130045997337, G Loss: 19.53937339782715\n",
      "Epoch: 33, Batch: 445, D Loss: 0.10033356583306441, G Loss: 19.315515518188477\n",
      "Epoch: 33, Batch: 446, D Loss: 0.09505328012566228, G Loss: 19.17637825012207\n",
      "Epoch: 33, Batch: 447, D Loss: 0.09840848507640709, G Loss: 19.396228790283203\n",
      "Epoch: 33, Batch: 448, D Loss: 0.08826263443149451, G Loss: 19.35247230529785\n",
      "Epoch: 33, Batch: 449, D Loss: 0.09989417508155285, G Loss: 19.713138580322266\n",
      "Epoch: 33, Batch: 450, D Loss: 0.09946506574273717, G Loss: 20.250539779663086\n",
      "Epoch: 33, Batch: 451, D Loss: 0.10338981502615252, G Loss: 21.04050636291504\n",
      "Epoch: 33, Batch: 452, D Loss: 0.09754637664250079, G Loss: 21.093290328979492\n",
      "Epoch: 33, Batch: 453, D Loss: 0.10561315750140085, G Loss: 21.079790115356445\n",
      "Epoch: 33, Batch: 454, D Loss: 0.10126332989161846, G Loss: 20.38582420349121\n",
      "Epoch: 33, Batch: 455, D Loss: 0.09491713464157592, G Loss: 19.38220977783203\n",
      "Epoch: 33, Batch: 456, D Loss: 0.10696550685396256, G Loss: 19.073057174682617\n",
      "Epoch: 33, Batch: 457, D Loss: 0.10397105156342668, G Loss: 19.2655086517334\n",
      "Epoch: 33, Batch: 458, D Loss: 0.10019103637649196, G Loss: 19.415225982666016\n",
      "Epoch: 33, Batch: 459, D Loss: 0.09661492165702401, G Loss: 19.228477478027344\n",
      "Epoch: 33, Batch: 460, D Loss: 0.09836153951154247, G Loss: 18.916677474975586\n",
      "Epoch: 33, Batch: 461, D Loss: 0.10535593623543993, G Loss: 19.011802673339844\n",
      "Epoch: 33, Batch: 462, D Loss: 0.09965817883732231, G Loss: 19.1971378326416\n",
      "Epoch: 33, Batch: 463, D Loss: 0.10165692339665067, G Loss: 19.306608200073242\n",
      "Epoch: 33, Batch: 464, D Loss: 0.10267418813168394, G Loss: 19.473011016845703\n",
      "Epoch: 33, Batch: 465, D Loss: 0.09751939993095604, G Loss: 19.053375244140625\n",
      "Epoch: 33, Batch: 466, D Loss: 0.10363731082495486, G Loss: 18.87838363647461\n",
      "Epoch: 33, Batch: 467, D Loss: 0.10281275542468182, G Loss: 18.822235107421875\n",
      "Epoch: 34, Batch: 0, D Loss: 0.10274156518788313, G Loss: 18.838428497314453\n",
      "Epoch: 34, Batch: 1, D Loss: 0.09580104432905134, G Loss: 18.592098236083984\n",
      "Epoch: 34, Batch: 2, D Loss: 0.09944241963487288, G Loss: 18.417442321777344\n",
      "Epoch: 34, Batch: 3, D Loss: 0.09763597481677744, G Loss: 18.349924087524414\n",
      "Epoch: 34, Batch: 4, D Loss: 0.09884591155284816, G Loss: 18.519636154174805\n",
      "Epoch: 34, Batch: 5, D Loss: 0.10129374628367382, G Loss: 18.96634864807129\n",
      "Epoch: 34, Batch: 6, D Loss: 0.10027963148178665, G Loss: 19.462907791137695\n",
      "Epoch: 34, Batch: 7, D Loss: 0.09639482361650431, G Loss: 19.641231536865234\n",
      "Epoch: 34, Batch: 8, D Loss: 0.10022167255509629, G Loss: 19.76285171508789\n",
      "Epoch: 34, Batch: 9, D Loss: 0.09480290262364455, G Loss: 19.542768478393555\n",
      "Epoch: 34, Batch: 10, D Loss: 0.0952822808088557, G Loss: 19.308393478393555\n",
      "Epoch: 34, Batch: 11, D Loss: 0.10026327708602678, G Loss: 19.49348258972168\n",
      "Epoch: 34, Batch: 12, D Loss: 0.10435282553232084, G Loss: 20.270587921142578\n",
      "Epoch: 34, Batch: 13, D Loss: 0.09687088489499024, G Loss: 20.801513671875\n",
      "Epoch: 34, Batch: 14, D Loss: 0.10475042497735376, G Loss: 21.31189727783203\n",
      "Epoch: 34, Batch: 15, D Loss: 0.09929873822756416, G Loss: 21.267580032348633\n",
      "Epoch: 34, Batch: 16, D Loss: 0.09734140373610145, G Loss: 20.801494598388672\n",
      "Epoch: 34, Batch: 17, D Loss: 0.09875055460495286, G Loss: 20.375043869018555\n",
      "Epoch: 34, Batch: 18, D Loss: 0.09852623273721173, G Loss: 20.166667938232422\n",
      "Epoch: 34, Batch: 19, D Loss: 0.09633285639490102, G Loss: 20.17317008972168\n",
      "Epoch: 34, Batch: 20, D Loss: 0.10147624529936988, G Loss: 20.664104461669922\n",
      "Epoch: 34, Batch: 21, D Loss: 0.10179071910861182, G Loss: 21.327043533325195\n",
      "Epoch: 34, Batch: 22, D Loss: 0.09956909738865305, G Loss: 21.678634643554688\n",
      "Epoch: 34, Batch: 23, D Loss: 0.09604125491681766, G Loss: 21.445581436157227\n",
      "Epoch: 34, Batch: 24, D Loss: 0.097186878637022, G Loss: 20.960174560546875\n",
      "Epoch: 34, Batch: 25, D Loss: 0.09895803080921861, G Loss: 20.646211624145508\n",
      "Epoch: 34, Batch: 26, D Loss: 0.09930682981120659, G Loss: 20.659090042114258\n",
      "Epoch: 34, Batch: 27, D Loss: 0.10498597512303182, G Loss: 21.236129760742188\n",
      "Epoch: 34, Batch: 28, D Loss: 0.09949753456461236, G Loss: 21.73836326599121\n",
      "Epoch: 34, Batch: 29, D Loss: 0.09856308270097655, G Loss: 21.702224731445312\n",
      "Epoch: 34, Batch: 30, D Loss: 0.10530114937676796, G Loss: 21.70915412902832\n",
      "Epoch: 34, Batch: 31, D Loss: 0.09389528657691693, G Loss: 21.113508224487305\n",
      "Epoch: 34, Batch: 32, D Loss: 0.10550186076837886, G Loss: 20.855587005615234\n",
      "Epoch: 34, Batch: 33, D Loss: 0.09954485345373015, G Loss: 20.678424835205078\n",
      "Epoch: 34, Batch: 34, D Loss: 0.09827672000071636, G Loss: 20.587276458740234\n",
      "Epoch: 34, Batch: 35, D Loss: 0.09550175131271366, G Loss: 20.48758316040039\n",
      "Epoch: 34, Batch: 36, D Loss: 0.10500012389950603, G Loss: 20.872121810913086\n",
      "Epoch: 34, Batch: 37, D Loss: 0.09573864231863288, G Loss: 21.011764526367188\n",
      "Epoch: 34, Batch: 38, D Loss: 0.09864316918571836, G Loss: 20.994359970092773\n",
      "Epoch: 34, Batch: 39, D Loss: 0.10277868842412624, G Loss: 21.15430450439453\n",
      "Epoch: 34, Batch: 40, D Loss: 0.09472562410167162, G Loss: 20.885255813598633\n",
      "Epoch: 34, Batch: 41, D Loss: 0.09766070594322801, G Loss: 20.5959529876709\n",
      "Epoch: 34, Batch: 42, D Loss: 0.0977247140071203, G Loss: 20.427438735961914\n",
      "Epoch: 34, Batch: 43, D Loss: 0.09973487320171431, G Loss: 20.578819274902344\n",
      "Epoch: 34, Batch: 44, D Loss: 0.09849903037946245, G Loss: 20.83928108215332\n",
      "Epoch: 34, Batch: 45, D Loss: 0.09680438083641374, G Loss: 20.955289840698242\n",
      "Epoch: 34, Batch: 46, D Loss: 0.0983244184503275, G Loss: 21.026735305786133\n",
      "Epoch: 34, Batch: 47, D Loss: 0.09811639077774187, G Loss: 21.021617889404297\n",
      "Epoch: 34, Batch: 48, D Loss: 0.09292837275909838, G Loss: 20.719675064086914\n",
      "Epoch: 34, Batch: 49, D Loss: 0.10149480451284154, G Loss: 20.77574348449707\n",
      "Epoch: 34, Batch: 50, D Loss: 0.09985617590071943, G Loss: 21.017383575439453\n",
      "Epoch: 34, Batch: 51, D Loss: 0.10453936485417956, G Loss: 21.575061798095703\n",
      "Epoch: 34, Batch: 52, D Loss: 0.10064834374322652, G Loss: 21.89742660522461\n",
      "Epoch: 34, Batch: 53, D Loss: 0.10291579380453748, G Loss: 21.99055290222168\n",
      "Epoch: 34, Batch: 54, D Loss: 0.09865564124753678, G Loss: 21.649152755737305\n",
      "Epoch: 34, Batch: 55, D Loss: 0.09651961949894133, G Loss: 21.042930603027344\n",
      "Epoch: 34, Batch: 56, D Loss: 0.10085687828105855, G Loss: 20.780397415161133\n",
      "Epoch: 34, Batch: 57, D Loss: 0.10475990214239558, G Loss: 21.19401741027832\n",
      "Epoch: 34, Batch: 58, D Loss: 0.09860125953228965, G Loss: 21.685876846313477\n",
      "Epoch: 34, Batch: 59, D Loss: 0.10222183182657626, G Loss: 22.18059730529785\n",
      "Epoch: 34, Batch: 60, D Loss: 0.09826514136628116, G Loss: 22.162771224975586\n",
      "Epoch: 34, Batch: 61, D Loss: 0.09843046977162348, G Loss: 21.854169845581055\n",
      "Epoch: 34, Batch: 62, D Loss: 0.0991648586494869, G Loss: 21.55323028564453\n",
      "Epoch: 34, Batch: 63, D Loss: 0.10558839162279932, G Loss: 21.722726821899414\n",
      "Epoch: 34, Batch: 64, D Loss: 0.09994846598553236, G Loss: 21.973182678222656\n",
      "Epoch: 34, Batch: 65, D Loss: 0.09951812787591256, G Loss: 22.066322326660156\n",
      "Epoch: 34, Batch: 66, D Loss: 0.09885834916034204, G Loss: 22.001953125\n",
      "Epoch: 34, Batch: 67, D Loss: 0.10639352363672853, G Loss: 22.246261596679688\n",
      "Epoch: 34, Batch: 68, D Loss: 0.107856862334702, G Loss: 22.659990310668945\n",
      "Epoch: 34, Batch: 69, D Loss: 0.1040936858130811, G Loss: 22.80272102355957\n",
      "Epoch: 34, Batch: 70, D Loss: 0.10151777423618744, G Loss: 22.547035217285156\n",
      "Epoch: 34, Batch: 71, D Loss: 0.09712272149149043, G Loss: 21.83365821838379\n",
      "Epoch: 34, Batch: 72, D Loss: 0.09640251123985394, G Loss: 21.124542236328125\n",
      "Epoch: 34, Batch: 73, D Loss: 0.08948168207266821, G Loss: 20.412927627563477\n",
      "Epoch: 34, Batch: 74, D Loss: 0.10086980520165922, G Loss: 20.72190284729004\n",
      "Epoch: 34, Batch: 75, D Loss: 0.10309872059366487, G Loss: 21.81532096862793\n",
      "Epoch: 34, Batch: 76, D Loss: 0.09424588095572026, G Loss: 22.556921005249023\n",
      "Epoch: 34, Batch: 77, D Loss: 0.0979785770875848, G Loss: 22.815229415893555\n",
      "Epoch: 34, Batch: 78, D Loss: 0.1026028022758873, G Loss: 22.904787063598633\n",
      "Epoch: 34, Batch: 79, D Loss: 0.09895651048374024, G Loss: 22.815731048583984\n",
      "Epoch: 34, Batch: 80, D Loss: 0.10026773816770937, G Loss: 22.74957847595215\n",
      "Epoch: 34, Batch: 81, D Loss: 0.09997253126751102, G Loss: 22.687959671020508\n",
      "Epoch: 34, Batch: 82, D Loss: 0.09621730452976013, G Loss: 22.93163299560547\n",
      "Epoch: 34, Batch: 83, D Loss: 0.10313014693857245, G Loss: 22.273998260498047\n",
      "Epoch: 34, Batch: 84, D Loss: 0.10273395490861065, G Loss: 22.019149780273438\n",
      "Epoch: 34, Batch: 85, D Loss: 0.10385961845460741, G Loss: 21.863357543945312\n",
      "Epoch: 34, Batch: 86, D Loss: 0.09639744483912172, G Loss: 21.30417251586914\n",
      "Epoch: 34, Batch: 87, D Loss: 0.10631714792067543, G Loss: 21.122617721557617\n",
      "Epoch: 34, Batch: 88, D Loss: 0.09039676242750633, G Loss: 20.242259979248047\n",
      "Epoch: 34, Batch: 89, D Loss: 0.1073892423320919, G Loss: 20.099088668823242\n",
      "Epoch: 34, Batch: 90, D Loss: 0.09165732670469295, G Loss: 19.830896377563477\n",
      "Epoch: 34, Batch: 91, D Loss: 0.09278920428791115, G Loss: 19.636085510253906\n",
      "Epoch: 34, Batch: 92, D Loss: 0.09987130885225215, G Loss: 19.983928680419922\n",
      "Epoch: 34, Batch: 93, D Loss: 0.09367921292152104, G Loss: 20.304401397705078\n",
      "Epoch: 34, Batch: 94, D Loss: 0.1061205719853261, G Loss: 21.134464263916016\n",
      "Epoch: 34, Batch: 95, D Loss: 0.10461419844274539, G Loss: 21.789581298828125\n",
      "Epoch: 34, Batch: 96, D Loss: 0.1022999660807929, G Loss: 21.897640228271484\n",
      "Epoch: 34, Batch: 97, D Loss: 0.10357816535471588, G Loss: 21.59601402282715\n",
      "Epoch: 34, Batch: 98, D Loss: 0.09832256317714616, G Loss: 20.88536834716797\n",
      "Epoch: 34, Batch: 99, D Loss: 0.10115942415012069, G Loss: 20.36493682861328\n",
      "Epoch: 34, Batch: 100, D Loss: 0.10455347663688669, G Loss: 20.521512985229492\n",
      "Epoch: 34, Batch: 101, D Loss: 0.09290390520900565, G Loss: 20.587923049926758\n",
      "Epoch: 34, Batch: 102, D Loss: 0.09340176042894971, G Loss: 20.613677978515625\n",
      "Epoch: 34, Batch: 103, D Loss: 0.1050022546567726, G Loss: 21.204526901245117\n",
      "Epoch: 34, Batch: 104, D Loss: 0.10069786035235267, G Loss: 21.761566162109375\n",
      "Epoch: 34, Batch: 105, D Loss: 0.0994353668463396, G Loss: 22.000747680664062\n",
      "Epoch: 34, Batch: 106, D Loss: 0.10589917762119071, G Loss: 22.140918731689453\n",
      "Epoch: 34, Batch: 107, D Loss: 0.10275322212020038, G Loss: 21.98565673828125\n",
      "Epoch: 34, Batch: 108, D Loss: 0.09753719735734072, G Loss: 21.479829788208008\n",
      "Epoch: 34, Batch: 109, D Loss: 0.09582429411968116, G Loss: 20.84571075439453\n",
      "Epoch: 34, Batch: 110, D Loss: 0.09117898409557934, G Loss: 20.135738372802734\n",
      "Epoch: 34, Batch: 111, D Loss: 0.09927070229910478, G Loss: 20.16168785095215\n",
      "Epoch: 34, Batch: 112, D Loss: 0.09449672769218864, G Loss: 20.58892250061035\n",
      "Epoch: 34, Batch: 113, D Loss: 0.09682912419540887, G Loss: 21.26776695251465\n",
      "Epoch: 34, Batch: 114, D Loss: 0.0984939338935597, G Loss: 21.829967498779297\n",
      "Epoch: 34, Batch: 115, D Loss: 0.09705786422931255, G Loss: 21.900833129882812\n",
      "Epoch: 34, Batch: 116, D Loss: 0.09663898515782622, G Loss: 21.60964584350586\n",
      "Epoch: 34, Batch: 117, D Loss: 0.1013770850761142, G Loss: 21.445558547973633\n",
      "Epoch: 34, Batch: 118, D Loss: 0.09766112295054108, G Loss: 21.240047454833984\n",
      "Epoch: 34, Batch: 119, D Loss: 0.09914770007010357, G Loss: 21.251483917236328\n",
      "Epoch: 34, Batch: 120, D Loss: 0.09791712490554147, G Loss: 21.375425338745117\n",
      "Epoch: 34, Batch: 121, D Loss: 0.09109547017957206, G Loss: 21.189468383789062\n",
      "Epoch: 34, Batch: 122, D Loss: 0.0942338112513049, G Loss: 20.985355377197266\n",
      "Epoch: 34, Batch: 123, D Loss: 0.09931288694904208, G Loss: 21.149600982666016\n",
      "Epoch: 34, Batch: 124, D Loss: 0.09811746355973552, G Loss: 21.518905639648438\n",
      "Epoch: 34, Batch: 125, D Loss: 0.1006721408955146, G Loss: 21.97047996520996\n",
      "Epoch: 34, Batch: 126, D Loss: 0.10198052984490848, G Loss: 22.323225021362305\n",
      "Epoch: 34, Batch: 127, D Loss: 0.09593868267120173, G Loss: 22.075597763061523\n",
      "Epoch: 34, Batch: 128, D Loss: 0.09986794755793577, G Loss: 21.691946029663086\n",
      "Epoch: 34, Batch: 129, D Loss: 0.09953746222137462, G Loss: 21.367591857910156\n",
      "Epoch: 34, Batch: 130, D Loss: 0.10056846615652099, G Loss: 21.330219268798828\n",
      "Epoch: 34, Batch: 131, D Loss: 0.09792716082831587, G Loss: 21.369476318359375\n",
      "Epoch: 34, Batch: 132, D Loss: 0.0927906933321739, G Loss: 21.195234298706055\n",
      "Epoch: 34, Batch: 133, D Loss: 0.10226094005240216, G Loss: 21.433000564575195\n",
      "Epoch: 34, Batch: 134, D Loss: 0.09277128453672501, G Loss: 21.369443893432617\n",
      "Epoch: 34, Batch: 135, D Loss: 0.09981305177174252, G Loss: 21.460899353027344\n",
      "Epoch: 34, Batch: 136, D Loss: 0.10130402466665357, G Loss: 21.720779418945312\n",
      "Epoch: 34, Batch: 137, D Loss: 0.09415319581746236, G Loss: 21.588180541992188\n",
      "Epoch: 34, Batch: 138, D Loss: 0.09887634985317413, G Loss: 21.462026596069336\n",
      "Epoch: 34, Batch: 139, D Loss: 0.09951204085431253, G Loss: 21.460954666137695\n",
      "Epoch: 34, Batch: 140, D Loss: 0.09764365130245381, G Loss: 21.501882553100586\n",
      "Epoch: 34, Batch: 141, D Loss: 0.10269812514277556, G Loss: 21.78775405883789\n",
      "Epoch: 34, Batch: 142, D Loss: 0.09999082998276708, G Loss: 21.962881088256836\n",
      "Epoch: 34, Batch: 143, D Loss: 0.10181589438305255, G Loss: 22.069185256958008\n",
      "Epoch: 34, Batch: 144, D Loss: 0.09774676724393161, G Loss: 21.92801284790039\n",
      "Epoch: 34, Batch: 145, D Loss: 0.09956111030679231, G Loss: 21.71348762512207\n",
      "Epoch: 34, Batch: 146, D Loss: 0.09969599567041204, G Loss: 21.390201568603516\n",
      "Epoch: 34, Batch: 147, D Loss: 0.09410220415728729, G Loss: 21.024621963500977\n",
      "Epoch: 34, Batch: 148, D Loss: 0.09932038225527592, G Loss: 20.99929428100586\n",
      "Epoch: 34, Batch: 149, D Loss: 0.10748244849291802, G Loss: 21.627094268798828\n",
      "Epoch: 34, Batch: 150, D Loss: 0.10138410345449199, G Loss: 22.119796752929688\n",
      "Epoch: 34, Batch: 151, D Loss: 0.09649095697604697, G Loss: 21.981325149536133\n",
      "Epoch: 34, Batch: 152, D Loss: 0.09340798876067388, G Loss: 21.21756362915039\n",
      "Epoch: 34, Batch: 153, D Loss: 0.1028249640040926, G Loss: 20.828306198120117\n",
      "Epoch: 34, Batch: 154, D Loss: 0.09925478744254951, G Loss: 20.73271369934082\n",
      "Epoch: 34, Batch: 155, D Loss: 0.09590708513124263, G Loss: 20.767194747924805\n",
      "Epoch: 34, Batch: 156, D Loss: 0.09290401685935168, G Loss: 20.75010871887207\n",
      "Epoch: 34, Batch: 157, D Loss: 0.09294974853376042, G Loss: 20.724035263061523\n",
      "Epoch: 34, Batch: 158, D Loss: 0.09519224660939674, G Loss: 20.84254264831543\n",
      "Epoch: 34, Batch: 159, D Loss: 0.10118997130587609, G Loss: 21.37464714050293\n",
      "Epoch: 34, Batch: 160, D Loss: 0.09679417333760446, G Loss: 21.73196029663086\n",
      "Epoch: 34, Batch: 161, D Loss: 0.10153593883640279, G Loss: 22.026752471923828\n",
      "Epoch: 34, Batch: 162, D Loss: 0.09778821482690638, G Loss: 21.924625396728516\n",
      "Epoch: 34, Batch: 163, D Loss: 0.1021609009871833, G Loss: 21.85675048828125\n",
      "Epoch: 34, Batch: 164, D Loss: 0.09529966135135041, G Loss: 21.524417877197266\n",
      "Epoch: 34, Batch: 165, D Loss: 0.1032393502437527, G Loss: 21.539281845092773\n",
      "Epoch: 34, Batch: 166, D Loss: 0.10335652548811565, G Loss: 21.8671875\n",
      "Epoch: 34, Batch: 167, D Loss: 0.09496045873735488, G Loss: 21.851964950561523\n",
      "Epoch: 34, Batch: 168, D Loss: 0.10081494615401065, G Loss: 21.89512825012207\n",
      "Epoch: 34, Batch: 169, D Loss: 0.09872229413248952, G Loss: 21.84052848815918\n",
      "Epoch: 34, Batch: 170, D Loss: 0.10000058279721996, G Loss: 21.862468719482422\n",
      "Epoch: 34, Batch: 171, D Loss: 0.10224539056059663, G Loss: 22.04583168029785\n",
      "Epoch: 34, Batch: 172, D Loss: 0.09223529712051366, G Loss: 21.748563766479492\n",
      "Epoch: 34, Batch: 173, D Loss: 0.09685405364690734, G Loss: 21.45639419555664\n",
      "Epoch: 34, Batch: 174, D Loss: 0.10245982579936921, G Loss: 21.59079360961914\n",
      "Epoch: 34, Batch: 175, D Loss: 0.09816710669557614, G Loss: 21.818939208984375\n",
      "Epoch: 34, Batch: 176, D Loss: 0.09831368193138758, G Loss: 22.024681091308594\n",
      "Epoch: 34, Batch: 177, D Loss: 0.09116891041991856, G Loss: 21.778894424438477\n",
      "Epoch: 34, Batch: 178, D Loss: 0.10490852610414485, G Loss: 21.93482780456543\n",
      "Epoch: 34, Batch: 179, D Loss: 0.10254763079310729, G Loss: 22.26125144958496\n",
      "Epoch: 34, Batch: 180, D Loss: 0.0978781134932278, G Loss: 22.319448471069336\n",
      "Epoch: 34, Batch: 181, D Loss: 0.09759519260539928, G Loss: 22.106647491455078\n",
      "Epoch: 34, Batch: 182, D Loss: 0.0975285099438905, G Loss: 21.789264678955078\n",
      "Epoch: 34, Batch: 183, D Loss: 0.09635471572707367, G Loss: 21.496112823486328\n",
      "Epoch: 34, Batch: 184, D Loss: 0.09964704535827348, G Loss: 21.565628051757812\n",
      "Epoch: 34, Batch: 185, D Loss: 0.09971250612219307, G Loss: 21.849353790283203\n",
      "Epoch: 34, Batch: 186, D Loss: 0.09594555959355726, G Loss: 21.979463577270508\n",
      "Epoch: 34, Batch: 187, D Loss: 0.09704439356307171, G Loss: 21.974123001098633\n",
      "Epoch: 34, Batch: 188, D Loss: 0.10267126573334405, G Loss: 22.140016555786133\n",
      "Epoch: 34, Batch: 189, D Loss: 0.09266934557892896, G Loss: 21.861621856689453\n",
      "Epoch: 34, Batch: 190, D Loss: 0.09783677774462321, G Loss: 21.675243377685547\n",
      "Epoch: 34, Batch: 191, D Loss: 0.10210803168598653, G Loss: 21.865659713745117\n",
      "Epoch: 34, Batch: 192, D Loss: 0.09056846815326783, G Loss: 21.651649475097656\n",
      "Epoch: 34, Batch: 193, D Loss: 0.09716035446241024, G Loss: 21.57622528076172\n",
      "Epoch: 34, Batch: 194, D Loss: 0.09911721963926642, G Loss: 21.783615112304688\n",
      "Epoch: 34, Batch: 195, D Loss: 0.09693682209201678, G Loss: 22.002046585083008\n",
      "Epoch: 34, Batch: 196, D Loss: 0.0977976546986825, G Loss: 22.13969612121582\n",
      "Epoch: 34, Batch: 197, D Loss: 0.09777320188715645, G Loss: 22.105974197387695\n",
      "Epoch: 34, Batch: 198, D Loss: 0.09463146343766696, G Loss: 21.787668228149414\n",
      "Epoch: 34, Batch: 199, D Loss: 0.10146806406441447, G Loss: 21.778053283691406\n",
      "Epoch: 34, Batch: 200, D Loss: 0.10570468767325022, G Loss: 22.22781753540039\n",
      "Epoch: 34, Batch: 201, D Loss: 0.09879407296588663, G Loss: 22.43838882446289\n",
      "Epoch: 34, Batch: 202, D Loss: 0.09950646022377041, G Loss: 22.364910125732422\n",
      "Epoch: 34, Batch: 203, D Loss: 0.09972043346032516, G Loss: 22.194671630859375\n",
      "Epoch: 34, Batch: 204, D Loss: 0.10088951897825654, G Loss: 22.091781616210938\n",
      "Epoch: 34, Batch: 205, D Loss: 0.10395215462921345, G Loss: 22.334392547607422\n",
      "Epoch: 34, Batch: 206, D Loss: 0.10114337513313564, G Loss: 22.448801040649414\n",
      "Epoch: 34, Batch: 207, D Loss: 0.09801691780521171, G Loss: 22.234739303588867\n",
      "Epoch: 34, Batch: 208, D Loss: 0.09656323506270928, G Loss: 21.816997528076172\n",
      "Epoch: 34, Batch: 209, D Loss: 0.10113537329482826, G Loss: 21.688987731933594\n",
      "Epoch: 34, Batch: 210, D Loss: 0.10154245811184259, G Loss: 21.864694595336914\n",
      "Epoch: 34, Batch: 211, D Loss: 0.10288943362963697, G Loss: 22.308212280273438\n",
      "Epoch: 34, Batch: 212, D Loss: 0.09280888002188438, G Loss: 22.174762725830078\n",
      "Epoch: 34, Batch: 213, D Loss: 0.10598492633003423, G Loss: 22.35997200012207\n",
      "Epoch: 34, Batch: 214, D Loss: 0.09386388969032791, G Loss: 22.03789520263672\n",
      "Epoch: 34, Batch: 215, D Loss: 0.09892834738559682, G Loss: 21.758562088012695\n",
      "Epoch: 34, Batch: 216, D Loss: 0.10357071475553524, G Loss: 21.927133560180664\n",
      "Epoch: 34, Batch: 217, D Loss: 0.10036748660670324, G Loss: 22.203123092651367\n",
      "Epoch: 34, Batch: 218, D Loss: 0.09730173658552325, G Loss: 22.24370002746582\n",
      "Epoch: 34, Batch: 219, D Loss: 0.09625215840424606, G Loss: 22.066375732421875\n",
      "Epoch: 34, Batch: 220, D Loss: 0.10139925790984525, G Loss: 22.064435958862305\n",
      "Epoch: 34, Batch: 221, D Loss: 0.09778760387063655, G Loss: 22.009159088134766\n",
      "Epoch: 34, Batch: 222, D Loss: 0.10017868891709365, G Loss: 21.82305145263672\n",
      "Epoch: 34, Batch: 223, D Loss: 0.09838745016435181, G Loss: 21.628446578979492\n",
      "Epoch: 34, Batch: 224, D Loss: 0.10050116501308494, G Loss: 21.477869033813477\n",
      "Epoch: 34, Batch: 225, D Loss: 0.10103021586115615, G Loss: 21.439374923706055\n",
      "Epoch: 34, Batch: 226, D Loss: 0.10399489127193962, G Loss: 21.602245330810547\n",
      "Epoch: 34, Batch: 227, D Loss: 0.10085931441392175, G Loss: 21.57624626159668\n",
      "Epoch: 34, Batch: 228, D Loss: 0.09358900814119653, G Loss: 21.013757705688477\n",
      "Epoch: 34, Batch: 229, D Loss: 0.10230514449550329, G Loss: 20.778888702392578\n",
      "Epoch: 34, Batch: 230, D Loss: 0.10197465911659892, G Loss: 20.883302688598633\n",
      "Epoch: 34, Batch: 231, D Loss: 0.09504710182871803, G Loss: 20.781993865966797\n",
      "Epoch: 34, Batch: 232, D Loss: 0.09981134579677775, G Loss: 20.841215133666992\n",
      "Epoch: 34, Batch: 233, D Loss: 0.09714464886995341, G Loss: 20.875743865966797\n",
      "Epoch: 34, Batch: 234, D Loss: 0.10093385021162496, G Loss: 21.013063430786133\n",
      "Epoch: 34, Batch: 235, D Loss: 0.10294546218594725, G Loss: 21.332536697387695\n",
      "Epoch: 34, Batch: 236, D Loss: 0.0983000400307096, G Loss: 21.40218734741211\n",
      "Epoch: 34, Batch: 237, D Loss: 0.09941995170466847, G Loss: 21.316814422607422\n",
      "Epoch: 34, Batch: 238, D Loss: 0.09808422656335472, G Loss: 21.08322525024414\n",
      "Epoch: 34, Batch: 239, D Loss: 0.09852869102517278, G Loss: 20.879375457763672\n",
      "Epoch: 34, Batch: 240, D Loss: 0.09585421580335873, G Loss: 20.66620445251465\n",
      "Epoch: 34, Batch: 241, D Loss: 0.10841006823498886, G Loss: 21.304908752441406\n",
      "Epoch: 34, Batch: 242, D Loss: 0.09449536378360435, G Loss: 21.52397346496582\n",
      "Epoch: 34, Batch: 243, D Loss: 0.10229566713764947, G Loss: 21.702180862426758\n",
      "Epoch: 34, Batch: 244, D Loss: 0.1001537891171104, G Loss: 21.653518676757812\n",
      "Epoch: 34, Batch: 245, D Loss: 0.09872012608450823, G Loss: 21.36517906188965\n",
      "Epoch: 34, Batch: 246, D Loss: 0.09502281282885261, G Loss: 20.862951278686523\n",
      "Epoch: 34, Batch: 247, D Loss: 0.0987378810750894, G Loss: 20.64932632446289\n",
      "Epoch: 34, Batch: 248, D Loss: 0.09666432493519705, G Loss: 20.675222396850586\n",
      "Epoch: 34, Batch: 249, D Loss: 0.1083268675576334, G Loss: 21.534229278564453\n",
      "Epoch: 34, Batch: 250, D Loss: 0.09718783216352322, G Loss: 22.093271255493164\n",
      "Epoch: 34, Batch: 251, D Loss: 0.1024583728226374, G Loss: 22.359312057495117\n",
      "Epoch: 34, Batch: 252, D Loss: 0.09521573794689343, G Loss: 21.851722717285156\n",
      "Epoch: 34, Batch: 253, D Loss: 0.09925928733970198, G Loss: 21.277572631835938\n",
      "Epoch: 34, Batch: 254, D Loss: 0.09742111004599036, G Loss: 20.799570083618164\n",
      "Epoch: 34, Batch: 255, D Loss: 0.09560512059238135, G Loss: 20.551767349243164\n",
      "Epoch: 34, Batch: 256, D Loss: 0.09704630131010805, G Loss: 20.732295989990234\n",
      "Epoch: 34, Batch: 257, D Loss: 0.09839735962958995, G Loss: 21.24993133544922\n",
      "Epoch: 34, Batch: 258, D Loss: 0.09487033659805019, G Loss: 21.626911163330078\n",
      "Epoch: 34, Batch: 259, D Loss: 0.09764198976583977, G Loss: 21.883384704589844\n",
      "Epoch: 34, Batch: 260, D Loss: 0.10322985811754133, G Loss: 22.149276733398438\n",
      "Epoch: 34, Batch: 261, D Loss: 0.09408186390499888, G Loss: 21.804523468017578\n",
      "Epoch: 34, Batch: 262, D Loss: 0.09899858405938136, G Loss: 21.44322395324707\n",
      "Epoch: 34, Batch: 263, D Loss: 0.09797405478572024, G Loss: 21.245756149291992\n",
      "Epoch: 34, Batch: 264, D Loss: 0.10860767982255208, G Loss: 21.866044998168945\n",
      "Epoch: 34, Batch: 265, D Loss: 0.09750796122449928, G Loss: 22.252716064453125\n",
      "Epoch: 34, Batch: 266, D Loss: 0.09693722437978228, G Loss: 22.20956039428711\n",
      "Epoch: 34, Batch: 267, D Loss: 0.09545135512913634, G Loss: 21.68939781188965\n",
      "Epoch: 34, Batch: 268, D Loss: 0.0979126098184438, G Loss: 21.25090789794922\n",
      "Epoch: 34, Batch: 269, D Loss: 0.09572698955326292, G Loss: 20.96331787109375\n",
      "Epoch: 34, Batch: 270, D Loss: 0.09831123090472993, G Loss: 21.11119270324707\n",
      "Epoch: 34, Batch: 271, D Loss: 0.09615166514443965, G Loss: 21.40247344970703\n",
      "Epoch: 34, Batch: 272, D Loss: 0.10020194967593926, G Loss: 21.88343620300293\n",
      "Epoch: 34, Batch: 273, D Loss: 0.09707142426873654, G Loss: 22.07050323486328\n",
      "Epoch: 34, Batch: 274, D Loss: 0.10413974534802369, G Loss: 22.344783782958984\n",
      "Epoch: 34, Batch: 275, D Loss: 0.09813945006335305, G Loss: 22.154739379882812\n",
      "Epoch: 34, Batch: 276, D Loss: 0.10033913716114815, G Loss: 21.80927848815918\n",
      "Epoch: 34, Batch: 277, D Loss: 0.10159683990932689, G Loss: 21.654081344604492\n",
      "Epoch: 34, Batch: 278, D Loss: 0.10743074135158538, G Loss: 22.044126510620117\n",
      "Epoch: 34, Batch: 279, D Loss: 0.09990331542555192, G Loss: 22.249839782714844\n",
      "Epoch: 34, Batch: 280, D Loss: 0.09964275371537337, G Loss: 22.154508590698242\n",
      "Epoch: 34, Batch: 281, D Loss: 0.1023407803230357, G Loss: 22.0784969329834\n",
      "Epoch: 34, Batch: 282, D Loss: 0.10236059141884175, G Loss: 22.11651039123535\n",
      "Epoch: 34, Batch: 283, D Loss: 0.09299917534479414, G Loss: 21.72293472290039\n",
      "Epoch: 34, Batch: 284, D Loss: 0.0951975064732729, G Loss: 21.34794044494629\n",
      "Epoch: 34, Batch: 285, D Loss: 0.10375449829707621, G Loss: 21.617454528808594\n",
      "Epoch: 34, Batch: 286, D Loss: 0.09649249183131856, G Loss: 21.982820510864258\n",
      "Epoch: 34, Batch: 287, D Loss: 0.09991503518531245, G Loss: 22.361351013183594\n",
      "Epoch: 34, Batch: 288, D Loss: 0.10266793527159508, G Loss: 22.754579544067383\n",
      "Epoch: 34, Batch: 289, D Loss: 0.10468442743731425, G Loss: 23.029726028442383\n",
      "Epoch: 34, Batch: 290, D Loss: 0.09956859802805594, G Loss: 22.8188419342041\n",
      "Epoch: 34, Batch: 291, D Loss: 0.09960245349061661, G Loss: 22.319366455078125\n",
      "Epoch: 34, Batch: 292, D Loss: 0.10131642234386197, G Loss: 22.001968383789062\n",
      "Epoch: 34, Batch: 293, D Loss: 0.09889732316478858, G Loss: 21.83228874206543\n",
      "Epoch: 34, Batch: 294, D Loss: 0.09688475744798843, G Loss: 21.802955627441406\n",
      "Epoch: 34, Batch: 295, D Loss: 0.09658543036412218, G Loss: 21.92680549621582\n",
      "Epoch: 34, Batch: 296, D Loss: 0.0956901909243074, G Loss: 22.17116928100586\n",
      "Epoch: 34, Batch: 297, D Loss: 0.10732573278347574, G Loss: 23.01181411743164\n",
      "Epoch: 34, Batch: 298, D Loss: 0.08815564220521065, G Loss: 22.914663314819336\n",
      "Epoch: 34, Batch: 299, D Loss: 0.09571373469490202, G Loss: 22.538110733032227\n",
      "Epoch: 34, Batch: 300, D Loss: 0.0985517279224645, G Loss: 22.325510025024414\n",
      "Epoch: 34, Batch: 301, D Loss: 0.1033205241812085, G Loss: 22.654863357543945\n",
      "Epoch: 34, Batch: 302, D Loss: 0.10402655606542491, G Loss: 23.343860626220703\n",
      "Epoch: 34, Batch: 303, D Loss: 0.09866718950958406, G Loss: 23.666189193725586\n",
      "Epoch: 34, Batch: 304, D Loss: 0.1035211533557227, G Loss: 23.77288246154785\n",
      "Epoch: 34, Batch: 305, D Loss: 0.09815120699939764, G Loss: 23.375293731689453\n",
      "Epoch: 34, Batch: 306, D Loss: 0.10113024715904362, G Loss: 22.999855041503906\n",
      "Epoch: 34, Batch: 307, D Loss: 0.09804624325134151, G Loss: 22.684858322143555\n",
      "Epoch: 34, Batch: 308, D Loss: 0.10091532773658815, G Loss: 22.73808479309082\n",
      "Epoch: 34, Batch: 309, D Loss: 0.10250190650814021, G Loss: 23.15382957458496\n",
      "Epoch: 34, Batch: 310, D Loss: 0.098849311509037, G Loss: 23.42980194091797\n",
      "Epoch: 34, Batch: 311, D Loss: 0.10143554958774749, G Loss: 23.599336624145508\n",
      "Epoch: 34, Batch: 312, D Loss: 0.09915137294001938, G Loss: 23.450733184814453\n",
      "Epoch: 34, Batch: 313, D Loss: 0.10107132795538996, G Loss: 23.572799682617188\n",
      "Epoch: 34, Batch: 314, D Loss: 0.10028986635582486, G Loss: 23.663801193237305\n",
      "Epoch: 34, Batch: 315, D Loss: 0.09497600797391853, G Loss: 23.10053825378418\n",
      "Epoch: 34, Batch: 316, D Loss: 0.09965108340263766, G Loss: 22.867931365966797\n",
      "Epoch: 34, Batch: 317, D Loss: 0.1126168072615857, G Loss: 23.627655029296875\n",
      "Epoch: 34, Batch: 318, D Loss: 0.10022039713663382, G Loss: 24.05413246154785\n",
      "Epoch: 34, Batch: 319, D Loss: 0.10195992888900843, G Loss: 23.958290100097656\n",
      "Epoch: 34, Batch: 320, D Loss: 0.09845396879179613, G Loss: 23.257844924926758\n",
      "Epoch: 34, Batch: 321, D Loss: 0.09881176060572425, G Loss: 22.43986701965332\n",
      "Epoch: 34, Batch: 322, D Loss: 0.09898919624046158, G Loss: 21.909839630126953\n",
      "Epoch: 34, Batch: 323, D Loss: 0.10193694397395545, G Loss: 22.010013580322266\n",
      "Epoch: 34, Batch: 324, D Loss: 0.09256581974388584, G Loss: 22.23410987854004\n",
      "Epoch: 34, Batch: 325, D Loss: 0.1022212431622384, G Loss: 22.875425338745117\n",
      "Epoch: 34, Batch: 326, D Loss: 0.10029242936982624, G Loss: 23.49883270263672\n",
      "Epoch: 34, Batch: 327, D Loss: 0.09917937222508522, G Loss: 23.352516174316406\n",
      "Epoch: 34, Batch: 328, D Loss: 0.09995457534032598, G Loss: 23.150863647460938\n",
      "Epoch: 34, Batch: 329, D Loss: 0.1002999172133231, G Loss: 22.844165802001953\n",
      "Epoch: 34, Batch: 330, D Loss: 0.10865806048454915, G Loss: 23.07667350769043\n",
      "Epoch: 34, Batch: 331, D Loss: 0.10551477972549392, G Loss: 23.473613739013672\n",
      "Epoch: 34, Batch: 332, D Loss: 0.09240893278467965, G Loss: 23.08402442932129\n",
      "Epoch: 34, Batch: 333, D Loss: 0.09701704240438927, G Loss: 22.458877563476562\n",
      "Epoch: 34, Batch: 334, D Loss: 0.09971598546011419, G Loss: 22.175689697265625\n",
      "Epoch: 34, Batch: 335, D Loss: 0.09525177640041808, G Loss: 22.09107208251953\n",
      "Epoch: 34, Batch: 336, D Loss: 0.09706052403852149, G Loss: 22.347593307495117\n",
      "Epoch: 34, Batch: 337, D Loss: 0.08970281492032181, G Loss: 22.266023635864258\n",
      "Epoch: 34, Batch: 338, D Loss: 0.09524018327945094, G Loss: 22.30386734008789\n",
      "Epoch: 34, Batch: 339, D Loss: 0.09698535511252462, G Loss: 22.498239517211914\n",
      "Epoch: 34, Batch: 340, D Loss: 0.10138011730278149, G Loss: 22.996217727661133\n",
      "Epoch: 34, Batch: 341, D Loss: 0.10306967798743497, G Loss: 23.549821853637695\n",
      "Epoch: 34, Batch: 342, D Loss: 0.0926652103999302, G Loss: 23.305112838745117\n",
      "Epoch: 34, Batch: 343, D Loss: 0.09703970705231854, G Loss: 22.880037307739258\n",
      "Epoch: 34, Batch: 344, D Loss: 0.09767104692187109, G Loss: 22.550682067871094\n",
      "Epoch: 34, Batch: 345, D Loss: 0.10814411944465782, G Loss: 23.02218246459961\n",
      "Epoch: 34, Batch: 346, D Loss: 0.09896723930137431, G Loss: 23.420289993286133\n",
      "Epoch: 34, Batch: 347, D Loss: 0.10156005623863583, G Loss: 23.701234817504883\n",
      "Epoch: 34, Batch: 348, D Loss: 0.09650028499805892, G Loss: 23.502708435058594\n",
      "Epoch: 34, Batch: 349, D Loss: 0.09804797176363758, G Loss: 23.1093692779541\n",
      "Epoch: 34, Batch: 350, D Loss: 0.09152478731611238, G Loss: 22.339937210083008\n",
      "Epoch: 34, Batch: 351, D Loss: 0.1012960077396188, G Loss: 22.209142684936523\n",
      "Epoch: 34, Batch: 352, D Loss: 0.10555206247057189, G Loss: 22.907686233520508\n",
      "Epoch: 34, Batch: 353, D Loss: 0.09544275706741749, G Loss: 22.88479232788086\n",
      "Epoch: 34, Batch: 354, D Loss: 0.09918028867517313, G Loss: 22.734519958496094\n",
      "Epoch: 34, Batch: 355, D Loss: 0.09451863179388012, G Loss: 22.02592658996582\n",
      "Epoch: 34, Batch: 356, D Loss: 0.10330145823136662, G Loss: 21.59511947631836\n",
      "Epoch: 34, Batch: 357, D Loss: 0.10349133632983452, G Loss: 21.478384017944336\n",
      "Epoch: 34, Batch: 358, D Loss: 0.09755950447026815, G Loss: 21.29352569580078\n",
      "Epoch: 34, Batch: 359, D Loss: 0.09913494468736345, G Loss: 21.133256912231445\n",
      "Epoch: 34, Batch: 360, D Loss: 0.10574014513770702, G Loss: 21.399139404296875\n",
      "Epoch: 34, Batch: 361, D Loss: 0.1006403269742813, G Loss: 21.54425621032715\n",
      "Epoch: 34, Batch: 362, D Loss: 0.09906670475307347, G Loss: 21.36984634399414\n",
      "Epoch: 34, Batch: 363, D Loss: 0.0989299419688914, G Loss: 21.023855209350586\n",
      "Epoch: 34, Batch: 364, D Loss: 0.10384940393921371, G Loss: 20.982444763183594\n",
      "Epoch: 34, Batch: 365, D Loss: 0.10042279997126993, G Loss: 20.9951171875\n",
      "Epoch: 34, Batch: 366, D Loss: 0.10173191165915646, G Loss: 21.119140625\n",
      "Epoch: 34, Batch: 367, D Loss: 0.0969792757060986, G Loss: 20.992938995361328\n",
      "Epoch: 34, Batch: 368, D Loss: 0.10081224183234944, G Loss: 20.921119689941406\n",
      "Epoch: 34, Batch: 369, D Loss: 0.10066539089233878, G Loss: 20.96889877319336\n",
      "Epoch: 34, Batch: 370, D Loss: 0.09365930455412891, G Loss: 20.61688995361328\n",
      "Epoch: 34, Batch: 371, D Loss: 0.09655662691268047, G Loss: 20.320310592651367\n",
      "Epoch: 34, Batch: 372, D Loss: 0.10619704484774584, G Loss: 20.765727996826172\n",
      "Epoch: 34, Batch: 373, D Loss: 0.0986179862279086, G Loss: 21.19346046447754\n",
      "Epoch: 34, Batch: 374, D Loss: 0.09889197377736608, G Loss: 21.391651153564453\n",
      "Epoch: 34, Batch: 375, D Loss: 0.10166263605536002, G Loss: 21.42496109008789\n",
      "Epoch: 34, Batch: 376, D Loss: 0.0967530983718694, G Loss: 21.05691146850586\n",
      "Epoch: 34, Batch: 377, D Loss: 0.10748220268478673, G Loss: 21.194499969482422\n",
      "Epoch: 34, Batch: 378, D Loss: 0.09726752373679276, G Loss: 21.098295211791992\n",
      "Epoch: 34, Batch: 379, D Loss: 0.10515834421157885, G Loss: 21.356586456298828\n",
      "Epoch: 34, Batch: 380, D Loss: 0.09507261989927746, G Loss: 21.242023468017578\n",
      "Epoch: 34, Batch: 381, D Loss: 0.09950590165398204, G Loss: 21.12327766418457\n",
      "Epoch: 34, Batch: 382, D Loss: 0.09965290162235202, G Loss: 21.153013229370117\n",
      "Epoch: 34, Batch: 383, D Loss: 0.09931887716730858, G Loss: 21.279945373535156\n",
      "Epoch: 34, Batch: 384, D Loss: 0.09578498482388517, G Loss: 21.22846031188965\n",
      "Epoch: 34, Batch: 385, D Loss: 0.1016406568591797, G Loss: 21.45090675354004\n",
      "Epoch: 34, Batch: 386, D Loss: 0.10297410955252151, G Loss: 21.80274200439453\n",
      "Epoch: 34, Batch: 387, D Loss: 0.09915111229389448, G Loss: 21.98259735107422\n",
      "Epoch: 34, Batch: 388, D Loss: 0.09625481085062683, G Loss: 21.759279251098633\n",
      "Epoch: 34, Batch: 389, D Loss: 0.09813820591057909, G Loss: 21.5006103515625\n",
      "Epoch: 34, Batch: 390, D Loss: 0.10000140243137325, G Loss: 21.484037399291992\n",
      "Epoch: 34, Batch: 391, D Loss: 0.09255408523421885, G Loss: 21.159076690673828\n",
      "Epoch: 34, Batch: 392, D Loss: 0.10180856316314571, G Loss: 21.37966537475586\n",
      "Epoch: 34, Batch: 393, D Loss: 0.09082370278631238, G Loss: 21.290807723999023\n",
      "Epoch: 34, Batch: 394, D Loss: 0.10136108125472632, G Loss: 21.527469635009766\n",
      "Epoch: 34, Batch: 395, D Loss: 0.09209864610427801, G Loss: 21.409257888793945\n",
      "Epoch: 34, Batch: 396, D Loss: 0.10236001037954963, G Loss: 21.5633487701416\n",
      "Epoch: 34, Batch: 397, D Loss: 0.09999226054172418, G Loss: 21.664684295654297\n",
      "Epoch: 34, Batch: 398, D Loss: 0.09919281323255984, G Loss: 21.679365158081055\n",
      "Epoch: 34, Batch: 399, D Loss: 0.09333434725113038, G Loss: 21.247562408447266\n",
      "Epoch: 34, Batch: 400, D Loss: 0.10121296377678474, G Loss: 21.132930755615234\n",
      "Epoch: 34, Batch: 401, D Loss: 0.10200142889736286, G Loss: 21.371295928955078\n",
      "Epoch: 34, Batch: 402, D Loss: 0.09945530467859962, G Loss: 21.578752517700195\n",
      "Epoch: 34, Batch: 403, D Loss: 0.10286346095872617, G Loss: 21.9009952545166\n",
      "Epoch: 34, Batch: 404, D Loss: 0.10107438280725448, G Loss: 22.02353286743164\n",
      "Epoch: 34, Batch: 405, D Loss: 0.10274118943646127, G Loss: 22.035785675048828\n",
      "Epoch: 34, Batch: 406, D Loss: 0.10162119581837596, G Loss: 21.902732849121094\n",
      "Epoch: 34, Batch: 407, D Loss: 0.1021740140202788, G Loss: 21.744504928588867\n",
      "Epoch: 34, Batch: 408, D Loss: 0.093908265476743, G Loss: 21.17119789123535\n",
      "Epoch: 34, Batch: 409, D Loss: 0.10194332187001232, G Loss: 21.03482437133789\n",
      "Epoch: 34, Batch: 410, D Loss: 0.10237729580033361, G Loss: 21.377662658691406\n",
      "Epoch: 34, Batch: 411, D Loss: 0.09738571964403035, G Loss: 21.649311065673828\n",
      "Epoch: 34, Batch: 412, D Loss: 0.0965511875355173, G Loss: 21.641550064086914\n",
      "Epoch: 34, Batch: 413, D Loss: 0.10321243870572036, G Loss: 21.819204330444336\n",
      "Epoch: 34, Batch: 414, D Loss: 0.09590388107348614, G Loss: 21.687118530273438\n",
      "Epoch: 34, Batch: 415, D Loss: 0.1014688091347915, G Loss: 21.738561630249023\n",
      "Epoch: 34, Batch: 416, D Loss: 0.10193926112537695, G Loss: 21.908933639526367\n",
      "Epoch: 34, Batch: 417, D Loss: 0.10727369052061009, G Loss: 22.398818969726562\n",
      "Epoch: 34, Batch: 418, D Loss: 0.10266777881278566, G Loss: 22.64192008972168\n",
      "Epoch: 34, Batch: 419, D Loss: 0.09688214966686226, G Loss: 22.260950088500977\n",
      "Epoch: 34, Batch: 420, D Loss: 0.10048376786348504, G Loss: 21.307048797607422\n",
      "Epoch: 34, Batch: 421, D Loss: 0.09982997210216937, G Loss: 21.096969604492188\n",
      "Epoch: 34, Batch: 422, D Loss: 0.09471920174710466, G Loss: 20.722705841064453\n",
      "Epoch: 34, Batch: 423, D Loss: 0.10106486120301908, G Loss: 21.242542266845703\n",
      "Epoch: 34, Batch: 424, D Loss: 0.10295331496617137, G Loss: 22.101133346557617\n",
      "Epoch: 34, Batch: 425, D Loss: 0.10375581692270375, G Loss: 22.44269371032715\n",
      "Epoch: 34, Batch: 426, D Loss: 0.09995462010381659, G Loss: 22.23343276977539\n",
      "Epoch: 34, Batch: 427, D Loss: 0.09591475890302667, G Loss: 21.51750373840332\n",
      "Epoch: 34, Batch: 428, D Loss: 0.10489088321112142, G Loss: 21.3874454498291\n",
      "Epoch: 34, Batch: 429, D Loss: 0.09844050581633623, G Loss: 21.428966522216797\n",
      "Epoch: 34, Batch: 430, D Loss: 0.10042552671558683, G Loss: 21.686424255371094\n",
      "Epoch: 34, Batch: 431, D Loss: 0.09889624285326085, G Loss: 21.85174560546875\n",
      "Epoch: 34, Batch: 432, D Loss: 0.09976357236963798, G Loss: 21.95161247253418\n",
      "Epoch: 34, Batch: 433, D Loss: 0.1044299901829537, G Loss: 22.181686401367188\n",
      "Epoch: 34, Batch: 434, D Loss: 0.09953981650187017, G Loss: 22.08696174621582\n",
      "Epoch: 34, Batch: 435, D Loss: 0.10039918139333982, G Loss: 21.828548431396484\n",
      "Epoch: 34, Batch: 436, D Loss: 0.09471983484447191, G Loss: 21.300704956054688\n",
      "Epoch: 34, Batch: 437, D Loss: 0.09945569964304588, G Loss: 21.063871383666992\n",
      "Epoch: 34, Batch: 438, D Loss: 0.09995093974114663, G Loss: 21.242813110351562\n",
      "Epoch: 34, Batch: 439, D Loss: 0.09891466820633818, G Loss: 21.633872985839844\n",
      "Epoch: 34, Batch: 440, D Loss: 0.10309135928272974, G Loss: 22.2664794921875\n",
      "Epoch: 34, Batch: 441, D Loss: 0.09811862567841761, G Loss: 22.448150634765625\n",
      "Epoch: 34, Batch: 442, D Loss: 0.10047635445588736, G Loss: 22.32099151611328\n",
      "Epoch: 34, Batch: 443, D Loss: 0.10084944974929588, G Loss: 22.082870483398438\n",
      "Epoch: 34, Batch: 444, D Loss: 0.09483016299465045, G Loss: 21.53411865234375\n",
      "Epoch: 34, Batch: 445, D Loss: 0.09129203886664058, G Loss: 20.92643165588379\n",
      "Epoch: 34, Batch: 446, D Loss: 0.10056401080941002, G Loss: 21.1263370513916\n",
      "Epoch: 34, Batch: 447, D Loss: 0.10064939431571737, G Loss: 21.914934158325195\n",
      "Epoch: 34, Batch: 448, D Loss: 0.09939809153379003, G Loss: 22.74000358581543\n",
      "Epoch: 34, Batch: 449, D Loss: 0.09392311430136323, G Loss: 22.899906158447266\n",
      "Epoch: 34, Batch: 450, D Loss: 0.09090733536070744, G Loss: 22.261812210083008\n",
      "Epoch: 34, Batch: 451, D Loss: 0.09611372664187615, G Loss: 21.688739776611328\n",
      "Epoch: 34, Batch: 452, D Loss: 0.10348367707942253, G Loss: 21.916765213012695\n",
      "Epoch: 34, Batch: 453, D Loss: 0.09881098580012959, G Loss: 22.43026351928711\n",
      "Epoch: 34, Batch: 454, D Loss: 0.0999724493093636, G Loss: 23.026132583618164\n",
      "Epoch: 34, Batch: 455, D Loss: 0.09336324041088113, G Loss: 23.038684844970703\n",
      "Epoch: 34, Batch: 456, D Loss: 0.09770565485613963, G Loss: 22.79222297668457\n",
      "Epoch: 34, Batch: 457, D Loss: 0.10481273388839751, G Loss: 22.909957885742188\n",
      "Epoch: 34, Batch: 458, D Loss: 0.09496978676504803, G Loss: 22.738229751586914\n",
      "Epoch: 34, Batch: 459, D Loss: 0.10073809332299084, G Loss: 22.75667953491211\n",
      "Epoch: 34, Batch: 460, D Loss: 0.09977501636915456, G Loss: 22.88076400756836\n",
      "Epoch: 34, Batch: 461, D Loss: 0.10316132013775492, G Loss: 23.255674362182617\n",
      "Epoch: 34, Batch: 462, D Loss: 0.10083595667170517, G Loss: 23.310224533081055\n",
      "Epoch: 34, Batch: 463, D Loss: 0.10279332105205591, G Loss: 23.261760711669922\n",
      "Epoch: 34, Batch: 464, D Loss: 0.09537591790417967, G Loss: 22.72975730895996\n",
      "Epoch: 34, Batch: 465, D Loss: 0.09071363519145308, G Loss: 21.891950607299805\n",
      "Epoch: 34, Batch: 466, D Loss: 0.10164235549101262, G Loss: 21.743234634399414\n",
      "Epoch: 34, Batch: 467, D Loss: 0.08767190596200633, G Loss: 21.491844177246094\n",
      "Epoch: 35, Batch: 0, D Loss: 0.09289042673544746, G Loss: 21.603017807006836\n",
      "Epoch: 35, Batch: 1, D Loss: 0.09919302179296723, G Loss: 22.379030227661133\n",
      "Epoch: 35, Batch: 2, D Loss: 0.09680420166438693, G Loss: 23.215818405151367\n",
      "Epoch: 35, Batch: 3, D Loss: 0.09219339493753276, G Loss: 23.36850357055664\n",
      "Epoch: 35, Batch: 4, D Loss: 0.09979028258328407, G Loss: 23.352052688598633\n",
      "Epoch: 35, Batch: 5, D Loss: 0.09615476433648962, G Loss: 23.069766998291016\n",
      "Epoch: 35, Batch: 6, D Loss: 0.09614470606885273, G Loss: 22.70339584350586\n",
      "Epoch: 35, Batch: 7, D Loss: 0.09394872941949559, G Loss: 22.34827423095703\n",
      "Epoch: 35, Batch: 8, D Loss: 0.10309198506755043, G Loss: 22.73637580871582\n",
      "Epoch: 35, Batch: 9, D Loss: 0.09385342901792648, G Loss: 23.002296447753906\n",
      "Epoch: 35, Batch: 10, D Loss: 0.09920459989973195, G Loss: 23.360517501831055\n",
      "Epoch: 35, Batch: 11, D Loss: 0.10506004097769715, G Loss: 23.90074348449707\n",
      "Epoch: 35, Batch: 12, D Loss: 0.09604507686938542, G Loss: 23.77198028564453\n",
      "Epoch: 35, Batch: 13, D Loss: 0.09556756171880054, G Loss: 23.157020568847656\n",
      "Epoch: 35, Batch: 14, D Loss: 0.09315737343665917, G Loss: 22.325061798095703\n",
      "Epoch: 35, Batch: 15, D Loss: 0.10250100503689415, G Loss: 22.292177200317383\n",
      "Epoch: 35, Batch: 16, D Loss: 0.10202516622901298, G Loss: 22.91330337524414\n",
      "Epoch: 35, Batch: 17, D Loss: 0.09475339208511946, G Loss: 23.353456497192383\n",
      "Epoch: 35, Batch: 18, D Loss: 0.09910878542216484, G Loss: 23.620576858520508\n",
      "Epoch: 35, Batch: 19, D Loss: 0.09602680805380831, G Loss: 23.43898582458496\n",
      "Epoch: 35, Batch: 20, D Loss: 0.09920252863400122, G Loss: 23.171817779541016\n",
      "Epoch: 35, Batch: 21, D Loss: 0.10379789773646453, G Loss: 23.320341110229492\n",
      "Epoch: 35, Batch: 22, D Loss: 0.10158289972230852, G Loss: 23.571819305419922\n",
      "Epoch: 35, Batch: 23, D Loss: 0.10638205709335931, G Loss: 24.04095458984375\n",
      "Epoch: 35, Batch: 24, D Loss: 0.10004930199957161, G Loss: 24.091413497924805\n",
      "Epoch: 35, Batch: 25, D Loss: 0.09178888800392526, G Loss: 23.284639358520508\n",
      "Epoch: 35, Batch: 26, D Loss: 0.10486324881106149, G Loss: 22.968494415283203\n",
      "Epoch: 35, Batch: 27, D Loss: 0.09613384312551984, G Loss: 22.693592071533203\n",
      "Epoch: 35, Batch: 28, D Loss: 0.0990303755482338, G Loss: 22.75307273864746\n",
      "Epoch: 35, Batch: 29, D Loss: 0.09636746353067042, G Loss: 22.88897705078125\n",
      "Epoch: 35, Batch: 30, D Loss: 0.09831836824742629, G Loss: 23.11418342590332\n",
      "Epoch: 35, Batch: 31, D Loss: 0.09837690000031303, G Loss: 23.248577117919922\n",
      "Epoch: 35, Batch: 32, D Loss: 0.10629937055899302, G Loss: 23.68965721130371\n",
      "Epoch: 35, Batch: 33, D Loss: 0.09821167590777263, G Loss: 23.713041305541992\n",
      "Epoch: 35, Batch: 34, D Loss: 0.0991876125620322, G Loss: 23.477996826171875\n",
      "Epoch: 35, Batch: 35, D Loss: 0.09954470399879815, G Loss: 23.12151527404785\n",
      "Epoch: 35, Batch: 36, D Loss: 0.10579747710862955, G Loss: 23.26638412475586\n",
      "Epoch: 35, Batch: 37, D Loss: 0.0995843187325112, G Loss: 23.484237670898438\n",
      "Epoch: 35, Batch: 38, D Loss: 0.09862010183968975, G Loss: 23.572301864624023\n",
      "Epoch: 35, Batch: 39, D Loss: 0.10475115480515608, G Loss: 23.868877410888672\n",
      "Epoch: 35, Batch: 40, D Loss: 0.09911759199855998, G Loss: 23.876184463500977\n",
      "Epoch: 35, Batch: 41, D Loss: 0.09945598992022057, G Loss: 23.738676071166992\n",
      "Epoch: 35, Batch: 42, D Loss: 0.10022556039410746, G Loss: 23.555217742919922\n",
      "Epoch: 35, Batch: 43, D Loss: 0.10295408221882969, G Loss: 23.662355422973633\n",
      "Epoch: 35, Batch: 44, D Loss: 0.10124796631311556, G Loss: 23.880084991455078\n",
      "Epoch: 35, Batch: 45, D Loss: 0.10608371348883412, G Loss: 24.313161849975586\n",
      "Epoch: 35, Batch: 46, D Loss: 0.10308146477968483, G Loss: 24.543001174926758\n",
      "Epoch: 35, Batch: 47, D Loss: 0.10039848090398858, G Loss: 24.40274429321289\n",
      "Epoch: 35, Batch: 48, D Loss: 0.09717099370316093, G Loss: 23.787656784057617\n",
      "Epoch: 35, Batch: 49, D Loss: 0.10135865214412931, G Loss: 23.358036041259766\n",
      "Epoch: 35, Batch: 50, D Loss: 0.10356663915852626, G Loss: 23.506492614746094\n",
      "Epoch: 35, Batch: 51, D Loss: 0.10073122384725554, G Loss: 23.864147186279297\n",
      "Epoch: 35, Batch: 52, D Loss: 0.10254529120249897, G Loss: 24.307985305786133\n",
      "Epoch: 35, Batch: 53, D Loss: 0.09621933849134377, G Loss: 24.19977378845215\n",
      "Epoch: 35, Batch: 54, D Loss: 0.10596042872961169, G Loss: 24.27490234375\n",
      "Epoch: 35, Batch: 55, D Loss: 0.09414488079030106, G Loss: 23.773880004882812\n",
      "Epoch: 35, Batch: 56, D Loss: 0.09804886582627054, G Loss: 23.25237274169922\n",
      "Epoch: 35, Batch: 57, D Loss: 0.10393698517323074, G Loss: 23.336204528808594\n",
      "Epoch: 35, Batch: 58, D Loss: 0.09979441765066259, G Loss: 23.65761375427246\n",
      "Epoch: 35, Batch: 59, D Loss: 0.10130894186285383, G Loss: 24.0407657623291\n",
      "Epoch: 35, Batch: 60, D Loss: 0.09676547350360787, G Loss: 23.989952087402344\n",
      "Epoch: 35, Batch: 61, D Loss: 0.1003133803812609, G Loss: 23.837745666503906\n",
      "Epoch: 35, Batch: 62, D Loss: 0.0985057056205656, G Loss: 23.57090187072754\n",
      "Epoch: 35, Batch: 63, D Loss: 0.09799357506998556, G Loss: 23.298673629760742\n",
      "Epoch: 35, Batch: 64, D Loss: 0.0940639749628441, G Loss: 22.942686080932617\n",
      "Epoch: 35, Batch: 65, D Loss: 0.09757720684635636, G Loss: 22.88907814025879\n",
      "Epoch: 35, Batch: 66, D Loss: 0.09751088177491185, G Loss: 23.040956497192383\n",
      "Epoch: 35, Batch: 67, D Loss: 0.09843291346451943, G Loss: 23.346742630004883\n",
      "Epoch: 35, Batch: 68, D Loss: 0.0972416475758781, G Loss: 23.450401306152344\n",
      "Epoch: 35, Batch: 69, D Loss: 0.10595501961934484, G Loss: 23.878463745117188\n",
      "Epoch: 35, Batch: 70, D Loss: 0.09642218055619181, G Loss: 23.752168655395508\n",
      "Epoch: 35, Batch: 71, D Loss: 0.09884832802415724, G Loss: 23.35472297668457\n",
      "Epoch: 35, Batch: 72, D Loss: 0.10391400758343865, G Loss: 23.206134796142578\n",
      "Epoch: 35, Batch: 73, D Loss: 0.10241124783015257, G Loss: 23.274137496948242\n",
      "Epoch: 35, Batch: 74, D Loss: 0.10701245072633411, G Loss: 23.692665100097656\n",
      "Epoch: 35, Batch: 75, D Loss: 0.0989295244472649, G Loss: 23.699951171875\n",
      "Epoch: 35, Batch: 76, D Loss: 0.09357896450691393, G Loss: 23.091045379638672\n",
      "Epoch: 35, Batch: 77, D Loss: 0.09754709905653228, G Loss: 22.54987335205078\n",
      "Epoch: 35, Batch: 78, D Loss: 0.10071885593859924, G Loss: 22.54433822631836\n",
      "Epoch: 35, Batch: 79, D Loss: 0.09760098166399647, G Loss: 22.79729461669922\n",
      "Epoch: 35, Batch: 80, D Loss: 0.10097555820964249, G Loss: 23.31291389465332\n",
      "Epoch: 35, Batch: 81, D Loss: 0.10245281460713447, G Loss: 23.86049461364746\n",
      "Epoch: 35, Batch: 82, D Loss: 0.09804883601417225, G Loss: 23.890888214111328\n",
      "Epoch: 35, Batch: 83, D Loss: 0.09180099520306474, G Loss: 23.094511032104492\n",
      "Epoch: 35, Batch: 84, D Loss: 0.10021416849184167, G Loss: 22.54107666015625\n",
      "Epoch: 35, Batch: 85, D Loss: 0.10505673296630191, G Loss: 22.735828399658203\n",
      "Epoch: 35, Batch: 86, D Loss: 0.09878787403909664, G Loss: 23.081762313842773\n",
      "Epoch: 35, Batch: 87, D Loss: 0.10694948587087814, G Loss: 23.795495986938477\n",
      "Epoch: 35, Batch: 88, D Loss: 0.0993580892891564, G Loss: 23.986310958862305\n",
      "Epoch: 35, Batch: 89, D Loss: 0.09474511447193273, G Loss: 23.385540008544922\n",
      "Epoch: 35, Batch: 90, D Loss: 0.0978044122980755, G Loss: 22.61496353149414\n",
      "Epoch: 35, Batch: 91, D Loss: 0.1012265981116883, G Loss: 22.33707046508789\n",
      "Epoch: 35, Batch: 92, D Loss: 0.09428873668858462, G Loss: 22.20521354675293\n",
      "Epoch: 35, Batch: 93, D Loss: 0.09982793787558139, G Loss: 22.570528030395508\n",
      "Epoch: 35, Batch: 94, D Loss: 0.10350713138989627, G Loss: 23.36878204345703\n",
      "Epoch: 35, Batch: 95, D Loss: 0.09459227326688853, G Loss: 23.591360092163086\n",
      "Epoch: 35, Batch: 96, D Loss: 0.09680908921514778, G Loss: 23.40467071533203\n",
      "Epoch: 35, Batch: 97, D Loss: 0.09679619227135469, G Loss: 22.990982055664062\n",
      "Epoch: 35, Batch: 98, D Loss: 0.09262933589112911, G Loss: 22.405515670776367\n",
      "Epoch: 35, Batch: 99, D Loss: 0.10389858492701724, G Loss: 22.591840744018555\n",
      "Epoch: 35, Batch: 100, D Loss: 0.09846166527400044, G Loss: 23.04239845275879\n",
      "Epoch: 35, Batch: 101, D Loss: 0.0927193984845028, G Loss: 23.187652587890625\n",
      "Epoch: 35, Batch: 102, D Loss: 0.0972062498740429, G Loss: 23.260711669921875\n",
      "Epoch: 35, Batch: 103, D Loss: 0.09563259039415517, G Loss: 23.207515716552734\n",
      "Epoch: 35, Batch: 104, D Loss: 0.10288093987676049, G Loss: 23.513957977294922\n",
      "Epoch: 35, Batch: 105, D Loss: 0.10308811071007484, G Loss: 23.924558639526367\n",
      "Epoch: 35, Batch: 106, D Loss: 0.10088543595708908, G Loss: 24.13184928894043\n",
      "Epoch: 35, Batch: 107, D Loss: 0.1028556227849435, G Loss: 24.132369995117188\n",
      "Epoch: 35, Batch: 108, D Loss: 0.09659010918998959, G Loss: 23.72335433959961\n",
      "Epoch: 35, Batch: 109, D Loss: 0.10054855051640121, G Loss: 23.3790283203125\n",
      "Epoch: 35, Batch: 110, D Loss: 0.09919305149704727, G Loss: 23.14928436279297\n",
      "Epoch: 35, Batch: 111, D Loss: 0.10368470851461559, G Loss: 23.40924072265625\n",
      "Epoch: 35, Batch: 112, D Loss: 0.10060980918839887, G Loss: 23.771326065063477\n",
      "Epoch: 35, Batch: 113, D Loss: 0.10446422548957664, G Loss: 24.238338470458984\n",
      "Epoch: 35, Batch: 114, D Loss: 0.0967196896835013, G Loss: 24.067089080810547\n",
      "Epoch: 35, Batch: 115, D Loss: 0.0973415300481383, G Loss: 23.552831649780273\n",
      "Epoch: 35, Batch: 116, D Loss: 0.09978131953519755, G Loss: 23.166152954101562\n",
      "Epoch: 35, Batch: 117, D Loss: 0.10366652910007565, G Loss: 23.292625427246094\n",
      "Epoch: 35, Batch: 118, D Loss: 0.09911763671415233, G Loss: 23.544166564941406\n",
      "Epoch: 35, Batch: 119, D Loss: 0.09982240202631058, G Loss: 23.81060218811035\n",
      "Epoch: 35, Batch: 120, D Loss: 0.10202799739418929, G Loss: 24.09383201599121\n",
      "Epoch: 35, Batch: 121, D Loss: 0.09982621671471781, G Loss: 24.111846923828125\n",
      "Epoch: 35, Batch: 122, D Loss: 0.09174475076212628, G Loss: 23.443714141845703\n",
      "Epoch: 35, Batch: 123, D Loss: 0.10716871920574042, G Loss: 23.424514770507812\n",
      "Epoch: 35, Batch: 124, D Loss: 0.10213339331746489, G Loss: 23.65020751953125\n",
      "Epoch: 35, Batch: 125, D Loss: 0.10416439922856292, G Loss: 24.03046226501465\n",
      "Epoch: 35, Batch: 126, D Loss: 0.09871536495091514, G Loss: 24.073474884033203\n",
      "Epoch: 35, Batch: 127, D Loss: 0.10237169267594753, G Loss: 23.974632263183594\n",
      "Epoch: 35, Batch: 128, D Loss: 0.09944008292990791, G Loss: 23.712034225463867\n",
      "Epoch: 35, Batch: 129, D Loss: 0.09838190677828038, G Loss: 23.349782943725586\n",
      "Epoch: 35, Batch: 130, D Loss: 0.09700520340917132, G Loss: 23.0258846282959\n",
      "Epoch: 35, Batch: 131, D Loss: 0.09973302488352084, G Loss: 23.106542587280273\n",
      "Epoch: 35, Batch: 132, D Loss: 0.10002558682247019, G Loss: 23.445959091186523\n",
      "Epoch: 35, Batch: 133, D Loss: 0.10158938172104785, G Loss: 23.871671676635742\n",
      "Epoch: 35, Batch: 134, D Loss: 0.0939822942246786, G Loss: 23.754486083984375\n",
      "Epoch: 35, Batch: 135, D Loss: 0.10132531824276585, G Loss: 23.650545120239258\n",
      "Epoch: 35, Batch: 136, D Loss: 0.0968630239673493, G Loss: 23.396636962890625\n",
      "Epoch: 35, Batch: 137, D Loss: 0.09724450115275894, G Loss: 23.170955657958984\n",
      "Epoch: 35, Batch: 138, D Loss: 0.09780327980210649, G Loss: 23.112613677978516\n",
      "Epoch: 35, Batch: 139, D Loss: 0.09622000162318665, G Loss: 23.15461540222168\n",
      "Epoch: 35, Batch: 140, D Loss: 0.09800949696775461, G Loss: 23.31112289428711\n",
      "Epoch: 35, Batch: 141, D Loss: 0.09887042644900954, G Loss: 23.58135414123535\n",
      "Epoch: 35, Batch: 142, D Loss: 0.09673155847034343, G Loss: 23.612499237060547\n",
      "Epoch: 35, Batch: 143, D Loss: 0.10016214105121793, G Loss: 23.729572296142578\n",
      "Epoch: 35, Batch: 144, D Loss: 0.10050893577129642, G Loss: 23.9729061126709\n",
      "Epoch: 35, Batch: 145, D Loss: 0.10238775612935799, G Loss: 23.90324592590332\n",
      "Epoch: 35, Batch: 146, D Loss: 0.10158109667211493, G Loss: 23.716386795043945\n",
      "Epoch: 35, Batch: 147, D Loss: 0.09454120699096831, G Loss: 23.078676223754883\n",
      "Epoch: 35, Batch: 148, D Loss: 0.09626920528029229, G Loss: 22.402572631835938\n",
      "Epoch: 35, Batch: 149, D Loss: 0.0971824378928516, G Loss: 21.999874114990234\n",
      "Epoch: 35, Batch: 150, D Loss: 0.09743643566433827, G Loss: 21.9451847076416\n",
      "Epoch: 35, Batch: 151, D Loss: 0.09933541727552452, G Loss: 22.272842407226562\n",
      "Epoch: 35, Batch: 152, D Loss: 0.09810218224018918, G Loss: 22.58130645751953\n",
      "Epoch: 35, Batch: 153, D Loss: 0.10578542953566074, G Loss: 23.14137077331543\n",
      "Epoch: 35, Batch: 154, D Loss: 0.09825629745451288, G Loss: 23.123512268066406\n",
      "Epoch: 35, Batch: 155, D Loss: 0.10028833156178504, G Loss: 22.82072639465332\n",
      "Epoch: 35, Batch: 156, D Loss: 0.0985767916649054, G Loss: 22.307945251464844\n",
      "Epoch: 35, Batch: 157, D Loss: 0.09737622006133761, G Loss: 21.81297492980957\n",
      "Epoch: 35, Batch: 158, D Loss: 0.10512251421843888, G Loss: 22.03993797302246\n",
      "Epoch: 35, Batch: 159, D Loss: 0.09761888545536455, G Loss: 22.29825782775879\n",
      "Epoch: 35, Batch: 160, D Loss: 0.10653249926581422, G Loss: 22.99667739868164\n",
      "Epoch: 35, Batch: 161, D Loss: 0.10331629220676157, G Loss: 23.47381019592285\n",
      "Epoch: 35, Batch: 162, D Loss: 0.09383634482009824, G Loss: 22.973779678344727\n",
      "Epoch: 35, Batch: 163, D Loss: 0.10343329615126372, G Loss: 22.520811080932617\n",
      "Epoch: 35, Batch: 164, D Loss: 0.09743378322057283, G Loss: 22.042362213134766\n",
      "Epoch: 35, Batch: 165, D Loss: 0.09954014434905208, G Loss: 21.903366088867188\n",
      "Epoch: 35, Batch: 166, D Loss: 0.10143068445506515, G Loss: 22.26654815673828\n",
      "Epoch: 35, Batch: 167, D Loss: 0.10327468819888205, G Loss: 22.953615188598633\n",
      "Epoch: 35, Batch: 168, D Loss: 0.0949825794013651, G Loss: 23.057748794555664\n",
      "Epoch: 35, Batch: 169, D Loss: 0.10410517458648512, G Loss: 23.197362899780273\n",
      "Epoch: 35, Batch: 170, D Loss: 0.09955047075705725, G Loss: 22.979145050048828\n",
      "Epoch: 35, Batch: 171, D Loss: 0.10289262240873606, G Loss: 22.816516876220703\n",
      "Epoch: 35, Batch: 172, D Loss: 0.09402267642897284, G Loss: 22.31471824645996\n",
      "Epoch: 35, Batch: 173, D Loss: 0.09791310143585308, G Loss: 21.99794578552246\n",
      "Epoch: 35, Batch: 174, D Loss: 0.09801958515515317, G Loss: 21.972564697265625\n",
      "Epoch: 35, Batch: 175, D Loss: 0.10057544719986312, G Loss: 22.354141235351562\n",
      "Epoch: 35, Batch: 176, D Loss: 0.10212475813688904, G Loss: 22.93412971496582\n",
      "Epoch: 35, Batch: 177, D Loss: 0.09878808264686958, G Loss: 23.217201232910156\n",
      "Epoch: 35, Batch: 178, D Loss: 0.10016830269695624, G Loss: 23.197359085083008\n",
      "Epoch: 35, Batch: 179, D Loss: 0.09803928440022987, G Loss: 22.80660629272461\n",
      "Epoch: 35, Batch: 180, D Loss: 0.09447181233445981, G Loss: 22.18762969970703\n",
      "Epoch: 35, Batch: 181, D Loss: 0.09518657639159882, G Loss: 21.766517639160156\n",
      "Epoch: 35, Batch: 182, D Loss: 0.09825924055403086, G Loss: 21.890932083129883\n",
      "Epoch: 35, Batch: 183, D Loss: 0.10054190467588708, G Loss: 22.598487854003906\n",
      "Epoch: 35, Batch: 184, D Loss: 0.10118632023364904, G Loss: 23.487852096557617\n",
      "Epoch: 35, Batch: 185, D Loss: 0.10266941788039197, G Loss: 24.14682388305664\n",
      "Epoch: 35, Batch: 186, D Loss: 0.09429582955412887, G Loss: 23.796335220336914\n",
      "Epoch: 35, Batch: 187, D Loss: 0.09633380178230859, G Loss: 22.958477020263672\n",
      "Epoch: 35, Batch: 188, D Loss: 0.1034133732959327, G Loss: 22.616514205932617\n",
      "Epoch: 35, Batch: 189, D Loss: 0.09606282421056435, G Loss: 22.490093231201172\n",
      "Epoch: 35, Batch: 190, D Loss: 0.09755976505772965, G Loss: 22.701894760131836\n",
      "Epoch: 35, Batch: 191, D Loss: 0.09796264773210586, G Loss: 23.114910125732422\n",
      "Epoch: 35, Batch: 192, D Loss: 0.09670162949886714, G Loss: 23.417699813842773\n",
      "Epoch: 35, Batch: 193, D Loss: 0.09557484093688884, G Loss: 23.428436279296875\n",
      "Epoch: 35, Batch: 194, D Loss: 0.10209622237199618, G Loss: 23.576086044311523\n",
      "Epoch: 35, Batch: 195, D Loss: 0.0889630318071894, G Loss: 23.032333374023438\n",
      "Epoch: 35, Batch: 196, D Loss: 0.0996855870441446, G Loss: 22.83193016052246\n",
      "Epoch: 35, Batch: 197, D Loss: 0.10449329023557846, G Loss: 23.214027404785156\n",
      "Epoch: 35, Batch: 198, D Loss: 0.08604663615368631, G Loss: 22.891223907470703\n",
      "Epoch: 35, Batch: 199, D Loss: 0.10080738371320117, G Loss: 22.908784866333008\n",
      "Epoch: 35, Batch: 200, D Loss: 0.09586226200756937, G Loss: 22.896320343017578\n",
      "Epoch: 35, Batch: 201, D Loss: 0.0999400839711442, G Loss: 23.13577651977539\n",
      "Epoch: 35, Batch: 202, D Loss: 0.10505792501887046, G Loss: 23.71717071533203\n",
      "Epoch: 35, Batch: 203, D Loss: 0.09782178702262607, G Loss: 23.885730743408203\n",
      "Epoch: 35, Batch: 204, D Loss: 0.09212377670335295, G Loss: 23.281147003173828\n",
      "Epoch: 35, Batch: 205, D Loss: 0.09117481118730078, G Loss: 22.371055603027344\n",
      "Epoch: 35, Batch: 206, D Loss: 0.10309176901310578, G Loss: 22.443641662597656\n",
      "Epoch: 35, Batch: 207, D Loss: 0.10128266370588374, G Loss: 23.125102996826172\n",
      "Epoch: 35, Batch: 208, D Loss: 0.09703540060353197, G Loss: 23.664045333862305\n",
      "Epoch: 35, Batch: 209, D Loss: 0.09982143344750788, G Loss: 23.96394920349121\n",
      "Epoch: 35, Batch: 210, D Loss: 0.09912298621808562, G Loss: 23.865234375\n",
      "Epoch: 35, Batch: 211, D Loss: 0.09699184450329647, G Loss: 23.37012481689453\n",
      "Epoch: 35, Batch: 212, D Loss: 0.10390375558499029, G Loss: 23.170318603515625\n",
      "Epoch: 35, Batch: 213, D Loss: 0.10138340298670269, G Loss: 23.178905487060547\n",
      "Epoch: 35, Batch: 214, D Loss: 0.09772597257831267, G Loss: 23.08513069152832\n",
      "Epoch: 35, Batch: 215, D Loss: 0.09868296985684674, G Loss: 23.04001235961914\n",
      "Epoch: 35, Batch: 216, D Loss: 0.09433497494145317, G Loss: 22.782527923583984\n",
      "Epoch: 35, Batch: 217, D Loss: 0.09974200284995119, G Loss: 22.75458335876465\n",
      "Epoch: 35, Batch: 218, D Loss: 0.09373442835807766, G Loss: 22.59050941467285\n",
      "Epoch: 35, Batch: 219, D Loss: 0.09241452822082734, G Loss: 22.31573486328125\n",
      "Epoch: 35, Batch: 220, D Loss: 0.10037270942651896, G Loss: 22.49464988708496\n",
      "Epoch: 35, Batch: 221, D Loss: 0.09632687278055857, G Loss: 22.75615882873535\n",
      "Epoch: 35, Batch: 222, D Loss: 0.10371055458834977, G Loss: 23.338462829589844\n",
      "Epoch: 35, Batch: 223, D Loss: 0.09928014877685733, G Loss: 23.576507568359375\n",
      "Epoch: 35, Batch: 224, D Loss: 0.10095994177453971, G Loss: 23.518009185791016\n",
      "Epoch: 35, Batch: 225, D Loss: 0.09983468804296076, G Loss: 23.253799438476562\n",
      "Epoch: 35, Batch: 226, D Loss: 0.09361593430788405, G Loss: 22.633249282836914\n",
      "Epoch: 35, Batch: 227, D Loss: 0.09942678370656438, G Loss: 22.36607551574707\n",
      "Epoch: 35, Batch: 228, D Loss: 0.10475216813430013, G Loss: 22.849712371826172\n",
      "Epoch: 35, Batch: 229, D Loss: 0.09594248985262842, G Loss: 23.19281578063965\n",
      "Epoch: 35, Batch: 230, D Loss: 0.09928580377212348, G Loss: 23.454877853393555\n",
      "Epoch: 35, Batch: 231, D Loss: 0.10042998197773398, G Loss: 23.56134033203125\n",
      "Epoch: 35, Batch: 232, D Loss: 0.09631796184619389, G Loss: 23.26714515686035\n",
      "Epoch: 35, Batch: 233, D Loss: 0.09407441323402929, G Loss: 22.673643112182617\n",
      "Epoch: 35, Batch: 234, D Loss: 0.10163798190779433, G Loss: 22.55402946472168\n",
      "Epoch: 35, Batch: 235, D Loss: 0.10297912365685918, G Loss: 22.967756271362305\n",
      "Epoch: 35, Batch: 236, D Loss: 0.09752091769856062, G Loss: 23.298948287963867\n",
      "Epoch: 35, Batch: 237, D Loss: 0.1055981219099991, G Loss: 23.84731674194336\n",
      "Epoch: 35, Batch: 238, D Loss: 0.09842672946259824, G Loss: 23.854534149169922\n",
      "Epoch: 35, Batch: 239, D Loss: 0.0976901203668105, G Loss: 23.421730041503906\n",
      "Epoch: 35, Batch: 240, D Loss: 0.09633331750664699, G Loss: 22.745859146118164\n",
      "Epoch: 35, Batch: 241, D Loss: 0.10368603474740815, G Loss: 22.6945858001709\n",
      "Epoch: 35, Batch: 242, D Loss: 0.09134353705223845, G Loss: 22.44993019104004\n",
      "Epoch: 35, Batch: 243, D Loss: 0.09093470881862147, G Loss: 22.151182174682617\n",
      "Epoch: 35, Batch: 244, D Loss: 0.10114166150234158, G Loss: 22.559289932250977\n",
      "Epoch: 35, Batch: 245, D Loss: 0.0998597145630975, G Loss: 23.263179779052734\n",
      "Epoch: 35, Batch: 246, D Loss: 0.09942004087489976, G Loss: 23.844446182250977\n",
      "Epoch: 35, Batch: 247, D Loss: 0.09962686898342116, G Loss: 24.0133056640625\n",
      "Epoch: 35, Batch: 248, D Loss: 0.1058954671200673, G Loss: 24.127641677856445\n",
      "Epoch: 35, Batch: 249, D Loss: 0.09497476371387933, G Loss: 23.554800033569336\n",
      "Epoch: 35, Batch: 250, D Loss: 0.09602221850852384, G Loss: 22.848125457763672\n",
      "Epoch: 35, Batch: 251, D Loss: 0.09403963395284193, G Loss: 22.22902488708496\n",
      "Epoch: 35, Batch: 252, D Loss: 0.09612132620622207, G Loss: 22.123994827270508\n",
      "Epoch: 35, Batch: 253, D Loss: 0.10056762406391524, G Loss: 22.69984245300293\n",
      "Epoch: 35, Batch: 254, D Loss: 0.10483966026735622, G Loss: 23.73859405517578\n",
      "Epoch: 35, Batch: 255, D Loss: 0.0982005894366537, G Loss: 24.29969024658203\n",
      "Epoch: 35, Batch: 256, D Loss: 0.1017938628929245, G Loss: 24.346586227416992\n",
      "Epoch: 35, Batch: 257, D Loss: 0.10239806772916318, G Loss: 23.957429885864258\n",
      "Epoch: 35, Batch: 258, D Loss: 0.09932651373655584, G Loss: 23.22730827331543\n",
      "Epoch: 35, Batch: 259, D Loss: 0.0946030468391188, G Loss: 22.367040634155273\n",
      "Epoch: 35, Batch: 260, D Loss: 0.09998124849062914, G Loss: 22.089826583862305\n",
      "Epoch: 35, Batch: 261, D Loss: 0.09454151255388467, G Loss: 22.141469955444336\n",
      "Epoch: 35, Batch: 262, D Loss: 0.09232158224764708, G Loss: 22.340526580810547\n",
      "Epoch: 35, Batch: 263, D Loss: 0.10357961065022384, G Loss: 23.171300888061523\n",
      "Epoch: 35, Batch: 264, D Loss: 0.10437045994045545, G Loss: 24.11847686767578\n",
      "Epoch: 35, Batch: 265, D Loss: 0.1010067612071334, G Loss: 24.480485916137695\n",
      "Epoch: 35, Batch: 266, D Loss: 0.10192304850970967, G Loss: 24.20951271057129\n",
      "Epoch: 35, Batch: 267, D Loss: 0.09755802901989133, G Loss: 23.360633850097656\n",
      "Epoch: 35, Batch: 268, D Loss: 0.09688600903553825, G Loss: 22.452882766723633\n",
      "Epoch: 35, Batch: 269, D Loss: 0.0975259990627059, G Loss: 21.99820327758789\n",
      "Epoch: 35, Batch: 270, D Loss: 0.10623115311404446, G Loss: 22.58348274230957\n",
      "Epoch: 35, Batch: 271, D Loss: 0.09616151457665267, G Loss: 23.208526611328125\n",
      "Epoch: 35, Batch: 272, D Loss: 0.10130611065061935, G Loss: 23.824567794799805\n",
      "Epoch: 35, Batch: 273, D Loss: 0.09363471718960042, G Loss: 23.7681884765625\n",
      "Epoch: 35, Batch: 274, D Loss: 0.09364590797022573, G Loss: 23.22077178955078\n",
      "Epoch: 35, Batch: 275, D Loss: 0.09901912515463313, G Loss: 22.824880599975586\n",
      "Epoch: 35, Batch: 276, D Loss: 0.09672944999621466, G Loss: 22.61183738708496\n",
      "Epoch: 35, Batch: 277, D Loss: 0.10286059981794768, G Loss: 22.999296188354492\n",
      "Epoch: 35, Batch: 278, D Loss: 0.1010091528664861, G Loss: 23.630054473876953\n",
      "Epoch: 35, Batch: 279, D Loss: 0.0948838368310032, G Loss: 23.785497665405273\n",
      "Epoch: 35, Batch: 280, D Loss: 0.10266673567074842, G Loss: 23.933719635009766\n",
      "Epoch: 35, Batch: 281, D Loss: 0.08791755142865999, G Loss: 23.154752731323242\n",
      "Epoch: 35, Batch: 282, D Loss: 0.09045393770797036, G Loss: 22.618532180786133\n",
      "Epoch: 35, Batch: 283, D Loss: 0.09606471665294603, G Loss: 22.612211227416992\n",
      "Epoch: 35, Batch: 284, D Loss: 0.09386803960695972, G Loss: 23.097572326660156\n",
      "Epoch: 35, Batch: 285, D Loss: 0.10099890085585086, G Loss: 24.269372940063477\n",
      "Epoch: 35, Batch: 286, D Loss: 0.10777609050888674, G Loss: 25.885120391845703\n",
      "Epoch: 35, Batch: 287, D Loss: 0.09755837172458504, G Loss: 26.678455352783203\n",
      "Epoch: 35, Batch: 288, D Loss: 0.10341479629399829, G Loss: 26.799087524414062\n",
      "Epoch: 35, Batch: 289, D Loss: 0.09683820605447035, G Loss: 26.063800811767578\n",
      "Epoch: 35, Batch: 290, D Loss: 0.10085282475116428, G Loss: 25.287981033325195\n",
      "Epoch: 35, Batch: 291, D Loss: 0.09883650392966538, G Loss: 24.800687789916992\n",
      "Epoch: 35, Batch: 292, D Loss: 0.10343486071351599, G Loss: 25.11417007446289\n",
      "Epoch: 35, Batch: 293, D Loss: 0.10272437334455886, G Loss: 25.967130661010742\n",
      "Epoch: 35, Batch: 294, D Loss: 0.09707503766014565, G Loss: 26.560762405395508\n",
      "Epoch: 35, Batch: 295, D Loss: 0.09851478040348083, G Loss: 26.782760620117188\n",
      "Epoch: 35, Batch: 296, D Loss: 0.10040277242819394, G Loss: 26.19785499572754\n",
      "Epoch: 35, Batch: 297, D Loss: 0.09587439895011501, G Loss: 25.304563522338867\n",
      "Epoch: 35, Batch: 298, D Loss: 0.10016541183724513, G Loss: 24.63140296936035\n",
      "Epoch: 35, Batch: 299, D Loss: 0.1055301651459158, G Loss: 24.628374099731445\n",
      "Epoch: 35, Batch: 300, D Loss: 0.10483685881728658, G Loss: 24.996889114379883\n",
      "Epoch: 35, Batch: 301, D Loss: 0.10603586584892166, G Loss: 25.402374267578125\n",
      "Epoch: 35, Batch: 302, D Loss: 0.09949916601687295, G Loss: 25.238271713256836\n",
      "Epoch: 35, Batch: 303, D Loss: 0.093272946783777, G Loss: 24.3303279876709\n",
      "Epoch: 35, Batch: 304, D Loss: 0.10680199416196405, G Loss: 23.896133422851562\n",
      "Epoch: 35, Batch: 305, D Loss: 0.09341169896583078, G Loss: 23.31635284423828\n",
      "Epoch: 35, Batch: 306, D Loss: 0.09839338068371298, G Loss: 23.106334686279297\n",
      "Epoch: 35, Batch: 307, D Loss: 0.10081166778048646, G Loss: 23.37108039855957\n",
      "Epoch: 35, Batch: 308, D Loss: 0.09792019429800537, G Loss: 23.70016098022461\n",
      "Epoch: 35, Batch: 309, D Loss: 0.09970573338031552, G Loss: 24.026512145996094\n",
      "Epoch: 35, Batch: 310, D Loss: 0.09658999742923827, G Loss: 24.018346786499023\n",
      "Epoch: 35, Batch: 311, D Loss: 0.09459010513891611, G Loss: 23.64562225341797\n",
      "Epoch: 35, Batch: 312, D Loss: 0.10356317463291619, G Loss: 23.60106658935547\n",
      "Epoch: 35, Batch: 313, D Loss: 0.10348197820286767, G Loss: 23.837322235107422\n",
      "Epoch: 35, Batch: 314, D Loss: 0.09791691603419755, G Loss: 23.905223846435547\n",
      "Epoch: 35, Batch: 315, D Loss: 0.09480597826275759, G Loss: 23.61524200439453\n",
      "Epoch: 35, Batch: 316, D Loss: 0.09989947828778192, G Loss: 23.399124145507812\n",
      "Epoch: 35, Batch: 317, D Loss: 0.10012327883184217, G Loss: 23.358877182006836\n",
      "Epoch: 35, Batch: 318, D Loss: 0.09796389940945688, G Loss: 23.380083084106445\n",
      "Epoch: 35, Batch: 319, D Loss: 0.09446747604711891, G Loss: 23.290069580078125\n",
      "Epoch: 35, Batch: 320, D Loss: 0.10418123755075837, G Loss: 23.63810920715332\n",
      "Epoch: 35, Batch: 321, D Loss: 0.0911674350793363, G Loss: 23.48893165588379\n",
      "Epoch: 35, Batch: 322, D Loss: 0.10663599523588375, G Loss: 23.803661346435547\n",
      "Epoch: 35, Batch: 323, D Loss: 0.09733168783047498, G Loss: 23.84849739074707\n",
      "Epoch: 35, Batch: 324, D Loss: 0.10022077711635727, G Loss: 23.8461971282959\n",
      "Epoch: 35, Batch: 325, D Loss: 0.10152566435105075, G Loss: 23.889448165893555\n",
      "Epoch: 35, Batch: 326, D Loss: 0.09799358996029754, G Loss: 23.756685256958008\n",
      "Epoch: 35, Batch: 327, D Loss: 0.09365925195843322, G Loss: 23.33221435546875\n",
      "Epoch: 35, Batch: 328, D Loss: 0.0911296159543952, G Loss: 22.693857192993164\n",
      "Epoch: 35, Batch: 329, D Loss: 0.09626472004042524, G Loss: 22.496501922607422\n",
      "Epoch: 35, Batch: 330, D Loss: 0.10383944964528469, G Loss: 23.130826950073242\n",
      "Epoch: 35, Batch: 331, D Loss: 0.10323712977534039, G Loss: 23.979934692382812\n",
      "Epoch: 35, Batch: 332, D Loss: 0.10095011444362748, G Loss: 24.50179672241211\n",
      "Epoch: 35, Batch: 333, D Loss: 0.10004918278247901, G Loss: 24.64341163635254\n",
      "Epoch: 35, Batch: 334, D Loss: 0.09949132801371732, G Loss: 24.174148559570312\n",
      "Epoch: 35, Batch: 335, D Loss: 0.1021554842795535, G Loss: 23.69305992126465\n",
      "Epoch: 35, Batch: 336, D Loss: 0.09506195787142165, G Loss: 23.088333129882812\n",
      "Epoch: 35, Batch: 337, D Loss: 0.09808347379608073, G Loss: 22.82133674621582\n",
      "Epoch: 35, Batch: 338, D Loss: 0.09868477290596889, G Loss: 22.96555519104004\n",
      "Epoch: 35, Batch: 339, D Loss: 0.09894070033522621, G Loss: 23.383045196533203\n",
      "Epoch: 35, Batch: 340, D Loss: 0.10688671471928025, G Loss: 24.229467391967773\n",
      "Epoch: 35, Batch: 341, D Loss: 0.09684832395423365, G Loss: 24.501724243164062\n",
      "Epoch: 35, Batch: 342, D Loss: 0.0963458418983623, G Loss: 24.150405883789062\n",
      "Epoch: 35, Batch: 343, D Loss: 0.10095909239913031, G Loss: 23.706275939941406\n",
      "Epoch: 35, Batch: 344, D Loss: 0.0976175219148803, G Loss: 23.213329315185547\n",
      "Epoch: 35, Batch: 345, D Loss: 0.09753250335511811, G Loss: 22.92515754699707\n",
      "Epoch: 35, Batch: 346, D Loss: 0.09630966192241042, G Loss: 22.862375259399414\n",
      "Epoch: 35, Batch: 347, D Loss: 0.1036710739585439, G Loss: 23.374618530273438\n",
      "Epoch: 35, Batch: 348, D Loss: 0.10375029596034402, G Loss: 24.163494110107422\n",
      "Epoch: 35, Batch: 349, D Loss: 0.09997397662511004, G Loss: 24.558616638183594\n",
      "Epoch: 35, Batch: 350, D Loss: 0.10084118695183487, G Loss: 24.495046615600586\n",
      "Epoch: 35, Batch: 351, D Loss: 0.09986086936234248, G Loss: 24.082538604736328\n",
      "Epoch: 35, Batch: 352, D Loss: 0.1025351435158563, G Loss: 23.70045280456543\n",
      "Epoch: 35, Batch: 353, D Loss: 0.09867043051289934, G Loss: 23.29888153076172\n",
      "Epoch: 35, Batch: 354, D Loss: 0.10189132396287212, G Loss: 23.262121200561523\n",
      "Epoch: 35, Batch: 355, D Loss: 0.09498114888048452, G Loss: 23.16832160949707\n",
      "Epoch: 35, Batch: 356, D Loss: 0.10213737193516696, G Loss: 23.44620132446289\n",
      "Epoch: 35, Batch: 357, D Loss: 0.09796729686787156, G Loss: 23.675554275512695\n",
      "Epoch: 35, Batch: 358, D Loss: 0.0957506671813328, G Loss: 23.644590377807617\n",
      "Epoch: 35, Batch: 359, D Loss: 0.09781216832930942, G Loss: 23.493955612182617\n",
      "Epoch: 35, Batch: 360, D Loss: 0.10134711864724082, G Loss: 23.504880905151367\n",
      "Epoch: 35, Batch: 361, D Loss: 0.09695378694214188, G Loss: 23.410015106201172\n",
      "Epoch: 35, Batch: 362, D Loss: 0.09517146650740463, G Loss: 23.220043182373047\n",
      "Epoch: 35, Batch: 363, D Loss: 0.09787484262773048, G Loss: 23.111963272094727\n",
      "Epoch: 35, Batch: 364, D Loss: 0.10112891350373321, G Loss: 23.299694061279297\n",
      "Epoch: 35, Batch: 365, D Loss: 0.10371131452880575, G Loss: 23.786741256713867\n",
      "Epoch: 35, Batch: 366, D Loss: 0.09824456276573593, G Loss: 24.02225685119629\n",
      "Epoch: 35, Batch: 367, D Loss: 0.10210976006386793, G Loss: 24.08502197265625\n",
      "Epoch: 35, Batch: 368, D Loss: 0.09663449229894126, G Loss: 23.735105514526367\n",
      "Epoch: 35, Batch: 369, D Loss: 0.09910126033452357, G Loss: 23.353578567504883\n",
      "Epoch: 35, Batch: 370, D Loss: 0.0954103917342573, G Loss: 22.89303207397461\n",
      "Epoch: 35, Batch: 371, D Loss: 0.09680433577782352, G Loss: 22.66415023803711\n",
      "Epoch: 35, Batch: 372, D Loss: 0.1016303599495719, G Loss: 22.95893096923828\n",
      "Epoch: 35, Batch: 373, D Loss: 0.10519429299807231, G Loss: 23.735523223876953\n",
      "Epoch: 35, Batch: 374, D Loss: 0.09819670023520984, G Loss: 24.14048194885254\n",
      "Epoch: 35, Batch: 375, D Loss: 0.10419561715392141, G Loss: 24.36409568786621\n",
      "Epoch: 35, Batch: 376, D Loss: 0.10031135381774609, G Loss: 24.10080909729004\n",
      "Epoch: 35, Batch: 377, D Loss: 0.09610481562756566, G Loss: 23.354516983032227\n",
      "Epoch: 35, Batch: 378, D Loss: 0.09613126521726793, G Loss: 22.588451385498047\n",
      "Epoch: 35, Batch: 379, D Loss: 0.10467223830751238, G Loss: 22.604915618896484\n",
      "Epoch: 35, Batch: 380, D Loss: 0.10059071338152939, G Loss: 23.078935623168945\n",
      "Epoch: 35, Batch: 381, D Loss: 0.10126194361232267, G Loss: 23.73134994506836\n",
      "Epoch: 35, Batch: 382, D Loss: 0.10275436939646393, G Loss: 24.29267120361328\n",
      "Epoch: 35, Batch: 383, D Loss: 0.10119901598801537, G Loss: 24.442838668823242\n",
      "Epoch: 35, Batch: 384, D Loss: 0.09300827236708034, G Loss: 23.772043228149414\n",
      "Epoch: 35, Batch: 385, D Loss: 0.09787896278945335, G Loss: 23.07271957397461\n",
      "Epoch: 35, Batch: 386, D Loss: 0.10223858063645008, G Loss: 22.912551879882812\n",
      "Epoch: 35, Batch: 387, D Loss: 0.09661433851132468, G Loss: 22.991498947143555\n",
      "Epoch: 35, Batch: 388, D Loss: 0.09877745811456393, G Loss: 23.350139617919922\n",
      "Epoch: 35, Batch: 389, D Loss: 0.09703439477072044, G Loss: 23.726490020751953\n",
      "Epoch: 35, Batch: 390, D Loss: 0.10208799691923459, G Loss: 24.218360900878906\n",
      "Epoch: 35, Batch: 391, D Loss: 0.10168932379551066, G Loss: 24.573015213012695\n",
      "Epoch: 35, Batch: 392, D Loss: 0.09736438841784463, G Loss: 24.414691925048828\n",
      "Epoch: 35, Batch: 393, D Loss: 0.10292673857409561, G Loss: 24.2087345123291\n",
      "Epoch: 35, Batch: 394, D Loss: 0.09234602751530219, G Loss: 23.53541374206543\n",
      "Epoch: 35, Batch: 395, D Loss: 0.10219880196884185, G Loss: 23.29353141784668\n",
      "Epoch: 35, Batch: 396, D Loss: 0.09792916480528455, G Loss: 23.305864334106445\n",
      "Epoch: 35, Batch: 397, D Loss: 0.09999702128956531, G Loss: 23.640817642211914\n",
      "Epoch: 35, Batch: 398, D Loss: 0.09614661338306298, G Loss: 23.898204803466797\n",
      "Epoch: 35, Batch: 399, D Loss: 0.09689149262488853, G Loss: 24.01270866394043\n",
      "Epoch: 35, Batch: 400, D Loss: 0.10065864028290665, G Loss: 24.138885498046875\n",
      "Epoch: 35, Batch: 401, D Loss: 0.09199771287047116, G Loss: 23.77444839477539\n",
      "Epoch: 35, Batch: 402, D Loss: 0.09822630139950617, G Loss: 23.491313934326172\n",
      "Epoch: 35, Batch: 403, D Loss: 0.10321813079532238, G Loss: 23.710538864135742\n",
      "Epoch: 35, Batch: 404, D Loss: 0.09295316043098055, G Loss: 23.665563583374023\n",
      "Epoch: 35, Batch: 405, D Loss: 0.10491988810017248, G Loss: 24.097841262817383\n",
      "Epoch: 35, Batch: 406, D Loss: 0.10691142083414079, G Loss: 24.772342681884766\n",
      "Epoch: 35, Batch: 407, D Loss: 0.10532937944632155, G Loss: 25.198223114013672\n",
      "Epoch: 35, Batch: 408, D Loss: 0.10341885686507366, G Loss: 25.142061233520508\n",
      "Epoch: 35, Batch: 409, D Loss: 0.10294802487652058, G Loss: 24.711368560791016\n",
      "Epoch: 35, Batch: 410, D Loss: 0.09769752623073358, G Loss: 23.89560317993164\n",
      "Epoch: 35, Batch: 411, D Loss: 0.09647968414656177, G Loss: 23.079622268676758\n",
      "Epoch: 35, Batch: 412, D Loss: 0.1006184369847552, G Loss: 22.896644592285156\n",
      "Epoch: 35, Batch: 413, D Loss: 0.0995002985469755, G Loss: 23.26366424560547\n",
      "Epoch: 35, Batch: 414, D Loss: 0.09867644312929344, G Loss: 23.822772979736328\n",
      "Epoch: 35, Batch: 415, D Loss: 0.10265566410245182, G Loss: 24.460044860839844\n",
      "Epoch: 35, Batch: 416, D Loss: 0.10020396859496233, G Loss: 24.714046478271484\n",
      "Epoch: 35, Batch: 417, D Loss: 0.09965801985117205, G Loss: 24.47991943359375\n",
      "Epoch: 35, Batch: 418, D Loss: 0.10613024236049359, G Loss: 24.30835723876953\n",
      "Epoch: 35, Batch: 419, D Loss: 0.10002636911161217, G Loss: 23.947799682617188\n",
      "Epoch: 35, Batch: 420, D Loss: 0.0986784696821908, G Loss: 23.567596435546875\n",
      "Epoch: 35, Batch: 421, D Loss: 0.10637819769709232, G Loss: 23.70174789428711\n",
      "Epoch: 35, Batch: 422, D Loss: 0.10116952659993447, G Loss: 23.898298263549805\n",
      "Epoch: 35, Batch: 423, D Loss: 0.1007532552078528, G Loss: 24.040935516357422\n",
      "Epoch: 35, Batch: 424, D Loss: 0.09551794829040688, G Loss: 23.800575256347656\n",
      "Epoch: 35, Batch: 425, D Loss: 0.09421569112001608, G Loss: 23.274877548217773\n",
      "Epoch: 35, Batch: 426, D Loss: 0.09699445967530704, G Loss: 22.95023536682129\n",
      "Epoch: 35, Batch: 427, D Loss: 0.09526249772222858, G Loss: 22.788829803466797\n",
      "Epoch: 35, Batch: 428, D Loss: 0.09871381526634043, G Loss: 23.090417861938477\n",
      "Epoch: 35, Batch: 429, D Loss: 0.09992779794952004, G Loss: 23.59362030029297\n",
      "Epoch: 35, Batch: 430, D Loss: 0.10045477750062373, G Loss: 24.122453689575195\n",
      "Epoch: 35, Batch: 431, D Loss: 0.09722088278919704, G Loss: 24.22727394104004\n",
      "Epoch: 35, Batch: 432, D Loss: 0.10096251966133839, G Loss: 24.151962280273438\n",
      "Epoch: 35, Batch: 433, D Loss: 0.0926812887417902, G Loss: 23.517478942871094\n",
      "Epoch: 35, Batch: 434, D Loss: 0.10218717161371482, G Loss: 23.24472999572754\n",
      "Epoch: 35, Batch: 435, D Loss: 0.09513460104245337, G Loss: 23.009265899658203\n",
      "Epoch: 35, Batch: 436, D Loss: 0.0962474048645355, G Loss: 23.009536743164062\n",
      "Epoch: 35, Batch: 437, D Loss: 0.09861792628334305, G Loss: 23.31108283996582\n",
      "Epoch: 35, Batch: 438, D Loss: 0.09768969568742755, G Loss: 23.66678810119629\n",
      "Epoch: 35, Batch: 439, D Loss: 0.10068153592058843, G Loss: 24.101694107055664\n",
      "Epoch: 35, Batch: 440, D Loss: 0.09647186102158303, G Loss: 24.135265350341797\n",
      "Epoch: 35, Batch: 441, D Loss: 0.1022677645246692, G Loss: 24.199087142944336\n",
      "Epoch: 35, Batch: 442, D Loss: 0.10181929172646495, G Loss: 24.179107666015625\n",
      "Epoch: 35, Batch: 443, D Loss: 0.09714699538370275, G Loss: 23.920408248901367\n",
      "Epoch: 35, Batch: 444, D Loss: 0.09871875497070035, G Loss: 23.654157638549805\n",
      "Epoch: 35, Batch: 445, D Loss: 0.09718018773227496, G Loss: 23.425247192382812\n",
      "Epoch: 35, Batch: 446, D Loss: 0.10111012312903303, G Loss: 23.56688117980957\n",
      "Epoch: 35, Batch: 447, D Loss: 0.0992907136931401, G Loss: 23.83576202392578\n",
      "Epoch: 35, Batch: 448, D Loss: 0.09746839853183968, G Loss: 23.997783660888672\n",
      "Epoch: 35, Batch: 449, D Loss: 0.09829002620659556, G Loss: 24.020130157470703\n",
      "Epoch: 35, Batch: 450, D Loss: 0.10357805343103024, G Loss: 24.27145004272461\n",
      "Epoch: 35, Batch: 451, D Loss: 0.0924151539968538, G Loss: 23.99998664855957\n",
      "Epoch: 35, Batch: 452, D Loss: 0.10140882434411676, G Loss: 23.937591552734375\n",
      "Epoch: 35, Batch: 453, D Loss: 0.0955233872153188, G Loss: 23.796825408935547\n",
      "Epoch: 35, Batch: 454, D Loss: 0.09747520091528848, G Loss: 23.74327850341797\n",
      "Epoch: 35, Batch: 455, D Loss: 0.09828895332825073, G Loss: 23.778234481811523\n",
      "Epoch: 35, Batch: 456, D Loss: 0.09733563663777733, G Loss: 23.90681266784668\n",
      "Epoch: 35, Batch: 457, D Loss: 0.10080868752546857, G Loss: 24.24281883239746\n",
      "Epoch: 35, Batch: 458, D Loss: 0.0951534807826678, G Loss: 24.28752899169922\n",
      "Epoch: 35, Batch: 459, D Loss: 0.09931966663801346, G Loss: 24.316743850708008\n",
      "Epoch: 35, Batch: 460, D Loss: 0.09299076350163303, G Loss: 24.00518226623535\n",
      "Epoch: 35, Batch: 461, D Loss: 0.10363006593539528, G Loss: 24.147371292114258\n",
      "Epoch: 35, Batch: 462, D Loss: 0.10009122641316337, G Loss: 24.40581512451172\n",
      "Epoch: 35, Batch: 463, D Loss: 0.09926672280956896, G Loss: 24.622949600219727\n",
      "Epoch: 35, Batch: 464, D Loss: 0.1017038449734106, G Loss: 24.866493225097656\n",
      "Epoch: 35, Batch: 465, D Loss: 0.09990994633012987, G Loss: 24.92669677734375\n",
      "Epoch: 35, Batch: 466, D Loss: 0.10443336517334785, G Loss: 25.007705688476562\n",
      "Epoch: 35, Batch: 467, D Loss: 0.10063475371166992, G Loss: 24.82181167602539\n",
      "Epoch: 36, Batch: 0, D Loss: 0.10197182000596235, G Loss: 24.64066505432129\n",
      "Epoch: 36, Batch: 1, D Loss: 0.09951558710263385, G Loss: 24.417158126831055\n",
      "Epoch: 36, Batch: 2, D Loss: 0.09058481456589701, G Loss: 23.777984619140625\n",
      "Epoch: 36, Batch: 3, D Loss: 0.10081655534596735, G Loss: 23.685359954833984\n",
      "Epoch: 36, Batch: 4, D Loss: 0.09913689645417956, G Loss: 23.9290828704834\n",
      "Epoch: 36, Batch: 5, D Loss: 0.09742324055952686, G Loss: 24.25004768371582\n",
      "Epoch: 36, Batch: 6, D Loss: 0.09450783581980368, G Loss: 24.29104232788086\n",
      "Epoch: 36, Batch: 7, D Loss: 0.09851235897770658, G Loss: 24.27678680419922\n",
      "Epoch: 36, Batch: 8, D Loss: 0.10330731422968699, G Loss: 24.519487380981445\n",
      "Epoch: 36, Batch: 9, D Loss: 0.09948959947680519, G Loss: 24.650314331054688\n",
      "Epoch: 36, Batch: 10, D Loss: 0.09870740772329556, G Loss: 24.554813385009766\n",
      "Epoch: 36, Batch: 11, D Loss: 0.09907243402027885, G Loss: 24.33658218383789\n",
      "Epoch: 36, Batch: 12, D Loss: 0.10339273513671851, G Loss: 24.393569946289062\n",
      "Epoch: 36, Batch: 13, D Loss: 0.0975356996191308, G Loss: 24.327096939086914\n",
      "Epoch: 36, Batch: 14, D Loss: 0.10326406360878897, G Loss: 24.556396484375\n",
      "Epoch: 36, Batch: 15, D Loss: 0.10434514284986753, G Loss: 25.008625030517578\n",
      "Epoch: 36, Batch: 16, D Loss: 0.10407350957955812, G Loss: 25.393600463867188\n",
      "Epoch: 36, Batch: 17, D Loss: 0.10561627149997325, G Loss: 25.62194061279297\n",
      "Epoch: 36, Batch: 18, D Loss: 0.10437558591762024, G Loss: 25.50637435913086\n",
      "Epoch: 36, Batch: 19, D Loss: 0.10027270764681011, G Loss: 24.923526763916016\n",
      "Epoch: 36, Batch: 20, D Loss: 0.09661796690207577, G Loss: 24.06960105895996\n",
      "Epoch: 36, Batch: 21, D Loss: 0.09318209442210518, G Loss: 23.2604923248291\n",
      "Epoch: 36, Batch: 22, D Loss: 0.08874133234620839, G Loss: 22.680713653564453\n",
      "Epoch: 36, Batch: 23, D Loss: 0.101443775049185, G Loss: 23.299318313598633\n",
      "Epoch: 36, Batch: 24, D Loss: 0.10028025509892105, G Loss: 24.55250358581543\n",
      "Epoch: 36, Batch: 25, D Loss: 0.0993909537852596, G Loss: 25.6663875579834\n",
      "Epoch: 36, Batch: 26, D Loss: 0.10040220618515927, G Loss: 26.2059326171875\n",
      "Epoch: 36, Batch: 27, D Loss: 0.09745454788454182, G Loss: 25.884679794311523\n",
      "Epoch: 36, Batch: 28, D Loss: 0.09675647318799303, G Loss: 25.086027145385742\n",
      "Epoch: 36, Batch: 29, D Loss: 0.10162024200794906, G Loss: 24.577728271484375\n",
      "Epoch: 36, Batch: 30, D Loss: 0.09994855524228045, G Loss: 24.47422218322754\n",
      "Epoch: 36, Batch: 31, D Loss: 0.09521345795360053, G Loss: 24.499820709228516\n",
      "Epoch: 36, Batch: 32, D Loss: 0.1012311279865654, G Loss: 24.91669464111328\n",
      "Epoch: 36, Batch: 33, D Loss: 0.10699721426261341, G Loss: 25.737642288208008\n",
      "Epoch: 36, Batch: 34, D Loss: 0.10107679665351789, G Loss: 26.179567337036133\n",
      "Epoch: 36, Batch: 35, D Loss: 0.10180148482534856, G Loss: 26.191272735595703\n",
      "Epoch: 36, Batch: 36, D Loss: 0.09722808003713995, G Loss: 25.59658432006836\n",
      "Epoch: 36, Batch: 37, D Loss: 0.09300645441476885, G Loss: 24.557226181030273\n",
      "Epoch: 36, Batch: 38, D Loss: 0.10056748987637255, G Loss: 24.075319290161133\n",
      "Epoch: 36, Batch: 39, D Loss: 0.09837269039660826, G Loss: 24.132610321044922\n",
      "Epoch: 36, Batch: 40, D Loss: 0.09619256855448204, G Loss: 24.460912704467773\n",
      "Epoch: 36, Batch: 41, D Loss: 0.10199301690685524, G Loss: 25.16318702697754\n",
      "Epoch: 36, Batch: 42, D Loss: 0.09987743944352269, G Loss: 25.7961368560791\n",
      "Epoch: 36, Batch: 43, D Loss: 0.1025361567761927, G Loss: 26.13132095336914\n",
      "Epoch: 36, Batch: 44, D Loss: 0.10021166503676521, G Loss: 25.9448299407959\n",
      "Epoch: 36, Batch: 45, D Loss: 0.09244702756854527, G Loss: 24.973291397094727\n",
      "Epoch: 36, Batch: 46, D Loss: 0.10586736352129565, G Loss: 24.57810401916504\n",
      "Epoch: 36, Batch: 47, D Loss: 0.09816802294164526, G Loss: 24.501785278320312\n",
      "Epoch: 36, Batch: 48, D Loss: 0.09877885879121882, G Loss: 24.688705444335938\n",
      "Epoch: 36, Batch: 49, D Loss: 0.10404330492720194, G Loss: 25.2629451751709\n",
      "Epoch: 36, Batch: 50, D Loss: 0.09956463426787113, G Loss: 25.649303436279297\n",
      "Epoch: 36, Batch: 51, D Loss: 0.10251912474967667, G Loss: 25.798246383666992\n",
      "Epoch: 36, Batch: 52, D Loss: 0.09974445402979107, G Loss: 25.546161651611328\n",
      "Epoch: 36, Batch: 53, D Loss: 0.09947191179306367, G Loss: 25.103059768676758\n",
      "Epoch: 36, Batch: 54, D Loss: 0.10238004476562015, G Loss: 24.812042236328125\n",
      "Epoch: 36, Batch: 55, D Loss: 0.0988412574026594, G Loss: 24.614261627197266\n",
      "Epoch: 36, Batch: 56, D Loss: 0.09699891508734737, G Loss: 24.457477569580078\n",
      "Epoch: 36, Batch: 57, D Loss: 0.09685917944949833, G Loss: 24.396347045898438\n",
      "Epoch: 36, Batch: 58, D Loss: 0.10155975819666992, G Loss: 24.78870391845703\n",
      "Epoch: 36, Batch: 59, D Loss: 0.10396011919397555, G Loss: 25.422292709350586\n",
      "Epoch: 36, Batch: 60, D Loss: 0.09572806954836144, G Loss: 25.43456268310547\n",
      "Epoch: 36, Batch: 61, D Loss: 0.09929104149845688, G Loss: 25.217273712158203\n",
      "Epoch: 36, Batch: 62, D Loss: 0.10265002400288172, G Loss: 25.06576156616211\n",
      "Epoch: 36, Batch: 63, D Loss: 0.09755485505625162, G Loss: 24.770366668701172\n",
      "Epoch: 36, Batch: 64, D Loss: 0.09619680048097212, G Loss: 24.399227142333984\n",
      "Epoch: 36, Batch: 65, D Loss: 0.09834175558249235, G Loss: 24.27614974975586\n",
      "Epoch: 36, Batch: 66, D Loss: 0.10036585481234911, G Loss: 24.519287109375\n",
      "Epoch: 36, Batch: 67, D Loss: 0.10411302746145389, G Loss: 25.15591049194336\n",
      "Epoch: 36, Batch: 68, D Loss: 0.0998657196808443, G Loss: 25.552780151367188\n",
      "Epoch: 36, Batch: 69, D Loss: 0.102007865909442, G Loss: 25.708904266357422\n",
      "Epoch: 36, Batch: 70, D Loss: 0.09739760309870957, G Loss: 25.34812355041504\n",
      "Epoch: 36, Batch: 71, D Loss: 0.09660319239598955, G Loss: 24.67639923095703\n",
      "Epoch: 36, Batch: 72, D Loss: 0.10207785667108582, G Loss: 24.383451461791992\n",
      "Epoch: 36, Batch: 73, D Loss: 0.09633861483541566, G Loss: 24.2252254486084\n",
      "Epoch: 36, Batch: 74, D Loss: 0.09766589851601769, G Loss: 24.345680236816406\n",
      "Epoch: 36, Batch: 75, D Loss: 0.0992292538395999, G Loss: 24.701980590820312\n",
      "Epoch: 36, Batch: 76, D Loss: 0.08951585740858468, G Loss: 24.561166763305664\n",
      "Epoch: 36, Batch: 77, D Loss: 0.10220237077266886, G Loss: 24.732036590576172\n",
      "Epoch: 36, Batch: 78, D Loss: 0.09820113331952818, G Loss: 24.80584144592285\n",
      "Epoch: 36, Batch: 79, D Loss: 0.10039320588891669, G Loss: 24.954591751098633\n",
      "Epoch: 36, Batch: 80, D Loss: 0.0969561189488845, G Loss: 24.87506866455078\n",
      "Epoch: 36, Batch: 81, D Loss: 0.09542331100448695, G Loss: 24.54010772705078\n",
      "Epoch: 36, Batch: 82, D Loss: 0.10025215895157162, G Loss: 24.428438186645508\n",
      "Epoch: 36, Batch: 83, D Loss: 0.10247050226839735, G Loss: 24.631898880004883\n",
      "Epoch: 36, Batch: 84, D Loss: 0.1044837981539784, G Loss: 25.12628746032715\n",
      "Epoch: 36, Batch: 85, D Loss: 0.09571070224632235, G Loss: 25.21044921875\n",
      "Epoch: 36, Batch: 86, D Loss: 0.09848685563239583, G Loss: 24.998655319213867\n",
      "Epoch: 36, Batch: 87, D Loss: 0.093579843650002, G Loss: 24.368934631347656\n",
      "Epoch: 36, Batch: 88, D Loss: 0.09589315952542726, G Loss: 23.897836685180664\n",
      "Epoch: 36, Batch: 89, D Loss: 0.10484015198256984, G Loss: 24.29536247253418\n",
      "Epoch: 36, Batch: 90, D Loss: 0.10263669491788115, G Loss: 24.991100311279297\n",
      "Epoch: 36, Batch: 91, D Loss: 0.10375605524070414, G Loss: 25.69252586364746\n",
      "Epoch: 36, Batch: 92, D Loss: 0.10211575031577819, G Loss: 25.98847007751465\n",
      "Epoch: 36, Batch: 93, D Loss: 0.09472073614942304, G Loss: 25.438512802124023\n",
      "Epoch: 36, Batch: 94, D Loss: 0.09872078896233484, G Loss: 24.684528350830078\n",
      "Epoch: 36, Batch: 95, D Loss: 0.10442700983189512, G Loss: 24.417139053344727\n",
      "Epoch: 36, Batch: 96, D Loss: 0.09982949496551295, G Loss: 24.429580688476562\n",
      "Epoch: 36, Batch: 97, D Loss: 0.095797196042621, G Loss: 24.473527908325195\n",
      "Epoch: 36, Batch: 98, D Loss: 0.10402459652168278, G Loss: 24.905364990234375\n",
      "Epoch: 36, Batch: 99, D Loss: 0.10002230108426824, G Loss: 25.231163024902344\n",
      "Epoch: 36, Batch: 100, D Loss: 0.09479156137127671, G Loss: 25.02289390563965\n",
      "Epoch: 36, Batch: 101, D Loss: 0.09505246580501964, G Loss: 24.583873748779297\n",
      "Epoch: 36, Batch: 102, D Loss: 0.10567162932006806, G Loss: 24.604652404785156\n",
      "Epoch: 36, Batch: 103, D Loss: 0.09841353447250294, G Loss: 24.65340805053711\n",
      "Epoch: 36, Batch: 104, D Loss: 0.10111203790602027, G Loss: 24.83829689025879\n",
      "Epoch: 36, Batch: 105, D Loss: 0.10158331692934805, G Loss: 25.086397171020508\n",
      "Epoch: 36, Batch: 106, D Loss: 0.10177253932342362, G Loss: 25.259231567382812\n",
      "Epoch: 36, Batch: 107, D Loss: 0.09863580763915589, G Loss: 25.123220443725586\n",
      "Epoch: 36, Batch: 108, D Loss: 0.09840096534039552, G Loss: 24.764249801635742\n",
      "Epoch: 36, Batch: 109, D Loss: 0.09745417536380299, G Loss: 24.378684997558594\n",
      "Epoch: 36, Batch: 110, D Loss: 0.09769977630641137, G Loss: 24.151954650878906\n",
      "Epoch: 36, Batch: 111, D Loss: 0.09598411621294403, G Loss: 24.14088249206543\n",
      "Epoch: 36, Batch: 112, D Loss: 0.09831960500709933, G Loss: 24.409770965576172\n",
      "Epoch: 36, Batch: 113, D Loss: 0.09992858023456846, G Loss: 24.82780647277832\n",
      "Epoch: 36, Batch: 114, D Loss: 0.1002527624437025, G Loss: 25.18342399597168\n",
      "Epoch: 36, Batch: 115, D Loss: 0.09652301669721441, G Loss: 25.110557556152344\n",
      "Epoch: 36, Batch: 116, D Loss: 0.09786930680991107, G Loss: 24.840007781982422\n",
      "Epoch: 36, Batch: 117, D Loss: 0.09859886766422128, G Loss: 24.564369201660156\n",
      "Epoch: 36, Batch: 118, D Loss: 0.10184847564580764, G Loss: 24.560789108276367\n",
      "Epoch: 36, Batch: 119, D Loss: 0.09436478466963599, G Loss: 24.407236099243164\n",
      "Epoch: 36, Batch: 120, D Loss: 0.09617924691589497, G Loss: 24.28053092956543\n",
      "Epoch: 36, Batch: 121, D Loss: 0.09982267023443597, G Loss: 24.440649032592773\n",
      "Epoch: 36, Batch: 122, D Loss: 0.10370387137842538, G Loss: 24.9971981048584\n",
      "Epoch: 36, Batch: 123, D Loss: 0.1048455536414192, G Loss: 25.675769805908203\n",
      "Epoch: 36, Batch: 124, D Loss: 0.1027996540098809, G Loss: 26.035747528076172\n",
      "Epoch: 36, Batch: 125, D Loss: 0.09946423769276097, G Loss: 25.798160552978516\n",
      "Epoch: 36, Batch: 126, D Loss: 0.09471753985166462, G Loss: 24.994047164916992\n",
      "Epoch: 36, Batch: 127, D Loss: 0.10135075450873363, G Loss: 24.450170516967773\n",
      "Epoch: 36, Batch: 128, D Loss: 0.10043556989487457, G Loss: 24.38085174560547\n",
      "Epoch: 36, Batch: 129, D Loss: 0.0982268005722866, G Loss: 24.62626838684082\n",
      "Epoch: 36, Batch: 130, D Loss: 0.10441269726250248, G Loss: 25.348188400268555\n",
      "Epoch: 36, Batch: 131, D Loss: 0.09800677001885341, G Loss: 25.692047119140625\n",
      "Epoch: 36, Batch: 132, D Loss: 0.1003357693586237, G Loss: 25.7755069732666\n",
      "Epoch: 36, Batch: 133, D Loss: 0.09386090934693717, G Loss: 25.26970863342285\n",
      "Epoch: 36, Batch: 134, D Loss: 0.09688319266548648, G Loss: 24.72332191467285\n",
      "Epoch: 36, Batch: 135, D Loss: 0.09738168121464691, G Loss: 24.408870697021484\n",
      "Epoch: 36, Batch: 136, D Loss: 0.09621146322581217, G Loss: 24.36353874206543\n",
      "Epoch: 36, Batch: 137, D Loss: 0.09919171036392489, G Loss: 24.69407844543457\n",
      "Epoch: 36, Batch: 138, D Loss: 0.09921214730257251, G Loss: 25.232341766357422\n",
      "Epoch: 36, Batch: 139, D Loss: 0.09469892085092478, G Loss: 25.438152313232422\n",
      "Epoch: 36, Batch: 140, D Loss: 0.09645150602331325, G Loss: 25.35761070251465\n",
      "Epoch: 36, Batch: 141, D Loss: 0.10118320584784427, G Loss: 25.35131072998047\n",
      "Epoch: 36, Batch: 142, D Loss: 0.1039504557892379, G Loss: 25.53347396850586\n",
      "Epoch: 36, Batch: 143, D Loss: 0.10577157140117598, G Loss: 25.879514694213867\n",
      "Epoch: 36, Batch: 144, D Loss: 0.10407169163489359, G Loss: 26.058353424072266\n",
      "Epoch: 36, Batch: 145, D Loss: 0.10256038606425069, G Loss: 25.92694664001465\n",
      "Epoch: 36, Batch: 146, D Loss: 0.09975281358120637, G Loss: 25.437667846679688\n",
      "Epoch: 36, Batch: 147, D Loss: 0.10116508603683617, G Loss: 24.922212600708008\n",
      "Epoch: 36, Batch: 148, D Loss: 0.10456947983112333, G Loss: 24.798559188842773\n",
      "Epoch: 36, Batch: 149, D Loss: 0.10779780895190169, G Loss: 25.24125862121582\n",
      "Epoch: 36, Batch: 150, D Loss: 0.10224352032393716, G Loss: 25.617353439331055\n",
      "Epoch: 36, Batch: 151, D Loss: 0.10233621299607847, G Loss: 25.79541015625\n",
      "Epoch: 36, Batch: 152, D Loss: 0.09886230528709407, G Loss: 25.560087203979492\n",
      "Epoch: 36, Batch: 153, D Loss: 0.1018652692484776, G Loss: 25.213003158569336\n",
      "Epoch: 36, Batch: 154, D Loss: 0.0978652685951891, G Loss: 24.757871627807617\n",
      "Epoch: 36, Batch: 155, D Loss: 0.10696890951040436, G Loss: 24.862079620361328\n",
      "Epoch: 36, Batch: 156, D Loss: 0.09999509901553198, G Loss: 24.990596771240234\n",
      "Epoch: 36, Batch: 157, D Loss: 0.09967814386566445, G Loss: 25.061010360717773\n",
      "Epoch: 36, Batch: 158, D Loss: 0.09497937560843599, G Loss: 24.767290115356445\n",
      "Epoch: 36, Batch: 159, D Loss: 0.09866241366685544, G Loss: 24.489316940307617\n",
      "Epoch: 36, Batch: 160, D Loss: 0.09846224637080972, G Loss: 24.355762481689453\n",
      "Epoch: 36, Batch: 161, D Loss: 0.09517043830371019, G Loss: 24.238527297973633\n",
      "Epoch: 36, Batch: 162, D Loss: 0.09988060594972509, G Loss: 24.397932052612305\n",
      "Epoch: 36, Batch: 163, D Loss: 0.10038386286388193, G Loss: 24.697092056274414\n",
      "Epoch: 36, Batch: 164, D Loss: 0.09594862909049269, G Loss: 24.72923469543457\n",
      "Epoch: 36, Batch: 165, D Loss: 0.09702771903082899, G Loss: 24.55360984802246\n",
      "Epoch: 36, Batch: 166, D Loss: 0.09667463601890633, G Loss: 24.277097702026367\n",
      "Epoch: 36, Batch: 167, D Loss: 0.10325255246307856, G Loss: 24.405282974243164\n",
      "Epoch: 36, Batch: 168, D Loss: 0.10346654058514643, G Loss: 24.819955825805664\n",
      "Epoch: 36, Batch: 169, D Loss: 0.10061404854763488, G Loss: 25.134822845458984\n",
      "Epoch: 36, Batch: 170, D Loss: 0.09652923793245202, G Loss: 25.020193099975586\n",
      "Epoch: 36, Batch: 171, D Loss: 0.09940610826795923, G Loss: 24.758831024169922\n",
      "Epoch: 36, Batch: 172, D Loss: 0.09545652569437661, G Loss: 24.347326278686523\n",
      "Epoch: 36, Batch: 173, D Loss: 0.10347244889829257, G Loss: 24.417980194091797\n",
      "Epoch: 36, Batch: 174, D Loss: 0.10021756590471127, G Loss: 24.723003387451172\n",
      "Epoch: 36, Batch: 175, D Loss: 0.09803673625815333, G Loss: 24.926687240600586\n",
      "Epoch: 36, Batch: 176, D Loss: 0.09860824049235967, G Loss: 25.005592346191406\n",
      "Epoch: 36, Batch: 177, D Loss: 0.10646793246842343, G Loss: 25.35957908630371\n",
      "Epoch: 36, Batch: 178, D Loss: 0.10160671174967902, G Loss: 25.53605079650879\n",
      "Epoch: 36, Batch: 179, D Loss: 0.10142900050120118, G Loss: 25.411958694458008\n",
      "Epoch: 36, Batch: 180, D Loss: 0.09406147897889099, G Loss: 24.765554428100586\n",
      "Epoch: 36, Batch: 181, D Loss: 0.0936265438929498, G Loss: 23.95503044128418\n",
      "Epoch: 36, Batch: 182, D Loss: 0.09869849684149555, G Loss: 23.669002532958984\n",
      "Epoch: 36, Batch: 183, D Loss: 0.11079569162565, G Loss: 24.579090118408203\n",
      "Epoch: 36, Batch: 184, D Loss: 0.1005703359908474, G Loss: 25.466920852661133\n",
      "Epoch: 36, Batch: 185, D Loss: 0.09583273530408785, G Loss: 25.616575241088867\n",
      "Epoch: 36, Batch: 186, D Loss: 0.10258916020800879, G Loss: 25.457672119140625\n",
      "Epoch: 36, Batch: 187, D Loss: 0.10450568795687516, G Loss: 25.27639389038086\n",
      "Epoch: 36, Batch: 188, D Loss: 0.09494008124595688, G Loss: 24.67719841003418\n",
      "Epoch: 36, Batch: 189, D Loss: 0.09984145314682845, G Loss: 24.28041648864746\n",
      "Epoch: 36, Batch: 190, D Loss: 0.09545635433667983, G Loss: 23.988262176513672\n",
      "Epoch: 36, Batch: 191, D Loss: 0.09754139186792679, G Loss: 24.058406829833984\n",
      "Epoch: 36, Batch: 192, D Loss: 0.10180423410076954, G Loss: 24.611995697021484\n",
      "Epoch: 36, Batch: 193, D Loss: 0.10075699538721054, G Loss: 25.25536346435547\n",
      "Epoch: 36, Batch: 194, D Loss: 0.1040253043214923, G Loss: 25.809267044067383\n",
      "Epoch: 36, Batch: 195, D Loss: 0.10027030110660007, G Loss: 25.861114501953125\n",
      "Epoch: 36, Batch: 196, D Loss: 0.0972066000143513, G Loss: 25.293048858642578\n",
      "Epoch: 36, Batch: 197, D Loss: 0.10553073883664875, G Loss: 24.987768173217773\n",
      "Epoch: 36, Batch: 198, D Loss: 0.09303034842988399, G Loss: 24.366798400878906\n",
      "Epoch: 36, Batch: 199, D Loss: 0.0988646447807753, G Loss: 24.116601943969727\n",
      "Epoch: 36, Batch: 200, D Loss: 0.09296202661389948, G Loss: 24.00359535217285\n",
      "Epoch: 36, Batch: 201, D Loss: 0.099875926986227, G Loss: 24.459964752197266\n",
      "Epoch: 36, Batch: 202, D Loss: 0.09798277915394894, G Loss: 25.05487060546875\n",
      "Epoch: 36, Batch: 203, D Loss: 0.09556972981054508, G Loss: 25.375545501708984\n",
      "Epoch: 36, Batch: 204, D Loss: 0.10613740980993186, G Loss: 25.867931365966797\n",
      "Epoch: 36, Batch: 205, D Loss: 0.10374514013786028, G Loss: 26.10585594177246\n",
      "Epoch: 36, Batch: 206, D Loss: 0.09197100997299795, G Loss: 25.424837112426758\n",
      "Epoch: 36, Batch: 207, D Loss: 0.09655909240956081, G Loss: 24.570472717285156\n",
      "Epoch: 36, Batch: 208, D Loss: 0.10188813508822755, G Loss: 24.24561309814453\n",
      "Epoch: 36, Batch: 209, D Loss: 0.08976437153181678, G Loss: 23.92308235168457\n",
      "Epoch: 36, Batch: 210, D Loss: 0.10286811740781296, G Loss: 24.413097381591797\n",
      "Epoch: 36, Batch: 211, D Loss: 0.09866932035361971, G Loss: 25.09940528869629\n",
      "Epoch: 36, Batch: 212, D Loss: 0.10198634118277539, G Loss: 25.794870376586914\n",
      "Epoch: 36, Batch: 213, D Loss: 0.10178019851704691, G Loss: 26.161680221557617\n",
      "Epoch: 36, Batch: 214, D Loss: 0.09864767641075418, G Loss: 25.92346954345703\n",
      "Epoch: 36, Batch: 215, D Loss: 0.09755304456143812, G Loss: 25.280302047729492\n",
      "Epoch: 36, Batch: 216, D Loss: 0.09678926319652217, G Loss: 24.552040100097656\n",
      "Epoch: 36, Batch: 217, D Loss: 0.10045336933174887, G Loss: 24.315353393554688\n",
      "Epoch: 36, Batch: 218, D Loss: 0.1014717668412095, G Loss: 24.621896743774414\n",
      "Epoch: 36, Batch: 219, D Loss: 0.09826439619858386, G Loss: 25.084108352661133\n",
      "Epoch: 36, Batch: 220, D Loss: 0.10572356731130207, G Loss: 25.830968856811523\n",
      "Epoch: 36, Batch: 221, D Loss: 0.10180162638672899, G Loss: 26.21530532836914\n",
      "Epoch: 36, Batch: 222, D Loss: 0.0983245819830067, G Loss: 26.00435447692871\n",
      "Epoch: 36, Batch: 223, D Loss: 0.10486136377153968, G Loss: 25.71459197998047\n",
      "Epoch: 36, Batch: 224, D Loss: 0.10379932821184117, G Loss: 25.466751098632812\n",
      "Epoch: 36, Batch: 225, D Loss: 0.098693668847506, G Loss: 25.132648468017578\n",
      "Epoch: 36, Batch: 226, D Loss: 0.09844559431786408, G Loss: 24.836538314819336\n",
      "Epoch: 36, Batch: 227, D Loss: 0.099013224252372, G Loss: 24.818788528442383\n",
      "Epoch: 36, Batch: 228, D Loss: 0.09593465925091882, G Loss: 24.82685661315918\n",
      "Epoch: 36, Batch: 229, D Loss: 0.09386081994441263, G Loss: 24.746503829956055\n",
      "Epoch: 36, Batch: 230, D Loss: 0.10371983797071911, G Loss: 25.174423217773438\n",
      "Epoch: 36, Batch: 231, D Loss: 0.10318392515610765, G Loss: 25.760765075683594\n",
      "Epoch: 36, Batch: 232, D Loss: 0.10011077672523967, G Loss: 26.0351619720459\n",
      "Epoch: 36, Batch: 233, D Loss: 0.0981512740282121, G Loss: 25.813106536865234\n",
      "Epoch: 36, Batch: 234, D Loss: 0.09714043140818811, G Loss: 25.28054428100586\n",
      "Epoch: 36, Batch: 235, D Loss: 0.09996287525346802, G Loss: 24.882265090942383\n",
      "Epoch: 36, Batch: 236, D Loss: 0.10585887730822904, G Loss: 25.08694076538086\n",
      "Epoch: 36, Batch: 237, D Loss: 0.0946468859974164, G Loss: 25.100797653198242\n",
      "Epoch: 36, Batch: 238, D Loss: 0.09663758427539218, G Loss: 25.080692291259766\n",
      "Epoch: 36, Batch: 239, D Loss: 0.09686958045409859, G Loss: 25.07512664794922\n",
      "Epoch: 36, Batch: 240, D Loss: 0.09772837162657808, G Loss: 25.087482452392578\n",
      "Epoch: 36, Batch: 241, D Loss: 0.10357751697824573, G Loss: 25.460857391357422\n",
      "Epoch: 36, Batch: 242, D Loss: 0.08715809882224258, G Loss: 25.072967529296875\n",
      "Epoch: 36, Batch: 243, D Loss: 0.1012765318223124, G Loss: 24.97881317138672\n",
      "Epoch: 36, Batch: 244, D Loss: 0.09626378119715728, G Loss: 24.94019317626953\n",
      "Epoch: 36, Batch: 245, D Loss: 0.09839332849481665, G Loss: 25.054033279418945\n",
      "Epoch: 36, Batch: 246, D Loss: 0.09504595399536367, G Loss: 25.126008987426758\n",
      "Epoch: 36, Batch: 247, D Loss: 0.0987413153108232, G Loss: 25.29867935180664\n",
      "Epoch: 36, Batch: 248, D Loss: 0.10137674212894093, G Loss: 25.605236053466797\n",
      "Epoch: 36, Batch: 249, D Loss: 0.09770511091119419, G Loss: 25.682802200317383\n",
      "Epoch: 36, Batch: 250, D Loss: 0.09489668906137298, G Loss: 25.422529220581055\n",
      "Epoch: 36, Batch: 251, D Loss: 0.09943404049159191, G Loss: 25.329545974731445\n",
      "Epoch: 36, Batch: 252, D Loss: 0.09233107418412709, G Loss: 25.01006507873535\n",
      "Epoch: 36, Batch: 253, D Loss: 0.09794875980111688, G Loss: 25.008188247680664\n",
      "Epoch: 36, Batch: 254, D Loss: 0.09801767767081866, G Loss: 25.25078773498535\n",
      "Epoch: 36, Batch: 255, D Loss: 0.09529478848469053, G Loss: 25.442440032958984\n",
      "Epoch: 36, Batch: 256, D Loss: 0.09786932170801477, G Loss: 25.601152420043945\n",
      "Epoch: 36, Batch: 257, D Loss: 0.09854205698132233, G Loss: 25.721229553222656\n",
      "Epoch: 36, Batch: 258, D Loss: 0.10796436667696259, G Loss: 26.261735916137695\n",
      "Epoch: 36, Batch: 259, D Loss: 0.09560997784337337, G Loss: 26.233125686645508\n",
      "Epoch: 36, Batch: 260, D Loss: 0.10437785089224577, G Loss: 26.1750431060791\n",
      "Epoch: 36, Batch: 261, D Loss: 0.10057578981168316, G Loss: 25.916950225830078\n",
      "Epoch: 36, Batch: 262, D Loss: 0.0954909771718624, G Loss: 25.32991600036621\n",
      "Epoch: 36, Batch: 263, D Loss: 0.09648226202195126, G Loss: 24.79548454284668\n",
      "Epoch: 36, Batch: 264, D Loss: 0.10174186528578807, G Loss: 24.800552368164062\n",
      "Epoch: 36, Batch: 265, D Loss: 0.09885182977457874, G Loss: 25.070144653320312\n",
      "Epoch: 36, Batch: 266, D Loss: 0.1006865799479024, G Loss: 25.48641014099121\n",
      "Epoch: 36, Batch: 267, D Loss: 0.09499383718206444, G Loss: 25.46805763244629\n",
      "Epoch: 36, Batch: 268, D Loss: 0.10544635355877188, G Loss: 25.604978561401367\n",
      "Epoch: 36, Batch: 269, D Loss: 0.10317699611555962, G Loss: 25.656898498535156\n",
      "Epoch: 36, Batch: 270, D Loss: 0.093579374258627, G Loss: 25.079370498657227\n",
      "Epoch: 36, Batch: 271, D Loss: 0.10063390434590161, G Loss: 24.653593063354492\n",
      "Epoch: 36, Batch: 272, D Loss: 0.09589070082918433, G Loss: 24.260168075561523\n",
      "Epoch: 36, Batch: 273, D Loss: 0.10210034252574526, G Loss: 24.386899948120117\n",
      "Epoch: 36, Batch: 274, D Loss: 0.10043840111341756, G Loss: 24.78488540649414\n",
      "Epoch: 36, Batch: 275, D Loss: 0.09847690165767808, G Loss: 25.111772537231445\n",
      "Epoch: 36, Batch: 276, D Loss: 0.09588702023678261, G Loss: 25.02811622619629\n",
      "Epoch: 36, Batch: 277, D Loss: 0.09917141497872181, G Loss: 24.861526489257812\n",
      "Epoch: 36, Batch: 278, D Loss: 0.09568900615919834, G Loss: 24.54254150390625\n",
      "Epoch: 36, Batch: 279, D Loss: 0.10192726553571477, G Loss: 24.563905715942383\n",
      "Epoch: 36, Batch: 280, D Loss: 0.10096424818970208, G Loss: 24.83466148376465\n",
      "Epoch: 36, Batch: 281, D Loss: 0.096410110600572, G Loss: 24.945199966430664\n",
      "Epoch: 36, Batch: 282, D Loss: 0.10213851929215984, G Loss: 25.654447555541992\n",
      "Epoch: 36, Batch: 283, D Loss: 0.10291899740953181, G Loss: 26.297914505004883\n",
      "Epoch: 36, Batch: 284, D Loss: 0.09462347626867838, G Loss: 26.37864875793457\n",
      "Epoch: 36, Batch: 285, D Loss: 0.0997260808962057, G Loss: 26.39364242553711\n",
      "Epoch: 36, Batch: 286, D Loss: 0.09563349187558373, G Loss: 26.266250610351562\n",
      "Epoch: 36, Batch: 287, D Loss: 0.10325918346807837, G Loss: 26.597963333129883\n",
      "Epoch: 36, Batch: 288, D Loss: 0.10493002832031616, G Loss: 27.326072692871094\n",
      "Epoch: 36, Batch: 289, D Loss: 0.10372839868116254, G Loss: 28.0\n",
      "Epoch: 36, Batch: 290, D Loss: 0.10235370695620477, G Loss: 28.301149368286133\n",
      "Epoch: 36, Batch: 291, D Loss: 0.09792265296012907, G Loss: 27.963685989379883\n",
      "Epoch: 36, Batch: 292, D Loss: 0.09949505329173536, G Loss: 27.686738967895508\n",
      "Epoch: 36, Batch: 293, D Loss: 0.0972203910356351, G Loss: 27.381250381469727\n",
      "Epoch: 36, Batch: 294, D Loss: 0.09921529144089576, G Loss: 28.238296508789062\n",
      "Epoch: 36, Batch: 295, D Loss: 0.09382295608545825, G Loss: 28.3774356842041\n",
      "Epoch: 36, Batch: 296, D Loss: 0.1022424325347137, G Loss: 33.170501708984375\n",
      "Epoch: 36, Batch: 297, D Loss: 0.09781661629676852, G Loss: 36.54676818847656\n",
      "Epoch: 36, Batch: 298, D Loss: 0.10183000564575195, G Loss: 43.10780715942383\n",
      "Epoch: 36, Batch: 299, D Loss: 0.10263079404830933, G Loss: 54.05376434326172\n",
      "Epoch: 36, Batch: 300, D Loss: 0.15553712844848633, G Loss: 24.971153259277344\n",
      "Epoch: 36, Batch: 301, D Loss: 0.10396900206238513, G Loss: 7.567387580871582\n",
      "Epoch: 36, Batch: 302, D Loss: 0.19793733209371567, G Loss: 18.055727005004883\n",
      "Epoch: 36, Batch: 303, D Loss: 0.10350220650434494, G Loss: 62.57958984375\n",
      "Epoch: 36, Batch: 304, D Loss: 0.10164356231689453, G Loss: 102.4146728515625\n",
      "Epoch: 36, Batch: 305, D Loss: 0.11591391265392303, G Loss: 127.34949493408203\n",
      "Epoch: 36, Batch: 306, D Loss: 0.4592577815055847, G Loss: 94.638427734375\n",
      "Epoch: 36, Batch: 307, D Loss: 0.1038074940443039, G Loss: 70.93305206298828\n",
      "Epoch: 36, Batch: 308, D Loss: 0.08791515231132507, G Loss: 53.8757209777832\n",
      "Epoch: 36, Batch: 309, D Loss: 0.10672850906848907, G Loss: 41.5202522277832\n",
      "Epoch: 36, Batch: 310, D Loss: 0.10230563580989842, G Loss: 33.35687255859375\n",
      "Epoch: 36, Batch: 311, D Loss: 0.0979125797748876, G Loss: 28.157142639160156\n",
      "Epoch: 36, Batch: 312, D Loss: 0.09750583023027198, G Loss: 24.73040199279785\n",
      "Epoch: 36, Batch: 313, D Loss: 0.10526605698708605, G Loss: 22.295562744140625\n",
      "Epoch: 36, Batch: 314, D Loss: 0.10020436376968164, G Loss: 20.265853881835938\n",
      "Epoch: 36, Batch: 315, D Loss: 0.09959896847085448, G Loss: 18.57488441467285\n",
      "Epoch: 36, Batch: 316, D Loss: 0.09573391979138002, G Loss: 17.157493591308594\n",
      "Epoch: 36, Batch: 317, D Loss: 0.09909168751975628, G Loss: 16.0947208404541\n",
      "Epoch: 36, Batch: 318, D Loss: 0.1031889474663572, G Loss: 15.368742942810059\n",
      "Epoch: 36, Batch: 319, D Loss: 0.10010468123148542, G Loss: 14.826812744140625\n",
      "Epoch: 36, Batch: 320, D Loss: 0.1043858867800651, G Loss: 14.406657218933105\n",
      "Epoch: 36, Batch: 321, D Loss: 0.09862865154900646, G Loss: 14.029873847961426\n",
      "Epoch: 36, Batch: 322, D Loss: 0.09953138978630705, G Loss: 13.699834823608398\n",
      "Epoch: 36, Batch: 323, D Loss: 0.0982423595239652, G Loss: 13.371431350708008\n",
      "Epoch: 36, Batch: 324, D Loss: 0.09671319223758701, G Loss: 13.147575378417969\n",
      "Epoch: 36, Batch: 325, D Loss: 0.09639156003061089, G Loss: 13.066564559936523\n",
      "Epoch: 36, Batch: 326, D Loss: 0.10091267786015123, G Loss: 13.109341621398926\n",
      "Epoch: 36, Batch: 327, D Loss: 0.10789088879801056, G Loss: 13.245668411254883\n",
      "Epoch: 36, Batch: 328, D Loss: 0.10050858481451996, G Loss: 13.37879467010498\n",
      "Epoch: 36, Batch: 329, D Loss: 0.09755390650809659, G Loss: 13.477624893188477\n",
      "Epoch: 36, Batch: 330, D Loss: 0.1012136965906052, G Loss: 13.528504371643066\n",
      "Epoch: 36, Batch: 331, D Loss: 0.09572969637503093, G Loss: 13.441638946533203\n",
      "Epoch: 36, Batch: 332, D Loss: 0.10618444796614313, G Loss: 13.419113159179688\n",
      "Epoch: 36, Batch: 333, D Loss: 0.09790189754266976, G Loss: 13.42796802520752\n",
      "Epoch: 36, Batch: 334, D Loss: 0.09666564635449504, G Loss: 13.476021766662598\n",
      "Epoch: 36, Batch: 335, D Loss: 0.09978449486743557, G Loss: 13.599377632141113\n",
      "Epoch: 36, Batch: 336, D Loss: 0.09550988398677873, G Loss: 13.700399398803711\n",
      "Epoch: 36, Batch: 337, D Loss: 0.0956523153089961, G Loss: 13.843607902526855\n",
      "Epoch: 36, Batch: 338, D Loss: 0.08874358987583264, G Loss: 13.866303443908691\n",
      "Epoch: 36, Batch: 339, D Loss: 0.10130044149946116, G Loss: 13.963210105895996\n",
      "Epoch: 36, Batch: 340, D Loss: 0.09291999160583941, G Loss: 14.069416046142578\n",
      "Epoch: 36, Batch: 341, D Loss: 0.10512324193092581, G Loss: 14.249163627624512\n",
      "Epoch: 36, Batch: 342, D Loss: 0.0980698228819108, G Loss: 14.428980827331543\n",
      "Epoch: 36, Batch: 343, D Loss: 0.09215478702117252, G Loss: 14.558270454406738\n",
      "Epoch: 36, Batch: 344, D Loss: 0.10463772236580837, G Loss: 14.726829528808594\n",
      "Epoch: 36, Batch: 345, D Loss: 0.09508124855301503, G Loss: 14.723349571228027\n",
      "Epoch: 36, Batch: 346, D Loss: 0.0938295912921916, G Loss: 14.697687149047852\n",
      "Epoch: 36, Batch: 347, D Loss: 0.10450037886226937, G Loss: 14.730118751525879\n",
      "Epoch: 36, Batch: 348, D Loss: 0.09748950923682287, G Loss: 14.770661354064941\n",
      "Epoch: 36, Batch: 349, D Loss: 0.1062742217037993, G Loss: 14.871776580810547\n",
      "Epoch: 36, Batch: 350, D Loss: 0.09394596990304649, G Loss: 14.937003135681152\n",
      "Epoch: 36, Batch: 351, D Loss: 0.1026501502265944, G Loss: 15.025629043579102\n",
      "Epoch: 36, Batch: 352, D Loss: 0.09435508829908201, G Loss: 15.073552131652832\n",
      "Epoch: 36, Batch: 353, D Loss: 0.1062331960766727, G Loss: 15.167128562927246\n",
      "Epoch: 36, Batch: 354, D Loss: 0.09116987985885316, G Loss: 15.19856071472168\n",
      "Epoch: 36, Batch: 355, D Loss: 0.10346957550555658, G Loss: 15.260440826416016\n",
      "Epoch: 36, Batch: 356, D Loss: 0.10709787135856175, G Loss: 15.371336936950684\n",
      "Epoch: 36, Batch: 357, D Loss: 0.10721405734085465, G Loss: 15.511809349060059\n",
      "Epoch: 36, Batch: 358, D Loss: 0.0997535194736372, G Loss: 15.604573249816895\n",
      "Epoch: 36, Batch: 359, D Loss: 0.09834019085428736, G Loss: 15.647723197937012\n",
      "Epoch: 36, Batch: 360, D Loss: 0.10534700379962914, G Loss: 15.694622039794922\n",
      "Epoch: 36, Batch: 361, D Loss: 0.09503531716880786, G Loss: 15.67995834350586\n",
      "Epoch: 36, Batch: 362, D Loss: 0.09791358996986332, G Loss: 15.650416374206543\n",
      "Epoch: 36, Batch: 363, D Loss: 0.10336451737236274, G Loss: 15.660845756530762\n",
      "Epoch: 36, Batch: 364, D Loss: 0.10158223964094049, G Loss: 15.699667930603027\n",
      "Epoch: 36, Batch: 365, D Loss: 0.10312156993490618, G Loss: 15.774544715881348\n",
      "Epoch: 36, Batch: 366, D Loss: 0.09344009534378728, G Loss: 15.810951232910156\n",
      "Epoch: 36, Batch: 367, D Loss: 0.10167331151541248, G Loss: 15.86829948425293\n",
      "Epoch: 36, Batch: 368, D Loss: 0.09930340478878463, G Loss: 15.925971984863281\n",
      "Epoch: 36, Batch: 369, D Loss: 0.09712330220656185, G Loss: 15.97058391571045\n",
      "Epoch: 36, Batch: 370, D Loss: 0.0971147692332508, G Loss: 15.997467994689941\n",
      "Epoch: 36, Batch: 371, D Loss: 0.09491921643749635, G Loss: 16.0001220703125\n",
      "Epoch: 36, Batch: 372, D Loss: 0.09410282688451233, G Loss: 15.985499382019043\n",
      "Epoch: 36, Batch: 373, D Loss: 0.098539007378033, G Loss: 15.981709480285645\n",
      "Epoch: 36, Batch: 374, D Loss: 0.10097984643180524, G Loss: 16.019887924194336\n",
      "Epoch: 36, Batch: 375, D Loss: 0.09107069210606866, G Loss: 16.029521942138672\n",
      "Epoch: 36, Batch: 376, D Loss: 0.10262975202450164, G Loss: 16.083110809326172\n",
      "Epoch: 36, Batch: 377, D Loss: 0.10357507039899971, G Loss: 16.178346633911133\n",
      "Epoch: 36, Batch: 378, D Loss: 0.10406294430779539, G Loss: 16.296655654907227\n",
      "Epoch: 36, Batch: 379, D Loss: 0.09876794706873326, G Loss: 16.354286193847656\n",
      "Epoch: 36, Batch: 380, D Loss: 0.09635702779645072, G Loss: 16.340635299682617\n",
      "Epoch: 36, Batch: 381, D Loss: 0.09786209815914759, G Loss: 16.309389114379883\n",
      "Epoch: 36, Batch: 382, D Loss: 0.10264410465747531, G Loss: 16.320091247558594\n",
      "Epoch: 36, Batch: 383, D Loss: 0.10165462176686546, G Loss: 16.361051559448242\n",
      "Epoch: 36, Batch: 384, D Loss: 0.09953955656841273, G Loss: 16.412872314453125\n",
      "Epoch: 36, Batch: 385, D Loss: 0.10159776973080525, G Loss: 16.482818603515625\n",
      "Epoch: 36, Batch: 386, D Loss: 0.10071474682780135, G Loss: 16.553476333618164\n",
      "Epoch: 36, Batch: 387, D Loss: 0.0994651855919102, G Loss: 16.607473373413086\n",
      "Epoch: 36, Batch: 388, D Loss: 0.09586556320492079, G Loss: 16.622114181518555\n",
      "Epoch: 36, Batch: 389, D Loss: 0.0921722661343587, G Loss: 16.582033157348633\n",
      "Epoch: 36, Batch: 390, D Loss: 0.10610599950831912, G Loss: 16.6016788482666\n",
      "Epoch: 36, Batch: 391, D Loss: 0.10172229298270707, G Loss: 16.643999099731445\n",
      "Epoch: 36, Batch: 392, D Loss: 0.09569224663498943, G Loss: 16.66323471069336\n",
      "Epoch: 36, Batch: 393, D Loss: 0.10088848194716427, G Loss: 16.69597053527832\n",
      "Epoch: 36, Batch: 394, D Loss: 0.1004502601623738, G Loss: 16.733287811279297\n",
      "Epoch: 36, Batch: 395, D Loss: 0.1012071038790161, G Loss: 16.78151512145996\n",
      "Epoch: 36, Batch: 396, D Loss: 0.09614684758174441, G Loss: 16.794347763061523\n",
      "Epoch: 36, Batch: 397, D Loss: 0.09122944991769444, G Loss: 16.751054763793945\n",
      "Epoch: 36, Batch: 398, D Loss: 0.10241710074650001, G Loss: 16.749256134033203\n",
      "Epoch: 36, Batch: 399, D Loss: 0.09478547126434655, G Loss: 16.735027313232422\n",
      "Epoch: 36, Batch: 400, D Loss: 0.09946024119543218, G Loss: 16.748512268066406\n",
      "Epoch: 36, Batch: 401, D Loss: 0.10364937378797556, G Loss: 16.81221580505371\n",
      "Epoch: 36, Batch: 402, D Loss: 0.10048117654736899, G Loss: 16.88875389099121\n",
      "Epoch: 36, Batch: 403, D Loss: 0.09950289875189, G Loss: 16.95602035522461\n",
      "Epoch: 36, Batch: 404, D Loss: 0.10003232825579644, G Loss: 17.009496688842773\n",
      "Epoch: 36, Batch: 405, D Loss: 0.10810985139607432, G Loss: 17.098064422607422\n",
      "Epoch: 36, Batch: 406, D Loss: 0.1021789270551583, G Loss: 17.160781860351562\n",
      "Epoch: 36, Batch: 407, D Loss: 0.09815733404962401, G Loss: 17.164562225341797\n",
      "Epoch: 36, Batch: 408, D Loss: 0.1030657765815608, G Loss: 17.157337188720703\n",
      "Epoch: 36, Batch: 409, D Loss: 0.09754746735139719, G Loss: 17.10641098022461\n",
      "Epoch: 36, Batch: 410, D Loss: 0.09838708925664541, G Loss: 17.043014526367188\n",
      "Epoch: 36, Batch: 411, D Loss: 0.09802713056522983, G Loss: 16.984472274780273\n",
      "Epoch: 36, Batch: 412, D Loss: 0.09582178219483062, G Loss: 16.934755325317383\n",
      "Epoch: 36, Batch: 413, D Loss: 0.10000460577004411, G Loss: 16.929861068725586\n",
      "Epoch: 36, Batch: 414, D Loss: 0.09221354874698129, G Loss: 16.91672134399414\n",
      "Epoch: 36, Batch: 415, D Loss: 0.10298082927331542, G Loss: 16.973976135253906\n",
      "Epoch: 36, Batch: 416, D Loss: 0.09843422281494085, G Loss: 17.048873901367188\n",
      "Epoch: 36, Batch: 417, D Loss: 0.09591409981425159, G Loss: 17.112855911254883\n",
      "Epoch: 36, Batch: 418, D Loss: 0.09644660670429595, G Loss: 17.15818214416504\n",
      "Epoch: 36, Batch: 419, D Loss: 0.09995490548438113, G Loss: 17.204368591308594\n",
      "Epoch: 36, Batch: 420, D Loss: 0.10404852917225504, G Loss: 17.27187156677246\n",
      "Epoch: 36, Batch: 421, D Loss: 0.10516404384179623, G Loss: 17.351133346557617\n",
      "Epoch: 36, Batch: 422, D Loss: 0.10310897153726639, G Loss: 17.41097068786621\n",
      "Epoch: 36, Batch: 423, D Loss: 0.09677134339998972, G Loss: 17.407337188720703\n",
      "Epoch: 36, Batch: 424, D Loss: 0.09620640354998411, G Loss: 17.352962493896484\n",
      "Epoch: 36, Batch: 425, D Loss: 0.0975794645377448, G Loss: 17.279321670532227\n",
      "Epoch: 36, Batch: 426, D Loss: 0.09890058765449261, G Loss: 17.21690559387207\n",
      "Epoch: 36, Batch: 427, D Loss: 0.1072482408562987, G Loss: 17.232624053955078\n",
      "Epoch: 36, Batch: 428, D Loss: 0.10309074178596944, G Loss: 17.287622451782227\n",
      "Epoch: 36, Batch: 429, D Loss: 0.10052499188887865, G Loss: 17.348709106445312\n",
      "Epoch: 36, Batch: 430, D Loss: 0.09752391967158403, G Loss: 17.385665893554688\n",
      "Epoch: 36, Batch: 431, D Loss: 0.09487511138882887, G Loss: 17.381750106811523\n",
      "Epoch: 36, Batch: 432, D Loss: 0.09169064424495765, G Loss: 17.3309326171875\n",
      "Epoch: 36, Batch: 433, D Loss: 0.09261931533039913, G Loss: 17.26017951965332\n",
      "Epoch: 36, Batch: 434, D Loss: 0.09214890920239505, G Loss: 17.18344497680664\n",
      "Epoch: 36, Batch: 435, D Loss: 0.10029448069363589, G Loss: 17.17101287841797\n",
      "Epoch: 36, Batch: 436, D Loss: 0.09441862501246767, G Loss: 17.18181037902832\n",
      "Epoch: 36, Batch: 437, D Loss: 0.09988928022013077, G Loss: 17.24471664428711\n",
      "Epoch: 36, Batch: 438, D Loss: 0.0984177297409552, G Loss: 17.330669403076172\n",
      "Epoch: 36, Batch: 439, D Loss: 0.11013263340597046, G Loss: 17.49211883544922\n",
      "Epoch: 36, Batch: 440, D Loss: 0.10430959285969443, G Loss: 17.65180015563965\n",
      "Epoch: 36, Batch: 441, D Loss: 0.09909734416016835, G Loss: 17.73828887939453\n",
      "Epoch: 36, Batch: 442, D Loss: 0.09769693260563539, G Loss: 17.74051856994629\n",
      "Epoch: 36, Batch: 443, D Loss: 0.10127748066519526, G Loss: 17.702266693115234\n",
      "Epoch: 36, Batch: 444, D Loss: 0.10386211731240369, G Loss: 17.656278610229492\n",
      "Epoch: 36, Batch: 445, D Loss: 0.09436205413453358, G Loss: 17.562000274658203\n",
      "Epoch: 36, Batch: 446, D Loss: 0.09814794853252007, G Loss: 17.473840713500977\n",
      "Epoch: 36, Batch: 447, D Loss: 0.09702025202374553, G Loss: 17.402931213378906\n",
      "Epoch: 36, Batch: 448, D Loss: 0.09808938869230044, G Loss: 17.36944007873535\n",
      "Epoch: 36, Batch: 449, D Loss: 0.10049741643441568, G Loss: 17.387088775634766\n",
      "Epoch: 36, Batch: 450, D Loss: 0.09770527369044313, G Loss: 17.427217483520508\n",
      "Epoch: 36, Batch: 451, D Loss: 0.10063430477585378, G Loss: 17.49936866760254\n",
      "Epoch: 36, Batch: 452, D Loss: 0.1017270506140111, G Loss: 17.58879280090332\n",
      "Epoch: 36, Batch: 453, D Loss: 0.09633055698204185, G Loss: 17.648405075073242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 11:34:29.545445: W tensorflow/core/data/root_dataset.cc:286] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Batch: 454, D Loss: 0.10256415163776023, G Loss: 17.710012435913086\n",
      "Epoch: 36, Batch: 455, D Loss: 0.0965671118636875, G Loss: 17.727802276611328\n",
      "Epoch: 36, Batch: 456, D Loss: 0.09823917115159553, G Loss: 17.713592529296875\n",
      "Epoch: 36, Batch: 457, D Loss: 0.09799214739513484, G Loss: 17.681079864501953\n",
      "Epoch: 36, Batch: 458, D Loss: 0.10250323573403985, G Loss: 17.67283058166504\n",
      "Epoch: 36, Batch: 459, D Loss: 0.10737271152562133, G Loss: 17.711013793945312\n",
      "Epoch: 36, Batch: 460, D Loss: 0.09951091071675222, G Loss: 17.735698699951172\n",
      "Epoch: 36, Batch: 461, D Loss: 0.1027861707596065, G Loss: 17.76842498779297\n",
      "Epoch: 36, Batch: 462, D Loss: 0.09813004200275355, G Loss: 17.77267074584961\n",
      "Epoch: 36, Batch: 463, D Loss: 0.10090283515802767, G Loss: 17.77252197265625\n",
      "Epoch: 36, Batch: 464, D Loss: 0.09313994882149945, G Loss: 17.7241268157959\n",
      "Epoch: 36, Batch: 465, D Loss: 0.10028650886428903, G Loss: 17.694164276123047\n",
      "Epoch: 36, Batch: 466, D Loss: 0.09792230579902217, G Loss: 17.671817779541016\n",
      "Epoch: 36, Batch: 467, D Loss: 0.09924941080034877, G Loss: 17.66765022277832\n",
      "Epoch: 37, Batch: 0, D Loss: 0.09812051370581099, G Loss: 17.6756591796875\n",
      "Epoch: 37, Batch: 1, D Loss: 0.09824667424311961, G Loss: 17.694475173950195\n",
      "Epoch: 37, Batch: 2, D Loss: 0.09959946842357148, G Loss: 17.73068618774414\n",
      "Epoch: 37, Batch: 3, D Loss: 0.09387217707579687, G Loss: 17.743675231933594\n",
      "Epoch: 37, Batch: 4, D Loss: 0.0994410388449003, G Loss: 17.769201278686523\n",
      "Epoch: 37, Batch: 5, D Loss: 0.09888316146698806, G Loss: 17.796661376953125\n",
      "Epoch: 37, Batch: 6, D Loss: 0.09738332958770535, G Loss: 17.81310272216797\n",
      "Epoch: 37, Batch: 7, D Loss: 0.09582550998665695, G Loss: 17.809768676757812\n",
      "Epoch: 37, Batch: 8, D Loss: 0.10020443223227016, G Loss: 17.82065200805664\n",
      "Epoch: 37, Batch: 9, D Loss: 0.10353046804786725, G Loss: 17.857112884521484\n",
      "Epoch: 37, Batch: 10, D Loss: 0.09427555784519726, G Loss: 17.856609344482422\n",
      "Epoch: 37, Batch: 11, D Loss: 0.09605903318701259, G Loss: 17.843717575073242\n",
      "Epoch: 37, Batch: 12, D Loss: 0.09777538628436222, G Loss: 17.834383010864258\n",
      "Epoch: 37, Batch: 13, D Loss: 0.10271091901934959, G Loss: 17.85840606689453\n",
      "Epoch: 37, Batch: 14, D Loss: 0.09390563651393347, G Loss: 17.856430053710938\n",
      "Epoch: 37, Batch: 15, D Loss: 0.09796117380216529, G Loss: 17.857196807861328\n",
      "Epoch: 37, Batch: 16, D Loss: 0.09996706374209552, G Loss: 17.872100830078125\n",
      "Epoch: 37, Batch: 17, D Loss: 0.09888246766789877, G Loss: 17.89287757873535\n",
      "Epoch: 37, Batch: 18, D Loss: 0.09662585802916368, G Loss: 17.90529441833496\n",
      "Epoch: 37, Batch: 19, D Loss: 0.10059782198413725, G Loss: 17.931901931762695\n",
      "Epoch: 37, Batch: 20, D Loss: 0.1051109810242501, G Loss: 17.991180419921875\n",
      "Epoch: 37, Batch: 21, D Loss: 0.1029859110526572, G Loss: 18.054912567138672\n",
      "Epoch: 37, Batch: 22, D Loss: 0.104638389763128, G Loss: 18.11924171447754\n",
      "Epoch: 37, Batch: 23, D Loss: 0.09861456526146384, G Loss: 18.14116668701172\n",
      "Epoch: 37, Batch: 24, D Loss: 0.10320079984428876, G Loss: 18.15176773071289\n",
      "Epoch: 37, Batch: 25, D Loss: 0.09207794002670777, G Loss: 18.086145401000977\n",
      "Epoch: 37, Batch: 26, D Loss: 0.09313061827986191, G Loss: 17.97831153869629\n",
      "Epoch: 37, Batch: 27, D Loss: 0.093632877679652, G Loss: 17.866310119628906\n",
      "Epoch: 37, Batch: 28, D Loss: 0.10533074429505884, G Loss: 17.835634231567383\n",
      "Epoch: 37, Batch: 29, D Loss: 0.10209287099279596, G Loss: 17.86037826538086\n",
      "Epoch: 37, Batch: 30, D Loss: 0.10591498107894459, G Loss: 17.949922561645508\n",
      "Epoch: 37, Batch: 31, D Loss: 0.09349990693625365, G Loss: 17.866804122924805\n",
      "Epoch: 37, Batch: 32, D Loss: 0.10431393269954459, G Loss: 18.075340270996094\n",
      "Epoch: 37, Batch: 33, D Loss: 0.09971228173656455, G Loss: 18.154739379882812\n",
      "Epoch: 37, Batch: 34, D Loss: 0.09917244211894971, G Loss: 18.186315536499023\n",
      "Epoch: 37, Batch: 35, D Loss: 0.09906574254426248, G Loss: 18.086172103881836\n",
      "Epoch: 37, Batch: 36, D Loss: 0.09480253678375661, G Loss: 17.785913467407227\n",
      "Epoch: 37, Batch: 37, D Loss: 0.1062855221130885, G Loss: 17.741180419921875\n",
      "Epoch: 37, Batch: 38, D Loss: 0.10116037964561109, G Loss: 17.748619079589844\n",
      "Epoch: 37, Batch: 39, D Loss: 0.09837059178781438, G Loss: 17.72465705871582\n",
      "Epoch: 37, Batch: 40, D Loss: 0.09261764197836175, G Loss: 17.54495620727539\n",
      "Epoch: 37, Batch: 41, D Loss: 0.10009783262519889, G Loss: 17.475479125976562\n",
      "Epoch: 37, Batch: 42, D Loss: 0.1024758490273685, G Loss: 17.5843448638916\n",
      "Epoch: 37, Batch: 43, D Loss: 0.10082824092092135, G Loss: 17.755380630493164\n",
      "Epoch: 37, Batch: 44, D Loss: 0.10064398644284278, G Loss: 17.918495178222656\n",
      "Epoch: 37, Batch: 45, D Loss: 0.10158035928231168, G Loss: 18.0537166595459\n",
      "Epoch: 37, Batch: 46, D Loss: 0.10356424679831111, G Loss: 18.17745018005371\n",
      "Epoch: 37, Batch: 47, D Loss: 0.10247643906503257, G Loss: 18.247953414916992\n",
      "Epoch: 37, Batch: 48, D Loss: 0.09899659300196362, G Loss: 18.260793685913086\n",
      "Epoch: 37, Batch: 49, D Loss: 0.10249153367916719, G Loss: 18.25605583190918\n",
      "Epoch: 37, Batch: 50, D Loss: 0.10166329737066215, G Loss: 18.24968910217285\n",
      "Epoch: 37, Batch: 51, D Loss: 0.09683775015987406, G Loss: 18.215133666992188\n",
      "Epoch: 37, Batch: 52, D Loss: 0.1025129766573527, G Loss: 18.214340209960938\n",
      "Epoch: 37, Batch: 53, D Loss: 0.10322707012926369, G Loss: 18.224334716796875\n",
      "Epoch: 37, Batch: 54, D Loss: 0.10086276985810771, G Loss: 18.240266799926758\n",
      "Epoch: 37, Batch: 55, D Loss: 0.10835174306150508, G Loss: 18.301448822021484\n",
      "Epoch: 37, Batch: 56, D Loss: 0.09610407611797545, G Loss: 18.32221794128418\n",
      "Epoch: 37, Batch: 57, D Loss: 0.10278892317431021, G Loss: 18.344783782958984\n",
      "Epoch: 37, Batch: 58, D Loss: 0.09884954038506866, G Loss: 18.344532012939453\n",
      "Epoch: 37, Batch: 59, D Loss: 0.10068246519730017, G Loss: 18.334577560424805\n",
      "Epoch: 37, Batch: 60, D Loss: 0.09893387362527406, G Loss: 18.312480926513672\n",
      "Epoch: 37, Batch: 61, D Loss: 0.0985769611700884, G Loss: 18.278797149658203\n",
      "Epoch: 37, Batch: 62, D Loss: 0.10263002498706486, G Loss: 18.267290115356445\n",
      "Epoch: 37, Batch: 63, D Loss: 0.1006365700256362, G Loss: 18.267436981201172\n",
      "Epoch: 37, Batch: 64, D Loss: 0.09830565588666706, G Loss: 18.267040252685547\n",
      "Epoch: 37, Batch: 65, D Loss: 0.09999035879523932, G Loss: 18.275339126586914\n",
      "Epoch: 37, Batch: 66, D Loss: 0.10026418245891167, G Loss: 18.292356491088867\n",
      "Epoch: 37, Batch: 67, D Loss: 0.10113756919576034, G Loss: 18.318246841430664\n",
      "Epoch: 37, Batch: 68, D Loss: 0.09839912308474874, G Loss: 18.333887100219727\n",
      "Epoch: 37, Batch: 69, D Loss: 0.09479918134545162, G Loss: 18.32283592224121\n",
      "Epoch: 37, Batch: 70, D Loss: 0.09626459143735921, G Loss: 18.29920768737793\n",
      "Epoch: 37, Batch: 71, D Loss: 0.10142820892477689, G Loss: 18.301782608032227\n",
      "Epoch: 37, Batch: 72, D Loss: 0.09794688041979827, G Loss: 18.30541229248047\n",
      "Epoch: 37, Batch: 73, D Loss: 0.09564819005591829, G Loss: 18.297142028808594\n",
      "Epoch: 37, Batch: 74, D Loss: 0.10075418468120834, G Loss: 18.310157775878906\n",
      "Epoch: 37, Batch: 75, D Loss: 0.09942540333452943, G Loss: 18.3323917388916\n",
      "Epoch: 37, Batch: 76, D Loss: 0.09537371048137944, G Loss: 18.336362838745117\n",
      "Epoch: 37, Batch: 77, D Loss: 0.09570982108447845, G Loss: 18.328889846801758\n",
      "Epoch: 37, Batch: 78, D Loss: 0.09382217187633213, G Loss: 18.304706573486328\n",
      "Epoch: 37, Batch: 79, D Loss: 0.09909480626630396, G Loss: 18.305219650268555\n",
      "Epoch: 37, Batch: 80, D Loss: 0.1014566476767027, G Loss: 18.335222244262695\n",
      "Epoch: 37, Batch: 81, D Loss: 0.09283169902763122, G Loss: 18.338687896728516\n",
      "Epoch: 37, Batch: 82, D Loss: 0.10393935972809709, G Loss: 18.38134765625\n",
      "Epoch: 37, Batch: 83, D Loss: 0.09449793168972453, G Loss: 18.398128509521484\n",
      "Epoch: 37, Batch: 84, D Loss: 0.09457974649250156, G Loss: 18.391422271728516\n",
      "Epoch: 37, Batch: 85, D Loss: 0.09563878698445638, G Loss: 18.373640060424805\n",
      "Epoch: 37, Batch: 86, D Loss: 0.09595291846820908, G Loss: 18.351778030395508\n",
      "Epoch: 37, Batch: 87, D Loss: 0.09597752039148144, G Loss: 18.33380126953125\n",
      "Epoch: 37, Batch: 88, D Loss: 0.09904267437358394, G Loss: 18.341035842895508\n",
      "Epoch: 37, Batch: 89, D Loss: 0.10498566705381274, G Loss: 18.400562286376953\n",
      "Epoch: 37, Batch: 90, D Loss: 0.09939779835709528, G Loss: 18.460472106933594\n",
      "Epoch: 37, Batch: 91, D Loss: 0.10283524261856636, G Loss: 18.527910232543945\n",
      "Epoch: 37, Batch: 92, D Loss: 0.09483854172335748, G Loss: 18.547155380249023\n",
      "Epoch: 37, Batch: 93, D Loss: 0.09726745333264386, G Loss: 18.537137985229492\n",
      "Epoch: 37, Batch: 94, D Loss: 0.10225075184343435, G Loss: 18.533220291137695\n",
      "Epoch: 37, Batch: 95, D Loss: 0.10494628991458077, G Loss: 18.550615310668945\n",
      "Epoch: 37, Batch: 96, D Loss: 0.102407459793882, G Loss: 18.569076538085938\n",
      "Epoch: 37, Batch: 97, D Loss: 0.0963027520710944, G Loss: 18.554567337036133\n",
      "Epoch: 37, Batch: 98, D Loss: 0.09998025441832992, G Loss: 18.536115646362305\n",
      "Epoch: 37, Batch: 99, D Loss: 0.10394496169710177, G Loss: 18.54267692565918\n",
      "Epoch: 37, Batch: 100, D Loss: 0.09539170265622765, G Loss: 18.52237319946289\n",
      "Epoch: 37, Batch: 101, D Loss: 0.09991667875060806, G Loss: 18.507266998291016\n",
      "Epoch: 37, Batch: 102, D Loss: 0.10146880607884379, G Loss: 18.509836196899414\n",
      "Epoch: 37, Batch: 103, D Loss: 0.09662594361080057, G Loss: 18.499752044677734\n",
      "Epoch: 37, Batch: 104, D Loss: 0.09972706898685724, G Loss: 18.502025604248047\n",
      "Epoch: 37, Batch: 105, D Loss: 0.09431760478441342, G Loss: 18.484535217285156\n",
      "Epoch: 37, Batch: 106, D Loss: 0.09556405721220029, G Loss: 18.461368560791016\n",
      "Epoch: 37, Batch: 107, D Loss: 0.09663257486286492, G Loss: 18.448596954345703\n",
      "Epoch: 37, Batch: 108, D Loss: 0.09228436396398276, G Loss: 18.424436569213867\n",
      "Epoch: 37, Batch: 109, D Loss: 0.1058129269901471, G Loss: 18.467939376831055\n",
      "Epoch: 37, Batch: 110, D Loss: 0.09493859581712094, G Loss: 18.498510360717773\n",
      "Epoch: 37, Batch: 111, D Loss: 0.09837801463350226, G Loss: 18.53484535217285\n",
      "Epoch: 37, Batch: 112, D Loss: 0.09947923261982483, G Loss: 18.57794952392578\n",
      "Epoch: 37, Batch: 113, D Loss: 0.09495938993309494, G Loss: 18.592899322509766\n",
      "Epoch: 37, Batch: 114, D Loss: 0.10195273575062469, G Loss: 18.62421417236328\n",
      "Epoch: 37, Batch: 115, D Loss: 0.1064432004842839, G Loss: 18.686203002929688\n",
      "Epoch: 37, Batch: 116, D Loss: 0.10178240016285622, G Loss: 18.740381240844727\n",
      "Epoch: 37, Batch: 117, D Loss: 0.10157401471956273, G Loss: 18.772104263305664\n",
      "Epoch: 37, Batch: 118, D Loss: 0.10103337817808788, G Loss: 18.7766056060791\n",
      "Epoch: 37, Batch: 119, D Loss: 0.09890980628680524, G Loss: 18.75046730041504\n",
      "Epoch: 37, Batch: 120, D Loss: 0.09910430382062096, G Loss: 18.707059860229492\n",
      "Epoch: 37, Batch: 121, D Loss: 0.09087906427516179, G Loss: 18.612457275390625\n",
      "Epoch: 37, Batch: 122, D Loss: 0.09990684370224745, G Loss: 18.547550201416016\n",
      "Epoch: 37, Batch: 123, D Loss: 0.0970414027936064, G Loss: 18.50432586669922\n",
      "Epoch: 37, Batch: 124, D Loss: 0.09855027958672258, G Loss: 18.49675178527832\n",
      "Epoch: 37, Batch: 125, D Loss: 0.09717261506126329, G Loss: 18.511417388916016\n",
      "Epoch: 37, Batch: 126, D Loss: 0.0986024484082475, G Loss: 18.550430297851562\n",
      "Epoch: 37, Batch: 127, D Loss: 0.098794233598829, G Loss: 18.60420799255371\n",
      "Epoch: 37, Batch: 128, D Loss: 0.10292563986642378, G Loss: 18.68364906311035\n",
      "Epoch: 37, Batch: 129, D Loss: 0.10097113621429776, G Loss: 18.757831573486328\n",
      "Epoch: 37, Batch: 130, D Loss: 0.09217347560324596, G Loss: 18.76502227783203\n",
      "Epoch: 37, Batch: 131, D Loss: 0.0956458559810005, G Loss: 18.738508224487305\n",
      "Epoch: 37, Batch: 132, D Loss: 0.09522443638533185, G Loss: 18.687681198120117\n",
      "Epoch: 37, Batch: 133, D Loss: 0.10196674258294491, G Loss: 18.66168975830078\n",
      "Epoch: 37, Batch: 134, D Loss: 0.09956342377461747, G Loss: 18.649383544921875\n",
      "Epoch: 37, Batch: 135, D Loss: 0.09754878682159873, G Loss: 18.641157150268555\n",
      "Epoch: 37, Batch: 136, D Loss: 0.09639321670322731, G Loss: 18.63387107849121\n",
      "Epoch: 37, Batch: 137, D Loss: 0.09880369558660718, G Loss: 18.643535614013672\n",
      "Epoch: 37, Batch: 138, D Loss: 0.09822587319545173, G Loss: 18.665084838867188\n",
      "Epoch: 37, Batch: 139, D Loss: 0.10693641383241337, G Loss: 18.741168975830078\n",
      "Epoch: 37, Batch: 140, D Loss: 0.09744087214938135, G Loss: 18.792375564575195\n",
      "Epoch: 37, Batch: 141, D Loss: 0.10245216228656395, G Loss: 18.842554092407227\n",
      "Epoch: 37, Batch: 142, D Loss: 0.10142965936833304, G Loss: 18.877294540405273\n",
      "Epoch: 37, Batch: 143, D Loss: 0.10154758707925993, G Loss: 18.893068313598633\n",
      "Epoch: 37, Batch: 144, D Loss: 0.10183784677496743, G Loss: 18.892940521240234\n",
      "Epoch: 37, Batch: 145, D Loss: 0.10228526905282664, G Loss: 18.885868072509766\n",
      "Epoch: 37, Batch: 146, D Loss: 0.09564868683038785, G Loss: 18.836803436279297\n",
      "Epoch: 37, Batch: 147, D Loss: 0.09943564574710084, G Loss: 18.78746795654297\n",
      "Epoch: 37, Batch: 148, D Loss: 0.10218989454904293, G Loss: 18.763988494873047\n",
      "Epoch: 37, Batch: 149, D Loss: 0.09359664088678099, G Loss: 18.716447830200195\n",
      "Epoch: 37, Batch: 150, D Loss: 0.0998106860056267, G Loss: 18.692224502563477\n",
      "Epoch: 37, Batch: 151, D Loss: 0.09935318314762176, G Loss: 18.692232131958008\n",
      "Epoch: 37, Batch: 152, D Loss: 0.10167657213357906, G Loss: 18.726089477539062\n",
      "Epoch: 37, Batch: 153, D Loss: 0.10553630795572655, G Loss: 18.8015193939209\n",
      "Epoch: 37, Batch: 154, D Loss: 0.09891915652119931, G Loss: 18.863388061523438\n",
      "Epoch: 37, Batch: 155, D Loss: 0.10274363620888405, G Loss: 18.920225143432617\n",
      "Epoch: 37, Batch: 156, D Loss: 0.09405781632798349, G Loss: 18.91614532470703\n",
      "Epoch: 37, Batch: 157, D Loss: 0.1010856957120867, G Loss: 18.903156280517578\n",
      "Epoch: 37, Batch: 158, D Loss: 0.09482911546222628, G Loss: 18.85211753845215\n",
      "Epoch: 37, Batch: 159, D Loss: 0.09491955826153409, G Loss: 18.781003952026367\n",
      "Epoch: 37, Batch: 160, D Loss: 0.09611206863079369, G Loss: 18.71378517150879\n",
      "Epoch: 37, Batch: 161, D Loss: 0.10111312945303741, G Loss: 18.69327163696289\n",
      "Epoch: 37, Batch: 162, D Loss: 0.0952929594613714, G Loss: 18.685131072998047\n",
      "Epoch: 37, Batch: 163, D Loss: 0.1005952246981896, G Loss: 18.717254638671875\n",
      "Epoch: 37, Batch: 164, D Loss: 0.10391186534089014, G Loss: 18.79763412475586\n",
      "Epoch: 37, Batch: 165, D Loss: 0.09623940621423355, G Loss: 18.857534408569336\n",
      "Epoch: 37, Batch: 166, D Loss: 0.10181855722667699, G Loss: 18.921947479248047\n",
      "Epoch: 37, Batch: 167, D Loss: 0.09720630496772587, G Loss: 18.952856063842773\n",
      "Epoch: 37, Batch: 168, D Loss: 0.10406029512468873, G Loss: 18.989723205566406\n",
      "Epoch: 37, Batch: 169, D Loss: 0.09590067253514922, G Loss: 18.98281478881836\n",
      "Epoch: 37, Batch: 170, D Loss: 0.10068574835284716, G Loss: 18.966447830200195\n",
      "Epoch: 37, Batch: 171, D Loss: 0.1005628287277367, G Loss: 18.946107864379883\n",
      "Epoch: 37, Batch: 172, D Loss: 0.10122740567350585, G Loss: 18.927366256713867\n",
      "Epoch: 37, Batch: 173, D Loss: 0.09683689781892535, G Loss: 18.892837524414062\n",
      "Epoch: 37, Batch: 174, D Loss: 0.10111312882596768, G Loss: 18.877580642700195\n",
      "Epoch: 37, Batch: 175, D Loss: 0.10059915803275632, G Loss: 18.846054077148438\n",
      "Epoch: 37, Batch: 176, D Loss: 0.09373109383436651, G Loss: 18.76590347290039\n",
      "Epoch: 37, Batch: 177, D Loss: 0.09311887253126372, G Loss: 18.649402618408203\n",
      "Epoch: 37, Batch: 178, D Loss: 0.09920000688241526, G Loss: 18.623502731323242\n",
      "Epoch: 37, Batch: 179, D Loss: 0.10264267415807371, G Loss: 18.718109130859375\n",
      "Epoch: 37, Batch: 180, D Loss: 0.10221413118712341, G Loss: 18.880510330200195\n",
      "Epoch: 37, Batch: 181, D Loss: 0.09578989747439404, G Loss: 18.963470458984375\n",
      "Epoch: 37, Batch: 182, D Loss: 0.10367165042990578, G Loss: 19.019559860229492\n",
      "Epoch: 37, Batch: 183, D Loss: 0.10636690523593884, G Loss: 19.09100341796875\n",
      "Epoch: 37, Batch: 184, D Loss: 0.09214528906481001, G Loss: 19.086437225341797\n",
      "Epoch: 37, Batch: 185, D Loss: 0.10246122141951086, G Loss: 19.074872970581055\n",
      "Epoch: 37, Batch: 186, D Loss: 0.09465082257754398, G Loss: 19.017122268676758\n",
      "Epoch: 37, Batch: 187, D Loss: 0.1025432152821526, G Loss: 18.979951858520508\n",
      "Epoch: 37, Batch: 188, D Loss: 0.10243826647128951, G Loss: 18.968374252319336\n",
      "Epoch: 37, Batch: 189, D Loss: 0.09945822800276627, G Loss: 18.93975067138672\n",
      "Epoch: 37, Batch: 190, D Loss: 0.10200801786595814, G Loss: 18.957338333129883\n",
      "Epoch: 37, Batch: 191, D Loss: 0.0933351844786916, G Loss: 18.906042098999023\n",
      "Epoch: 37, Batch: 192, D Loss: 0.09447834214224726, G Loss: 18.84075355529785\n",
      "Epoch: 37, Batch: 193, D Loss: 0.09725639559936927, G Loss: 18.798965454101562\n",
      "Epoch: 37, Batch: 194, D Loss: 0.09496938790191445, G Loss: 18.742237091064453\n",
      "Epoch: 37, Batch: 195, D Loss: 0.09515981745830171, G Loss: 18.705595016479492\n",
      "Epoch: 37, Batch: 196, D Loss: 0.09787604585293685, G Loss: 18.723934173583984\n",
      "Epoch: 37, Batch: 197, D Loss: 0.10084921471855224, G Loss: 18.82418441772461\n",
      "Epoch: 37, Batch: 198, D Loss: 0.10152286601927218, G Loss: 18.960535049438477\n",
      "Epoch: 37, Batch: 199, D Loss: 0.09482758028477156, G Loss: 19.027877807617188\n",
      "Epoch: 37, Batch: 200, D Loss: 0.09873187806861572, G Loss: 19.081613540649414\n",
      "Epoch: 37, Batch: 201, D Loss: 0.09713064391706072, G Loss: 19.08436393737793\n",
      "Epoch: 37, Batch: 202, D Loss: 0.09000152619407098, G Loss: 18.991857528686523\n",
      "Epoch: 37, Batch: 203, D Loss: 0.10443072306799617, G Loss: 18.969703674316406\n",
      "Epoch: 37, Batch: 204, D Loss: 0.09733312122894544, G Loss: 18.955745697021484\n",
      "Epoch: 37, Batch: 205, D Loss: 0.09765681917288482, G Loss: 18.955793380737305\n",
      "Epoch: 37, Batch: 206, D Loss: 0.09781943554466377, G Loss: 18.95594596862793\n",
      "Epoch: 37, Batch: 207, D Loss: 0.09764939092228575, G Loss: 18.96977996826172\n",
      "Epoch: 37, Batch: 208, D Loss: 0.10069664101925935, G Loss: 19.03346061706543\n",
      "Epoch: 37, Batch: 209, D Loss: 0.10141355061049917, G Loss: 19.08948516845703\n",
      "Epoch: 37, Batch: 210, D Loss: 0.09953325493013732, G Loss: 19.12690544128418\n",
      "Epoch: 37, Batch: 211, D Loss: 0.10254628452996939, G Loss: 19.166242599487305\n",
      "Epoch: 37, Batch: 212, D Loss: 0.09960898992149558, G Loss: 19.18320083618164\n",
      "Epoch: 37, Batch: 213, D Loss: 0.10050793970038141, G Loss: 19.186634063720703\n",
      "Epoch: 37, Batch: 214, D Loss: 0.09726220604798486, G Loss: 19.1624698638916\n",
      "Epoch: 37, Batch: 215, D Loss: 0.0960080275549764, G Loss: 19.112443923950195\n",
      "Epoch: 37, Batch: 216, D Loss: 0.09460243097130272, G Loss: 19.044750213623047\n",
      "Epoch: 37, Batch: 217, D Loss: 0.09659248121780872, G Loss: 18.98575210571289\n",
      "Epoch: 37, Batch: 218, D Loss: 0.0934259622723479, G Loss: 18.932016372680664\n",
      "Epoch: 37, Batch: 219, D Loss: 0.09357606180385747, G Loss: 18.894790649414062\n",
      "Epoch: 37, Batch: 220, D Loss: 0.09892581712562842, G Loss: 18.90694808959961\n",
      "Epoch: 37, Batch: 221, D Loss: 0.0983013242712627, G Loss: 18.951993942260742\n",
      "Epoch: 37, Batch: 222, D Loss: 0.10784663536508199, G Loss: 19.067977905273438\n",
      "Epoch: 37, Batch: 223, D Loss: 0.10060453662008917, G Loss: 19.177474975585938\n",
      "Epoch: 37, Batch: 224, D Loss: 0.09654040861671143, G Loss: 19.239837646484375\n",
      "Epoch: 37, Batch: 225, D Loss: 0.10084293254202992, G Loss: 19.273645401000977\n",
      "Epoch: 37, Batch: 226, D Loss: 0.09723763382397377, G Loss: 19.260921478271484\n",
      "Epoch: 37, Batch: 227, D Loss: 0.1008279419963174, G Loss: 19.235055923461914\n",
      "Epoch: 37, Batch: 228, D Loss: 0.0963548742684035, G Loss: 19.179906845092773\n",
      "Epoch: 37, Batch: 229, D Loss: 0.09925059470017472, G Loss: 19.125232696533203\n",
      "Epoch: 37, Batch: 230, D Loss: 0.09575264410906215, G Loss: 19.06591796875\n",
      "Epoch: 37, Batch: 231, D Loss: 0.10169214275311433, G Loss: 19.04607582092285\n",
      "Epoch: 37, Batch: 232, D Loss: 0.09830970584451904, G Loss: 19.047876358032227\n",
      "Epoch: 37, Batch: 233, D Loss: 0.09696927932013089, G Loss: 19.06035041809082\n",
      "Epoch: 37, Batch: 234, D Loss: 0.10181306560477221, G Loss: 19.10297966003418\n",
      "Epoch: 37, Batch: 235, D Loss: 0.09948869295798879, G Loss: 19.152631759643555\n",
      "Epoch: 37, Batch: 236, D Loss: 0.10254598641947799, G Loss: 19.212909698486328\n",
      "Epoch: 37, Batch: 237, D Loss: 0.10032393259414296, G Loss: 19.258018493652344\n",
      "Epoch: 37, Batch: 238, D Loss: 0.09800277120471446, G Loss: 19.2694091796875\n",
      "Epoch: 37, Batch: 239, D Loss: 0.10508574011618288, G Loss: 19.29371452331543\n",
      "Epoch: 37, Batch: 240, D Loss: 0.09318963650802603, G Loss: 19.26072120666504\n",
      "Epoch: 37, Batch: 241, D Loss: 0.10211064885544574, G Loss: 19.233169555664062\n",
      "Epoch: 37, Batch: 242, D Loss: 0.09494143207605177, G Loss: 19.179853439331055\n",
      "Epoch: 37, Batch: 243, D Loss: 0.09789201857164054, G Loss: 19.13288116455078\n",
      "Epoch: 37, Batch: 244, D Loss: 0.10088353106557002, G Loss: 19.115856170654297\n",
      "Epoch: 37, Batch: 245, D Loss: 0.1013383070566567, G Loss: 19.12961769104004\n",
      "Epoch: 37, Batch: 246, D Loss: 0.10181658210649425, G Loss: 19.17201042175293\n",
      "Epoch: 37, Batch: 247, D Loss: 0.10239905347955824, G Loss: 19.228355407714844\n",
      "Epoch: 37, Batch: 248, D Loss: 0.1026251859207794, G Loss: 19.2890567779541\n",
      "Epoch: 37, Batch: 249, D Loss: 0.09775921164177626, G Loss: 19.31640625\n",
      "Epoch: 37, Batch: 250, D Loss: 0.10138961130551127, G Loss: 19.329124450683594\n",
      "Epoch: 37, Batch: 251, D Loss: 0.1082047765373979, G Loss: 19.364490509033203\n",
      "Epoch: 37, Batch: 252, D Loss: 0.09762086169663631, G Loss: 19.35625648498535\n",
      "Epoch: 37, Batch: 253, D Loss: 0.10380605805512921, G Loss: 19.345848083496094\n",
      "Epoch: 37, Batch: 254, D Loss: 0.09616099501284792, G Loss: 19.29829216003418\n",
      "Epoch: 37, Batch: 255, D Loss: 0.09593720949481943, G Loss: 19.231386184692383\n",
      "Epoch: 37, Batch: 256, D Loss: 0.10327051806150567, G Loss: 19.198436737060547\n",
      "Epoch: 37, Batch: 257, D Loss: 0.09951182686773685, G Loss: 19.180400848388672\n",
      "Epoch: 37, Batch: 258, D Loss: 0.09732312199320803, G Loss: 19.169506072998047\n",
      "Epoch: 37, Batch: 259, D Loss: 0.09837045011748069, G Loss: 19.17145538330078\n",
      "Epoch: 37, Batch: 260, D Loss: 0.10305298351306558, G Loss: 19.20820426940918\n",
      "Epoch: 37, Batch: 261, D Loss: 0.10173357499428093, G Loss: 19.260700225830078\n",
      "Epoch: 37, Batch: 262, D Loss: 0.09754670623193284, G Loss: 19.296607971191406\n",
      "Epoch: 37, Batch: 263, D Loss: 0.090939017252611, G Loss: 19.278594970703125\n",
      "Epoch: 37, Batch: 264, D Loss: 0.10240844104313274, G Loss: 19.27719497680664\n",
      "Epoch: 37, Batch: 265, D Loss: 0.10170591088579362, G Loss: 19.288959503173828\n",
      "Epoch: 37, Batch: 266, D Loss: 0.10066011756442239, G Loss: 19.30232810974121\n",
      "Epoch: 37, Batch: 267, D Loss: 0.09569607138076242, G Loss: 19.293415069580078\n",
      "Epoch: 37, Batch: 268, D Loss: 0.10070000052752759, G Loss: 19.293621063232422\n",
      "Epoch: 37, Batch: 269, D Loss: 0.0975983163866887, G Loss: 19.282320022583008\n",
      "Epoch: 37, Batch: 270, D Loss: 0.09674298976844753, G Loss: 19.261747360229492\n",
      "Epoch: 37, Batch: 271, D Loss: 0.09699420849166551, G Loss: 19.239213943481445\n",
      "Epoch: 37, Batch: 272, D Loss: 0.0960280619561884, G Loss: 19.214025497436523\n",
      "Epoch: 37, Batch: 273, D Loss: 0.10344455615238357, G Loss: 19.23204803466797\n",
      "Epoch: 37, Batch: 274, D Loss: 0.09908898393460785, G Loss: 19.261917114257812\n",
      "Epoch: 37, Batch: 275, D Loss: 0.09941366526356288, G Loss: 19.298891067504883\n",
      "Epoch: 37, Batch: 276, D Loss: 0.09913809801936968, G Loss: 19.329776763916016\n",
      "Epoch: 37, Batch: 277, D Loss: 0.10043150385026611, G Loss: 19.358154296875\n",
      "Epoch: 37, Batch: 278, D Loss: 0.10163191898687951, G Loss: 19.38839340209961\n",
      "Epoch: 37, Batch: 279, D Loss: 0.09437160385082821, G Loss: 19.3768367767334\n",
      "Epoch: 37, Batch: 280, D Loss: 0.10019177391975176, G Loss: 19.363513946533203\n",
      "Epoch: 37, Batch: 281, D Loss: 0.11059346240469425, G Loss: 19.40635108947754\n",
      "Epoch: 37, Batch: 282, D Loss: 0.09735357947010237, G Loss: 19.416521072387695\n",
      "Epoch: 37, Batch: 283, D Loss: 0.09820483810865999, G Loss: 19.404245376586914\n",
      "Epoch: 37, Batch: 284, D Loss: 0.10036781618990198, G Loss: 19.38674545288086\n",
      "Epoch: 37, Batch: 285, D Loss: 0.09352004723400387, G Loss: 19.33705711364746\n",
      "Epoch: 37, Batch: 286, D Loss: 0.10186924243003448, G Loss: 19.31184959411621\n",
      "Epoch: 37, Batch: 287, D Loss: 0.09938127008908149, G Loss: 19.299468994140625\n",
      "Epoch: 37, Batch: 288, D Loss: 0.09948387949321003, G Loss: 19.303117752075195\n",
      "Epoch: 37, Batch: 289, D Loss: 0.09912301805362977, G Loss: 19.317302703857422\n",
      "Epoch: 37, Batch: 290, D Loss: 0.09568962658783708, G Loss: 19.31747817993164\n",
      "Epoch: 37, Batch: 291, D Loss: 0.10444112322182164, G Loss: 19.353656768798828\n",
      "Epoch: 37, Batch: 292, D Loss: 0.10245844913553159, G Loss: 19.40216636657715\n",
      "Epoch: 37, Batch: 293, D Loss: 0.10108959858022815, G Loss: 19.445396423339844\n",
      "Epoch: 37, Batch: 294, D Loss: 0.10119952437863178, G Loss: 19.478057861328125\n",
      "Epoch: 37, Batch: 295, D Loss: 0.1006621661150604, G Loss: 19.491348266601562\n",
      "Epoch: 37, Batch: 296, D Loss: 0.0990375223135267, G Loss: 19.478139877319336\n",
      "Epoch: 37, Batch: 297, D Loss: 0.10268436547044302, G Loss: 19.46645164489746\n",
      "Epoch: 37, Batch: 298, D Loss: 0.09568759233611579, G Loss: 19.42437744140625\n",
      "Epoch: 37, Batch: 299, D Loss: 0.089720981252289, G Loss: 19.33661460876465\n",
      "Epoch: 37, Batch: 300, D Loss: 0.10116361286879183, G Loss: 19.28801918029785\n",
      "Epoch: 37, Batch: 301, D Loss: 0.10165316822325376, G Loss: 19.281465530395508\n",
      "Epoch: 37, Batch: 302, D Loss: 0.10375161675880795, G Loss: 19.322782516479492\n",
      "Epoch: 37, Batch: 303, D Loss: 0.10161954361030268, G Loss: 19.383285522460938\n",
      "Epoch: 37, Batch: 304, D Loss: 0.09466199764755645, G Loss: 19.41415786743164\n",
      "Epoch: 37, Batch: 305, D Loss: 0.0945810321606807, G Loss: 19.414398193359375\n",
      "Epoch: 37, Batch: 306, D Loss: 0.10158224587799958, G Loss: 19.426624298095703\n",
      "Epoch: 37, Batch: 307, D Loss: 0.10280921490667472, G Loss: 19.451684951782227\n",
      "Epoch: 37, Batch: 308, D Loss: 0.10261552211344116, G Loss: 19.481903076171875\n",
      "Epoch: 37, Batch: 309, D Loss: 0.10462271591847383, G Loss: 19.518930435180664\n",
      "Epoch: 37, Batch: 310, D Loss: 0.10043486372906063, G Loss: 19.53687858581543\n",
      "Epoch: 37, Batch: 311, D Loss: 0.10293729021059805, G Loss: 19.548006057739258\n",
      "Epoch: 37, Batch: 312, D Loss: 0.09712679848400219, G Loss: 19.521574020385742\n",
      "Epoch: 37, Batch: 313, D Loss: 0.10609346795011942, G Loss: 19.51572608947754\n",
      "Epoch: 37, Batch: 314, D Loss: 0.09587359598792322, G Loss: 19.480791091918945\n",
      "Epoch: 37, Batch: 315, D Loss: 0.0982805880733244, G Loss: 19.43874740600586\n",
      "Epoch: 37, Batch: 316, D Loss: 0.10209807191137776, G Loss: 19.41823959350586\n",
      "Epoch: 37, Batch: 317, D Loss: 0.09566894360995182, G Loss: 19.38802146911621\n",
      "Epoch: 37, Batch: 318, D Loss: 0.09653009666949774, G Loss: 19.362241744995117\n",
      "Epoch: 37, Batch: 319, D Loss: 0.0939201657901414, G Loss: 19.333721160888672\n",
      "Epoch: 37, Batch: 320, D Loss: 0.10820890413444673, G Loss: 19.384103775024414\n",
      "Epoch: 37, Batch: 321, D Loss: 0.10104784553682578, G Loss: 19.45098876953125\n",
      "Epoch: 37, Batch: 322, D Loss: 0.0988415347996644, G Loss: 19.504846572875977\n",
      "Epoch: 37, Batch: 323, D Loss: 0.10311126128260584, G Loss: 19.559280395507812\n",
      "Epoch: 37, Batch: 324, D Loss: 0.10021831252710633, G Loss: 19.591110229492188\n",
      "Epoch: 37, Batch: 325, D Loss: 0.09927514350390776, G Loss: 19.593420028686523\n",
      "Epoch: 37, Batch: 326, D Loss: 0.09283387075023997, G Loss: 19.541004180908203\n",
      "Epoch: 37, Batch: 327, D Loss: 0.10530445144912182, G Loss: 19.516279220581055\n",
      "Epoch: 37, Batch: 328, D Loss: 0.0969482006826421, G Loss: 19.475114822387695\n",
      "Epoch: 37, Batch: 329, D Loss: 0.1038633676979499, G Loss: 19.46689796447754\n",
      "Epoch: 37, Batch: 330, D Loss: 0.09750506458775476, G Loss: 19.453262329101562\n",
      "Epoch: 37, Batch: 331, D Loss: 0.09969593762797557, G Loss: 19.451242446899414\n",
      "Epoch: 37, Batch: 332, D Loss: 0.09636634767499597, G Loss: 19.44244384765625\n",
      "Epoch: 37, Batch: 333, D Loss: 0.09657209547529155, G Loss: 19.43233299255371\n",
      "Epoch: 37, Batch: 334, D Loss: 0.09703137908136805, G Loss: 19.424951553344727\n",
      "Epoch: 37, Batch: 335, D Loss: 0.0976991373715258, G Loss: 19.42727279663086\n",
      "Epoch: 37, Batch: 336, D Loss: 0.10152992785886639, G Loss: 19.45908546447754\n",
      "Epoch: 37, Batch: 337, D Loss: 0.1026054041911636, G Loss: 19.512176513671875\n",
      "Epoch: 37, Batch: 338, D Loss: 0.09658813641791886, G Loss: 19.54241180419922\n",
      "Epoch: 37, Batch: 339, D Loss: 0.10226817589060089, G Loss: 19.57637596130371\n",
      "Epoch: 37, Batch: 340, D Loss: 0.0972671897022086, G Loss: 19.581214904785156\n",
      "Epoch: 37, Batch: 341, D Loss: 0.09774723806887753, G Loss: 19.566936492919922\n",
      "Epoch: 37, Batch: 342, D Loss: 0.10203796784644492, G Loss: 19.56011390686035\n",
      "Epoch: 37, Batch: 343, D Loss: 0.1033516095086291, G Loss: 19.57242774963379\n",
      "Epoch: 37, Batch: 344, D Loss: 0.09964448371274548, G Loss: 19.576833724975586\n",
      "Epoch: 37, Batch: 345, D Loss: 0.09614852229840454, G Loss: 19.55684471130371\n",
      "Epoch: 37, Batch: 346, D Loss: 0.1000147776093605, G Loss: 19.542152404785156\n",
      "Epoch: 37, Batch: 347, D Loss: 0.10621553820262919, G Loss: 19.566774368286133\n",
      "Epoch: 37, Batch: 348, D Loss: 0.10492453134226853, G Loss: 19.61298179626465\n",
      "Epoch: 37, Batch: 349, D Loss: 0.09846985490236715, G Loss: 19.6339111328125\n",
      "Epoch: 37, Batch: 350, D Loss: 0.10210397986945285, G Loss: 19.649795532226562\n",
      "Epoch: 37, Batch: 351, D Loss: 0.1046098485141217, G Loss: 19.67279815673828\n",
      "Epoch: 37, Batch: 352, D Loss: 0.10482313625078288, G Loss: 19.697412490844727\n",
      "Epoch: 37, Batch: 353, D Loss: 0.09402646266303549, G Loss: 19.664180755615234\n",
      "Epoch: 37, Batch: 354, D Loss: 0.09896109401005004, G Loss: 19.61684799194336\n",
      "Epoch: 37, Batch: 355, D Loss: 0.10206686114273877, G Loss: 19.582111358642578\n",
      "Epoch: 37, Batch: 356, D Loss: 0.10633061982051983, G Loss: 19.590862274169922\n",
      "Epoch: 37, Batch: 357, D Loss: 0.0965273544870946, G Loss: 19.58326530456543\n",
      "Epoch: 37, Batch: 358, D Loss: 0.10652707670768768, G Loss: 19.616804122924805\n",
      "Epoch: 37, Batch: 359, D Loss: 0.09610204549509616, G Loss: 19.62089729309082\n",
      "Epoch: 37, Batch: 360, D Loss: 0.09913443179728743, G Loss: 19.618173599243164\n",
      "Epoch: 37, Batch: 361, D Loss: 0.09635390493979012, G Loss: 19.59686279296875\n",
      "Epoch: 37, Batch: 362, D Loss: 0.10057132846097072, G Loss: 19.588214874267578\n",
      "Epoch: 37, Batch: 363, D Loss: 0.10106885588374526, G Loss: 19.59323501586914\n",
      "Epoch: 37, Batch: 364, D Loss: 0.10084128533507664, G Loss: 19.607059478759766\n",
      "Epoch: 37, Batch: 365, D Loss: 0.09379993533259612, G Loss: 19.588943481445312\n",
      "Epoch: 37, Batch: 366, D Loss: 0.1024963498692163, G Loss: 19.59747886657715\n",
      "Epoch: 37, Batch: 367, D Loss: 0.09167023904768601, G Loss: 19.567413330078125\n",
      "Epoch: 37, Batch: 368, D Loss: 0.09208180918641684, G Loss: 19.51531410217285\n",
      "Epoch: 37, Batch: 369, D Loss: 0.09305063807134717, G Loss: 19.462980270385742\n",
      "Epoch: 37, Batch: 370, D Loss: 0.09351992042225699, G Loss: 19.4222412109375\n",
      "Epoch: 37, Batch: 371, D Loss: 0.09672069733731925, G Loss: 19.417194366455078\n",
      "Epoch: 37, Batch: 372, D Loss: 0.09745162907298388, G Loss: 19.445833206176758\n",
      "Epoch: 37, Batch: 373, D Loss: 0.09903799916133504, G Loss: 19.507394790649414\n",
      "Epoch: 37, Batch: 374, D Loss: 0.10453175168078788, G Loss: 19.610177993774414\n",
      "Epoch: 37, Batch: 375, D Loss: 0.09780614969069579, G Loss: 19.689605712890625\n",
      "Epoch: 37, Batch: 376, D Loss: 0.10159543292333706, G Loss: 19.756492614746094\n",
      "Epoch: 37, Batch: 377, D Loss: 0.10194645950419345, G Loss: 19.80204963684082\n",
      "Epoch: 37, Batch: 378, D Loss: 0.0968103048890786, G Loss: 19.795528411865234\n",
      "Epoch: 37, Batch: 379, D Loss: 0.10510996856082278, G Loss: 19.788145065307617\n",
      "Epoch: 37, Batch: 380, D Loss: 0.10244909802584468, G Loss: 19.769380569458008\n",
      "Epoch: 37, Batch: 381, D Loss: 0.10353139173708936, G Loss: 19.754037857055664\n",
      "Epoch: 37, Batch: 382, D Loss: 0.09976063802614887, G Loss: 19.724334716796875\n",
      "Epoch: 37, Batch: 383, D Loss: 0.10205866533880581, G Loss: 19.701107025146484\n",
      "Epoch: 37, Batch: 384, D Loss: 0.10270478716125253, G Loss: 19.691204071044922\n",
      "Epoch: 37, Batch: 385, D Loss: 0.09967490426863479, G Loss: 19.679481506347656\n",
      "Epoch: 37, Batch: 386, D Loss: 0.10494176438991787, G Loss: 19.698341369628906\n",
      "Epoch: 37, Batch: 387, D Loss: 0.10174633700285429, G Loss: 19.720844268798828\n",
      "Epoch: 37, Batch: 388, D Loss: 0.09619688379492486, G Loss: 19.713075637817383\n",
      "Epoch: 37, Batch: 389, D Loss: 0.0973782106247213, G Loss: 19.688032150268555\n",
      "Epoch: 37, Batch: 390, D Loss: 0.09946155690472314, G Loss: 19.66695213317871\n",
      "Epoch: 37, Batch: 391, D Loss: 0.09865841414636312, G Loss: 19.649356842041016\n",
      "Epoch: 37, Batch: 392, D Loss: 0.09912751761979732, G Loss: 19.64192771911621\n",
      "Epoch: 37, Batch: 393, D Loss: 0.09623268395170703, G Loss: 19.628204345703125\n",
      "Epoch: 37, Batch: 394, D Loss: 0.0963440179995777, G Loss: 19.61259651184082\n",
      "Epoch: 37, Batch: 395, D Loss: 0.09783400747155979, G Loss: 19.611000061035156\n",
      "Epoch: 37, Batch: 396, D Loss: 0.10025838913047769, G Loss: 19.63055419921875\n",
      "Epoch: 37, Batch: 397, D Loss: 0.1035599797573381, G Loss: 19.682579040527344\n",
      "Epoch: 37, Batch: 398, D Loss: 0.1069381399562247, G Loss: 19.7698974609375\n",
      "Epoch: 37, Batch: 399, D Loss: 0.10271611934661973, G Loss: 19.841264724731445\n",
      "Epoch: 37, Batch: 400, D Loss: 0.09567383051941558, G Loss: 19.8502254486084\n",
      "Epoch: 37, Batch: 401, D Loss: 0.1052293640382096, G Loss: 19.857263565063477\n",
      "Epoch: 37, Batch: 402, D Loss: 0.09300530824649222, G Loss: 19.795833587646484\n",
      "Epoch: 37, Batch: 403, D Loss: 0.10038164388685766, G Loss: 19.73264503479004\n",
      "Epoch: 37, Batch: 404, D Loss: 0.09608891746337678, G Loss: 19.658552169799805\n",
      "Epoch: 37, Batch: 405, D Loss: 0.10070436595951959, G Loss: 19.618669509887695\n",
      "Epoch: 37, Batch: 406, D Loss: 0.10699506252419011, G Loss: 19.650341033935547\n",
      "Epoch: 37, Batch: 407, D Loss: 0.10390917352891793, G Loss: 19.7176456451416\n",
      "Epoch: 37, Batch: 408, D Loss: 0.09936706854355415, G Loss: 19.775800704956055\n",
      "Epoch: 37, Batch: 409, D Loss: 0.09457063058036552, G Loss: 19.787694931030273\n",
      "Epoch: 37, Batch: 410, D Loss: 0.09993378945311615, G Loss: 19.79025650024414\n",
      "Epoch: 37, Batch: 411, D Loss: 0.1008306679934039, G Loss: 19.788299560546875\n",
      "Epoch: 37, Batch: 412, D Loss: 0.10287433989412764, G Loss: 19.797927856445312\n",
      "Epoch: 37, Batch: 413, D Loss: 0.09148122499543099, G Loss: 19.751020431518555\n",
      "Epoch: 37, Batch: 414, D Loss: 0.1085630668431038, G Loss: 19.76237678527832\n",
      "Epoch: 37, Batch: 415, D Loss: 0.10938993222714011, G Loss: 19.82668113708496\n",
      "Epoch: 37, Batch: 416, D Loss: 0.09707753481250647, G Loss: 19.851530075073242\n",
      "Epoch: 37, Batch: 417, D Loss: 0.10040998577912075, G Loss: 19.8597412109375\n",
      "Epoch: 37, Batch: 418, D Loss: 0.09511685492286781, G Loss: 19.823097229003906\n",
      "Epoch: 37, Batch: 419, D Loss: 0.09966662651808988, G Loss: 19.782350540161133\n",
      "Epoch: 37, Batch: 420, D Loss: 0.09616020453640683, G Loss: 19.728715896606445\n",
      "Epoch: 37, Batch: 421, D Loss: 0.09878710795225654, G Loss: 19.69146156311035\n",
      "Epoch: 37, Batch: 422, D Loss: 0.10295687755682359, G Loss: 19.69845199584961\n",
      "Epoch: 37, Batch: 423, D Loss: 0.10056641089864071, G Loss: 19.73019027709961\n",
      "Epoch: 37, Batch: 424, D Loss: 0.09812957181164728, G Loss: 19.76203727722168\n",
      "Epoch: 37, Batch: 425, D Loss: 0.10291087754698791, G Loss: 19.813154220581055\n",
      "Epoch: 37, Batch: 426, D Loss: 0.0994696554814325, G Loss: 19.84876251220703\n",
      "Epoch: 37, Batch: 427, D Loss: 0.1002052065679565, G Loss: 19.86774444580078\n",
      "Epoch: 37, Batch: 428, D Loss: 0.1036936652355338, G Loss: 19.891862869262695\n",
      "Epoch: 37, Batch: 429, D Loss: 0.09851800020449908, G Loss: 19.886747360229492\n",
      "Epoch: 37, Batch: 430, D Loss: 0.1061505537764903, G Loss: 19.90033531188965\n",
      "Epoch: 37, Batch: 431, D Loss: 0.10507533811773984, G Loss: 19.923351287841797\n",
      "Epoch: 37, Batch: 432, D Loss: 0.10160563997032346, G Loss: 19.930416107177734\n",
      "Epoch: 37, Batch: 433, D Loss: 0.0977957036385354, G Loss: 19.902151107788086\n",
      "Epoch: 37, Batch: 434, D Loss: 0.09700381873083908, G Loss: 19.842844009399414\n",
      "Epoch: 37, Batch: 435, D Loss: 0.09227042027002552, G Loss: 19.746870040893555\n",
      "Epoch: 37, Batch: 436, D Loss: 0.10178588466922289, G Loss: 19.698535919189453\n",
      "Epoch: 37, Batch: 437, D Loss: 0.09981291136170967, G Loss: 19.688190460205078\n",
      "Epoch: 37, Batch: 438, D Loss: 0.09919357439042131, G Loss: 19.709178924560547\n",
      "Epoch: 37, Batch: 439, D Loss: 0.09701543437077342, G Loss: 19.738712310791016\n",
      "Epoch: 37, Batch: 440, D Loss: 0.098496661899517, G Loss: 19.780502319335938\n",
      "Epoch: 37, Batch: 441, D Loss: 0.09469609834843218, G Loss: 19.797155380249023\n",
      "Epoch: 37, Batch: 442, D Loss: 0.0983418387766759, G Loss: 19.814048767089844\n",
      "Epoch: 37, Batch: 443, D Loss: 0.10196635993917247, G Loss: 19.850215911865234\n",
      "Epoch: 37, Batch: 444, D Loss: 0.09601436674613284, G Loss: 19.85810089111328\n",
      "Epoch: 37, Batch: 445, D Loss: 0.10175915180058226, G Loss: 19.876623153686523\n",
      "Epoch: 37, Batch: 446, D Loss: 0.09962098416318799, G Loss: 19.888736724853516\n",
      "Epoch: 37, Batch: 447, D Loss: 0.10227612520104434, G Loss: 19.907129287719727\n",
      "Epoch: 37, Batch: 448, D Loss: 0.09965729081067343, G Loss: 19.914091110229492\n",
      "Epoch: 37, Batch: 449, D Loss: 0.09772072845646951, G Loss: 19.899200439453125\n",
      "Epoch: 37, Batch: 450, D Loss: 0.09694769349582077, G Loss: 19.864225387573242\n",
      "Epoch: 37, Batch: 451, D Loss: 0.09315884235427874, G Loss: 19.79991912841797\n",
      "Epoch: 37, Batch: 452, D Loss: 0.09312635791128254, G Loss: 19.724956512451172\n",
      "Epoch: 37, Batch: 453, D Loss: 0.09805511076429552, G Loss: 19.689435958862305\n",
      "Epoch: 37, Batch: 454, D Loss: 0.09821120044680176, G Loss: 19.69550132751465\n",
      "Epoch: 37, Batch: 455, D Loss: 0.09670113164841332, G Loss: 19.723060607910156\n",
      "Epoch: 37, Batch: 456, D Loss: 0.10519123207246961, G Loss: 19.810184478759766\n",
      "Epoch: 37, Batch: 457, D Loss: 0.10440643249081516, G Loss: 19.924087524414062\n",
      "Epoch: 37, Batch: 458, D Loss: 0.10539783641848655, G Loss: 20.0424747467041\n",
      "Epoch: 37, Batch: 459, D Loss: 0.09622459955206697, G Loss: 20.085844039916992\n",
      "Epoch: 37, Batch: 460, D Loss: 0.10019491707768424, G Loss: 20.080455780029297\n",
      "Epoch: 37, Batch: 461, D Loss: 0.09588380256359041, G Loss: 20.015308380126953\n",
      "Epoch: 37, Batch: 462, D Loss: 0.0999535183750927, G Loss: 19.93760108947754\n",
      "Epoch: 37, Batch: 463, D Loss: 0.09663269038657585, G Loss: 19.84955596923828\n",
      "Epoch: 37, Batch: 464, D Loss: 0.09123014040593691, G Loss: 19.739017486572266\n",
      "Epoch: 37, Batch: 465, D Loss: 0.10359419273104975, G Loss: 19.709999084472656\n",
      "Epoch: 37, Batch: 466, D Loss: 0.10153594748522654, G Loss: 19.74195671081543\n",
      "Epoch: 37, Batch: 467, D Loss: 0.09889018665090987, G Loss: 19.79883575439453\n",
      "Epoch: 38, Batch: 0, D Loss: 0.0968050596440887, G Loss: 19.853816986083984\n",
      "Epoch: 38, Batch: 1, D Loss: 0.10055155422467488, G Loss: 19.91658592224121\n",
      "Epoch: 38, Batch: 2, D Loss: 0.10332626957174862, G Loss: 19.990285873413086\n",
      "Epoch: 38, Batch: 3, D Loss: 0.09494549139016673, G Loss: 20.010168075561523\n",
      "Epoch: 38, Batch: 4, D Loss: 0.09632699294640934, G Loss: 19.990774154663086\n",
      "Epoch: 38, Batch: 5, D Loss: 0.10055373714445548, G Loss: 19.96613311767578\n",
      "Epoch: 38, Batch: 6, D Loss: 0.09869423617139028, G Loss: 19.932910919189453\n",
      "Epoch: 38, Batch: 7, D Loss: 0.10052605829878669, G Loss: 19.910903930664062\n",
      "Epoch: 38, Batch: 8, D Loss: 0.09998230004274622, G Loss: 19.901836395263672\n",
      "Epoch: 38, Batch: 9, D Loss: 0.0994210701633812, G Loss: 19.901182174682617\n",
      "Epoch: 38, Batch: 10, D Loss: 0.1006761949630034, G Loss: 19.91474151611328\n",
      "Epoch: 38, Batch: 11, D Loss: 0.09997566155224402, G Loss: 19.93770408630371\n",
      "Epoch: 38, Batch: 12, D Loss: 0.10250511872967327, G Loss: 19.976177215576172\n",
      "Epoch: 38, Batch: 13, D Loss: 0.10091470285634563, G Loss: 20.009965896606445\n",
      "Epoch: 38, Batch: 14, D Loss: 0.0960277329186493, G Loss: 20.004871368408203\n",
      "Epoch: 38, Batch: 15, D Loss: 0.11027306418450666, G Loss: 20.04982566833496\n",
      "Epoch: 38, Batch: 16, D Loss: 0.10003279246610841, G Loss: 20.06888771057129\n",
      "Epoch: 38, Batch: 17, D Loss: 0.09729807176125405, G Loss: 20.047649383544922\n",
      "Epoch: 38, Batch: 18, D Loss: 0.09683141213227264, G Loss: 19.997453689575195\n",
      "Epoch: 38, Batch: 19, D Loss: 0.10122679279391467, G Loss: 19.958805084228516\n",
      "Epoch: 38, Batch: 20, D Loss: 0.09992351491992624, G Loss: 19.930355072021484\n",
      "Epoch: 38, Batch: 21, D Loss: 0.10483472158875151, G Loss: 19.945268630981445\n",
      "Epoch: 38, Batch: 22, D Loss: 0.0957836072632473, G Loss: 19.940109252929688\n",
      "Epoch: 38, Batch: 23, D Loss: 0.10614670920178237, G Loss: 19.98108673095703\n",
      "Epoch: 38, Batch: 24, D Loss: 0.101106652156283, G Loss: 20.020153045654297\n",
      "Epoch: 38, Batch: 25, D Loss: 0.09917406092875536, G Loss: 20.03684425354004\n",
      "Epoch: 38, Batch: 26, D Loss: 0.103031546862413, G Loss: 20.053056716918945\n",
      "Epoch: 38, Batch: 27, D Loss: 0.10010335692174444, G Loss: 20.052738189697266\n",
      "Epoch: 38, Batch: 28, D Loss: 0.09976133802741072, G Loss: 20.037582397460938\n",
      "Epoch: 38, Batch: 29, D Loss: 0.10247109930139608, G Loss: 20.02814292907715\n",
      "Epoch: 38, Batch: 30, D Loss: 0.10057856243312302, G Loss: 20.01711082458496\n",
      "Epoch: 38, Batch: 31, D Loss: 0.10303072732469742, G Loss: 20.02105140686035\n",
      "Epoch: 38, Batch: 32, D Loss: 0.10237457703465358, G Loss: 20.03374481201172\n",
      "Epoch: 38, Batch: 33, D Loss: 0.10251195827587578, G Loss: 20.049814224243164\n",
      "Epoch: 38, Batch: 34, D Loss: 0.10285930432563017, G Loss: 20.06964874267578\n",
      "Epoch: 38, Batch: 35, D Loss: 0.09582623936678225, G Loss: 20.046728134155273\n",
      "Epoch: 38, Batch: 36, D Loss: 0.1013726751024393, G Loss: 20.025043487548828\n",
      "Epoch: 38, Batch: 37, D Loss: 0.10530850391281288, G Loss: 20.034324645996094\n",
      "Epoch: 38, Batch: 38, D Loss: 0.10224387148552161, G Loss: 20.0479793548584\n",
      "Epoch: 38, Batch: 39, D Loss: 0.09871365228467344, G Loss: 20.042570114135742\n",
      "Epoch: 38, Batch: 40, D Loss: 0.09645222972899647, G Loss: 20.011409759521484\n",
      "Epoch: 38, Batch: 41, D Loss: 0.10037519140930329, G Loss: 19.98716926574707\n",
      "Epoch: 38, Batch: 42, D Loss: 0.09640816705505961, G Loss: 19.951513290405273\n",
      "Epoch: 38, Batch: 43, D Loss: 0.10365118194027456, G Loss: 19.960317611694336\n",
      "Epoch: 38, Batch: 44, D Loss: 0.09967595445029698, G Loss: 19.97870445251465\n",
      "Epoch: 38, Batch: 45, D Loss: 0.09976954862174192, G Loss: 20.001951217651367\n",
      "Epoch: 38, Batch: 46, D Loss: 0.09750489992957945, G Loss: 20.01093101501465\n",
      "Epoch: 38, Batch: 47, D Loss: 0.1042659739729388, G Loss: 20.045610427856445\n",
      "Epoch: 38, Batch: 48, D Loss: 0.10000242390094427, G Loss: 20.070037841796875\n",
      "Epoch: 38, Batch: 49, D Loss: 0.09290201314700852, G Loss: 20.03727149963379\n",
      "Epoch: 38, Batch: 50, D Loss: 0.09937964480727168, G Loss: 20.00607681274414\n",
      "Epoch: 38, Batch: 51, D Loss: 0.09943304314575241, G Loss: 19.9833927154541\n",
      "Epoch: 38, Batch: 52, D Loss: 0.09751461552112561, G Loss: 19.96474838256836\n",
      "Epoch: 38, Batch: 53, D Loss: 0.09455790479034298, G Loss: 19.937076568603516\n",
      "Epoch: 38, Batch: 54, D Loss: 0.09715410432635518, G Loss: 19.92118263244629\n",
      "Epoch: 38, Batch: 55, D Loss: 0.1013604413558068, G Loss: 19.94454002380371\n",
      "Epoch: 38, Batch: 56, D Loss: 0.09261480827890789, G Loss: 19.942920684814453\n",
      "Epoch: 38, Batch: 57, D Loss: 0.10186527776612031, G Loss: 19.977018356323242\n",
      "Epoch: 38, Batch: 58, D Loss: 0.09826717629211434, G Loss: 20.012895584106445\n",
      "Epoch: 38, Batch: 59, D Loss: 0.09111227942681999, G Loss: 19.998950958251953\n",
      "Epoch: 38, Batch: 60, D Loss: 0.09932255848240323, G Loss: 19.99656105041504\n",
      "Epoch: 38, Batch: 61, D Loss: 0.10238756341549238, G Loss: 20.02037811279297\n",
      "Epoch: 38, Batch: 62, D Loss: 0.09744455020697806, G Loss: 20.03139305114746\n",
      "Epoch: 38, Batch: 63, D Loss: 0.10650976099453491, G Loss: 20.082351684570312\n",
      "Epoch: 38, Batch: 64, D Loss: 0.09932957682907506, G Loss: 20.115375518798828\n",
      "Epoch: 38, Batch: 65, D Loss: 0.09342664573256693, G Loss: 20.090415954589844\n",
      "Epoch: 38, Batch: 66, D Loss: 0.09217300363901337, G Loss: 20.01674461364746\n",
      "Epoch: 38, Batch: 67, D Loss: 0.0975494171740875, G Loss: 19.95087432861328\n",
      "Epoch: 38, Batch: 68, D Loss: 0.09864731243400549, G Loss: 19.913362503051758\n",
      "Epoch: 38, Batch: 69, D Loss: 0.09317623193223079, G Loss: 19.879789352416992\n",
      "Epoch: 38, Batch: 70, D Loss: 0.10234923030241183, G Loss: 19.90763282775879\n",
      "Epoch: 38, Batch: 71, D Loss: 0.10080282499433668, G Loss: 19.971271514892578\n",
      "Epoch: 38, Batch: 72, D Loss: 0.10264057022269324, G Loss: 20.05926513671875\n",
      "Epoch: 38, Batch: 73, D Loss: 0.09830090497515842, G Loss: 20.12238311767578\n",
      "Epoch: 38, Batch: 74, D Loss: 0.09911602825186167, G Loss: 20.15448760986328\n",
      "Epoch: 38, Batch: 75, D Loss: 0.09123756081868561, G Loss: 20.10978126525879\n",
      "Epoch: 38, Batch: 76, D Loss: 0.10130296741749756, G Loss: 20.072086334228516\n",
      "Epoch: 38, Batch: 77, D Loss: 0.10105101861348431, G Loss: 20.047531127929688\n",
      "Epoch: 38, Batch: 78, D Loss: 0.1020215461560855, G Loss: 20.04461097717285\n",
      "Epoch: 38, Batch: 79, D Loss: 0.09298644315246696, G Loss: 20.010082244873047\n",
      "Epoch: 38, Batch: 80, D Loss: 0.09889575942209106, G Loss: 19.9891357421875\n",
      "Epoch: 38, Batch: 81, D Loss: 0.10283212466795899, G Loss: 20.00965690612793\n",
      "Epoch: 38, Batch: 82, D Loss: 0.0986616025501339, G Loss: 20.03602409362793\n",
      "Epoch: 38, Batch: 83, D Loss: 0.10113866724522513, G Loss: 20.076847076416016\n",
      "Epoch: 38, Batch: 84, D Loss: 0.09868599568471215, G Loss: 20.104970932006836\n",
      "Epoch: 38, Batch: 85, D Loss: 0.10169020386530625, G Loss: 20.1340389251709\n",
      "Epoch: 38, Batch: 86, D Loss: 0.0948913255483555, G Loss: 20.11796760559082\n",
      "Epoch: 38, Batch: 87, D Loss: 0.09660563711418968, G Loss: 20.079429626464844\n",
      "Epoch: 38, Batch: 88, D Loss: 0.09988645560801568, G Loss: 20.051233291625977\n",
      "Epoch: 38, Batch: 89, D Loss: 0.09500792722708773, G Loss: 20.008567810058594\n",
      "Epoch: 38, Batch: 90, D Loss: 0.09868011727075121, G Loss: 19.985170364379883\n",
      "Epoch: 38, Batch: 91, D Loss: 0.0974777500414512, G Loss: 19.975555419921875\n",
      "Epoch: 38, Batch: 92, D Loss: 0.09687387303756068, G Loss: 19.976877212524414\n",
      "Epoch: 38, Batch: 93, D Loss: 0.09774433180990039, G Loss: 19.992639541625977\n",
      "Epoch: 38, Batch: 94, D Loss: 0.09676046027284069, G Loss: 20.0105037689209\n",
      "Epoch: 38, Batch: 95, D Loss: 0.09824422102553021, G Loss: 20.034448623657227\n",
      "Epoch: 38, Batch: 96, D Loss: 0.09868803718570662, G Loss: 20.060304641723633\n",
      "Epoch: 38, Batch: 97, D Loss: 0.09072362729664274, G Loss: 20.03948211669922\n",
      "Epoch: 38, Batch: 98, D Loss: 0.1050544092882707, G Loss: 20.06719398498535\n",
      "Epoch: 38, Batch: 99, D Loss: 0.09985578899955283, G Loss: 20.09944725036621\n",
      "Epoch: 38, Batch: 100, D Loss: 0.09963254722552983, G Loss: 20.12657928466797\n",
      "Epoch: 38, Batch: 101, D Loss: 0.10215084344101444, G Loss: 20.157230377197266\n",
      "Epoch: 38, Batch: 102, D Loss: 0.09670451371746985, G Loss: 20.152482986450195\n",
      "Epoch: 38, Batch: 103, D Loss: 0.09676854402293655, G Loss: 20.12301254272461\n",
      "Epoch: 38, Batch: 104, D Loss: 0.09767916146480149, G Loss: 20.085655212402344\n",
      "Epoch: 38, Batch: 105, D Loss: 0.09936910963521517, G Loss: 20.06123924255371\n",
      "Epoch: 38, Batch: 106, D Loss: 0.09705909439559302, G Loss: 20.040943145751953\n",
      "Epoch: 38, Batch: 107, D Loss: 0.10203327336576151, G Loss: 20.05864715576172\n",
      "Epoch: 38, Batch: 108, D Loss: 0.1007414767729804, G Loss: 20.097211837768555\n",
      "Epoch: 38, Batch: 109, D Loss: 0.10133130194498174, G Loss: 20.14597511291504\n",
      "Epoch: 38, Batch: 110, D Loss: 0.09691029875240237, G Loss: 20.16510581970215\n",
      "Epoch: 38, Batch: 111, D Loss: 0.09955075470184893, G Loss: 20.17343521118164\n",
      "Epoch: 38, Batch: 112, D Loss: 0.09779962984458718, G Loss: 20.16246223449707\n",
      "Epoch: 38, Batch: 113, D Loss: 0.09246594549138137, G Loss: 20.10455894470215\n",
      "Epoch: 38, Batch: 114, D Loss: 0.1054450431817282, G Loss: 20.10284423828125\n",
      "Epoch: 38, Batch: 115, D Loss: 0.10102602931731358, G Loss: 20.117887496948242\n",
      "Epoch: 38, Batch: 116, D Loss: 0.09415866526687522, G Loss: 20.107406616210938\n",
      "Epoch: 38, Batch: 117, D Loss: 0.10214766206779924, G Loss: 20.122718811035156\n",
      "Epoch: 38, Batch: 118, D Loss: 0.09706888438990041, G Loss: 20.123538970947266\n",
      "Epoch: 38, Batch: 119, D Loss: 0.10421285122642054, G Loss: 20.15876007080078\n",
      "Epoch: 38, Batch: 120, D Loss: 0.10154555824105638, G Loss: 20.19811248779297\n",
      "Epoch: 38, Batch: 121, D Loss: 0.09896984780206314, G Loss: 20.214488983154297\n",
      "Epoch: 38, Batch: 122, D Loss: 0.09627093458737368, G Loss: 20.195432662963867\n",
      "Epoch: 38, Batch: 123, D Loss: 0.0970810660432147, G Loss: 20.156352996826172\n",
      "Epoch: 38, Batch: 124, D Loss: 0.10298408656572, G Loss: 20.14523696899414\n",
      "Epoch: 38, Batch: 125, D Loss: 0.09510658027077012, G Loss: 20.111242294311523\n",
      "Epoch: 38, Batch: 126, D Loss: 0.09515260254286739, G Loss: 20.06841468811035\n",
      "Epoch: 38, Batch: 127, D Loss: 0.09430734911797312, G Loss: 20.022884368896484\n",
      "Epoch: 38, Batch: 128, D Loss: 0.1002984131514677, G Loss: 20.023054122924805\n",
      "Epoch: 38, Batch: 129, D Loss: 0.09638495843231187, G Loss: 20.037532806396484\n",
      "Epoch: 38, Batch: 130, D Loss: 0.10505479669751427, G Loss: 20.110071182250977\n",
      "Epoch: 38, Batch: 131, D Loss: 0.09560091883549343, G Loss: 20.15823745727539\n",
      "Epoch: 38, Batch: 132, D Loss: 0.10222624327703816, G Loss: 20.21485710144043\n",
      "Epoch: 38, Batch: 133, D Loss: 0.09410385870583055, G Loss: 20.215858459472656\n",
      "Epoch: 38, Batch: 134, D Loss: 0.09592793221375356, G Loss: 20.18217658996582\n",
      "Epoch: 38, Batch: 135, D Loss: 0.09670130251535014, G Loss: 20.134033203125\n",
      "Epoch: 38, Batch: 136, D Loss: 0.10196483971183229, G Loss: 20.11801528930664\n",
      "Epoch: 38, Batch: 137, D Loss: 0.09928162487652947, G Loss: 20.115869522094727\n",
      "Epoch: 38, Batch: 138, D Loss: 0.09953507127047401, G Loss: 20.13072967529297\n",
      "Epoch: 38, Batch: 139, D Loss: 0.10681778279637755, G Loss: 20.201696395874023\n",
      "Epoch: 38, Batch: 140, D Loss: 0.09920310311127067, G Loss: 20.251405715942383\n",
      "Epoch: 38, Batch: 141, D Loss: 0.10727180617776289, G Loss: 20.32224464416504\n",
      "Epoch: 38, Batch: 142, D Loss: 0.0968679718643109, G Loss: 20.33421516418457\n",
      "Epoch: 38, Batch: 143, D Loss: 0.09787942544248324, G Loss: 20.299882888793945\n",
      "Epoch: 38, Batch: 144, D Loss: 0.098156475318595, G Loss: 20.240116119384766\n",
      "Epoch: 38, Batch: 145, D Loss: 0.0962171414000687, G Loss: 20.16183853149414\n",
      "Epoch: 38, Batch: 146, D Loss: 0.09589643867594477, G Loss: 20.08708381652832\n",
      "Epoch: 38, Batch: 147, D Loss: 0.10583540146335468, G Loss: 20.093381881713867\n",
      "Epoch: 38, Batch: 148, D Loss: 0.09127758537999509, G Loss: 20.077953338623047\n",
      "Epoch: 38, Batch: 149, D Loss: 0.10430927667601353, G Loss: 20.12578582763672\n",
      "Epoch: 38, Batch: 150, D Loss: 0.106634438898917, G Loss: 20.228261947631836\n",
      "Epoch: 38, Batch: 151, D Loss: 0.0938524164801659, G Loss: 20.27762794494629\n",
      "Epoch: 38, Batch: 152, D Loss: 0.09954489099357378, G Loss: 20.307395935058594\n",
      "Epoch: 38, Batch: 153, D Loss: 0.0990791328368002, G Loss: 20.310382843017578\n",
      "Epoch: 38, Batch: 154, D Loss: 0.10281245485745821, G Loss: 20.316967010498047\n",
      "Epoch: 38, Batch: 155, D Loss: 0.09925677703014146, G Loss: 20.30132293701172\n",
      "Epoch: 38, Batch: 156, D Loss: 0.09904524761508049, G Loss: 20.269062042236328\n",
      "Epoch: 38, Batch: 157, D Loss: 0.10573612232029678, G Loss: 20.275184631347656\n",
      "Epoch: 38, Batch: 158, D Loss: 0.09740457017679016, G Loss: 20.259145736694336\n",
      "Epoch: 38, Batch: 159, D Loss: 0.09337920032398361, G Loss: 20.203149795532227\n",
      "Epoch: 38, Batch: 160, D Loss: 0.10033873554180783, G Loss: 20.17121696472168\n",
      "Epoch: 38, Batch: 161, D Loss: 0.09840437112371292, G Loss: 20.156152725219727\n",
      "Epoch: 38, Batch: 162, D Loss: 0.0946794161171533, G Loss: 20.13576889038086\n",
      "Epoch: 38, Batch: 163, D Loss: 0.09033887180493405, G Loss: 20.089555740356445\n",
      "Epoch: 38, Batch: 164, D Loss: 0.10426272544569776, G Loss: 20.120973587036133\n",
      "Epoch: 38, Batch: 165, D Loss: 0.09362790078950883, G Loss: 20.139606475830078\n",
      "Epoch: 38, Batch: 166, D Loss: 0.10579633798697796, G Loss: 20.219791412353516\n",
      "Epoch: 38, Batch: 167, D Loss: 0.09297323308251065, G Loss: 20.252405166625977\n",
      "Epoch: 38, Batch: 168, D Loss: 0.10270824361455988, G Loss: 20.299976348876953\n",
      "Epoch: 38, Batch: 169, D Loss: 0.10288341417719787, G Loss: 20.351200103759766\n",
      "Epoch: 38, Batch: 170, D Loss: 0.10217706930235859, G Loss: 20.388694763183594\n",
      "Epoch: 38, Batch: 171, D Loss: 0.09799282322923153, G Loss: 20.381582260131836\n",
      "Epoch: 38, Batch: 172, D Loss: 0.10385236959872668, G Loss: 20.37142562866211\n",
      "Epoch: 38, Batch: 173, D Loss: 0.10130900961523193, G Loss: 20.350200653076172\n",
      "Epoch: 38, Batch: 174, D Loss: 0.09872955158083224, G Loss: 20.308090209960938\n",
      "Epoch: 38, Batch: 175, D Loss: 0.09299501855880538, G Loss: 20.223377227783203\n",
      "Epoch: 38, Batch: 176, D Loss: 0.09667843665961923, G Loss: 20.149097442626953\n",
      "Epoch: 38, Batch: 177, D Loss: 0.0964128235142398, G Loss: 20.102224349975586\n",
      "Epoch: 38, Batch: 178, D Loss: 0.09681964759237072, G Loss: 20.09138298034668\n",
      "Epoch: 38, Batch: 179, D Loss: 0.1038678595569123, G Loss: 20.157188415527344\n",
      "Epoch: 38, Batch: 180, D Loss: 0.09828339601639552, G Loss: 20.235309600830078\n",
      "Epoch: 38, Batch: 181, D Loss: 0.09834800739098382, G Loss: 20.305753707885742\n",
      "Epoch: 38, Batch: 182, D Loss: 0.09647312089778559, G Loss: 20.3419246673584\n",
      "Epoch: 38, Batch: 183, D Loss: 0.09768423510944346, G Loss: 20.350933074951172\n",
      "Epoch: 38, Batch: 184, D Loss: 0.10104884279452714, G Loss: 20.3603515625\n",
      "Epoch: 38, Batch: 185, D Loss: 0.0934063427042987, G Loss: 20.319684982299805\n",
      "Epoch: 38, Batch: 186, D Loss: 0.09584792035567152, G Loss: 20.260391235351562\n",
      "Epoch: 38, Batch: 187, D Loss: 0.09856029681205036, G Loss: 20.21633529663086\n",
      "Epoch: 38, Batch: 188, D Loss: 0.09847863847387894, G Loss: 20.198118209838867\n",
      "Epoch: 38, Batch: 189, D Loss: 0.09809590215419206, G Loss: 20.201929092407227\n",
      "Epoch: 38, Batch: 190, D Loss: 0.10383408598434452, G Loss: 20.257564544677734\n",
      "Epoch: 38, Batch: 191, D Loss: 0.09821039515867919, G Loss: 20.306900024414062\n",
      "Epoch: 38, Batch: 192, D Loss: 0.09090528713434898, G Loss: 20.2960205078125\n",
      "Epoch: 38, Batch: 193, D Loss: 0.10358735994863127, G Loss: 20.315805435180664\n",
      "Epoch: 38, Batch: 194, D Loss: 0.0897855468325538, G Loss: 20.274200439453125\n",
      "Epoch: 38, Batch: 195, D Loss: 0.10391599018026532, G Loss: 20.279516220092773\n",
      "Epoch: 38, Batch: 196, D Loss: 0.0992414959060976, G Loss: 20.29344367980957\n",
      "Epoch: 38, Batch: 197, D Loss: 0.09772104101431867, G Loss: 20.30115509033203\n",
      "Epoch: 38, Batch: 198, D Loss: 0.0983165212122672, G Loss: 20.308364868164062\n",
      "Epoch: 38, Batch: 199, D Loss: 0.09862414823004878, G Loss: 20.313127517700195\n",
      "Epoch: 38, Batch: 200, D Loss: 0.09711572603621027, G Loss: 20.303625106811523\n",
      "Epoch: 38, Batch: 201, D Loss: 0.09325985688168709, G Loss: 20.263896942138672\n",
      "Epoch: 38, Batch: 202, D Loss: 0.10221836049910438, G Loss: 20.267000198364258\n",
      "Epoch: 38, Batch: 203, D Loss: 0.10426376836985723, G Loss: 20.31414794921875\n",
      "Epoch: 38, Batch: 204, D Loss: 0.11156064342716127, G Loss: 20.43038558959961\n",
      "Epoch: 38, Batch: 205, D Loss: 0.10052321915590678, G Loss: 20.50786590576172\n",
      "Epoch: 38, Batch: 206, D Loss: 0.09590800913606934, G Loss: 20.507831573486328\n",
      "Epoch: 38, Batch: 207, D Loss: 0.10153871837648171, G Loss: 20.478919982910156\n",
      "Epoch: 38, Batch: 208, D Loss: 0.10607247118947799, G Loss: 20.463315963745117\n",
      "Epoch: 38, Batch: 209, D Loss: 0.1058023280432483, G Loss: 20.46250343322754\n",
      "Epoch: 38, Batch: 210, D Loss: 0.09218328513593632, G Loss: 20.38934898376465\n",
      "Epoch: 38, Batch: 211, D Loss: 0.09284912868875805, G Loss: 20.277551651000977\n",
      "Epoch: 38, Batch: 212, D Loss: 0.09487110458814474, G Loss: 20.173858642578125\n",
      "Epoch: 38, Batch: 213, D Loss: 0.09930738895236346, G Loss: 20.13277816772461\n",
      "Epoch: 38, Batch: 214, D Loss: 0.09617625267088747, G Loss: 20.1342830657959\n",
      "Epoch: 38, Batch: 215, D Loss: 0.09713229625175401, G Loss: 20.175851821899414\n",
      "Epoch: 38, Batch: 216, D Loss: 0.10019686900815084, G Loss: 20.260087966918945\n",
      "Epoch: 38, Batch: 217, D Loss: 0.09826505260129642, G Loss: 20.34572410583496\n",
      "Epoch: 38, Batch: 218, D Loss: 0.09570843052234357, G Loss: 20.399709701538086\n",
      "Epoch: 38, Batch: 219, D Loss: 0.09782808342023558, G Loss: 20.430530548095703\n",
      "Epoch: 38, Batch: 220, D Loss: 0.1025632775448933, G Loss: 20.465272903442383\n",
      "Epoch: 38, Batch: 221, D Loss: 0.09918895428298419, G Loss: 20.472074508666992\n",
      "Epoch: 38, Batch: 222, D Loss: 0.10211831395384391, G Loss: 20.476551055908203\n",
      "Epoch: 38, Batch: 223, D Loss: 0.09681263631132819, G Loss: 20.443557739257812\n",
      "Epoch: 38, Batch: 224, D Loss: 0.09354882011239962, G Loss: 20.363840103149414\n",
      "Epoch: 38, Batch: 225, D Loss: 0.09618176594506739, G Loss: 20.28563690185547\n",
      "Epoch: 38, Batch: 226, D Loss: 0.10429123866605422, G Loss: 20.28380012512207\n",
      "Epoch: 38, Batch: 227, D Loss: 0.0987311832814195, G Loss: 20.3089599609375\n",
      "Epoch: 38, Batch: 228, D Loss: 0.09448799566068555, G Loss: 20.322383880615234\n",
      "Epoch: 38, Batch: 229, D Loss: 0.09622144773370245, G Loss: 20.332332611083984\n",
      "Epoch: 38, Batch: 230, D Loss: 0.10372149271063796, G Loss: 20.387250900268555\n",
      "Epoch: 38, Batch: 231, D Loss: 0.10011717745056375, G Loss: 20.443241119384766\n",
      "Epoch: 38, Batch: 232, D Loss: 0.09709481215239407, G Loss: 20.467361450195312\n",
      "Epoch: 38, Batch: 233, D Loss: 0.10545517567169538, G Loss: 20.515968322753906\n",
      "Epoch: 38, Batch: 234, D Loss: 0.0982907793093118, G Loss: 20.523529052734375\n",
      "Epoch: 38, Batch: 235, D Loss: 0.10798290431716417, G Loss: 20.562368392944336\n",
      "Epoch: 38, Batch: 236, D Loss: 0.10223852901319608, G Loss: 20.577253341674805\n",
      "Epoch: 38, Batch: 237, D Loss: 0.10059889464349592, G Loss: 20.56026840209961\n",
      "Epoch: 38, Batch: 238, D Loss: 0.09933408410136291, G Loss: 20.511497497558594\n",
      "Epoch: 38, Batch: 239, D Loss: 0.10738053234824552, G Loss: 20.50534439086914\n",
      "Epoch: 38, Batch: 240, D Loss: 0.09792549971492903, G Loss: 20.47041893005371\n",
      "Epoch: 38, Batch: 241, D Loss: 0.09910473293293609, G Loss: 20.429397583007812\n",
      "Epoch: 38, Batch: 242, D Loss: 0.09622677484706699, G Loss: 20.37319564819336\n",
      "Epoch: 38, Batch: 243, D Loss: 0.10091187876733382, G Loss: 20.35106658935547\n",
      "Epoch: 38, Batch: 244, D Loss: 0.09453268422953454, G Loss: 20.319107055664062\n",
      "Epoch: 38, Batch: 245, D Loss: 0.09924140647445145, G Loss: 20.319406509399414\n",
      "Epoch: 38, Batch: 246, D Loss: 0.1029886461619135, G Loss: 20.3742618560791\n",
      "Epoch: 38, Batch: 247, D Loss: 0.0995075560529079, G Loss: 20.432849884033203\n",
      "Epoch: 38, Batch: 248, D Loss: 0.09908245569152752, G Loss: 20.47898292541504\n",
      "Epoch: 38, Batch: 249, D Loss: 0.1021349510818389, G Loss: 20.525854110717773\n",
      "Epoch: 38, Batch: 250, D Loss: 0.1058202540821081, G Loss: 20.584280014038086\n",
      "Epoch: 38, Batch: 251, D Loss: 0.09759730903093683, G Loss: 20.586135864257812\n",
      "Epoch: 38, Batch: 252, D Loss: 0.09900035022558795, G Loss: 20.549314498901367\n",
      "Epoch: 38, Batch: 253, D Loss: 0.1044395721017658, G Loss: 20.527389526367188\n",
      "Epoch: 38, Batch: 254, D Loss: 0.10243944885186401, G Loss: 20.508079528808594\n",
      "Epoch: 38, Batch: 255, D Loss: 0.10060565236278496, G Loss: 20.488445281982422\n",
      "Epoch: 38, Batch: 256, D Loss: 0.09679412906443896, G Loss: 20.44657325744629\n",
      "Epoch: 38, Batch: 257, D Loss: 0.10473401910316532, G Loss: 20.45026969909668\n",
      "Epoch: 38, Batch: 258, D Loss: 0.09965440696398242, G Loss: 20.456483840942383\n",
      "Epoch: 38, Batch: 259, D Loss: 0.09873206978788157, G Loss: 20.455791473388672\n",
      "Epoch: 38, Batch: 260, D Loss: 0.10550729994328117, G Loss: 20.497249603271484\n",
      "Epoch: 38, Batch: 261, D Loss: 0.10702662975243632, G Loss: 20.57231330871582\n",
      "Epoch: 38, Batch: 262, D Loss: 0.09407521842451427, G Loss: 20.57249641418457\n",
      "Epoch: 38, Batch: 263, D Loss: 0.10124406277078246, G Loss: 20.55917739868164\n",
      "Epoch: 38, Batch: 264, D Loss: 0.09744950444318412, G Loss: 20.511463165283203\n",
      "Epoch: 38, Batch: 265, D Loss: 0.10332307282037045, G Loss: 20.48906707763672\n",
      "Epoch: 38, Batch: 266, D Loss: 0.09349911725364918, G Loss: 20.423694610595703\n",
      "Epoch: 38, Batch: 267, D Loss: 0.0969274349010853, G Loss: 20.367074966430664\n",
      "Epoch: 38, Batch: 268, D Loss: 0.09506597443176124, G Loss: 20.317977905273438\n",
      "Epoch: 38, Batch: 269, D Loss: 0.09827554301452951, G Loss: 20.30439567565918\n",
      "Epoch: 38, Batch: 270, D Loss: 0.09828100428656272, G Loss: 20.325576782226562\n",
      "Epoch: 38, Batch: 271, D Loss: 0.10092080456618308, G Loss: 20.38517189025879\n",
      "Epoch: 38, Batch: 272, D Loss: 0.09592232921689381, G Loss: 20.42913818359375\n",
      "Epoch: 38, Batch: 273, D Loss: 0.0933397791528609, G Loss: 20.432212829589844\n",
      "Epoch: 38, Batch: 274, D Loss: 0.10776642029488825, G Loss: 20.499238967895508\n",
      "Epoch: 38, Batch: 275, D Loss: 0.09714411260554118, G Loss: 20.532840728759766\n",
      "Epoch: 38, Batch: 276, D Loss: 0.10064855277798151, G Loss: 20.55268096923828\n",
      "Epoch: 38, Batch: 277, D Loss: 0.09790986090986425, G Loss: 20.540279388427734\n",
      "Epoch: 38, Batch: 278, D Loss: 0.0927709868801262, G Loss: 20.475610733032227\n",
      "Epoch: 38, Batch: 279, D Loss: 0.10262224143212406, G Loss: 20.446802139282227\n",
      "Epoch: 38, Batch: 280, D Loss: 0.10061369157327588, G Loss: 20.443143844604492\n",
      "Epoch: 38, Batch: 281, D Loss: 0.09649650819004679, G Loss: 20.434818267822266\n",
      "Epoch: 38, Batch: 282, D Loss: 0.10157302833010856, G Loss: 20.456315994262695\n",
      "Epoch: 38, Batch: 283, D Loss: 0.09666846757527292, G Loss: 20.466197967529297\n",
      "Epoch: 38, Batch: 284, D Loss: 0.09418401187401165, G Loss: 20.44729232788086\n",
      "Epoch: 38, Batch: 285, D Loss: 0.09820684856787187, G Loss: 20.43924903869629\n",
      "Epoch: 38, Batch: 286, D Loss: 0.10112691736319396, G Loss: 20.46126365661621\n",
      "Epoch: 38, Batch: 287, D Loss: 0.09956508938837283, G Loss: 20.491836547851562\n",
      "Epoch: 38, Batch: 288, D Loss: 0.1012357777560724, G Loss: 20.534008026123047\n",
      "Epoch: 38, Batch: 289, D Loss: 0.10041675775953302, G Loss: 20.5690860748291\n",
      "Epoch: 38, Batch: 290, D Loss: 0.10714714285544796, G Loss: 20.631969451904297\n",
      "Epoch: 38, Batch: 291, D Loss: 0.10023343617090946, G Loss: 20.6589412689209\n",
      "Epoch: 38, Batch: 292, D Loss: 0.09947805160318429, G Loss: 20.646387100219727\n",
      "Epoch: 38, Batch: 293, D Loss: 0.09893529172352322, G Loss: 20.60299301147461\n",
      "Epoch: 38, Batch: 294, D Loss: 0.10446101484150161, G Loss: 20.58029556274414\n",
      "Epoch: 38, Batch: 295, D Loss: 0.09985999076512309, G Loss: 20.55183982849121\n",
      "Epoch: 38, Batch: 296, D Loss: 0.0977269268140023, G Loss: 20.510881423950195\n",
      "Epoch: 38, Batch: 297, D Loss: 0.09283558343477727, G Loss: 20.439424514770508\n",
      "Epoch: 38, Batch: 298, D Loss: 0.10287472672584025, G Loss: 20.426250457763672\n",
      "Epoch: 38, Batch: 299, D Loss: 0.1012987650101908, G Loss: 20.457012176513672\n",
      "Epoch: 38, Batch: 300, D Loss: 0.10154342714616715, G Loss: 20.516372680664062\n",
      "Epoch: 38, Batch: 301, D Loss: 0.0943256473666449, G Loss: 20.53628158569336\n",
      "Epoch: 38, Batch: 302, D Loss: 0.10027849733825028, G Loss: 20.55800437927246\n",
      "Epoch: 38, Batch: 303, D Loss: 0.10030862002316365, G Loss: 20.5784854888916\n",
      "Epoch: 38, Batch: 304, D Loss: 0.10642306562854731, G Loss: 20.630855560302734\n",
      "Epoch: 38, Batch: 305, D Loss: 0.09701906944322108, G Loss: 20.637788772583008\n",
      "Epoch: 38, Batch: 306, D Loss: 0.1001536106577246, G Loss: 20.628103256225586\n",
      "Epoch: 38, Batch: 307, D Loss: 0.10035169180175607, G Loss: 20.608272552490234\n",
      "Epoch: 38, Batch: 308, D Loss: 0.09997604844246516, G Loss: 20.581371307373047\n",
      "Epoch: 38, Batch: 309, D Loss: 0.09516622930536256, G Loss: 20.524436950683594\n",
      "Epoch: 38, Batch: 310, D Loss: 0.09360420767347494, G Loss: 20.449321746826172\n",
      "Epoch: 38, Batch: 311, D Loss: 0.10041405327183722, G Loss: 20.424665451049805\n",
      "Epoch: 38, Batch: 312, D Loss: 0.09613230146965052, G Loss: 20.420499801635742\n",
      "Epoch: 38, Batch: 313, D Loss: 0.10432232981728778, G Loss: 20.486467361450195\n",
      "Epoch: 38, Batch: 314, D Loss: 0.0999682924262395, G Loss: 20.567522048950195\n",
      "Epoch: 38, Batch: 315, D Loss: 0.09445783553208686, G Loss: 20.604402542114258\n",
      "Epoch: 38, Batch: 316, D Loss: 0.10254944915971792, G Loss: 20.64798927307129\n",
      "Epoch: 38, Batch: 317, D Loss: 0.10507321410056647, G Loss: 20.704565048217773\n",
      "Epoch: 38, Batch: 318, D Loss: 0.09907938590640225, G Loss: 20.71535873413086\n",
      "Epoch: 38, Batch: 319, D Loss: 0.09707819721839289, G Loss: 20.677980422973633\n",
      "Epoch: 38, Batch: 320, D Loss: 0.10107685678951389, G Loss: 20.639175415039062\n",
      "Epoch: 38, Batch: 321, D Loss: 0.10137170608424728, G Loss: 20.610450744628906\n",
      "Epoch: 38, Batch: 322, D Loss: 0.09935311284860276, G Loss: 20.581850051879883\n",
      "Epoch: 38, Batch: 323, D Loss: 0.09875465242739134, G Loss: 20.559221267700195\n",
      "Epoch: 38, Batch: 324, D Loss: 0.09555530608019602, G Loss: 20.527021408081055\n",
      "Epoch: 38, Batch: 325, D Loss: 0.09650209607710175, G Loss: 20.502948760986328\n",
      "Epoch: 38, Batch: 326, D Loss: 0.09432756964292915, G Loss: 20.438167572021484\n",
      "Epoch: 38, Batch: 327, D Loss: 0.10277667707318683, G Loss: 20.461700439453125\n",
      "Epoch: 38, Batch: 328, D Loss: 0.10585006386564688, G Loss: 20.608022689819336\n",
      "Epoch: 38, Batch: 329, D Loss: 0.10212019883782564, G Loss: 20.715435028076172\n",
      "Epoch: 38, Batch: 330, D Loss: 0.09844969262156833, G Loss: 20.763044357299805\n",
      "Epoch: 38, Batch: 331, D Loss: 0.1032397230237137, G Loss: 20.789844512939453\n",
      "Epoch: 38, Batch: 332, D Loss: 0.09578158754304378, G Loss: 20.745813369750977\n",
      "Epoch: 38, Batch: 333, D Loss: 0.09545277111827893, G Loss: 20.588037490844727\n",
      "Epoch: 38, Batch: 334, D Loss: 0.09896051946024437, G Loss: 20.425979614257812\n",
      "Epoch: 38, Batch: 335, D Loss: 0.09735921097562616, G Loss: 20.29036521911621\n",
      "Epoch: 38, Batch: 336, D Loss: 0.09984177428339597, G Loss: 20.284242630004883\n",
      "Epoch: 38, Batch: 337, D Loss: 0.10129415317002022, G Loss: 20.39522361755371\n",
      "Epoch: 38, Batch: 338, D Loss: 0.09679682618503477, G Loss: 20.499528884887695\n",
      "Epoch: 38, Batch: 339, D Loss: 0.09832385987281766, G Loss: 20.58302116394043\n",
      "Epoch: 38, Batch: 340, D Loss: 0.10232749635914645, G Loss: 20.663312911987305\n",
      "Epoch: 38, Batch: 341, D Loss: 0.09634783916641249, G Loss: 20.680316925048828\n",
      "Epoch: 38, Batch: 342, D Loss: 0.09713701211465797, G Loss: 20.661985397338867\n",
      "Epoch: 38, Batch: 343, D Loss: 0.09879496747512034, G Loss: 20.63572120666504\n",
      "Epoch: 38, Batch: 344, D Loss: 0.10214916671439428, G Loss: 20.62936019897461\n",
      "Epoch: 38, Batch: 345, D Loss: 0.09801703001768025, G Loss: 20.614986419677734\n",
      "Epoch: 38, Batch: 346, D Loss: 0.09921330269574719, G Loss: 20.604570388793945\n",
      "Epoch: 38, Batch: 347, D Loss: 0.09837932196219568, G Loss: 20.595172882080078\n",
      "Epoch: 38, Batch: 348, D Loss: 0.10187494811098619, G Loss: 20.61296844482422\n",
      "Epoch: 38, Batch: 349, D Loss: 0.09979175086406694, G Loss: 20.63394546508789\n",
      "Epoch: 38, Batch: 350, D Loss: 0.10617138498435702, G Loss: 20.69076919555664\n",
      "Epoch: 38, Batch: 351, D Loss: 0.09432773343757678, G Loss: 20.68937110900879\n",
      "Epoch: 38, Batch: 352, D Loss: 0.10111330501447091, G Loss: 20.684293746948242\n",
      "Epoch: 38, Batch: 353, D Loss: 0.10519249788784957, G Loss: 20.70149803161621\n",
      "Epoch: 38, Batch: 354, D Loss: 0.10165484300464878, G Loss: 20.710102081298828\n",
      "Epoch: 38, Batch: 355, D Loss: 0.09601639262844325, G Loss: 20.672901153564453\n",
      "Epoch: 38, Batch: 356, D Loss: 0.10359147244051298, G Loss: 20.657835006713867\n",
      "Epoch: 38, Batch: 357, D Loss: 0.09956710094464954, G Loss: 20.639724731445312\n",
      "Epoch: 38, Batch: 358, D Loss: 0.10148258561725515, G Loss: 20.63577651977539\n",
      "Epoch: 38, Batch: 359, D Loss: 0.09824685062329308, G Loss: 20.621206283569336\n",
      "Epoch: 38, Batch: 360, D Loss: 0.10453163142106647, G Loss: 20.643207550048828\n",
      "Epoch: 38, Batch: 361, D Loss: 0.09444578046591762, G Loss: 20.627206802368164\n",
      "Epoch: 38, Batch: 362, D Loss: 0.09552068319372553, G Loss: 20.59177017211914\n",
      "Epoch: 38, Batch: 363, D Loss: 0.10234046039394346, G Loss: 20.591699600219727\n",
      "Epoch: 38, Batch: 364, D Loss: 0.09587397483763482, G Loss: 20.579681396484375\n",
      "Epoch: 38, Batch: 365, D Loss: 0.0980702569898439, G Loss: 20.57781219482422\n",
      "Epoch: 38, Batch: 366, D Loss: 0.09738916216400323, G Loss: 20.581390380859375\n",
      "Epoch: 38, Batch: 367, D Loss: 0.09404568432208832, G Loss: 20.5673885345459\n",
      "Epoch: 38, Batch: 368, D Loss: 0.09786268382090807, G Loss: 20.567623138427734\n",
      "Epoch: 38, Batch: 369, D Loss: 0.09782972989874356, G Loss: 20.58108139038086\n",
      "Epoch: 38, Batch: 370, D Loss: 0.10136099216102085, G Loss: 20.62303352355957\n",
      "Epoch: 38, Batch: 371, D Loss: 0.09767945165162772, G Loss: 20.654582977294922\n",
      "Epoch: 38, Batch: 372, D Loss: 0.09531953984354186, G Loss: 20.656700134277344\n",
      "Epoch: 38, Batch: 373, D Loss: 0.09630947613955876, G Loss: 20.641164779663086\n",
      "Epoch: 38, Batch: 374, D Loss: 0.10092514807476549, G Loss: 20.646320343017578\n",
      "Epoch: 38, Batch: 375, D Loss: 0.09925791674967493, G Loss: 20.654926300048828\n",
      "Epoch: 38, Batch: 376, D Loss: 0.09802441352392599, G Loss: 20.658817291259766\n",
      "Epoch: 38, Batch: 377, D Loss: 0.10072695516646785, G Loss: 20.679622650146484\n",
      "Epoch: 38, Batch: 378, D Loss: 0.0983888884602297, G Loss: 20.69403648376465\n",
      "Epoch: 38, Batch: 379, D Loss: 0.09572036616341367, G Loss: 20.66946792602539\n",
      "Epoch: 38, Batch: 380, D Loss: 0.10270544194295661, G Loss: 20.66953468322754\n",
      "Epoch: 38, Batch: 381, D Loss: 0.09973222069915177, G Loss: 20.67445945739746\n",
      "Epoch: 38, Batch: 382, D Loss: 0.09418632143593642, G Loss: 20.638671875\n",
      "Epoch: 38, Batch: 383, D Loss: 0.1042894279389846, G Loss: 20.655611038208008\n",
      "Epoch: 38, Batch: 384, D Loss: 0.09979645215744543, G Loss: 20.67632293701172\n",
      "Epoch: 38, Batch: 385, D Loss: 0.09695592575349604, G Loss: 20.664695739746094\n",
      "Epoch: 38, Batch: 386, D Loss: 0.10158635728661741, G Loss: 20.67424201965332\n",
      "Epoch: 38, Batch: 387, D Loss: 0.1041709785811124, G Loss: 20.723134994506836\n",
      "Epoch: 38, Batch: 388, D Loss: 0.1014263709314574, G Loss: 20.763578414916992\n",
      "Epoch: 38, Batch: 389, D Loss: 0.09287934799602587, G Loss: 20.71437644958496\n",
      "Epoch: 38, Batch: 390, D Loss: 0.09835574082932291, G Loss: 20.65475845336914\n",
      "Epoch: 38, Batch: 391, D Loss: 0.10384133511880106, G Loss: 20.647912979125977\n",
      "Epoch: 38, Batch: 392, D Loss: 0.09770490283462552, G Loss: 20.63332176208496\n",
      "Epoch: 38, Batch: 393, D Loss: 0.09517405237637255, G Loss: 20.605575561523438\n",
      "Epoch: 38, Batch: 394, D Loss: 0.10240584667417785, G Loss: 20.63018226623535\n",
      "Epoch: 38, Batch: 395, D Loss: 0.09306327308714285, G Loss: 20.621479034423828\n",
      "Epoch: 38, Batch: 396, D Loss: 0.09627985264846028, G Loss: 20.612661361694336\n",
      "Epoch: 38, Batch: 397, D Loss: 0.10302127952179635, G Loss: 20.66128158569336\n",
      "Epoch: 38, Batch: 398, D Loss: 0.10060928068643055, G Loss: 20.71099853515625\n",
      "Epoch: 38, Batch: 399, D Loss: 0.09703867932544413, G Loss: 20.732379913330078\n",
      "Epoch: 38, Batch: 400, D Loss: 0.10033845950514186, G Loss: 20.752609252929688\n",
      "Epoch: 38, Batch: 401, D Loss: 0.0925512765829733, G Loss: 20.715225219726562\n",
      "Epoch: 38, Batch: 402, D Loss: 0.10105937770284074, G Loss: 20.695280075073242\n",
      "Epoch: 38, Batch: 403, D Loss: 0.10048574260734311, G Loss: 20.69162940979004\n",
      "Epoch: 38, Batch: 404, D Loss: 0.10325150242640657, G Loss: 20.719572067260742\n",
      "Epoch: 38, Batch: 405, D Loss: 0.09971793045439625, G Loss: 20.745426177978516\n",
      "Epoch: 38, Batch: 406, D Loss: 0.10778260278164786, G Loss: 20.814821243286133\n",
      "Epoch: 38, Batch: 407, D Loss: 0.10098663017114445, G Loss: 20.855379104614258\n",
      "Epoch: 38, Batch: 408, D Loss: 0.10046254142179606, G Loss: 20.85755729675293\n",
      "Epoch: 38, Batch: 409, D Loss: 0.10167065306992504, G Loss: 20.836849212646484\n",
      "Epoch: 38, Batch: 410, D Loss: 0.0963097815368783, G Loss: 20.769712448120117\n",
      "Epoch: 38, Batch: 411, D Loss: 0.09407711824571874, G Loss: 20.6579647064209\n",
      "Epoch: 38, Batch: 412, D Loss: 0.10190583075385212, G Loss: 20.603227615356445\n",
      "Epoch: 38, Batch: 413, D Loss: 0.09669581112911879, G Loss: 20.573453903198242\n",
      "Epoch: 38, Batch: 414, D Loss: 0.10219156798990486, G Loss: 20.608627319335938\n",
      "Epoch: 38, Batch: 415, D Loss: 0.09979367310537635, G Loss: 20.667217254638672\n",
      "Epoch: 38, Batch: 416, D Loss: 0.10450126281059152, G Loss: 20.760677337646484\n",
      "Epoch: 38, Batch: 417, D Loss: 0.09563991474555883, G Loss: 20.801715850830078\n",
      "Epoch: 38, Batch: 418, D Loss: 0.10205509559134926, G Loss: 20.831180572509766\n",
      "Epoch: 38, Batch: 419, D Loss: 0.09683734969082369, G Loss: 20.806211471557617\n",
      "Epoch: 38, Batch: 420, D Loss: 0.10253660427425038, G Loss: 20.783140182495117\n",
      "Epoch: 38, Batch: 421, D Loss: 0.09223574449098787, G Loss: 20.701841354370117\n",
      "Epoch: 38, Batch: 422, D Loss: 0.09611263179506452, G Loss: 20.61850929260254\n",
      "Epoch: 38, Batch: 423, D Loss: 0.10003228542064041, G Loss: 20.586137771606445\n",
      "Epoch: 38, Batch: 424, D Loss: 0.10554982777484218, G Loss: 20.642393112182617\n",
      "Epoch: 38, Batch: 425, D Loss: 0.09179756844055698, G Loss: 20.662097930908203\n",
      "Epoch: 38, Batch: 426, D Loss: 0.09949621610286047, G Loss: 20.700387954711914\n",
      "Epoch: 38, Batch: 427, D Loss: 0.10326306571300475, G Loss: 20.76654052734375\n",
      "Epoch: 38, Batch: 428, D Loss: 0.09829920577210166, G Loss: 20.80632781982422\n",
      "Epoch: 38, Batch: 429, D Loss: 0.09971465215986805, G Loss: 20.823522567749023\n",
      "Epoch: 38, Batch: 430, D Loss: 0.09308341191917502, G Loss: 20.774789810180664\n",
      "Epoch: 38, Batch: 431, D Loss: 0.09602430512085297, G Loss: 20.7056884765625\n",
      "Epoch: 38, Batch: 432, D Loss: 0.1016647746356879, G Loss: 20.67995262145996\n",
      "Epoch: 38, Batch: 433, D Loss: 0.09686235391086995, G Loss: 20.664701461791992\n",
      "Epoch: 38, Batch: 434, D Loss: 0.10357089392520996, G Loss: 20.707639694213867\n",
      "Epoch: 38, Batch: 435, D Loss: 0.1027103816386255, G Loss: 20.782058715820312\n",
      "Epoch: 38, Batch: 436, D Loss: 0.09419491188688806, G Loss: 20.80207633972168\n",
      "Epoch: 38, Batch: 437, D Loss: 0.10278984949784345, G Loss: 20.831727981567383\n",
      "Epoch: 38, Batch: 438, D Loss: 0.10052260800968843, G Loss: 20.848203659057617\n",
      "Epoch: 38, Batch: 439, D Loss: 0.09907161488731794, G Loss: 20.84064483642578\n",
      "Epoch: 38, Batch: 440, D Loss: 0.10055956289247608, G Loss: 20.827285766601562\n",
      "Epoch: 38, Batch: 441, D Loss: 0.09839440928010423, G Loss: 20.796213150024414\n",
      "Epoch: 38, Batch: 442, D Loss: 0.10152076231554596, G Loss: 20.783212661743164\n",
      "Epoch: 38, Batch: 443, D Loss: 0.10013745772279836, G Loss: 20.777109146118164\n",
      "Epoch: 38, Batch: 444, D Loss: 0.09845663654990328, G Loss: 20.757652282714844\n",
      "Epoch: 38, Batch: 445, D Loss: 0.10370150255961164, G Loss: 20.790382385253906\n",
      "Epoch: 38, Batch: 446, D Loss: 0.09934504376049968, G Loss: 20.825849533081055\n",
      "Epoch: 38, Batch: 447, D Loss: 0.09270086931042393, G Loss: 20.767066955566406\n",
      "Epoch: 38, Batch: 448, D Loss: 0.09490220298754587, G Loss: 20.68172836303711\n",
      "Epoch: 38, Batch: 449, D Loss: 0.09822279267929807, G Loss: 20.647512435913086\n",
      "Epoch: 38, Batch: 450, D Loss: 0.09638337845596301, G Loss: 20.62331199645996\n",
      "Epoch: 38, Batch: 451, D Loss: 0.10442388110003714, G Loss: 20.7278995513916\n",
      "Epoch: 38, Batch: 452, D Loss: 0.098904863481453, G Loss: 20.78995704650879\n",
      "Epoch: 38, Batch: 453, D Loss: 0.09719993219895831, G Loss: 20.8292236328125\n",
      "Epoch: 38, Batch: 454, D Loss: 0.09422121987256396, G Loss: 20.819229125976562\n",
      "Epoch: 38, Batch: 455, D Loss: 0.1007101689356619, G Loss: 20.817106246948242\n",
      "Epoch: 38, Batch: 456, D Loss: 0.09610720025038708, G Loss: 20.787899017333984\n",
      "Epoch: 38, Batch: 457, D Loss: 0.1007245485722903, G Loss: 20.779285430908203\n",
      "Epoch: 38, Batch: 458, D Loss: 0.09537617910228802, G Loss: 20.750341415405273\n",
      "Epoch: 38, Batch: 459, D Loss: 0.09921862233858836, G Loss: 20.74295425415039\n",
      "Epoch: 38, Batch: 460, D Loss: 0.10428667116208307, G Loss: 20.794038772583008\n",
      "Epoch: 38, Batch: 461, D Loss: 0.10015425876358078, G Loss: 20.848106384277344\n",
      "Epoch: 38, Batch: 462, D Loss: 0.09742404564165727, G Loss: 20.868867874145508\n",
      "Epoch: 38, Batch: 463, D Loss: 0.09749084754446416, G Loss: 20.862550735473633\n",
      "Epoch: 38, Batch: 464, D Loss: 0.09569837197440595, G Loss: 20.82009506225586\n",
      "Epoch: 38, Batch: 465, D Loss: 0.100476012093485, G Loss: 20.796253204345703\n",
      "Epoch: 38, Batch: 466, D Loss: 0.10173288779041714, G Loss: 20.804813385009766\n",
      "Epoch: 38, Batch: 467, D Loss: 0.10047286794452509, G Loss: 20.826414108276367\n",
      "Epoch: 39, Batch: 0, D Loss: 0.09537610457006424, G Loss: 20.815494537353516\n",
      "Epoch: 39, Batch: 1, D Loss: 0.0961694349505137, G Loss: 20.78769874572754\n",
      "Epoch: 39, Batch: 2, D Loss: 0.102816895114788, G Loss: 20.806041717529297\n",
      "Epoch: 39, Batch: 3, D Loss: 0.09867043838775236, G Loss: 20.825002670288086\n",
      "Epoch: 39, Batch: 4, D Loss: 0.10028040453651146, G Loss: 20.85053253173828\n",
      "Epoch: 39, Batch: 5, D Loss: 0.10257051183095575, G Loss: 20.894168853759766\n",
      "Epoch: 39, Batch: 6, D Loss: 0.0985283259760657, G Loss: 20.908279418945312\n",
      "Epoch: 39, Batch: 7, D Loss: 0.09628255707488295, G Loss: 20.879724502563477\n",
      "Epoch: 39, Batch: 8, D Loss: 0.09508792355188342, G Loss: 20.815147399902344\n",
      "Epoch: 39, Batch: 9, D Loss: 0.10006290720715674, G Loss: 20.77831268310547\n",
      "Epoch: 39, Batch: 10, D Loss: 0.09965655255065264, G Loss: 20.774059295654297\n",
      "Epoch: 39, Batch: 11, D Loss: 0.0976392929519786, G Loss: 20.781478881835938\n",
      "Epoch: 39, Batch: 12, D Loss: 0.1026648660122115, G Loss: 20.834213256835938\n",
      "Epoch: 39, Batch: 13, D Loss: 0.09875273748183658, G Loss: 20.88133430480957\n",
      "Epoch: 39, Batch: 14, D Loss: 0.09888532799785696, G Loss: 20.91118049621582\n",
      "Epoch: 39, Batch: 15, D Loss: 0.10178723972033327, G Loss: 20.944297790527344\n",
      "Epoch: 39, Batch: 16, D Loss: 0.10225606004157556, G Loss: 20.97246551513672\n",
      "Epoch: 39, Batch: 17, D Loss: 0.10136047044433735, G Loss: 20.98191261291504\n",
      "Epoch: 39, Batch: 18, D Loss: 0.09902347663386277, G Loss: 20.958547592163086\n",
      "Epoch: 39, Batch: 19, D Loss: 0.1000357721305486, G Loss: 20.921422958374023\n",
      "Epoch: 39, Batch: 20, D Loss: 0.1020822156638527, G Loss: 20.902193069458008\n",
      "Epoch: 39, Batch: 21, D Loss: 0.1059438292329283, G Loss: 20.931324005126953\n",
      "Epoch: 39, Batch: 22, D Loss: 0.09980075101681846, G Loss: 20.943063735961914\n",
      "Epoch: 39, Batch: 23, D Loss: 0.09849469404117886, G Loss: 20.929277420043945\n",
      "Epoch: 39, Batch: 24, D Loss: 0.1060572419599338, G Loss: 20.957643508911133\n",
      "Epoch: 39, Batch: 25, D Loss: 0.10315260330018247, G Loss: 20.988462448120117\n",
      "Epoch: 39, Batch: 26, D Loss: 0.10340766646611016, G Loss: 21.011323928833008\n",
      "Epoch: 39, Batch: 27, D Loss: 0.09755334296187643, G Loss: 20.98012351989746\n",
      "Epoch: 39, Batch: 28, D Loss: 0.09862635324487007, G Loss: 20.924453735351562\n",
      "Epoch: 39, Batch: 29, D Loss: 0.10132697266350132, G Loss: 20.88553810119629\n",
      "Epoch: 39, Batch: 30, D Loss: 0.10130421860105923, G Loss: 20.86903953552246\n",
      "Epoch: 39, Batch: 31, D Loss: 0.09772180064747374, G Loss: 20.837718963623047\n",
      "Epoch: 39, Batch: 32, D Loss: 0.09207020746782241, G Loss: 20.74571990966797\n",
      "Epoch: 39, Batch: 33, D Loss: 0.09646049192291539, G Loss: 20.687728881835938\n",
      "Epoch: 39, Batch: 34, D Loss: 0.10571718265015301, G Loss: 20.79059410095215\n",
      "Epoch: 39, Batch: 35, D Loss: 0.097235963195385, G Loss: 20.861385345458984\n",
      "Epoch: 39, Batch: 36, D Loss: 0.10162546527666066, G Loss: 20.929941177368164\n",
      "Epoch: 39, Batch: 37, D Loss: 0.10662312844291216, G Loss: 21.026962280273438\n",
      "Epoch: 39, Batch: 38, D Loss: 0.1003690812614649, G Loss: 21.07250213623047\n",
      "Epoch: 39, Batch: 39, D Loss: 0.09811727738358983, G Loss: 21.046905517578125\n",
      "Epoch: 39, Batch: 40, D Loss: 0.10562538392120926, G Loss: 21.02838134765625\n",
      "Epoch: 39, Batch: 41, D Loss: 0.10171248801389601, G Loss: 20.990768432617188\n",
      "Epoch: 39, Batch: 42, D Loss: 0.0990466106910235, G Loss: 20.92920684814453\n",
      "Epoch: 39, Batch: 43, D Loss: 0.10045064282540359, G Loss: 20.87615394592285\n",
      "Epoch: 39, Batch: 44, D Loss: 0.09404006645142296, G Loss: 20.795886993408203\n",
      "Epoch: 39, Batch: 45, D Loss: 0.09623825598144858, G Loss: 20.732927322387695\n",
      "Epoch: 39, Batch: 46, D Loss: 0.1012023394273544, G Loss: 20.73992347717285\n",
      "Epoch: 39, Batch: 47, D Loss: 0.09094064732325857, G Loss: 20.723527908325195\n",
      "Epoch: 39, Batch: 48, D Loss: 0.10147831637639665, G Loss: 20.774890899658203\n",
      "Epoch: 39, Batch: 49, D Loss: 0.09578135656058842, G Loss: 20.817567825317383\n",
      "Epoch: 39, Batch: 50, D Loss: 0.09963267340724205, G Loss: 20.873950958251953\n",
      "Epoch: 39, Batch: 51, D Loss: 0.10012742173793185, G Loss: 20.926023483276367\n",
      "Epoch: 39, Batch: 52, D Loss: 0.09902867715021071, G Loss: 20.95570182800293\n",
      "Epoch: 39, Batch: 53, D Loss: 0.10072559157553065, G Loss: 20.972570419311523\n",
      "Epoch: 39, Batch: 54, D Loss: 0.093353018565377, G Loss: 20.919296264648438\n",
      "Epoch: 39, Batch: 55, D Loss: 0.09897095007296283, G Loss: 20.863941192626953\n",
      "Epoch: 39, Batch: 56, D Loss: 0.09817572727640847, G Loss: 20.816232681274414\n",
      "Epoch: 39, Batch: 57, D Loss: 0.1041509737121345, G Loss: 20.832603454589844\n",
      "Epoch: 39, Batch: 58, D Loss: 0.09630602642780867, G Loss: 20.842546463012695\n",
      "Epoch: 39, Batch: 59, D Loss: 0.09754801585765108, G Loss: 20.850393295288086\n",
      "Epoch: 39, Batch: 60, D Loss: 0.10080304785224573, G Loss: 20.87945556640625\n",
      "Epoch: 39, Batch: 61, D Loss: 0.10088108521881115, G Loss: 20.918376922607422\n",
      "Epoch: 39, Batch: 62, D Loss: 0.09746007662233833, G Loss: 20.92736053466797\n",
      "Epoch: 39, Batch: 63, D Loss: 0.09701904695710942, G Loss: 20.907119750976562\n",
      "Epoch: 39, Batch: 64, D Loss: 0.0959072787848495, G Loss: 20.86259651184082\n",
      "Epoch: 39, Batch: 65, D Loss: 0.09850220426490408, G Loss: 20.828935623168945\n",
      "Epoch: 39, Batch: 66, D Loss: 0.10437387272242643, G Loss: 20.861238479614258\n",
      "Epoch: 39, Batch: 67, D Loss: 0.0969629739072094, G Loss: 20.8780574798584\n",
      "Epoch: 39, Batch: 68, D Loss: 0.102998212397892, G Loss: 20.92426872253418\n",
      "Epoch: 39, Batch: 69, D Loss: 0.09513927291953089, G Loss: 20.926389694213867\n",
      "Epoch: 39, Batch: 70, D Loss: 0.10200063924706015, G Loss: 20.943389892578125\n",
      "Epoch: 39, Batch: 71, D Loss: 0.10370802918717414, G Loss: 20.978618621826172\n",
      "Epoch: 39, Batch: 72, D Loss: 0.10363567658456402, G Loss: 21.017946243286133\n",
      "Epoch: 39, Batch: 73, D Loss: 0.10252124107892804, G Loss: 21.042020797729492\n",
      "Epoch: 39, Batch: 74, D Loss: 0.09619088508097884, G Loss: 21.000244140625\n",
      "Epoch: 39, Batch: 75, D Loss: 0.10675503351543986, G Loss: 20.995376586914062\n",
      "Epoch: 39, Batch: 76, D Loss: 0.0991235081247338, G Loss: 20.967037200927734\n",
      "Epoch: 39, Batch: 77, D Loss: 0.09860013465441395, G Loss: 20.923572540283203\n",
      "Epoch: 39, Batch: 78, D Loss: 0.09609049600885938, G Loss: 20.863174438476562\n",
      "Epoch: 39, Batch: 79, D Loss: 0.10594780786124988, G Loss: 20.883913040161133\n",
      "Epoch: 39, Batch: 80, D Loss: 0.0973662663753761, G Loss: 20.897512435913086\n",
      "Epoch: 39, Batch: 81, D Loss: 0.09707302642070265, G Loss: 20.901216506958008\n",
      "Epoch: 39, Batch: 82, D Loss: 0.1050884280690928, G Loss: 20.957706451416016\n",
      "Epoch: 39, Batch: 83, D Loss: 0.09578067103609225, G Loss: 20.96873664855957\n",
      "Epoch: 39, Batch: 84, D Loss: 0.0977873657110607, G Loss: 20.956493377685547\n",
      "Epoch: 39, Batch: 85, D Loss: 0.10250370243792528, G Loss: 20.968881607055664\n",
      "Epoch: 39, Batch: 86, D Loss: 0.09987260440250265, G Loss: 20.974334716796875\n",
      "Epoch: 39, Batch: 87, D Loss: 0.09764602819617474, G Loss: 20.956104278564453\n",
      "Epoch: 39, Batch: 88, D Loss: 0.10570311585276762, G Loss: 20.988279342651367\n",
      "Epoch: 39, Batch: 89, D Loss: 0.09700847455586659, G Loss: 20.9829158782959\n",
      "Epoch: 39, Batch: 90, D Loss: 0.0963440243364787, G Loss: 20.94461441040039\n",
      "Epoch: 39, Batch: 91, D Loss: 0.09542882483860535, G Loss: 20.883323669433594\n",
      "Epoch: 39, Batch: 92, D Loss: 0.0964824114655044, G Loss: 20.82842445373535\n",
      "Epoch: 39, Batch: 93, D Loss: 0.10065623417764955, G Loss: 20.83015251159668\n",
      "Epoch: 39, Batch: 94, D Loss: 0.10001190050625322, G Loss: 20.874706268310547\n",
      "Epoch: 39, Batch: 95, D Loss: 0.1016399864508763, G Loss: 20.951738357543945\n",
      "Epoch: 39, Batch: 96, D Loss: 0.0962288532581872, G Loss: 20.989301681518555\n",
      "Epoch: 39, Batch: 97, D Loss: 0.09434244075324597, G Loss: 20.97315216064453\n",
      "Epoch: 39, Batch: 98, D Loss: 0.0968542475497304, G Loss: 20.937101364135742\n",
      "Epoch: 39, Batch: 99, D Loss: 0.0922809843457342, G Loss: 20.858139038085938\n",
      "Epoch: 39, Batch: 100, D Loss: 0.0930789192120057, G Loss: 20.77288055419922\n",
      "Epoch: 39, Batch: 101, D Loss: 0.10256468551974973, G Loss: 20.783910751342773\n",
      "Epoch: 39, Batch: 102, D Loss: 0.10842576666917414, G Loss: 20.913366317749023\n",
      "Epoch: 39, Batch: 103, D Loss: 0.08963282446777082, G Loss: 20.955154418945312\n",
      "Epoch: 39, Batch: 104, D Loss: 0.0968581591009767, G Loss: 20.970481872558594\n",
      "Epoch: 39, Batch: 105, D Loss: 0.09928198197592353, G Loss: 20.980222702026367\n",
      "Epoch: 39, Batch: 106, D Loss: 0.10435149111457281, G Loss: 21.02059555053711\n",
      "Epoch: 39, Batch: 107, D Loss: 0.09889712966660452, G Loss: 21.03122901916504\n",
      "Epoch: 39, Batch: 108, D Loss: 0.10464330053738846, G Loss: 21.061288833618164\n",
      "Epoch: 39, Batch: 109, D Loss: 0.10215199029021141, G Loss: 21.078575134277344\n",
      "Epoch: 39, Batch: 110, D Loss: 0.10343536769442613, G Loss: 21.088809967041016\n",
      "Epoch: 39, Batch: 111, D Loss: 0.10449200158030075, G Loss: 21.100427627563477\n",
      "Epoch: 39, Batch: 112, D Loss: 0.09528514778223321, G Loss: 21.041423797607422\n",
      "Epoch: 39, Batch: 113, D Loss: 0.0945831243072959, G Loss: 20.933446884155273\n",
      "Epoch: 39, Batch: 114, D Loss: 0.10401502292981327, G Loss: 20.894805908203125\n",
      "Epoch: 39, Batch: 115, D Loss: 0.10252621811662901, G Loss: 20.91126823425293\n",
      "Epoch: 39, Batch: 116, D Loss: 0.10002085607098099, G Loss: 20.950916290283203\n",
      "Epoch: 39, Batch: 117, D Loss: 0.10245540776610254, G Loss: 21.014789581298828\n",
      "Epoch: 39, Batch: 118, D Loss: 0.10521982646011352, G Loss: 21.096357345581055\n",
      "Epoch: 39, Batch: 119, D Loss: 0.10110156271667761, G Loss: 21.14344024658203\n",
      "Epoch: 39, Batch: 120, D Loss: 0.10252746972196822, G Loss: 21.16150665283203\n",
      "Epoch: 39, Batch: 121, D Loss: 0.10467754336616764, G Loss: 21.164608001708984\n",
      "Epoch: 39, Batch: 122, D Loss: 0.10361190917758323, G Loss: 21.147377014160156\n",
      "Epoch: 39, Batch: 123, D Loss: 0.10055658254863689, G Loss: 21.095783233642578\n",
      "Epoch: 39, Batch: 124, D Loss: 0.09826459026523335, G Loss: 21.01471519470215\n",
      "Epoch: 39, Batch: 125, D Loss: 0.10203351118838114, G Loss: 20.96152687072754\n",
      "Epoch: 39, Batch: 126, D Loss: 0.09883464912993323, G Loss: 20.92547035217285\n",
      "Epoch: 39, Batch: 127, D Loss: 0.10289984981922573, G Loss: 20.94459342956543\n",
      "Epoch: 39, Batch: 128, D Loss: 0.10018304774709721, G Loss: 20.982284545898438\n",
      "Epoch: 39, Batch: 129, D Loss: 0.0966137576951559, G Loss: 20.997461318969727\n",
      "Epoch: 39, Batch: 130, D Loss: 0.09917075224726218, G Loss: 21.010162353515625\n",
      "Epoch: 39, Batch: 131, D Loss: 0.10327793694506421, G Loss: 21.051223754882812\n",
      "Epoch: 39, Batch: 132, D Loss: 0.10056144034584036, G Loss: 21.07977294921875\n",
      "Epoch: 39, Batch: 133, D Loss: 0.10137751733220593, G Loss: 21.0950984954834\n",
      "Epoch: 39, Batch: 134, D Loss: 0.0952037948923744, G Loss: 21.04798126220703\n",
      "Epoch: 39, Batch: 135, D Loss: 0.09658674188295197, G Loss: 20.972997665405273\n",
      "Epoch: 39, Batch: 136, D Loss: 0.08951735538255559, G Loss: 20.841609954833984\n",
      "Epoch: 39, Batch: 137, D Loss: 0.09724687831089673, G Loss: 20.767772674560547\n",
      "Epoch: 39, Batch: 138, D Loss: 0.0952819292611154, G Loss: 20.747419357299805\n",
      "Epoch: 39, Batch: 139, D Loss: 0.10222533391671376, G Loss: 20.84147834777832\n",
      "Epoch: 39, Batch: 140, D Loss: 0.1021478180215935, G Loss: 20.99416160583496\n",
      "Epoch: 39, Batch: 141, D Loss: 0.10227820312318345, G Loss: 21.15085220336914\n",
      "Epoch: 39, Batch: 142, D Loss: 0.09664181651299616, G Loss: 21.22136116027832\n",
      "Epoch: 39, Batch: 143, D Loss: 0.10403576523018676, G Loss: 21.261186599731445\n",
      "Epoch: 39, Batch: 144, D Loss: 0.1011350157824949, G Loss: 21.242849349975586\n",
      "Epoch: 39, Batch: 145, D Loss: 0.0996026772363734, G Loss: 21.17416000366211\n",
      "Epoch: 39, Batch: 146, D Loss: 0.09838002953768288, G Loss: 21.07159996032715\n",
      "Epoch: 39, Batch: 147, D Loss: 0.10182748026470922, G Loss: 21.00346565246582\n",
      "Epoch: 39, Batch: 148, D Loss: 0.09596666732829842, G Loss: 20.936264038085938\n",
      "Epoch: 39, Batch: 149, D Loss: 0.1005139727485336, G Loss: 20.924936294555664\n",
      "Epoch: 39, Batch: 150, D Loss: 0.09896868507634363, G Loss: 20.95151710510254\n",
      "Epoch: 39, Batch: 151, D Loss: 0.0994401950523113, G Loss: 21.009952545166016\n",
      "Epoch: 39, Batch: 152, D Loss: 0.10227238422651352, G Loss: 21.100814819335938\n",
      "Epoch: 39, Batch: 153, D Loss: 0.09990508887403002, G Loss: 21.17221450805664\n",
      "Epoch: 39, Batch: 154, D Loss: 0.10101848871866786, G Loss: 21.218183517456055\n",
      "Epoch: 39, Batch: 155, D Loss: 0.10365223914568811, G Loss: 21.249357223510742\n",
      "Epoch: 39, Batch: 156, D Loss: 0.09814998537613401, G Loss: 21.213228225708008\n",
      "Epoch: 39, Batch: 157, D Loss: 0.09612624379461007, G Loss: 21.11530303955078\n",
      "Epoch: 39, Batch: 158, D Loss: 0.10034002398962491, G Loss: 21.032928466796875\n",
      "Epoch: 39, Batch: 159, D Loss: 0.095050827052865, G Loss: 20.945449829101562\n",
      "Epoch: 39, Batch: 160, D Loss: 0.09523177188355142, G Loss: 20.87994956970215\n",
      "Epoch: 39, Batch: 161, D Loss: 0.09944754136431028, G Loss: 20.889131546020508\n",
      "Epoch: 39, Batch: 162, D Loss: 0.08686475499028351, G Loss: 20.848861694335938\n",
      "Epoch: 39, Batch: 163, D Loss: 0.09588087394074568, G Loss: 20.85565185546875\n",
      "Epoch: 39, Batch: 164, D Loss: 0.10070233833928213, G Loss: 20.941669464111328\n",
      "Epoch: 39, Batch: 165, D Loss: 0.09521731772861244, G Loss: 21.019105911254883\n",
      "Epoch: 39, Batch: 166, D Loss: 0.10242441331739849, G Loss: 21.12581443786621\n",
      "Epoch: 39, Batch: 167, D Loss: 0.09926746817813276, G Loss: 21.198715209960938\n",
      "Epoch: 39, Batch: 168, D Loss: 0.10311182618477263, G Loss: 21.257240295410156\n",
      "Epoch: 39, Batch: 169, D Loss: 0.10094258963399058, G Loss: 21.268640518188477\n",
      "Epoch: 39, Batch: 170, D Loss: 0.09877926885951607, G Loss: 21.223915100097656\n",
      "Epoch: 39, Batch: 171, D Loss: 0.0964149686898852, G Loss: 21.129499435424805\n",
      "Epoch: 39, Batch: 172, D Loss: 0.10260848735446615, G Loss: 21.065641403198242\n",
      "Epoch: 39, Batch: 173, D Loss: 0.10531890427696927, G Loss: 21.071683883666992\n",
      "Epoch: 39, Batch: 174, D Loss: 0.09896750783256977, G Loss: 21.082088470458984\n",
      "Epoch: 39, Batch: 175, D Loss: 0.08953270352320214, G Loss: 21.013965606689453\n",
      "Epoch: 39, Batch: 176, D Loss: 0.09728485384172075, G Loss: 20.966630935668945\n",
      "Epoch: 39, Batch: 177, D Loss: 0.09425435255212491, G Loss: 20.929349899291992\n",
      "Epoch: 39, Batch: 178, D Loss: 0.10178832004502916, G Loss: 20.972732543945312\n",
      "Epoch: 39, Batch: 179, D Loss: 0.11000256276176096, G Loss: 21.13227653503418\n",
      "Epoch: 39, Batch: 180, D Loss: 0.0957552644793076, G Loss: 21.22521209716797\n",
      "Epoch: 39, Batch: 181, D Loss: 0.10103164642672186, G Loss: 21.278892517089844\n",
      "Epoch: 39, Batch: 182, D Loss: 0.1061109605251391, G Loss: 21.324878692626953\n",
      "Epoch: 39, Batch: 183, D Loss: 0.09812033204333045, G Loss: 21.28959083557129\n",
      "Epoch: 39, Batch: 184, D Loss: 0.10086126654932623, G Loss: 21.222850799560547\n",
      "Epoch: 39, Batch: 185, D Loss: 0.09982474179942827, G Loss: 21.141273498535156\n",
      "Epoch: 39, Batch: 186, D Loss: 0.09144904499909812, G Loss: 21.00090980529785\n",
      "Epoch: 39, Batch: 187, D Loss: 0.0989943597695137, G Loss: 20.918989181518555\n",
      "Epoch: 39, Batch: 188, D Loss: 0.097373515783301, G Loss: 20.897613525390625\n",
      "Epoch: 39, Batch: 189, D Loss: 0.10669305960233938, G Loss: 21.007770538330078\n",
      "Epoch: 39, Batch: 190, D Loss: 0.09373782611237558, G Loss: 21.085670471191406\n",
      "Epoch: 39, Batch: 191, D Loss: 0.10616271975350203, G Loss: 21.215633392333984\n",
      "Epoch: 39, Batch: 192, D Loss: 0.09786110400824535, G Loss: 21.284381866455078\n",
      "Epoch: 39, Batch: 193, D Loss: 0.09691645233667551, G Loss: 21.276615142822266\n",
      "Epoch: 39, Batch: 194, D Loss: 0.09532946378154813, G Loss: 21.198034286499023\n",
      "Epoch: 39, Batch: 195, D Loss: 0.09866530480737201, G Loss: 21.11212730407715\n",
      "Epoch: 39, Batch: 196, D Loss: 0.09512742644407934, G Loss: 21.0170841217041\n",
      "Epoch: 39, Batch: 197, D Loss: 0.09947975762961164, G Loss: 20.979076385498047\n",
      "Epoch: 39, Batch: 198, D Loss: 0.09779103138829442, G Loss: 20.988304138183594\n",
      "Epoch: 39, Batch: 199, D Loss: 0.10164163298586024, G Loss: 21.06028175354004\n",
      "Epoch: 39, Batch: 200, D Loss: 0.1022272560399968, G Loss: 21.1639347076416\n",
      "Epoch: 39, Batch: 201, D Loss: 0.09873665900180462, G Loss: 21.238346099853516\n",
      "Epoch: 39, Batch: 202, D Loss: 0.09856194287162595, G Loss: 21.267024993896484\n",
      "Epoch: 39, Batch: 203, D Loss: 0.10701315133250441, G Loss: 21.316072463989258\n",
      "Epoch: 39, Batch: 204, D Loss: 0.09965520379891563, G Loss: 21.307397842407227\n",
      "Epoch: 39, Batch: 205, D Loss: 0.10335973678380336, G Loss: 21.288246154785156\n",
      "Epoch: 39, Batch: 206, D Loss: 0.10327356337496502, G Loss: 21.26312255859375\n",
      "Epoch: 39, Batch: 207, D Loss: 0.09777522862345592, G Loss: 21.195924758911133\n",
      "Epoch: 39, Batch: 208, D Loss: 0.0941886607130718, G Loss: 21.088077545166016\n",
      "Epoch: 39, Batch: 209, D Loss: 0.10686876659647418, G Loss: 21.082256317138672\n",
      "Epoch: 39, Batch: 210, D Loss: 0.10004489158294211, G Loss: 21.10675621032715\n",
      "Epoch: 39, Batch: 211, D Loss: 0.09591461751984892, G Loss: 21.116456985473633\n",
      "Epoch: 39, Batch: 212, D Loss: 0.09310565178081129, G Loss: 21.087892532348633\n",
      "Epoch: 39, Batch: 213, D Loss: 0.0996147621167294, G Loss: 21.0894775390625\n",
      "Epoch: 39, Batch: 214, D Loss: 0.09900370274432158, G Loss: 21.114238739013672\n",
      "Epoch: 39, Batch: 215, D Loss: 0.10143429073724242, G Loss: 21.171586990356445\n",
      "Epoch: 39, Batch: 216, D Loss: 0.10293740809854574, G Loss: 21.246957778930664\n",
      "Epoch: 39, Batch: 217, D Loss: 0.09289976984277104, G Loss: 21.234222412109375\n",
      "Epoch: 39, Batch: 218, D Loss: 0.09616711766534422, G Loss: 21.183441162109375\n",
      "Epoch: 39, Batch: 219, D Loss: 0.10240395398943455, G Loss: 21.169179916381836\n",
      "Epoch: 39, Batch: 220, D Loss: 0.09065857562954024, G Loss: 21.093402862548828\n",
      "Epoch: 39, Batch: 221, D Loss: 0.10179743205493613, G Loss: 21.081254959106445\n",
      "Epoch: 39, Batch: 222, D Loss: 0.10016901080396606, G Loss: 21.11388397216797\n",
      "Epoch: 39, Batch: 223, D Loss: 0.09959799084229784, G Loss: 21.164432525634766\n",
      "Epoch: 39, Batch: 224, D Loss: 0.09340727361417872, G Loss: 21.164573669433594\n",
      "Epoch: 39, Batch: 225, D Loss: 0.0976982343434512, G Loss: 21.163558959960938\n",
      "Epoch: 39, Batch: 226, D Loss: 0.10276704313080623, G Loss: 21.2042236328125\n",
      "Epoch: 39, Batch: 227, D Loss: 0.10100885510771015, G Loss: 21.252912521362305\n",
      "Epoch: 39, Batch: 228, D Loss: 0.0977248254361541, G Loss: 21.26639175415039\n",
      "Epoch: 39, Batch: 229, D Loss: 0.09546338051401995, G Loss: 21.227581024169922\n",
      "Epoch: 39, Batch: 230, D Loss: 0.09926295311302605, G Loss: 21.187171936035156\n",
      "Epoch: 39, Batch: 231, D Loss: 0.10102577539134625, G Loss: 21.175365447998047\n",
      "Epoch: 39, Batch: 232, D Loss: 0.10166642101285259, G Loss: 21.196247100830078\n",
      "Epoch: 39, Batch: 233, D Loss: 0.1036833751244283, G Loss: 21.253767013549805\n",
      "Epoch: 39, Batch: 234, D Loss: 0.09977731137494256, G Loss: 21.292129516601562\n",
      "Epoch: 39, Batch: 235, D Loss: 0.10506150153921537, G Loss: 21.349689483642578\n",
      "Epoch: 39, Batch: 236, D Loss: 0.1018754768026228, G Loss: 21.376705169677734\n",
      "Epoch: 39, Batch: 237, D Loss: 0.10667587842245027, G Loss: 21.412376403808594\n",
      "Epoch: 39, Batch: 238, D Loss: 0.099772393958309, G Loss: 21.383609771728516\n",
      "Epoch: 39, Batch: 239, D Loss: 0.09877444830591314, G Loss: 21.308372497558594\n",
      "Epoch: 39, Batch: 240, D Loss: 0.09938398777797738, G Loss: 21.221027374267578\n",
      "Epoch: 39, Batch: 241, D Loss: 0.10453221232767862, G Loss: 21.1915283203125\n",
      "Epoch: 39, Batch: 242, D Loss: 0.09775088014215283, G Loss: 21.16179847717285\n",
      "Epoch: 39, Batch: 243, D Loss: 0.10527140678714186, G Loss: 21.20404624938965\n",
      "Epoch: 39, Batch: 244, D Loss: 0.09870692372913673, G Loss: 21.23644256591797\n",
      "Epoch: 39, Batch: 245, D Loss: 0.09744088381580882, G Loss: 21.241334915161133\n",
      "Epoch: 39, Batch: 246, D Loss: 0.10163007706108787, G Loss: 21.259122848510742\n",
      "Epoch: 39, Batch: 247, D Loss: 0.09970584540974789, G Loss: 21.26185417175293\n",
      "Epoch: 39, Batch: 248, D Loss: 0.10230653016925792, G Loss: 21.275651931762695\n",
      "Epoch: 39, Batch: 249, D Loss: 0.09722378879114246, G Loss: 21.252613067626953\n",
      "Epoch: 39, Batch: 250, D Loss: 0.09825624555576415, G Loss: 21.215627670288086\n",
      "Epoch: 39, Batch: 251, D Loss: 0.10165829242148325, G Loss: 21.208560943603516\n",
      "Epoch: 39, Batch: 252, D Loss: 0.10053403706172592, G Loss: 21.218528747558594\n",
      "Epoch: 39, Batch: 253, D Loss: 0.10129825055847824, G Loss: 21.244998931884766\n",
      "Epoch: 39, Batch: 254, D Loss: 0.10454956470914165, G Loss: 21.302104949951172\n",
      "Epoch: 39, Batch: 255, D Loss: 0.09725610939754636, G Loss: 21.310285568237305\n",
      "Epoch: 39, Batch: 256, D Loss: 0.09638461499011292, G Loss: 21.269187927246094\n",
      "Epoch: 39, Batch: 257, D Loss: 0.09103897989728274, G Loss: 21.155977249145508\n",
      "Epoch: 39, Batch: 258, D Loss: 0.09798463467802607, G Loss: 21.076534271240234\n",
      "Epoch: 39, Batch: 259, D Loss: 0.1002774689153324, G Loss: 21.065792083740234\n",
      "Epoch: 39, Batch: 260, D Loss: 0.10206407342991203, G Loss: 21.124889373779297\n",
      "Epoch: 39, Batch: 261, D Loss: 0.09652061047840113, G Loss: 21.181949615478516\n",
      "Epoch: 39, Batch: 262, D Loss: 0.09447535903677412, G Loss: 21.205509185791016\n",
      "Epoch: 39, Batch: 263, D Loss: 0.10264904827074625, G Loss: 21.259845733642578\n",
      "Epoch: 39, Batch: 264, D Loss: 0.09801109909081507, G Loss: 21.283777236938477\n",
      "Epoch: 39, Batch: 265, D Loss: 0.09948739437961168, G Loss: 21.285959243774414\n",
      "Epoch: 39, Batch: 266, D Loss: 0.10067509143297551, G Loss: 21.281272888183594\n",
      "Epoch: 39, Batch: 267, D Loss: 0.09583627461936206, G Loss: 21.23319435119629\n",
      "Epoch: 39, Batch: 268, D Loss: 0.10176837474647202, G Loss: 21.213455200195312\n",
      "Epoch: 39, Batch: 269, D Loss: 0.09650197656348816, G Loss: 21.17892074584961\n",
      "Epoch: 39, Batch: 270, D Loss: 0.10361869664605469, G Loss: 21.19672966003418\n",
      "Epoch: 39, Batch: 271, D Loss: 0.10045436055303739, G Loss: 21.227802276611328\n",
      "Epoch: 39, Batch: 272, D Loss: 0.09676010936875343, G Loss: 21.22854995727539\n",
      "Epoch: 39, Batch: 273, D Loss: 0.10727781086575403, G Loss: 21.289321899414062\n",
      "Epoch: 39, Batch: 274, D Loss: 0.09506813465190869, G Loss: 21.285663604736328\n",
      "Epoch: 39, Batch: 275, D Loss: 0.1037258881178299, G Loss: 21.299915313720703\n",
      "Epoch: 39, Batch: 276, D Loss: 0.10161751536734806, G Loss: 21.304534912109375\n",
      "Epoch: 39, Batch: 277, D Loss: 0.10228449134170087, G Loss: 21.305015563964844\n",
      "Epoch: 39, Batch: 278, D Loss: 0.10048025874617972, G Loss: 21.292165756225586\n",
      "Epoch: 39, Batch: 279, D Loss: 0.10124588041207319, G Loss: 21.278579711914062\n",
      "Epoch: 39, Batch: 280, D Loss: 0.10387281356993297, G Loss: 21.28803825378418\n",
      "Epoch: 39, Batch: 281, D Loss: 0.09438625752355881, G Loss: 21.23480987548828\n",
      "Epoch: 39, Batch: 282, D Loss: 0.09485866160735246, G Loss: 21.15052604675293\n",
      "Epoch: 39, Batch: 283, D Loss: 0.10685612293583138, G Loss: 21.169771194458008\n",
      "Epoch: 39, Batch: 284, D Loss: 0.10001952232514372, G Loss: 21.20623779296875\n",
      "Epoch: 39, Batch: 285, D Loss: 0.10447521537346902, G Loss: 21.284015655517578\n",
      "Epoch: 39, Batch: 286, D Loss: 0.10252788690351797, G Loss: 21.358566284179688\n",
      "Epoch: 39, Batch: 287, D Loss: 0.10065460976220794, G Loss: 21.387853622436523\n",
      "Epoch: 39, Batch: 288, D Loss: 0.10192310090795498, G Loss: 21.384990692138672\n",
      "Epoch: 39, Batch: 289, D Loss: 0.10306409027425065, G Loss: 21.36479949951172\n",
      "Epoch: 39, Batch: 290, D Loss: 0.10057681825933526, G Loss: 21.31678009033203\n",
      "Epoch: 39, Batch: 291, D Loss: 0.09519812493882998, G Loss: 21.212936401367188\n",
      "Epoch: 39, Batch: 292, D Loss: 0.08883617851951361, G Loss: 21.03757095336914\n",
      "Epoch: 39, Batch: 293, D Loss: 0.09866257050208582, G Loss: 20.94594955444336\n",
      "Epoch: 39, Batch: 294, D Loss: 0.0939220939186852, G Loss: 20.909034729003906\n",
      "Epoch: 39, Batch: 295, D Loss: 0.10004318545397017, G Loss: 20.98623275756836\n",
      "Epoch: 39, Batch: 296, D Loss: 0.10402836685563471, G Loss: 21.16642951965332\n",
      "Epoch: 39, Batch: 297, D Loss: 0.09341576725649267, G Loss: 21.281457901000977\n",
      "Epoch: 39, Batch: 298, D Loss: 0.0976768064276766, G Loss: 21.351242065429688\n",
      "Epoch: 39, Batch: 299, D Loss: 0.10186500873365054, G Loss: 21.398746490478516\n",
      "Epoch: 39, Batch: 300, D Loss: 0.09809643800850434, G Loss: 21.385425567626953\n",
      "Epoch: 39, Batch: 301, D Loss: 0.10288906123505975, G Loss: 21.363021850585938\n",
      "Epoch: 39, Batch: 302, D Loss: 0.09756472734100483, G Loss: 21.296863555908203\n",
      "Epoch: 39, Batch: 303, D Loss: 0.09437739878920962, G Loss: 21.188011169433594\n",
      "Epoch: 39, Batch: 304, D Loss: 0.10143753918429163, G Loss: 21.140779495239258\n",
      "Epoch: 39, Batch: 305, D Loss: 0.09976871344458046, G Loss: 21.149019241333008\n",
      "Epoch: 39, Batch: 306, D Loss: 0.09827419402487778, G Loss: 21.183683395385742\n",
      "Epoch: 39, Batch: 307, D Loss: 0.09947734356761748, G Loss: 21.239473342895508\n",
      "Epoch: 39, Batch: 308, D Loss: 0.10291233687313636, G Loss: 21.32516860961914\n",
      "Epoch: 39, Batch: 309, D Loss: 0.10085499313103166, G Loss: 21.391334533691406\n",
      "Epoch: 39, Batch: 310, D Loss: 0.096440211195881, G Loss: 21.383438110351562\n",
      "Epoch: 39, Batch: 311, D Loss: 0.10458563293941145, G Loss: 21.38955307006836\n",
      "Epoch: 39, Batch: 312, D Loss: 0.09511265185277315, G Loss: 21.32101821899414\n",
      "Epoch: 39, Batch: 313, D Loss: 0.09635646670213935, G Loss: 21.222705841064453\n",
      "Epoch: 39, Batch: 314, D Loss: 0.10137413473239454, G Loss: 21.17570686340332\n",
      "Epoch: 39, Batch: 315, D Loss: 0.0965173098702134, G Loss: 21.142024993896484\n",
      "Epoch: 39, Batch: 316, D Loss: 0.09973497721457597, G Loss: 21.15406036376953\n",
      "Epoch: 39, Batch: 317, D Loss: 0.09711764784982826, G Loss: 21.17660903930664\n",
      "Epoch: 39, Batch: 318, D Loss: 0.09511297972849589, G Loss: 21.18471336364746\n",
      "Epoch: 39, Batch: 319, D Loss: 0.10176759988920023, G Loss: 21.237709045410156\n",
      "Epoch: 39, Batch: 320, D Loss: 0.09441103070910609, G Loss: 21.247543334960938\n",
      "Epoch: 39, Batch: 321, D Loss: 0.10297895996896678, G Loss: 21.290645599365234\n",
      "Epoch: 39, Batch: 322, D Loss: 0.0946699905273729, G Loss: 21.275136947631836\n",
      "Epoch: 39, Batch: 323, D Loss: 0.10033803462069141, G Loss: 21.268922805786133\n",
      "Epoch: 39, Batch: 324, D Loss: 0.10027705161859321, G Loss: 21.27393913269043\n",
      "Epoch: 39, Batch: 325, D Loss: 0.09751082985827925, G Loss: 21.26030731201172\n",
      "Epoch: 39, Batch: 326, D Loss: 0.09581007838263389, G Loss: 21.222091674804688\n",
      "Epoch: 39, Batch: 327, D Loss: 0.09903094203119311, G Loss: 21.204784393310547\n",
      "Epoch: 39, Batch: 328, D Loss: 0.10269351333893581, G Loss: 21.240644454956055\n",
      "Epoch: 39, Batch: 329, D Loss: 0.1028890910632593, G Loss: 21.313535690307617\n",
      "Epoch: 39, Batch: 330, D Loss: 0.10004308846747578, G Loss: 21.36447525024414\n",
      "Epoch: 39, Batch: 331, D Loss: 0.09680125888750729, G Loss: 21.360383987426758\n",
      "Epoch: 39, Batch: 332, D Loss: 0.09391716150082258, G Loss: 21.28883171081543\n",
      "Epoch: 39, Batch: 333, D Loss: 0.09573689877959662, G Loss: 21.198806762695312\n",
      "Epoch: 39, Batch: 334, D Loss: 0.11010190129777508, G Loss: 21.247020721435547\n",
      "Epoch: 39, Batch: 335, D Loss: 0.08908145159861036, G Loss: 21.211135864257812\n",
      "Epoch: 39, Batch: 336, D Loss: 0.09956894845656841, G Loss: 21.21172523498535\n",
      "Epoch: 39, Batch: 337, D Loss: 0.09831526905906235, G Loss: 21.228498458862305\n",
      "Epoch: 39, Batch: 338, D Loss: 0.09922715306132154, G Loss: 21.261253356933594\n",
      "Epoch: 39, Batch: 339, D Loss: 0.09839576511545145, G Loss: 21.28912925720215\n",
      "Epoch: 39, Batch: 340, D Loss: 0.09638473420000401, G Loss: 21.284292221069336\n",
      "Epoch: 39, Batch: 341, D Loss: 0.09675323992051316, G Loss: 21.260902404785156\n",
      "Epoch: 39, Batch: 342, D Loss: 0.10323759942310448, G Loss: 21.28327751159668\n",
      "Epoch: 39, Batch: 343, D Loss: 0.10525211719322172, G Loss: 21.357528686523438\n",
      "Epoch: 39, Batch: 344, D Loss: 0.10065297808248241, G Loss: 21.407621383666992\n",
      "Epoch: 39, Batch: 345, D Loss: 0.09723176087513344, G Loss: 21.39379119873047\n",
      "Epoch: 39, Batch: 346, D Loss: 0.09583041098467085, G Loss: 21.32065773010254\n",
      "Epoch: 39, Batch: 347, D Loss: 0.09751123963740285, G Loss: 21.236412048339844\n",
      "Epoch: 39, Batch: 348, D Loss: 0.09401081533943134, G Loss: 21.138893127441406\n",
      "Epoch: 39, Batch: 349, D Loss: 0.09824612770423341, G Loss: 21.097667694091797\n",
      "Epoch: 39, Batch: 350, D Loss: 0.0970189574805353, G Loss: 21.10541343688965\n",
      "Epoch: 39, Batch: 351, D Loss: 0.10408373209299973, G Loss: 21.21251678466797\n",
      "Epoch: 39, Batch: 352, D Loss: 0.09767185180708246, G Loss: 21.30894660949707\n",
      "Epoch: 39, Batch: 353, D Loss: 0.10565687741976273, G Loss: 21.440690994262695\n",
      "Epoch: 39, Batch: 354, D Loss: 0.10002505802824155, G Loss: 21.50748062133789\n",
      "Epoch: 39, Batch: 355, D Loss: 0.09871688508225564, G Loss: 21.486366271972656\n",
      "Epoch: 39, Batch: 356, D Loss: 0.10054344708016338, G Loss: 21.42068862915039\n",
      "Epoch: 39, Batch: 357, D Loss: 0.10307767267857171, G Loss: 21.362773895263672\n",
      "Epoch: 39, Batch: 358, D Loss: 0.09794387248811795, G Loss: 21.285276412963867\n",
      "Epoch: 39, Batch: 359, D Loss: 0.09996956616169847, G Loss: 21.230663299560547\n",
      "Epoch: 39, Batch: 360, D Loss: 0.10016540468316959, G Loss: 21.213356018066406\n",
      "Epoch: 39, Batch: 361, D Loss: 0.10151997983744246, G Loss: 21.247102737426758\n",
      "Epoch: 39, Batch: 362, D Loss: 0.10349971829389934, G Loss: 21.329984664916992\n",
      "Epoch: 39, Batch: 363, D Loss: 0.10140655215960967, G Loss: 21.404521942138672\n",
      "Epoch: 39, Batch: 364, D Loss: 0.09450057174463294, G Loss: 21.38735580444336\n",
      "Epoch: 39, Batch: 365, D Loss: 0.101231031380172, G Loss: 21.365581512451172\n",
      "Epoch: 39, Batch: 366, D Loss: 0.09373287139048023, G Loss: 21.279117584228516\n",
      "Epoch: 39, Batch: 367, D Loss: 0.0947530347158467, G Loss: 21.174468994140625\n",
      "Epoch: 39, Batch: 368, D Loss: 0.09979096832615852, G Loss: 21.134174346923828\n",
      "Epoch: 39, Batch: 369, D Loss: 0.09557271037107704, G Loss: 21.12102699279785\n",
      "Epoch: 39, Batch: 370, D Loss: 0.09234211627822267, G Loss: 21.100614547729492\n",
      "Epoch: 39, Batch: 371, D Loss: 0.10355865988154192, G Loss: 21.184608459472656\n",
      "Epoch: 39, Batch: 372, D Loss: 0.09561444104301281, G Loss: 21.254318237304688\n",
      "Epoch: 39, Batch: 373, D Loss: 0.09229739784685187, G Loss: 21.26129150390625\n",
      "Epoch: 39, Batch: 374, D Loss: 0.10456810919851989, G Loss: 21.325618743896484\n",
      "Epoch: 39, Batch: 375, D Loss: 0.0949604663004871, G Loss: 21.32944107055664\n",
      "Epoch: 39, Batch: 376, D Loss: 0.09661866752185211, G Loss: 21.300321578979492\n",
      "Epoch: 39, Batch: 377, D Loss: 0.09212531178802694, G Loss: 21.211589813232422\n",
      "Epoch: 39, Batch: 378, D Loss: 0.10094444484802667, G Loss: 21.18684196472168\n",
      "Epoch: 39, Batch: 379, D Loss: 0.09329667719577037, G Loss: 21.144529342651367\n",
      "Epoch: 39, Batch: 380, D Loss: 0.09605698320547407, G Loss: 21.130247116088867\n",
      "Epoch: 39, Batch: 381, D Loss: 0.09775503012523296, G Loss: 21.159976959228516\n",
      "Epoch: 39, Batch: 382, D Loss: 0.10318719626142106, G Loss: 21.270936965942383\n",
      "Epoch: 39, Batch: 383, D Loss: 0.10255923149111801, G Loss: 21.404890060424805\n",
      "Epoch: 39, Batch: 384, D Loss: 0.09781292105283945, G Loss: 21.47260856628418\n",
      "Epoch: 39, Batch: 385, D Loss: 0.09809608781167811, G Loss: 21.469635009765625\n",
      "Epoch: 39, Batch: 386, D Loss: 0.0960826578226115, G Loss: 21.391393661499023\n",
      "Epoch: 39, Batch: 387, D Loss: 0.09562404481045483, G Loss: 21.272171020507812\n",
      "Epoch: 39, Batch: 388, D Loss: 0.10166390269887518, G Loss: 21.2191162109375\n",
      "Epoch: 39, Batch: 389, D Loss: 0.09685780138965727, G Loss: 21.185914993286133\n",
      "Epoch: 39, Batch: 390, D Loss: 0.09964099557464223, G Loss: 21.21164894104004\n",
      "Epoch: 39, Batch: 391, D Loss: 0.10288441210332566, G Loss: 21.308704376220703\n",
      "Epoch: 39, Batch: 392, D Loss: 0.09439040747653946, G Loss: 21.353790283203125\n",
      "Epoch: 39, Batch: 393, D Loss: 0.09826339062506745, G Loss: 21.37795066833496\n",
      "Epoch: 39, Batch: 394, D Loss: 0.10072838540689788, G Loss: 21.40260124206543\n",
      "Epoch: 39, Batch: 395, D Loss: 0.10302451277761951, G Loss: 21.442306518554688\n",
      "Epoch: 39, Batch: 396, D Loss: 0.10128495866317427, G Loss: 21.46293067932129\n",
      "Epoch: 39, Batch: 397, D Loss: 0.1025783570993779, G Loss: 21.47361946105957\n",
      "Epoch: 39, Batch: 398, D Loss: 0.10165208601824924, G Loss: 21.46525764465332\n",
      "Epoch: 39, Batch: 399, D Loss: 0.10271208757272576, G Loss: 21.453876495361328\n",
      "Epoch: 39, Batch: 400, D Loss: 0.09340789939417529, G Loss: 21.3609619140625\n",
      "Epoch: 39, Batch: 401, D Loss: 0.09388625650074287, G Loss: 21.231678009033203\n",
      "Epoch: 39, Batch: 402, D Loss: 0.10506047338685767, G Loss: 21.221189498901367\n",
      "Epoch: 39, Batch: 403, D Loss: 0.0955252128897916, G Loss: 21.221487045288086\n",
      "Epoch: 39, Batch: 404, D Loss: 0.09786859929656264, G Loss: 21.25205421447754\n",
      "Epoch: 39, Batch: 405, D Loss: 0.09705609112031297, G Loss: 21.291833877563477\n",
      "Epoch: 39, Batch: 406, D Loss: 0.09864484546354158, G Loss: 21.341459274291992\n",
      "Epoch: 39, Batch: 407, D Loss: 0.10076762761928418, G Loss: 21.403209686279297\n",
      "Epoch: 39, Batch: 408, D Loss: 0.09546015436884331, G Loss: 21.408061981201172\n",
      "Epoch: 39, Batch: 409, D Loss: 0.09620603199684369, G Loss: 21.370559692382812\n",
      "Epoch: 39, Batch: 410, D Loss: 0.09787414994816457, G Loss: 21.325458526611328\n",
      "Epoch: 39, Batch: 411, D Loss: 0.09794183103335316, G Loss: 21.28924560546875\n",
      "Epoch: 39, Batch: 412, D Loss: 0.09743694989774324, G Loss: 21.26851463317871\n",
      "Epoch: 39, Batch: 413, D Loss: 0.10006795852186312, G Loss: 21.29320526123047\n",
      "Epoch: 39, Batch: 414, D Loss: 0.10192964253251194, G Loss: 21.363956451416016\n",
      "Epoch: 39, Batch: 415, D Loss: 0.10250917847236671, G Loss: 21.454952239990234\n",
      "Epoch: 39, Batch: 416, D Loss: 0.10001773410590764, G Loss: 21.507671356201172\n",
      "Epoch: 39, Batch: 417, D Loss: 0.10186271391977794, G Loss: 21.532808303833008\n",
      "Epoch: 39, Batch: 418, D Loss: 0.09676765673399469, G Loss: 21.479326248168945\n",
      "Epoch: 39, Batch: 419, D Loss: 0.09701301182247737, G Loss: 21.376991271972656\n",
      "Epoch: 39, Batch: 420, D Loss: 0.09999713328740462, G Loss: 21.299785614013672\n",
      "Epoch: 39, Batch: 421, D Loss: 0.10112070320642638, G Loss: 21.278635025024414\n",
      "Epoch: 39, Batch: 422, D Loss: 0.10265626041272954, G Loss: 21.325538635253906\n",
      "Epoch: 39, Batch: 423, D Loss: 0.09638510671406422, G Loss: 21.354150772094727\n",
      "Epoch: 39, Batch: 424, D Loss: 0.09126965728823624, G Loss: 21.30913543701172\n",
      "Epoch: 39, Batch: 425, D Loss: 0.09366714983214855, G Loss: 21.24158477783203\n",
      "Epoch: 39, Batch: 426, D Loss: 0.09438841820704372, G Loss: 21.180885314941406\n",
      "Epoch: 39, Batch: 427, D Loss: 0.0875091779594448, G Loss: 21.076416015625\n",
      "Epoch: 39, Batch: 428, D Loss: 0.09898889844820918, G Loss: 21.084671020507812\n",
      "Epoch: 39, Batch: 429, D Loss: 0.10691452058229639, G Loss: 21.253829956054688\n",
      "Epoch: 39, Batch: 430, D Loss: 0.09600102928736634, G Loss: 21.396413803100586\n",
      "Epoch: 39, Batch: 431, D Loss: 0.09515843565005297, G Loss: 21.466995239257812\n",
      "Epoch: 39, Batch: 432, D Loss: 0.09599603736335616, G Loss: 21.466279983520508\n",
      "Epoch: 39, Batch: 433, D Loss: 0.10144534730917801, G Loss: 21.461214065551758\n",
      "Epoch: 39, Batch: 434, D Loss: 0.1008194016844817, G Loss: 21.442089080810547\n",
      "Epoch: 39, Batch: 435, D Loss: 0.09546430434227532, G Loss: 21.37267303466797\n",
      "Epoch: 39, Batch: 436, D Loss: 0.09844218221467291, G Loss: 21.310792922973633\n",
      "Epoch: 39, Batch: 437, D Loss: 0.09476077585464424, G Loss: 21.239049911499023\n",
      "Epoch: 39, Batch: 438, D Loss: 0.0926274287822006, G Loss: 21.1663875579834\n",
      "Epoch: 39, Batch: 439, D Loss: 0.10297474296330211, G Loss: 21.218671798706055\n",
      "Epoch: 39, Batch: 440, D Loss: 0.0998949858443948, G Loss: 21.326745986938477\n",
      "Epoch: 39, Batch: 441, D Loss: 0.09875595595511671, G Loss: 21.429811477661133\n",
      "Epoch: 39, Batch: 442, D Loss: 0.09664800042081553, G Loss: 21.48122787475586\n",
      "Epoch: 39, Batch: 443, D Loss: 0.09924640529682127, G Loss: 21.502092361450195\n",
      "Epoch: 39, Batch: 444, D Loss: 0.0988887252736737, G Loss: 21.486839294433594\n",
      "Epoch: 39, Batch: 445, D Loss: 0.09680539393640547, G Loss: 21.426063537597656\n",
      "Epoch: 39, Batch: 446, D Loss: 0.09420458998515407, G Loss: 21.328649520874023\n",
      "Epoch: 39, Batch: 447, D Loss: 0.10264591155206967, G Loss: 21.30933380126953\n",
      "Epoch: 39, Batch: 448, D Loss: 0.10190944400739102, G Loss: 21.357378005981445\n",
      "Epoch: 39, Batch: 449, D Loss: 0.1047943758482211, G Loss: 21.4710636138916\n",
      "Epoch: 39, Batch: 450, D Loss: 0.09986300789169082, G Loss: 21.55051040649414\n",
      "Epoch: 39, Batch: 451, D Loss: 0.09970782718753288, G Loss: 21.57773780822754\n",
      "Epoch: 39, Batch: 452, D Loss: 0.1046838240936668, G Loss: 21.60135269165039\n",
      "Epoch: 39, Batch: 453, D Loss: 0.10319055637647685, G Loss: 21.600234985351562\n",
      "Epoch: 39, Batch: 454, D Loss: 0.10042086264931199, G Loss: 21.555187225341797\n",
      "Epoch: 39, Batch: 455, D Loss: 0.09978353999855484, G Loss: 21.4788875579834\n",
      "Epoch: 39, Batch: 456, D Loss: 0.10354436958009122, G Loss: 21.43662452697754\n",
      "Epoch: 39, Batch: 457, D Loss: 0.09227094825245297, G Loss: 21.326148986816406\n",
      "Epoch: 39, Batch: 458, D Loss: 0.09917829959006202, G Loss: 21.26723861694336\n",
      "Epoch: 39, Batch: 459, D Loss: 0.10091109602597009, G Loss: 21.284835815429688\n",
      "Epoch: 39, Batch: 460, D Loss: 0.09558811066898332, G Loss: 21.308395385742188\n",
      "Epoch: 39, Batch: 461, D Loss: 0.10144606259375771, G Loss: 21.386180877685547\n",
      "Epoch: 39, Batch: 462, D Loss: 0.09733656818851638, G Loss: 21.442241668701172\n",
      "Epoch: 39, Batch: 463, D Loss: 0.10514929913790144, G Loss: 21.538585662841797\n",
      "Epoch: 39, Batch: 464, D Loss: 0.10222399256063763, G Loss: 21.611509323120117\n",
      "Epoch: 39, Batch: 465, D Loss: 0.09576298317395157, G Loss: 21.577274322509766\n",
      "Epoch: 39, Batch: 466, D Loss: 0.10118002466445133, G Loss: 21.519784927368164\n",
      "Epoch: 39, Batch: 467, D Loss: 0.09574513161241319, G Loss: 21.408676147460938\n",
      "Epoch: 40, Batch: 0, D Loss: 0.1092883947010233, G Loss: 21.424362182617188\n",
      "Epoch: 40, Batch: 1, D Loss: 0.10308842385067879, G Loss: 21.479419708251953\n",
      "Epoch: 40, Batch: 2, D Loss: 0.09711165004505848, G Loss: 21.487180709838867\n",
      "Epoch: 40, Batch: 3, D Loss: 0.09647502773882222, G Loss: 21.45232391357422\n",
      "Epoch: 40, Batch: 4, D Loss: 0.09851507122109665, G Loss: 21.412721633911133\n",
      "Epoch: 40, Batch: 5, D Loss: 0.09537833954979372, G Loss: 21.351198196411133\n",
      "Epoch: 40, Batch: 6, D Loss: 0.10408127334164649, G Loss: 21.38079261779785\n",
      "Epoch: 40, Batch: 7, D Loss: 0.09940639163485496, G Loss: 21.428600311279297\n",
      "Epoch: 40, Batch: 8, D Loss: 0.10222815000868846, G Loss: 21.506948471069336\n",
      "Epoch: 40, Batch: 9, D Loss: 0.09785883896140907, G Loss: 21.5402774810791\n",
      "Epoch: 40, Batch: 10, D Loss: 0.10341002068671525, G Loss: 21.58189582824707\n",
      "Epoch: 40, Batch: 11, D Loss: 0.09696809223891949, G Loss: 21.55769920349121\n",
      "Epoch: 40, Batch: 12, D Loss: 0.0966420697442459, G Loss: 21.48369789123535\n",
      "Epoch: 40, Batch: 13, D Loss: 0.10134723806419271, G Loss: 21.44301986694336\n",
      "Epoch: 40, Batch: 14, D Loss: 0.09517198826240253, G Loss: 21.377368927001953\n",
      "Epoch: 40, Batch: 15, D Loss: 0.0948999377796603, G Loss: 21.31119728088379\n",
      "Epoch: 40, Batch: 16, D Loss: 0.10181593177259668, G Loss: 21.33987808227539\n",
      "Epoch: 40, Batch: 17, D Loss: 0.09912493851020537, G Loss: 21.40619659423828\n",
      "Epoch: 40, Batch: 18, D Loss: 0.10113696032885944, G Loss: 21.50588607788086\n",
      "Epoch: 40, Batch: 19, D Loss: 0.10539586863362442, G Loss: 21.639856338500977\n",
      "Epoch: 40, Batch: 20, D Loss: 0.09673799594027292, G Loss: 21.672685623168945\n",
      "Epoch: 40, Batch: 21, D Loss: 0.09757347424850399, G Loss: 21.61989974975586\n",
      "Epoch: 40, Batch: 22, D Loss: 0.10059347024889542, G Loss: 21.547306060791016\n",
      "Epoch: 40, Batch: 23, D Loss: 0.10459634683829201, G Loss: 21.528257369995117\n",
      "Epoch: 40, Batch: 24, D Loss: 0.09763772063493659, G Loss: 21.483488082885742\n",
      "Epoch: 40, Batch: 25, D Loss: 0.1003051030021549, G Loss: 21.460830688476562\n",
      "Epoch: 40, Batch: 26, D Loss: 0.09637536132920566, G Loss: 21.420576095581055\n",
      "Epoch: 40, Batch: 27, D Loss: 0.09765339667981973, G Loss: 21.396102905273438\n",
      "Epoch: 40, Batch: 28, D Loss: 0.09717811669705737, G Loss: 21.387611389160156\n",
      "Epoch: 40, Batch: 29, D Loss: 0.09782926763744287, G Loss: 21.406150817871094\n",
      "Epoch: 40, Batch: 30, D Loss: 0.10302408063684146, G Loss: 21.494178771972656\n",
      "Epoch: 40, Batch: 31, D Loss: 0.09907084725709259, G Loss: 21.56667709350586\n",
      "Epoch: 40, Batch: 32, D Loss: 0.09594279549103413, G Loss: 21.573204040527344\n",
      "Epoch: 40, Batch: 33, D Loss: 0.09774432353063038, G Loss: 21.540870666503906\n",
      "Epoch: 40, Batch: 34, D Loss: 0.10349205158253603, G Loss: 21.551313400268555\n",
      "Epoch: 40, Batch: 35, D Loss: 0.10165365061922642, G Loss: 21.5710391998291\n",
      "Epoch: 40, Batch: 36, D Loss: 0.09691338262841094, G Loss: 21.542688369750977\n",
      "Epoch: 40, Batch: 37, D Loss: 0.09878202550221053, G Loss: 21.50642204284668\n",
      "Epoch: 40, Batch: 38, D Loss: 0.10786592982470151, G Loss: 21.56863784790039\n",
      "Epoch: 40, Batch: 39, D Loss: 0.096437312876986, G Loss: 21.571510314941406\n",
      "Epoch: 40, Batch: 40, D Loss: 0.1026790218682708, G Loss: 21.59234619140625\n",
      "Epoch: 40, Batch: 41, D Loss: 0.09986010959846599, G Loss: 21.59270668029785\n",
      "Epoch: 40, Batch: 42, D Loss: 0.10008761307882354, G Loss: 21.575849533081055\n",
      "Epoch: 40, Batch: 43, D Loss: 0.09454122207913873, G Loss: 21.498003005981445\n",
      "Epoch: 40, Batch: 44, D Loss: 0.09768528515138797, G Loss: 21.43006706237793\n",
      "Epoch: 40, Batch: 45, D Loss: 0.09737983371214351, G Loss: 21.3868350982666\n",
      "Epoch: 40, Batch: 46, D Loss: 0.09022299972227027, G Loss: 21.305788040161133\n",
      "Epoch: 40, Batch: 47, D Loss: 0.09594491152532542, G Loss: 21.275161743164062\n",
      "Epoch: 40, Batch: 48, D Loss: 0.10245927450640499, G Loss: 21.369251251220703\n",
      "Epoch: 40, Batch: 49, D Loss: 0.10386627191364622, G Loss: 21.543550491333008\n",
      "Epoch: 40, Batch: 50, D Loss: 0.10441841950079657, G Loss: 21.732322692871094\n",
      "Epoch: 40, Batch: 51, D Loss: 0.09521214681773536, G Loss: 21.778474807739258\n",
      "Epoch: 40, Batch: 52, D Loss: 0.10204467939974023, G Loss: 21.765602111816406\n",
      "Epoch: 40, Batch: 53, D Loss: 0.10463913548012266, G Loss: 21.736839294433594\n",
      "Epoch: 40, Batch: 54, D Loss: 0.10165171344002683, G Loss: 21.66997528076172\n",
      "Epoch: 40, Batch: 55, D Loss: 0.10134369155085779, G Loss: 21.594865798950195\n",
      "Epoch: 40, Batch: 56, D Loss: 0.09748265169217135, G Loss: 21.497913360595703\n",
      "Epoch: 40, Batch: 57, D Loss: 0.09362066561707422, G Loss: 21.375944137573242\n",
      "Epoch: 40, Batch: 58, D Loss: 0.09416916993803212, G Loss: 21.281044006347656\n",
      "Epoch: 40, Batch: 59, D Loss: 0.09805299370309095, G Loss: 21.280731201171875\n",
      "Epoch: 40, Batch: 60, D Loss: 0.09855293509977459, G Loss: 21.361968994140625\n",
      "Epoch: 40, Batch: 61, D Loss: 0.09960579896780514, G Loss: 21.49198341369629\n",
      "Epoch: 40, Batch: 62, D Loss: 0.0966468083081209, G Loss: 21.58873176574707\n",
      "Epoch: 40, Batch: 63, D Loss: 0.09396994879902887, G Loss: 21.599687576293945\n",
      "Epoch: 40, Batch: 64, D Loss: 0.0961035864685017, G Loss: 21.56480598449707\n",
      "Epoch: 40, Batch: 65, D Loss: 0.09869699202114857, G Loss: 21.52678871154785\n",
      "Epoch: 40, Batch: 66, D Loss: 0.0976080077191479, G Loss: 21.487876892089844\n",
      "Epoch: 40, Batch: 67, D Loss: 0.10090729617459965, G Loss: 21.491762161254883\n",
      "Epoch: 40, Batch: 68, D Loss: 0.09660421335107058, G Loss: 21.486438751220703\n",
      "Epoch: 40, Batch: 69, D Loss: 0.09907718025864637, G Loss: 21.50625991821289\n",
      "Epoch: 40, Batch: 70, D Loss: 0.09583690040329337, G Loss: 21.505037307739258\n",
      "Epoch: 40, Batch: 71, D Loss: 0.09834771626145623, G Loss: 21.511768341064453\n",
      "Epoch: 40, Batch: 72, D Loss: 0.10122954867679639, G Loss: 21.551986694335938\n",
      "Epoch: 40, Batch: 73, D Loss: 0.09987829647005403, G Loss: 21.589990615844727\n",
      "Epoch: 40, Batch: 74, D Loss: 0.09685121497752897, G Loss: 21.58228302001953\n",
      "Epoch: 40, Batch: 75, D Loss: 0.10388405641892448, G Loss: 21.612939834594727\n",
      "Epoch: 40, Batch: 76, D Loss: 0.10001561811136718, G Loss: 21.62299156188965\n",
      "Epoch: 40, Batch: 77, D Loss: 0.09868305197062566, G Loss: 21.60150909423828\n",
      "Epoch: 40, Batch: 78, D Loss: 0.09693130872222697, G Loss: 21.542539596557617\n",
      "Epoch: 40, Batch: 79, D Loss: 0.10034520946536372, G Loss: 21.5078125\n",
      "Epoch: 40, Batch: 80, D Loss: 0.09387864196108062, G Loss: 21.439523696899414\n",
      "Epoch: 40, Batch: 81, D Loss: 0.09781649733576761, G Loss: 21.40874671936035\n",
      "Epoch: 40, Batch: 82, D Loss: 0.10143046850736948, G Loss: 21.45305061340332\n",
      "Epoch: 40, Batch: 83, D Loss: 0.09447900974726245, G Loss: 21.475595474243164\n",
      "Epoch: 40, Batch: 84, D Loss: 0.09505531215381235, G Loss: 21.47634506225586\n",
      "Epoch: 40, Batch: 85, D Loss: 0.09626048826896835, G Loss: 21.47469711303711\n",
      "Epoch: 40, Batch: 86, D Loss: 0.09625515365348358, G Loss: 21.47438621520996\n",
      "Epoch: 40, Batch: 87, D Loss: 0.10669006429598346, G Loss: 21.578018188476562\n",
      "Epoch: 40, Batch: 88, D Loss: 0.1016686113700873, G Loss: 21.683269500732422\n",
      "Epoch: 40, Batch: 89, D Loss: 0.09721963871519002, G Loss: 21.710294723510742\n",
      "Epoch: 40, Batch: 90, D Loss: 0.10406581330832654, G Loss: 21.732872009277344\n",
      "Epoch: 40, Batch: 91, D Loss: 0.09929518420171961, G Loss: 21.698713302612305\n",
      "Epoch: 40, Batch: 92, D Loss: 0.10374462623633095, G Loss: 21.672828674316406\n",
      "Epoch: 40, Batch: 93, D Loss: 0.09236185273275138, G Loss: 21.552459716796875\n",
      "Epoch: 40, Batch: 94, D Loss: 0.10188958816421581, G Loss: 21.490345001220703\n",
      "Epoch: 40, Batch: 95, D Loss: 0.09415850067431444, G Loss: 21.416793823242188\n",
      "Epoch: 40, Batch: 96, D Loss: 0.09455962504776966, G Loss: 21.36644172668457\n",
      "Epoch: 40, Batch: 97, D Loss: 0.0941729324724897, G Loss: 21.351459503173828\n",
      "Epoch: 40, Batch: 98, D Loss: 0.1022465082558553, G Loss: 21.44788932800293\n",
      "Epoch: 40, Batch: 99, D Loss: 0.1007527562243878, G Loss: 21.589073181152344\n",
      "Epoch: 40, Batch: 100, D Loss: 0.09910455365924828, G Loss: 21.702335357666016\n",
      "Epoch: 40, Batch: 101, D Loss: 0.10604283231278316, G Loss: 21.819026947021484\n",
      "Epoch: 40, Batch: 102, D Loss: 0.10030180232326041, G Loss: 21.844680786132812\n",
      "Epoch: 40, Batch: 103, D Loss: 0.09854787605051764, G Loss: 21.771289825439453\n",
      "Epoch: 40, Batch: 104, D Loss: 0.1002275126052411, G Loss: 21.658559799194336\n",
      "Epoch: 40, Batch: 105, D Loss: 0.09799460342652908, G Loss: 21.530624389648438\n",
      "Epoch: 40, Batch: 106, D Loss: 0.09877882176192163, G Loss: 21.43924331665039\n",
      "Epoch: 40, Batch: 107, D Loss: 0.09735712434024066, G Loss: 21.395580291748047\n",
      "Epoch: 40, Batch: 108, D Loss: 0.09274173554003032, G Loss: 21.357290267944336\n",
      "Epoch: 40, Batch: 109, D Loss: 0.09723732646680766, G Loss: 21.380416870117188\n",
      "Epoch: 40, Batch: 110, D Loss: 0.09813267017524821, G Loss: 21.452192306518555\n",
      "Epoch: 40, Batch: 111, D Loss: 0.10090342931740023, G Loss: 21.572053909301758\n",
      "Epoch: 40, Batch: 112, D Loss: 0.1016843991494604, G Loss: 21.697193145751953\n",
      "Epoch: 40, Batch: 113, D Loss: 0.09764978308064255, G Loss: 21.73996925354004\n",
      "Epoch: 40, Batch: 114, D Loss: 0.0932103695370202, G Loss: 21.661739349365234\n",
      "Epoch: 40, Batch: 115, D Loss: 0.10115067681154068, G Loss: 21.587038040161133\n",
      "Epoch: 40, Batch: 116, D Loss: 0.10419271907552491, G Loss: 21.575862884521484\n",
      "Epoch: 40, Batch: 117, D Loss: 0.09639911375402865, G Loss: 21.531909942626953\n",
      "Epoch: 40, Batch: 118, D Loss: 0.10234475157987272, G Loss: 21.539613723754883\n",
      "Epoch: 40, Batch: 119, D Loss: 0.09214635216138117, G Loss: 21.48134994506836\n",
      "Epoch: 40, Batch: 120, D Loss: 0.1015278401323704, G Loss: 21.48936653137207\n",
      "Epoch: 40, Batch: 121, D Loss: 0.10003878944025851, G Loss: 21.5295467376709\n",
      "Epoch: 40, Batch: 122, D Loss: 0.09821230195006886, G Loss: 21.566566467285156\n",
      "Epoch: 40, Batch: 123, D Loss: 0.09093061111702443, G Loss: 21.508119583129883\n",
      "Epoch: 40, Batch: 124, D Loss: 0.10333356283889492, G Loss: 21.522695541381836\n",
      "Epoch: 40, Batch: 125, D Loss: 0.10043226204514218, G Loss: 21.559118270874023\n",
      "Epoch: 40, Batch: 126, D Loss: 0.09894070050639397, G Loss: 21.58519744873047\n",
      "Epoch: 40, Batch: 127, D Loss: 0.09966074696247558, G Loss: 21.602577209472656\n",
      "Epoch: 40, Batch: 128, D Loss: 0.10078324398112251, G Loss: 21.619028091430664\n",
      "Epoch: 40, Batch: 129, D Loss: 0.10495130737609468, G Loss: 21.671905517578125\n",
      "Epoch: 40, Batch: 130, D Loss: 0.09835240264249855, G Loss: 21.669923782348633\n",
      "Epoch: 40, Batch: 131, D Loss: 0.09943754990784939, G Loss: 21.63545799255371\n",
      "Epoch: 40, Batch: 132, D Loss: 0.10374228676434674, G Loss: 21.62981605529785\n",
      "Epoch: 40, Batch: 133, D Loss: 0.10267756154402466, G Loss: 21.636014938354492\n",
      "Epoch: 40, Batch: 134, D Loss: 0.09334083667462892, G Loss: 21.556617736816406\n",
      "Epoch: 40, Batch: 135, D Loss: 0.09468182199412357, G Loss: 21.44331932067871\n",
      "Epoch: 40, Batch: 136, D Loss: 0.09323935236492945, G Loss: 21.333084106445312\n",
      "Epoch: 40, Batch: 137, D Loss: 0.0999232309796165, G Loss: 21.33147621154785\n",
      "Epoch: 40, Batch: 138, D Loss: 0.09883061822566519, G Loss: 21.40818214416504\n",
      "Epoch: 40, Batch: 139, D Loss: 0.08844971681847733, G Loss: 21.420236587524414\n",
      "Epoch: 40, Batch: 140, D Loss: 0.10433410876615878, G Loss: 21.533004760742188\n",
      "Epoch: 40, Batch: 141, D Loss: 0.09688461593261799, G Loss: 21.612899780273438\n",
      "Epoch: 40, Batch: 142, D Loss: 0.10275688787055717, G Loss: 21.699724197387695\n",
      "Epoch: 40, Batch: 143, D Loss: 0.09478021432100181, G Loss: 21.681699752807617\n",
      "Epoch: 40, Batch: 144, D Loss: 0.09769206513976772, G Loss: 21.61269760131836\n",
      "Epoch: 40, Batch: 145, D Loss: 0.10330852141962786, G Loss: 21.584903717041016\n",
      "Epoch: 40, Batch: 146, D Loss: 0.09878840318956494, G Loss: 21.551759719848633\n",
      "Epoch: 40, Batch: 147, D Loss: 0.10111475012701261, G Loss: 21.550012588500977\n",
      "Epoch: 40, Batch: 148, D Loss: 0.09414993993999816, G Loss: 21.503711700439453\n",
      "Epoch: 40, Batch: 149, D Loss: 0.09837050014116673, G Loss: 21.4779109954834\n",
      "Epoch: 40, Batch: 150, D Loss: 0.10116970562245144, G Loss: 21.507064819335938\n",
      "Epoch: 40, Batch: 151, D Loss: 0.10056513570023452, G Loss: 21.566898345947266\n",
      "Epoch: 40, Batch: 152, D Loss: 0.0952031465521994, G Loss: 21.578819274902344\n",
      "Epoch: 40, Batch: 153, D Loss: 0.09757025561194903, G Loss: 21.572887420654297\n",
      "Epoch: 40, Batch: 154, D Loss: 0.09693060836940998, G Loss: 21.552825927734375\n",
      "Epoch: 40, Batch: 155, D Loss: 0.09975808880687262, G Loss: 21.55259895324707\n",
      "Epoch: 40, Batch: 156, D Loss: 0.1025214495407294, G Loss: 21.595914840698242\n",
      "Epoch: 40, Batch: 157, D Loss: 0.10010146370072495, G Loss: 21.640886306762695\n",
      "Epoch: 40, Batch: 158, D Loss: 0.09933638592415156, G Loss: 21.664993286132812\n",
      "Epoch: 40, Batch: 159, D Loss: 0.10183720309919443, G Loss: 21.688514709472656\n",
      "Epoch: 40, Batch: 160, D Loss: 0.10769106466021239, G Loss: 21.761728286743164\n",
      "Epoch: 40, Batch: 161, D Loss: 0.10185766237474175, G Loss: 21.79629898071289\n",
      "Epoch: 40, Batch: 162, D Loss: 0.09729257243554526, G Loss: 21.74524688720703\n",
      "Epoch: 40, Batch: 163, D Loss: 0.09996639210862052, G Loss: 21.6661319732666\n",
      "Epoch: 40, Batch: 164, D Loss: 0.094862945585628, G Loss: 21.542734146118164\n",
      "Epoch: 40, Batch: 165, D Loss: 0.0997255819342563, G Loss: 21.47203254699707\n",
      "Epoch: 40, Batch: 166, D Loss: 0.09726402187513697, G Loss: 21.443361282348633\n",
      "Epoch: 40, Batch: 167, D Loss: 0.10111661279022913, G Loss: 21.496631622314453\n",
      "Epoch: 40, Batch: 168, D Loss: 0.09718291483773094, G Loss: 21.560941696166992\n",
      "Epoch: 40, Batch: 169, D Loss: 0.09861765822743074, G Loss: 21.63245964050293\n",
      "Epoch: 40, Batch: 170, D Loss: 0.10537255574367671, G Loss: 21.745370864868164\n",
      "Epoch: 40, Batch: 171, D Loss: 0.10454081761020051, G Loss: 21.845848083496094\n",
      "Epoch: 40, Batch: 172, D Loss: 0.09501320140330725, G Loss: 21.801280975341797\n",
      "Epoch: 40, Batch: 173, D Loss: 0.10380622017051744, G Loss: 21.74235725402832\n",
      "Epoch: 40, Batch: 174, D Loss: 0.09922149051360309, G Loss: 21.643808364868164\n",
      "Epoch: 40, Batch: 175, D Loss: 0.10050755760033467, G Loss: 21.55905532836914\n",
      "Epoch: 40, Batch: 176, D Loss: 0.10331170282737007, G Loss: 21.54568099975586\n",
      "Epoch: 40, Batch: 177, D Loss: 0.09523031137918551, G Loss: 21.509933471679688\n",
      "Epoch: 40, Batch: 178, D Loss: 0.10609067998401947, G Loss: 21.581466674804688\n",
      "Epoch: 40, Batch: 179, D Loss: 0.10126283785192051, G Loss: 21.658367156982422\n",
      "Epoch: 40, Batch: 180, D Loss: 0.10295307655144917, G Loss: 21.731760025024414\n",
      "Epoch: 40, Batch: 181, D Loss: 0.1031643750060954, G Loss: 21.780620574951172\n",
      "Epoch: 40, Batch: 182, D Loss: 0.10332729684739221, G Loss: 21.786684036254883\n",
      "Epoch: 40, Batch: 183, D Loss: 0.10656608658349696, G Loss: 21.793542861938477\n",
      "Epoch: 40, Batch: 184, D Loss: 0.09855023044382114, G Loss: 21.71003532409668\n",
      "Epoch: 40, Batch: 185, D Loss: 0.09846800585723908, G Loss: 21.575300216674805\n",
      "Epoch: 40, Batch: 186, D Loss: 0.10420209191497434, G Loss: 21.506874084472656\n",
      "Epoch: 40, Batch: 187, D Loss: 0.09974924498328985, G Loss: 21.46281623840332\n",
      "Epoch: 40, Batch: 188, D Loss: 0.09417834157619101, G Loss: 21.39689064025879\n",
      "Epoch: 40, Batch: 189, D Loss: 0.10165664578916053, G Loss: 21.413394927978516\n",
      "Epoch: 40, Batch: 190, D Loss: 0.10652250074867489, G Loss: 21.547163009643555\n",
      "Epoch: 40, Batch: 191, D Loss: 0.10396198948612888, G Loss: 21.697965621948242\n",
      "Epoch: 40, Batch: 192, D Loss: 0.10266497749145367, G Loss: 21.793848037719727\n",
      "Epoch: 40, Batch: 193, D Loss: 0.09593316930290796, G Loss: 21.73932456970215\n",
      "Epoch: 40, Batch: 194, D Loss: 0.09586352874607904, G Loss: 21.58392906188965\n",
      "Epoch: 40, Batch: 195, D Loss: 0.09475022577849443, G Loss: 21.386571884155273\n",
      "Epoch: 40, Batch: 196, D Loss: 0.09672105340109516, G Loss: 21.24396324157715\n",
      "Epoch: 40, Batch: 197, D Loss: 0.09711378843267252, G Loss: 21.1953182220459\n",
      "Epoch: 40, Batch: 198, D Loss: 0.09227395088990326, G Loss: 21.18779182434082\n",
      "Epoch: 40, Batch: 199, D Loss: 0.10388591914424658, G Loss: 21.349300384521484\n",
      "Epoch: 40, Batch: 200, D Loss: 0.10088992142854217, G Loss: 21.552467346191406\n",
      "Epoch: 40, Batch: 201, D Loss: 0.10177661498356033, G Loss: 21.7331485748291\n",
      "Epoch: 40, Batch: 202, D Loss: 0.09421534109221957, G Loss: 21.75688362121582\n",
      "Epoch: 40, Batch: 203, D Loss: 0.10783369856662413, G Loss: 21.790897369384766\n",
      "Epoch: 40, Batch: 204, D Loss: 0.09597009438492324, G Loss: 21.69318389892578\n",
      "Epoch: 40, Batch: 205, D Loss: 0.09500569125977691, G Loss: 21.513282775878906\n",
      "Epoch: 40, Batch: 206, D Loss: 0.10091046268062942, G Loss: 21.39427947998047\n",
      "Epoch: 40, Batch: 207, D Loss: 0.10133183773408394, G Loss: 21.370819091796875\n",
      "Epoch: 40, Batch: 208, D Loss: 0.09807809468075226, G Loss: 21.398189544677734\n",
      "Epoch: 40, Batch: 209, D Loss: 0.1025138201734008, G Loss: 21.50667953491211\n",
      "Epoch: 40, Batch: 210, D Loss: 0.09680053613666273, G Loss: 21.58346176147461\n",
      "Epoch: 40, Batch: 211, D Loss: 0.09950730970203078, G Loss: 21.63730239868164\n",
      "Epoch: 40, Batch: 212, D Loss: 0.1049585940376923, G Loss: 21.715965270996094\n",
      "Epoch: 40, Batch: 213, D Loss: 0.09733881819974888, G Loss: 21.707931518554688\n",
      "Epoch: 40, Batch: 214, D Loss: 0.09098586460173064, G Loss: 21.569120407104492\n",
      "Epoch: 40, Batch: 215, D Loss: 0.09736274950822242, G Loss: 21.439897537231445\n",
      "Epoch: 40, Batch: 216, D Loss: 0.09892645503449593, G Loss: 21.380094528198242\n",
      "Epoch: 40, Batch: 217, D Loss: 0.10402286822722434, G Loss: 21.4521541595459\n",
      "Epoch: 40, Batch: 218, D Loss: 0.10119251929441926, G Loss: 21.578428268432617\n",
      "Epoch: 40, Batch: 219, D Loss: 0.09836158176580555, G Loss: 21.67673683166504\n",
      "Epoch: 40, Batch: 220, D Loss: 0.09957758355990443, G Loss: 21.730688095092773\n",
      "Epoch: 40, Batch: 221, D Loss: 0.10317495483172104, G Loss: 21.769058227539062\n",
      "Epoch: 40, Batch: 222, D Loss: 0.09655021149136024, G Loss: 21.712955474853516\n",
      "Epoch: 40, Batch: 223, D Loss: 0.10066372175439388, G Loss: 21.641550064086914\n",
      "Epoch: 40, Batch: 224, D Loss: 0.09552103302197967, G Loss: 21.52866554260254\n",
      "Epoch: 40, Batch: 225, D Loss: 0.10206781350486796, G Loss: 21.493616104125977\n",
      "Epoch: 40, Batch: 226, D Loss: 0.0977174791038115, G Loss: 21.485193252563477\n",
      "Epoch: 40, Batch: 227, D Loss: 0.09807731979273906, G Loss: 21.51053237915039\n",
      "Epoch: 40, Batch: 228, D Loss: 0.09251868002755435, G Loss: 21.49100112915039\n",
      "Epoch: 40, Batch: 229, D Loss: 0.09878428303305924, G Loss: 21.511756896972656\n",
      "Epoch: 40, Batch: 230, D Loss: 0.10473354927281982, G Loss: 21.622373580932617\n",
      "Epoch: 40, Batch: 231, D Loss: 0.09356001039613643, G Loss: 21.642271041870117\n",
      "Epoch: 40, Batch: 232, D Loss: 0.10593060423152077, G Loss: 21.725624084472656\n",
      "Epoch: 40, Batch: 233, D Loss: 0.10188388842226333, G Loss: 21.78746223449707\n",
      "Epoch: 40, Batch: 234, D Loss: 0.0993647130074652, G Loss: 21.780899047851562\n",
      "Epoch: 40, Batch: 235, D Loss: 0.09937202203326517, G Loss: 21.71951675415039\n",
      "Epoch: 40, Batch: 236, D Loss: 0.10329632479911914, G Loss: 21.681081771850586\n",
      "Epoch: 40, Batch: 237, D Loss: 0.09603417684834437, G Loss: 21.595687866210938\n",
      "Epoch: 40, Batch: 238, D Loss: 0.10328020921596275, G Loss: 21.57659912109375\n",
      "Epoch: 40, Batch: 239, D Loss: 0.09820044807131878, G Loss: 21.568296432495117\n",
      "Epoch: 40, Batch: 240, D Loss: 0.09867885730220134, G Loss: 21.574251174926758\n",
      "Epoch: 40, Batch: 241, D Loss: 0.10184618851447821, G Loss: 21.626768112182617\n",
      "Epoch: 40, Batch: 242, D Loss: 0.10186296720922412, G Loss: 21.700057983398438\n",
      "Epoch: 40, Batch: 243, D Loss: 0.1027346404219413, G Loss: 21.771930694580078\n",
      "Epoch: 40, Batch: 244, D Loss: 0.09751809406009848, G Loss: 21.762229919433594\n",
      "Epoch: 40, Batch: 245, D Loss: 0.1003134401457766, G Loss: 21.723796844482422\n",
      "Epoch: 40, Batch: 246, D Loss: 0.0991487802972748, G Loss: 21.663455963134766\n",
      "Epoch: 40, Batch: 247, D Loss: 0.10964723695326885, G Loss: 21.727214813232422\n",
      "Epoch: 40, Batch: 248, D Loss: 0.10275331902374502, G Loss: 21.787260055541992\n",
      "Epoch: 40, Batch: 249, D Loss: 0.10096167045077038, G Loss: 21.801380157470703\n",
      "Epoch: 40, Batch: 250, D Loss: 0.09668307769117628, G Loss: 21.72595977783203\n",
      "Epoch: 40, Batch: 251, D Loss: 0.09843669106002956, G Loss: 21.628610610961914\n",
      "Epoch: 40, Batch: 252, D Loss: 0.09635595253669754, G Loss: 21.51873779296875\n",
      "Epoch: 40, Batch: 253, D Loss: 0.09374385351050216, G Loss: 21.405805587768555\n",
      "Epoch: 40, Batch: 254, D Loss: 0.10048637564424329, G Loss: 21.405208587646484\n",
      "Epoch: 40, Batch: 255, D Loss: 0.09783525789378203, G Loss: 21.469926834106445\n",
      "Epoch: 40, Batch: 256, D Loss: 0.10156901202735522, G Loss: 21.611610412597656\n",
      "Epoch: 40, Batch: 257, D Loss: 0.09959103186315915, G Loss: 21.736352920532227\n",
      "Epoch: 40, Batch: 258, D Loss: 0.09692722576741711, G Loss: 21.77750015258789\n",
      "Epoch: 40, Batch: 259, D Loss: 0.10072082298509395, G Loss: 21.78043556213379\n",
      "Epoch: 40, Batch: 260, D Loss: 0.09366065282146793, G Loss: 21.671215057373047\n",
      "Epoch: 40, Batch: 261, D Loss: 0.10335103442299194, G Loss: 21.621034622192383\n",
      "Epoch: 40, Batch: 262, D Loss: 0.09533918670133358, G Loss: 21.547571182250977\n",
      "Epoch: 40, Batch: 263, D Loss: 0.09986104838287187, G Loss: 21.5336856842041\n",
      "Epoch: 40, Batch: 264, D Loss: 0.0994314926068063, G Loss: 21.56633949279785\n",
      "Epoch: 40, Batch: 265, D Loss: 0.10358597358494502, G Loss: 21.677452087402344\n",
      "Epoch: 40, Batch: 266, D Loss: 0.09989101458092468, G Loss: 21.766141891479492\n",
      "Epoch: 40, Batch: 267, D Loss: 0.0961479695411177, G Loss: 21.76862144470215\n",
      "Epoch: 40, Batch: 268, D Loss: 0.10469470935502534, G Loss: 21.796384811401367\n",
      "Epoch: 40, Batch: 269, D Loss: 0.09439961630056695, G Loss: 21.71637725830078\n",
      "Epoch: 40, Batch: 270, D Loss: 0.10032608379245786, G Loss: 21.648611068725586\n",
      "Epoch: 40, Batch: 271, D Loss: 0.0977904798651135, G Loss: 21.58365249633789\n",
      "Epoch: 40, Batch: 272, D Loss: 0.0916245507459457, G Loss: 21.469606399536133\n",
      "Epoch: 40, Batch: 273, D Loss: 0.10316973202993099, G Loss: 21.49314308166504\n",
      "Epoch: 40, Batch: 274, D Loss: 0.09270484023497964, G Loss: 21.5014705657959\n",
      "Epoch: 40, Batch: 275, D Loss: 0.10168066642629213, G Loss: 21.59986686706543\n",
      "Epoch: 40, Batch: 276, D Loss: 0.09645265360838874, G Loss: 21.67210578918457\n",
      "Epoch: 40, Batch: 277, D Loss: 0.10087363440481405, G Loss: 21.751806259155273\n",
      "Epoch: 40, Batch: 278, D Loss: 0.10290739702411224, G Loss: 21.83460807800293\n",
      "Epoch: 40, Batch: 279, D Loss: 0.09981329755361633, G Loss: 21.856510162353516\n",
      "Epoch: 40, Batch: 280, D Loss: 0.10253756509465192, G Loss: 21.85236167907715\n",
      "Epoch: 40, Batch: 281, D Loss: 0.10290579514131813, G Loss: 21.834718704223633\n",
      "Epoch: 40, Batch: 282, D Loss: 0.0919730963103019, G Loss: 21.684791564941406\n",
      "Epoch: 40, Batch: 283, D Loss: 0.09264328351959161, G Loss: 21.48682403564453\n",
      "Epoch: 40, Batch: 284, D Loss: 0.0974337461084023, G Loss: 21.373197555541992\n",
      "Epoch: 40, Batch: 285, D Loss: 0.0963363352066578, G Loss: 21.359922409057617\n",
      "Epoch: 40, Batch: 286, D Loss: 0.10728237801729557, G Loss: 21.56186866760254\n",
      "Epoch: 40, Batch: 287, D Loss: 0.09872606416076896, G Loss: 21.76642608642578\n",
      "Epoch: 40, Batch: 288, D Loss: 0.10309931651747636, G Loss: 21.961938858032227\n",
      "Epoch: 40, Batch: 289, D Loss: 0.10148848606972934, G Loss: 22.06294822692871\n",
      "Epoch: 40, Batch: 290, D Loss: 0.10088826729102401, G Loss: 22.05434226989746\n",
      "Epoch: 40, Batch: 291, D Loss: 0.101829216022382, G Loss: 21.968820571899414\n",
      "Epoch: 40, Batch: 292, D Loss: 0.10028581336687019, G Loss: 21.833717346191406\n",
      "Epoch: 40, Batch: 293, D Loss: 0.10335688310246047, G Loss: 21.74405288696289\n",
      "Epoch: 40, Batch: 294, D Loss: 0.0972827674849647, G Loss: 21.651653289794922\n",
      "Epoch: 40, Batch: 295, D Loss: 0.09521870335729117, G Loss: 21.567224502563477\n",
      "Epoch: 40, Batch: 296, D Loss: 0.10132478943798769, G Loss: 21.594642639160156\n",
      "Epoch: 40, Batch: 297, D Loss: 0.1016170235461764, G Loss: 21.705013275146484\n",
      "Epoch: 40, Batch: 298, D Loss: 0.10095023381266376, G Loss: 21.840991973876953\n",
      "Epoch: 40, Batch: 299, D Loss: 0.093993172210679, G Loss: 21.868614196777344\n",
      "Epoch: 40, Batch: 300, D Loss: 0.09972159580432384, G Loss: 21.864906311035156\n",
      "Epoch: 40, Batch: 301, D Loss: 0.10246936992836542, G Loss: 21.869497299194336\n",
      "Epoch: 40, Batch: 302, D Loss: 0.09921038166935844, G Loss: 21.839088439941406\n",
      "Epoch: 40, Batch: 303, D Loss: 0.10052817331535813, G Loss: 21.805774688720703\n",
      "Epoch: 40, Batch: 304, D Loss: 0.10528396086668486, G Loss: 21.83664321899414\n",
      "Epoch: 40, Batch: 305, D Loss: 0.09752509014472409, G Loss: 21.821409225463867\n",
      "Epoch: 40, Batch: 306, D Loss: 0.10178992913918788, G Loss: 21.82466697692871\n",
      "Epoch: 40, Batch: 307, D Loss: 0.10349944995279695, G Loss: 21.85854148864746\n",
      "Epoch: 40, Batch: 308, D Loss: 0.10326340810283462, G Loss: 21.90003204345703\n",
      "Epoch: 40, Batch: 309, D Loss: 0.10673087850141265, G Loss: 21.973499298095703\n",
      "Epoch: 40, Batch: 310, D Loss: 0.10919460667809533, G Loss: 22.078601837158203\n",
      "Epoch: 40, Batch: 311, D Loss: 0.09605380906074462, G Loss: 22.016572952270508\n",
      "Epoch: 40, Batch: 312, D Loss: 0.09779465213410483, G Loss: 21.860063552856445\n",
      "Epoch: 40, Batch: 313, D Loss: 0.10203695314445195, G Loss: 21.727062225341797\n",
      "Epoch: 40, Batch: 314, D Loss: 0.09861744959610487, G Loss: 21.62552261352539\n",
      "Epoch: 40, Batch: 315, D Loss: 0.10009267946734111, G Loss: 21.603662490844727\n",
      "Epoch: 40, Batch: 316, D Loss: 0.0926153810957331, G Loss: 21.556581497192383\n",
      "Epoch: 40, Batch: 317, D Loss: 0.09507413230434347, G Loss: 21.5375919342041\n",
      "Epoch: 40, Batch: 318, D Loss: 0.10339620730305196, G Loss: 21.648639678955078\n",
      "Epoch: 40, Batch: 319, D Loss: 0.09483937193128184, G Loss: 21.72423553466797\n",
      "Epoch: 40, Batch: 320, D Loss: 0.10122500377431788, G Loss: 21.825759887695312\n",
      "Epoch: 40, Batch: 321, D Loss: 0.10077894494968066, G Loss: 21.904077529907227\n",
      "Epoch: 40, Batch: 322, D Loss: 0.10043029502279942, G Loss: 21.929622650146484\n",
      "Epoch: 40, Batch: 323, D Loss: 0.0956098140841573, G Loss: 21.85599708557129\n",
      "Epoch: 40, Batch: 324, D Loss: 0.09737349318645122, G Loss: 21.745803833007812\n",
      "Epoch: 40, Batch: 325, D Loss: 0.09978235531637797, G Loss: 21.675092697143555\n",
      "Epoch: 40, Batch: 326, D Loss: 0.09794807453750935, G Loss: 21.639366149902344\n",
      "Epoch: 40, Batch: 327, D Loss: 0.1010810809300982, G Loss: 21.684310913085938\n",
      "Epoch: 40, Batch: 328, D Loss: 0.10480238515089554, G Loss: 21.81712532043457\n",
      "Epoch: 40, Batch: 329, D Loss: 0.09612418727399252, G Loss: 21.87854766845703\n",
      "Epoch: 40, Batch: 330, D Loss: 0.1018390806068671, G Loss: 21.921741485595703\n",
      "Epoch: 40, Batch: 331, D Loss: 0.10030106470155394, G Loss: 21.92371940612793\n",
      "Epoch: 40, Batch: 332, D Loss: 0.09571725145816194, G Loss: 21.83949089050293\n",
      "Epoch: 40, Batch: 333, D Loss: 0.09720345603831752, G Loss: 21.73578453063965\n",
      "Epoch: 40, Batch: 334, D Loss: 0.09649622459470115, G Loss: 21.637109756469727\n",
      "Epoch: 40, Batch: 335, D Loss: 0.09511499127665321, G Loss: 21.568965911865234\n",
      "Epoch: 40, Batch: 336, D Loss: 0.09467277697562256, G Loss: 21.54860496520996\n",
      "Epoch: 40, Batch: 337, D Loss: 0.10306835195123902, G Loss: 21.668424606323242\n",
      "Epoch: 40, Batch: 338, D Loss: 0.09882415849097025, G Loss: 21.81277084350586\n",
      "Epoch: 40, Batch: 339, D Loss: 0.10710094884226114, G Loss: 22.01854705810547\n",
      "Epoch: 40, Batch: 340, D Loss: 0.09662836803333612, G Loss: 22.080978393554688\n",
      "Epoch: 40, Batch: 341, D Loss: 0.10045314593244177, G Loss: 22.05467987060547\n",
      "Epoch: 40, Batch: 342, D Loss: 0.09991209222894033, G Loss: 21.953237533569336\n",
      "Epoch: 40, Batch: 343, D Loss: 0.0972137676271124, G Loss: 21.80265998840332\n",
      "Epoch: 40, Batch: 344, D Loss: 0.09146482516444063, G Loss: 21.590288162231445\n",
      "Epoch: 40, Batch: 345, D Loss: 0.09935893885503216, G Loss: 21.49728775024414\n",
      "Epoch: 40, Batch: 346, D Loss: 0.09214970493163843, G Loss: 21.44603729248047\n",
      "Epoch: 40, Batch: 347, D Loss: 0.09528936469512372, G Loss: 21.483369827270508\n",
      "Epoch: 40, Batch: 348, D Loss: 0.10546942075987752, G Loss: 21.708059310913086\n",
      "Epoch: 40, Batch: 349, D Loss: 0.10078930871285884, G Loss: 21.944137573242188\n",
      "Epoch: 40, Batch: 350, D Loss: 0.09636390223094356, G Loss: 22.057153701782227\n",
      "Epoch: 40, Batch: 351, D Loss: 0.10141079140684747, G Loss: 22.09749984741211\n",
      "Epoch: 40, Batch: 352, D Loss: 0.09473919881899007, G Loss: 21.983970642089844\n",
      "Epoch: 40, Batch: 353, D Loss: 0.1020354928090782, G Loss: 21.870208740234375\n",
      "Epoch: 40, Batch: 354, D Loss: 0.08745352941953367, G Loss: 21.622514724731445\n",
      "Epoch: 40, Batch: 355, D Loss: 0.09723743818497654, G Loss: 21.46070671081543\n",
      "Epoch: 40, Batch: 356, D Loss: 0.09846661263883913, G Loss: 21.45253562927246\n",
      "Epoch: 40, Batch: 357, D Loss: 0.09909823559465822, G Loss: 21.57619285583496\n",
      "Epoch: 40, Batch: 358, D Loss: 0.09996394087097935, G Loss: 21.783748626708984\n",
      "Epoch: 40, Batch: 359, D Loss: 0.09766328350655892, G Loss: 21.951717376708984\n",
      "Epoch: 40, Batch: 360, D Loss: 0.09942728294894805, G Loss: 22.053483963012695\n",
      "Epoch: 40, Batch: 361, D Loss: 0.09853503121154705, G Loss: 22.06665802001953\n",
      "Epoch: 40, Batch: 362, D Loss: 0.08784955754376447, G Loss: 21.878671646118164\n",
      "Epoch: 40, Batch: 363, D Loss: 0.10385754721095115, G Loss: 21.776029586791992\n",
      "Epoch: 40, Batch: 364, D Loss: 0.09676917660542847, G Loss: 21.697158813476562\n",
      "Epoch: 40, Batch: 365, D Loss: 0.0937279017732278, G Loss: 21.633033752441406\n",
      "Epoch: 40, Batch: 366, D Loss: 0.10140182842406194, G Loss: 21.69707489013672\n",
      "Epoch: 40, Batch: 367, D Loss: 0.09864899533906368, G Loss: 21.809099197387695\n",
      "Epoch: 40, Batch: 368, D Loss: 0.10199954376291517, G Loss: 21.962783813476562\n",
      "Epoch: 40, Batch: 369, D Loss: 0.09657132639505457, G Loss: 22.036462783813477\n",
      "Epoch: 40, Batch: 370, D Loss: 0.10284165306063493, G Loss: 22.088451385498047\n",
      "Epoch: 40, Batch: 371, D Loss: 0.1004972608176014, G Loss: 22.085554122924805\n",
      "Epoch: 40, Batch: 372, D Loss: 0.09920334829230758, G Loss: 22.020193099975586\n",
      "Epoch: 40, Batch: 373, D Loss: 0.09747350230438613, G Loss: 21.90436363220215\n",
      "Epoch: 40, Batch: 374, D Loss: 0.10445204392727232, G Loss: 21.879119873046875\n",
      "Epoch: 40, Batch: 375, D Loss: 0.10136067882879086, G Loss: 21.896080017089844\n",
      "Epoch: 40, Batch: 376, D Loss: 0.0933334679994205, G Loss: 21.85332489013672\n",
      "Epoch: 40, Batch: 377, D Loss: 0.10161575690991932, G Loss: 21.873441696166992\n",
      "Epoch: 40, Batch: 378, D Loss: 0.09551972166682683, G Loss: 21.867401123046875\n",
      "Epoch: 40, Batch: 379, D Loss: 0.09522548334092727, G Loss: 21.836864471435547\n",
      "Epoch: 40, Batch: 380, D Loss: 0.09848430769185156, G Loss: 21.835546493530273\n",
      "Epoch: 40, Batch: 381, D Loss: 0.09677670912424133, G Loss: 21.843679428100586\n",
      "Epoch: 40, Batch: 382, D Loss: 0.09899346546376134, G Loss: 21.88719367980957\n",
      "Epoch: 40, Batch: 383, D Loss: 0.09960727408747208, G Loss: 21.94819450378418\n",
      "Epoch: 40, Batch: 384, D Loss: 0.0937155263117358, G Loss: 21.931909561157227\n",
      "Epoch: 40, Batch: 385, D Loss: 0.10036091521337441, G Loss: 21.94141387939453\n",
      "Epoch: 40, Batch: 386, D Loss: 0.09953111424803723, G Loss: 21.957765579223633\n",
      "Epoch: 40, Batch: 387, D Loss: 0.10111235096435907, G Loss: 21.992429733276367\n",
      "Epoch: 40, Batch: 388, D Loss: 0.1014706493795528, G Loss: 22.038755416870117\n",
      "Epoch: 40, Batch: 389, D Loss: 0.09197445227776407, G Loss: 21.960424423217773\n",
      "Epoch: 40, Batch: 390, D Loss: 0.0965711028909648, G Loss: 21.864864349365234\n",
      "Epoch: 40, Batch: 391, D Loss: 0.0963681192868958, G Loss: 21.787399291992188\n",
      "Epoch: 40, Batch: 392, D Loss: 0.09685486572612534, G Loss: 21.75885581970215\n",
      "Epoch: 40, Batch: 393, D Loss: 0.09455264377559723, G Loss: 21.748676300048828\n",
      "Epoch: 40, Batch: 394, D Loss: 0.10180756466729472, G Loss: 21.84676170349121\n",
      "Epoch: 40, Batch: 395, D Loss: 0.0989059360360575, G Loss: 21.967756271362305\n",
      "Epoch: 40, Batch: 396, D Loss: 0.10389256490638, G Loss: 22.121700286865234\n",
      "Epoch: 40, Batch: 397, D Loss: 0.10346414160381684, G Loss: 22.244749069213867\n",
      "Epoch: 40, Batch: 398, D Loss: 0.09362227480978154, G Loss: 22.180395126342773\n",
      "Epoch: 40, Batch: 399, D Loss: 0.0984128863870753, G Loss: 22.043537139892578\n",
      "Epoch: 40, Batch: 400, D Loss: 0.10074340566258902, G Loss: 21.93095588684082\n",
      "Epoch: 40, Batch: 401, D Loss: 0.09652936474410814, G Loss: 21.822284698486328\n",
      "Epoch: 40, Batch: 402, D Loss: 0.10465883479992209, G Loss: 21.85559844970703\n",
      "Epoch: 40, Batch: 403, D Loss: 0.10223063841750477, G Loss: 21.967815399169922\n",
      "Epoch: 40, Batch: 404, D Loss: 0.09951344891129378, G Loss: 22.070161819458008\n",
      "Epoch: 40, Batch: 405, D Loss: 0.10035249603365355, G Loss: 22.146305084228516\n",
      "Epoch: 40, Batch: 406, D Loss: 0.09847198438728805, G Loss: 22.15328025817871\n",
      "Epoch: 40, Batch: 407, D Loss: 0.10137727123644952, G Loss: 22.137237548828125\n",
      "Epoch: 40, Batch: 408, D Loss: 0.0982387067142564, G Loss: 22.0768985748291\n",
      "Epoch: 40, Batch: 409, D Loss: 0.09839934124086396, G Loss: 22.000452041625977\n",
      "Epoch: 40, Batch: 410, D Loss: 0.10023092492724701, G Loss: 21.964046478271484\n",
      "Epoch: 40, Batch: 411, D Loss: 0.0961829425382573, G Loss: 21.922035217285156\n",
      "Epoch: 40, Batch: 412, D Loss: 0.10279801502558465, G Loss: 21.978673934936523\n",
      "Epoch: 40, Batch: 413, D Loss: 0.10073860003252985, G Loss: 22.06574249267578\n",
      "Epoch: 40, Batch: 414, D Loss: 0.10059572768780643, G Loss: 22.150487899780273\n",
      "Epoch: 40, Batch: 415, D Loss: 0.09611341369248538, G Loss: 22.14757537841797\n",
      "Epoch: 40, Batch: 416, D Loss: 0.09873890889093868, G Loss: 22.10233497619629\n",
      "Epoch: 40, Batch: 417, D Loss: 0.10051409913018236, G Loss: 22.066631317138672\n",
      "Epoch: 40, Batch: 418, D Loss: 0.0989784152647069, G Loss: 22.028400421142578\n",
      "Epoch: 40, Batch: 419, D Loss: 0.10259914411635943, G Loss: 22.04454803466797\n",
      "Epoch: 40, Batch: 420, D Loss: 0.09984492523730278, G Loss: 22.068471908569336\n",
      "Epoch: 40, Batch: 421, D Loss: 0.09423103941952528, G Loss: 22.016382217407227\n",
      "Epoch: 40, Batch: 422, D Loss: 0.1014916004123133, G Loss: 22.01552963256836\n",
      "Epoch: 40, Batch: 423, D Loss: 0.09992276890755143, G Loss: 22.03536033630371\n",
      "Epoch: 40, Batch: 424, D Loss: 0.09792763008166375, G Loss: 22.044300079345703\n",
      "Epoch: 40, Batch: 425, D Loss: 0.09475336982573608, G Loss: 21.997652053833008\n",
      "Epoch: 40, Batch: 426, D Loss: 0.0918273331218136, G Loss: 21.88499641418457\n",
      "Epoch: 40, Batch: 427, D Loss: 0.09795787946571452, G Loss: 21.83284568786621\n",
      "Epoch: 40, Batch: 428, D Loss: 0.10526791230460911, G Loss: 21.9476318359375\n",
      "Epoch: 40, Batch: 429, D Loss: 0.10081617547737134, G Loss: 22.098169326782227\n",
      "Epoch: 40, Batch: 430, D Loss: 0.09737981122894873, G Loss: 22.18417739868164\n",
      "Epoch: 40, Batch: 431, D Loss: 0.0968966112698895, G Loss: 22.18756103515625\n",
      "Epoch: 40, Batch: 432, D Loss: 0.09899733972431285, G Loss: 22.148435592651367\n",
      "Epoch: 40, Batch: 433, D Loss: 0.09102997196838337, G Loss: 21.994144439697266\n",
      "Epoch: 40, Batch: 434, D Loss: 0.10065879687444414, G Loss: 21.908123016357422\n",
      "Epoch: 40, Batch: 435, D Loss: 0.09804647431360722, G Loss: 21.884143829345703\n",
      "Epoch: 40, Batch: 436, D Loss: 0.0980342106567473, G Loss: 21.920469284057617\n",
      "Epoch: 40, Batch: 437, D Loss: 0.09252679363120149, G Loss: 21.917236328125\n",
      "Epoch: 40, Batch: 438, D Loss: 0.0937772990798953, G Loss: 21.903799057006836\n",
      "Epoch: 40, Batch: 439, D Loss: 0.09810701027705326, G Loss: 21.93653678894043\n",
      "Epoch: 40, Batch: 440, D Loss: 0.09914371385552684, G Loss: 22.01189613342285\n",
      "Epoch: 40, Batch: 441, D Loss: 0.10542999220684553, G Loss: 22.165447235107422\n",
      "Epoch: 40, Batch: 442, D Loss: 0.09700693201569857, G Loss: 22.222347259521484\n",
      "Epoch: 40, Batch: 443, D Loss: 0.10637157421123075, G Loss: 22.29641342163086\n",
      "Epoch: 40, Batch: 444, D Loss: 0.09998060773354202, G Loss: 22.277780532836914\n",
      "Epoch: 40, Batch: 445, D Loss: 0.09432327013773299, G Loss: 22.118553161621094\n",
      "Epoch: 40, Batch: 446, D Loss: 0.09737475230021322, G Loss: 21.936304092407227\n",
      "Epoch: 40, Batch: 447, D Loss: 0.09547597186062735, G Loss: 21.774147033691406\n",
      "Epoch: 40, Batch: 448, D Loss: 0.09931091982081483, G Loss: 21.73592185974121\n",
      "Epoch: 40, Batch: 449, D Loss: 0.10529486851849948, G Loss: 21.87849998474121\n",
      "Epoch: 40, Batch: 450, D Loss: 0.10088368519536109, G Loss: 22.06203842163086\n",
      "Epoch: 40, Batch: 451, D Loss: 0.09990710777315422, G Loss: 22.199575424194336\n",
      "Epoch: 40, Batch: 452, D Loss: 0.09544358413957565, G Loss: 22.192508697509766\n",
      "Epoch: 40, Batch: 453, D Loss: 0.1043291689118068, G Loss: 22.188976287841797\n",
      "Epoch: 40, Batch: 454, D Loss: 0.09577324998670175, G Loss: 22.08221435546875\n",
      "Epoch: 40, Batch: 455, D Loss: 0.10194944603749215, G Loss: 21.99934959411621\n",
      "Epoch: 40, Batch: 456, D Loss: 0.09342706963514408, G Loss: 21.862693786621094\n",
      "Epoch: 40, Batch: 457, D Loss: 0.10383520291356195, G Loss: 21.862577438354492\n",
      "Epoch: 40, Batch: 458, D Loss: 0.1025021077721589, G Loss: 21.96126937866211\n",
      "Epoch: 40, Batch: 459, D Loss: 0.09534522905149932, G Loss: 22.01351547241211\n",
      "Epoch: 40, Batch: 460, D Loss: 0.10273645831363999, G Loss: 22.102481842041016\n",
      "Epoch: 40, Batch: 461, D Loss: 0.09884970647478838, G Loss: 22.146156311035156\n",
      "Epoch: 40, Batch: 462, D Loss: 0.1039516777969804, G Loss: 22.202898025512695\n",
      "Epoch: 40, Batch: 463, D Loss: 0.09785026323413896, G Loss: 22.17750358581543\n",
      "Epoch: 40, Batch: 464, D Loss: 0.10012469452747258, G Loss: 22.118268966674805\n",
      "Epoch: 40, Batch: 465, D Loss: 0.10396534961987469, G Loss: 22.10994529724121\n",
      "Epoch: 40, Batch: 466, D Loss: 0.09816597414852722, G Loss: 22.070594787597656\n",
      "Epoch: 40, Batch: 467, D Loss: 0.0920877160026543, G Loss: 21.949996948242188\n",
      "Epoch: 41, Batch: 0, D Loss: 0.10744770630717271, G Loss: 21.981191635131836\n",
      "Epoch: 41, Batch: 1, D Loss: 0.10441003008130392, G Loss: 22.099349975585938\n",
      "Epoch: 41, Batch: 2, D Loss: 0.09686283034434734, G Loss: 22.15415382385254\n",
      "Epoch: 41, Batch: 3, D Loss: 0.09622373444011423, G Loss: 22.132781982421875\n",
      "Epoch: 41, Batch: 4, D Loss: 0.09495814902503566, G Loss: 22.0384578704834\n",
      "Epoch: 41, Batch: 5, D Loss: 0.10155943049785891, G Loss: 21.998531341552734\n",
      "Epoch: 41, Batch: 6, D Loss: 0.09586396827699491, G Loss: 21.953001022338867\n",
      "Epoch: 41, Batch: 7, D Loss: 0.0940641017275017, G Loss: 21.895267486572266\n",
      "Epoch: 41, Batch: 8, D Loss: 0.10232885942002813, G Loss: 21.950908660888672\n",
      "Epoch: 41, Batch: 9, D Loss: 0.09609273090301498, G Loss: 22.00423240661621\n",
      "Epoch: 41, Batch: 10, D Loss: 0.10207228375674912, G Loss: 22.11310577392578\n",
      "Epoch: 41, Batch: 11, D Loss: 0.09757801902461158, G Loss: 22.17009162902832\n",
      "Epoch: 41, Batch: 12, D Loss: 0.09431269776897841, G Loss: 22.133056640625\n",
      "Epoch: 41, Batch: 13, D Loss: 0.0990784840049069, G Loss: 22.08327293395996\n",
      "Epoch: 41, Batch: 14, D Loss: 0.09852668656120915, G Loss: 22.040807723999023\n",
      "Epoch: 41, Batch: 15, D Loss: 0.10471142841475625, G Loss: 22.0953369140625\n",
      "Epoch: 41, Batch: 16, D Loss: 0.1048511565924518, G Loss: 22.211101531982422\n",
      "Epoch: 41, Batch: 17, D Loss: 0.09632071863889613, G Loss: 22.225934982299805\n",
      "Epoch: 41, Batch: 18, D Loss: 0.10468037437369707, G Loss: 22.265457153320312\n",
      "Epoch: 41, Batch: 19, D Loss: 0.09031443309350096, G Loss: 22.129627227783203\n",
      "Epoch: 41, Batch: 20, D Loss: 0.10206387949889484, G Loss: 22.043365478515625\n",
      "Epoch: 41, Batch: 21, D Loss: 0.09248894467399969, G Loss: 21.906538009643555\n",
      "Epoch: 41, Batch: 22, D Loss: 0.09858180598297096, G Loss: 21.850343704223633\n",
      "Epoch: 41, Batch: 23, D Loss: 0.10476695016316229, G Loss: 21.97235679626465\n",
      "Epoch: 41, Batch: 24, D Loss: 0.09553731991539373, G Loss: 22.072799682617188\n",
      "Epoch: 41, Batch: 25, D Loss: 0.09696011257778558, G Loss: 22.138460159301758\n",
      "Epoch: 41, Batch: 26, D Loss: 0.10120003682166671, G Loss: 22.20720100402832\n",
      "Epoch: 41, Batch: 27, D Loss: 0.09817293297579952, G Loss: 22.22085189819336\n",
      "Epoch: 41, Batch: 28, D Loss: 0.09637190413097797, G Loss: 22.16060447692871\n",
      "Epoch: 41, Batch: 29, D Loss: 0.0971876980117058, G Loss: 22.07445526123047\n",
      "Epoch: 41, Batch: 30, D Loss: 0.09987419111867324, G Loss: 22.030235290527344\n",
      "Epoch: 41, Batch: 31, D Loss: 0.10411740852646545, G Loss: 22.082489013671875\n",
      "Epoch: 41, Batch: 32, D Loss: 0.09615352762519823, G Loss: 22.10453224182129\n",
      "Epoch: 41, Batch: 33, D Loss: 0.10428811621757633, G Loss: 22.189632415771484\n",
      "Epoch: 41, Batch: 34, D Loss: 0.09792015712891149, G Loss: 22.21944808959961\n",
      "Epoch: 41, Batch: 35, D Loss: 0.09362669300818574, G Loss: 22.135229110717773\n",
      "Epoch: 41, Batch: 36, D Loss: 0.10166469228843382, G Loss: 22.086994171142578\n",
      "Epoch: 41, Batch: 37, D Loss: 0.10038760317327333, G Loss: 22.07356834411621\n",
      "Epoch: 41, Batch: 38, D Loss: 0.0948538185496314, G Loss: 22.023584365844727\n",
      "Epoch: 41, Batch: 39, D Loss: 0.09684715433884966, G Loss: 21.98838233947754\n",
      "Epoch: 41, Batch: 40, D Loss: 0.09951286776897937, G Loss: 22.010833740234375\n",
      "Epoch: 41, Batch: 41, D Loss: 0.09651368125021319, G Loss: 22.031343460083008\n",
      "Epoch: 41, Batch: 42, D Loss: 0.0972703622121574, G Loss: 22.061973571777344\n",
      "Epoch: 41, Batch: 43, D Loss: 0.10562439275139944, G Loss: 22.187108993530273\n",
      "Epoch: 41, Batch: 44, D Loss: 0.09360453497864636, G Loss: 22.2111759185791\n",
      "Epoch: 41, Batch: 45, D Loss: 0.10466630022730031, G Loss: 22.27262306213379\n",
      "Epoch: 41, Batch: 46, D Loss: 0.09669033448715286, G Loss: 22.249753952026367\n",
      "Epoch: 41, Batch: 47, D Loss: 0.10039713244776839, G Loss: 22.21466827392578\n",
      "Epoch: 41, Batch: 48, D Loss: 0.09652550530224345, G Loss: 22.138687133789062\n",
      "Epoch: 41, Batch: 49, D Loss: 0.09227500123893188, G Loss: 22.00441551208496\n",
      "Epoch: 41, Batch: 50, D Loss: 0.09778470560402806, G Loss: 21.935840606689453\n",
      "Epoch: 41, Batch: 51, D Loss: 0.10455916836194343, G Loss: 22.01816177368164\n",
      "Epoch: 41, Batch: 52, D Loss: 0.09989014280708754, G Loss: 22.148466110229492\n",
      "Epoch: 41, Batch: 53, D Loss: 0.0997354985409979, G Loss: 22.27198600769043\n",
      "Epoch: 41, Batch: 54, D Loss: 0.09956002245701077, G Loss: 22.33331871032715\n",
      "Epoch: 41, Batch: 55, D Loss: 0.09696839015009176, G Loss: 22.284494400024414\n",
      "Epoch: 41, Batch: 56, D Loss: 0.10469643782266333, G Loss: 22.26221466064453\n",
      "Epoch: 41, Batch: 57, D Loss: 0.10096687089468456, G Loss: 22.216371536254883\n",
      "Epoch: 41, Batch: 58, D Loss: 0.09926954668526332, G Loss: 22.141197204589844\n",
      "Epoch: 41, Batch: 59, D Loss: 0.09993793827912893, G Loss: 22.07526397705078\n",
      "Epoch: 41, Batch: 60, D Loss: 0.10025607062587351, G Loss: 22.048187255859375\n",
      "Epoch: 41, Batch: 61, D Loss: 0.10292351258869845, G Loss: 22.091835021972656\n",
      "Epoch: 41, Batch: 62, D Loss: 0.09612335277439794, G Loss: 22.08690643310547\n",
      "Epoch: 41, Batch: 63, D Loss: 0.09977497173184086, G Loss: 22.092491149902344\n",
      "Epoch: 41, Batch: 64, D Loss: 0.10063362134139815, G Loss: 22.116230010986328\n",
      "Epoch: 41, Batch: 65, D Loss: 0.0994170011320873, G Loss: 22.132736206054688\n",
      "Epoch: 41, Batch: 66, D Loss: 0.1027427018883436, G Loss: 22.174741744995117\n",
      "Epoch: 41, Batch: 67, D Loss: 0.0992527158238162, G Loss: 22.17677116394043\n",
      "Epoch: 41, Batch: 68, D Loss: 0.0979219080215363, G Loss: 22.130268096923828\n",
      "Epoch: 41, Batch: 69, D Loss: 0.09914913786052716, G Loss: 22.08851432800293\n",
      "Epoch: 41, Batch: 70, D Loss: 0.10205015552793924, G Loss: 22.102766036987305\n",
      "Epoch: 41, Batch: 71, D Loss: 0.1027102322603677, G Loss: 22.166011810302734\n",
      "Epoch: 41, Batch: 72, D Loss: 0.09905909758498223, G Loss: 22.198673248291016\n",
      "Epoch: 41, Batch: 73, D Loss: 0.09788246464329503, G Loss: 22.184335708618164\n",
      "Epoch: 41, Batch: 74, D Loss: 0.1069113166260662, G Loss: 22.25008201599121\n",
      "Epoch: 41, Batch: 75, D Loss: 0.09758658718075164, G Loss: 22.237598419189453\n",
      "Epoch: 41, Batch: 76, D Loss: 0.0971552134701497, G Loss: 22.16714096069336\n",
      "Epoch: 41, Batch: 77, D Loss: 0.10564221453431248, G Loss: 22.18581771850586\n",
      "Epoch: 41, Batch: 78, D Loss: 0.09916916501181544, G Loss: 22.186185836791992\n",
      "Epoch: 41, Batch: 79, D Loss: 0.10023029160136654, G Loss: 22.189531326293945\n",
      "Epoch: 41, Batch: 80, D Loss: 0.1032504664003655, G Loss: 22.225543975830078\n",
      "Epoch: 41, Batch: 81, D Loss: 0.1037202031497004, G Loss: 22.288759231567383\n",
      "Epoch: 41, Batch: 82, D Loss: 0.09199464332115548, G Loss: 22.194704055786133\n",
      "Epoch: 41, Batch: 83, D Loss: 0.09495869291307452, G Loss: 22.048017501831055\n",
      "Epoch: 41, Batch: 84, D Loss: 0.09675179436038397, G Loss: 21.931058883666992\n",
      "Epoch: 41, Batch: 85, D Loss: 0.08968644605300331, G Loss: 21.78742027282715\n",
      "Epoch: 41, Batch: 86, D Loss: 0.09840067493259459, G Loss: 21.79034996032715\n",
      "Epoch: 41, Batch: 87, D Loss: 0.10350498572639195, G Loss: 21.98192024230957\n",
      "Epoch: 41, Batch: 88, D Loss: 0.10075256986046695, G Loss: 22.217565536499023\n",
      "Epoch: 41, Batch: 89, D Loss: 0.09983550022357374, G Loss: 22.389942169189453\n",
      "Epoch: 41, Batch: 90, D Loss: 0.10052790501851482, G Loss: 22.464895248413086\n",
      "Epoch: 41, Batch: 91, D Loss: 0.09811998912840472, G Loss: 22.395187377929688\n",
      "Epoch: 41, Batch: 92, D Loss: 0.10038568089521352, G Loss: 22.266878128051758\n",
      "Epoch: 41, Batch: 93, D Loss: 0.09615826618555584, G Loss: 22.07625389099121\n",
      "Epoch: 41, Batch: 94, D Loss: 0.10051254941764713, G Loss: 21.97186279296875\n",
      "Epoch: 41, Batch: 95, D Loss: 0.09473645702060962, G Loss: 21.892440795898438\n",
      "Epoch: 41, Batch: 96, D Loss: 0.09113715605227712, G Loss: 21.814525604248047\n",
      "Epoch: 41, Batch: 97, D Loss: 0.09929609314944395, G Loss: 21.878023147583008\n",
      "Epoch: 41, Batch: 98, D Loss: 0.09589143112290695, G Loss: 21.985485076904297\n",
      "Epoch: 41, Batch: 99, D Loss: 0.10662866396204299, G Loss: 22.23385238647461\n",
      "Epoch: 41, Batch: 100, D Loss: 0.09821382175112375, G Loss: 22.39183235168457\n",
      "Epoch: 41, Batch: 101, D Loss: 0.09783397624258768, G Loss: 22.416851043701172\n",
      "Epoch: 41, Batch: 102, D Loss: 0.0942023919022459, G Loss: 22.276212692260742\n",
      "Epoch: 41, Batch: 103, D Loss: 0.0983317719065808, G Loss: 22.107816696166992\n",
      "Epoch: 41, Batch: 104, D Loss: 0.10366003973300397, G Loss: 22.046964645385742\n",
      "Epoch: 41, Batch: 105, D Loss: 0.09399864091427301, G Loss: 21.969758987426758\n",
      "Epoch: 41, Batch: 106, D Loss: 0.09094171986328586, G Loss: 21.857986450195312\n",
      "Epoch: 41, Batch: 107, D Loss: 0.10421529427625457, G Loss: 21.94503402709961\n",
      "Epoch: 41, Batch: 108, D Loss: 0.1069350541927374, G Loss: 22.198070526123047\n",
      "Epoch: 41, Batch: 109, D Loss: 0.1047355235620347, G Loss: 22.458171844482422\n",
      "Epoch: 41, Batch: 110, D Loss: 0.09539884337440904, G Loss: 22.50666046142578\n",
      "Epoch: 41, Batch: 111, D Loss: 0.09778458633958309, G Loss: 22.401704788208008\n",
      "Epoch: 41, Batch: 112, D Loss: 0.10460017631330736, G Loss: 22.306276321411133\n",
      "Epoch: 41, Batch: 113, D Loss: 0.10230631392031653, G Loss: 22.21755027770996\n",
      "Epoch: 41, Batch: 114, D Loss: 0.1021289230545344, G Loss: 22.166955947875977\n",
      "Epoch: 41, Batch: 115, D Loss: 0.10487009596487572, G Loss: 22.202577590942383\n",
      "Epoch: 41, Batch: 116, D Loss: 0.09794011723453513, G Loss: 22.204402923583984\n",
      "Epoch: 41, Batch: 117, D Loss: 0.10134075593303307, G Loss: 22.22005844116211\n",
      "Epoch: 41, Batch: 118, D Loss: 0.10192918788473557, G Loss: 22.2517147064209\n",
      "Epoch: 41, Batch: 119, D Loss: 0.10097009699324455, G Loss: 22.275556564331055\n",
      "Epoch: 41, Batch: 120, D Loss: 0.10010212670436583, G Loss: 22.27336883544922\n",
      "Epoch: 41, Batch: 121, D Loss: 0.10331726829797047, G Loss: 22.289810180664062\n",
      "Epoch: 41, Batch: 122, D Loss: 0.09959632168827061, G Loss: 22.27006721496582\n",
      "Epoch: 41, Batch: 123, D Loss: 0.09337504219459539, G Loss: 22.14471435546875\n",
      "Epoch: 41, Batch: 124, D Loss: 0.09266795976316977, G Loss: 21.96429443359375\n",
      "Epoch: 41, Batch: 125, D Loss: 0.09538124517132048, G Loss: 21.8404598236084\n",
      "Epoch: 41, Batch: 126, D Loss: 0.09646935777491071, G Loss: 21.822463989257812\n",
      "Epoch: 41, Batch: 127, D Loss: 0.10365369931173407, G Loss: 21.99478530883789\n",
      "Epoch: 41, Batch: 128, D Loss: 0.10661903035658868, G Loss: 22.299184799194336\n",
      "Epoch: 41, Batch: 129, D Loss: 0.0988577754237489, G Loss: 22.49625015258789\n",
      "Epoch: 41, Batch: 130, D Loss: 0.097317516887474, G Loss: 22.52290916442871\n",
      "Epoch: 41, Batch: 131, D Loss: 0.10662048318291692, G Loss: 22.527013778686523\n",
      "Epoch: 41, Batch: 132, D Loss: 0.09774620839832841, G Loss: 22.396181106567383\n",
      "Epoch: 41, Batch: 133, D Loss: 0.10854284474954412, G Loss: 22.344953536987305\n",
      "Epoch: 41, Batch: 134, D Loss: 0.09808611880248011, G Loss: 22.240489959716797\n",
      "Epoch: 41, Batch: 135, D Loss: 0.10612669598111604, G Loss: 22.238771438598633\n",
      "Epoch: 41, Batch: 136, D Loss: 0.10756302635319445, G Loss: 22.346599578857422\n",
      "Epoch: 41, Batch: 137, D Loss: 0.08870723108892167, G Loss: 22.250043869018555\n",
      "Epoch: 41, Batch: 138, D Loss: 0.10646648715784343, G Loss: 22.264698028564453\n",
      "Epoch: 41, Batch: 139, D Loss: 0.09519435476325186, G Loss: 22.214691162109375\n",
      "Epoch: 41, Batch: 140, D Loss: 0.09663088631369814, G Loss: 22.146984100341797\n",
      "Epoch: 41, Batch: 141, D Loss: 0.09808192414417945, G Loss: 22.107553482055664\n",
      "Epoch: 41, Batch: 142, D Loss: 0.09991179419018985, G Loss: 22.130369186401367\n",
      "Epoch: 41, Batch: 143, D Loss: 0.09163512302061808, G Loss: 22.085142135620117\n",
      "Epoch: 41, Batch: 144, D Loss: 0.09956385207940799, G Loss: 22.103605270385742\n",
      "Epoch: 41, Batch: 145, D Loss: 0.0947305039831472, G Loss: 22.099658966064453\n",
      "Epoch: 41, Batch: 146, D Loss: 0.09521466506315555, G Loss: 22.087047576904297\n",
      "Epoch: 41, Batch: 147, D Loss: 0.09854936612283482, G Loss: 22.121986389160156\n",
      "Epoch: 41, Batch: 148, D Loss: 0.09927061212053305, G Loss: 22.19003677368164\n",
      "Epoch: 41, Batch: 149, D Loss: 0.0933416337937477, G Loss: 22.174833297729492\n",
      "Epoch: 41, Batch: 150, D Loss: 0.09399802994942652, G Loss: 22.1070556640625\n",
      "Epoch: 41, Batch: 151, D Loss: 0.09776710731610873, G Loss: 22.075624465942383\n",
      "Epoch: 41, Batch: 152, D Loss: 0.09342139227557665, G Loss: 22.02507781982422\n",
      "Epoch: 41, Batch: 153, D Loss: 0.10494995875104063, G Loss: 22.131845474243164\n",
      "Epoch: 41, Batch: 154, D Loss: 0.09873162966560473, G Loss: 22.24544906616211\n",
      "Epoch: 41, Batch: 155, D Loss: 0.10017181943346623, G Loss: 22.33296775817871\n",
      "Epoch: 41, Batch: 156, D Loss: 0.09766218076152858, G Loss: 22.3444766998291\n",
      "Epoch: 41, Batch: 157, D Loss: 0.1032037959481984, G Loss: 22.362089157104492\n",
      "Epoch: 41, Batch: 158, D Loss: 0.10789572456793156, G Loss: 22.45339012145996\n",
      "Epoch: 41, Batch: 159, D Loss: 0.10410875835678927, G Loss: 22.50959587097168\n",
      "Epoch: 41, Batch: 160, D Loss: 0.10198244460921917, G Loss: 22.494565963745117\n",
      "Epoch: 41, Batch: 161, D Loss: 0.09125974783875562, G Loss: 22.281003952026367\n",
      "Epoch: 41, Batch: 162, D Loss: 0.0922535882624826, G Loss: 21.993179321289062\n",
      "Epoch: 41, Batch: 163, D Loss: 0.10752066239100924, G Loss: 21.960405349731445\n",
      "Epoch: 41, Batch: 164, D Loss: 0.101358220118724, G Loss: 22.06227684020996\n",
      "Epoch: 41, Batch: 165, D Loss: 0.09439191979825615, G Loss: 22.140522003173828\n",
      "Epoch: 41, Batch: 166, D Loss: 0.10414394002347699, G Loss: 22.304502487182617\n",
      "Epoch: 41, Batch: 167, D Loss: 0.10299063483402915, G Loss: 22.462783813476562\n",
      "Epoch: 41, Batch: 168, D Loss: 0.10023900129937308, G Loss: 22.527359008789062\n",
      "Epoch: 41, Batch: 169, D Loss: 0.09389045843294902, G Loss: 22.410316467285156\n",
      "Epoch: 41, Batch: 170, D Loss: 0.09773230562773683, G Loss: 22.24357032775879\n",
      "Epoch: 41, Batch: 171, D Loss: 0.09473302227444716, G Loss: 22.049245834350586\n",
      "Epoch: 41, Batch: 172, D Loss: 0.09828513874698437, G Loss: 21.949033737182617\n",
      "Epoch: 41, Batch: 173, D Loss: 0.09923887267287698, G Loss: 21.9747257232666\n",
      "Epoch: 41, Batch: 174, D Loss: 0.10263589037635684, G Loss: 22.142803192138672\n",
      "Epoch: 41, Batch: 175, D Loss: 0.1031375975486347, G Loss: 22.37527847290039\n",
      "Epoch: 41, Batch: 176, D Loss: 0.09757965067039492, G Loss: 22.50480842590332\n",
      "Epoch: 41, Batch: 177, D Loss: 0.09739844509426554, G Loss: 22.50731658935547\n",
      "Epoch: 41, Batch: 178, D Loss: 0.10582126685366386, G Loss: 22.522762298583984\n",
      "Epoch: 41, Batch: 179, D Loss: 0.10462218531278375, G Loss: 22.52655601501465\n",
      "Epoch: 41, Batch: 180, D Loss: 0.09825508305126623, G Loss: 22.43659210205078\n",
      "Epoch: 41, Batch: 181, D Loss: 0.09713840494363421, G Loss: 22.288196563720703\n",
      "Epoch: 41, Batch: 182, D Loss: 0.09965899597785852, G Loss: 22.172958374023438\n",
      "Epoch: 41, Batch: 183, D Loss: 0.08790501965248722, G Loss: 21.96628189086914\n",
      "Epoch: 41, Batch: 184, D Loss: 0.09526563450958948, G Loss: 21.871150970458984\n",
      "Epoch: 41, Batch: 185, D Loss: 0.08735075609590771, G Loss: 21.785598754882812\n",
      "Epoch: 41, Batch: 186, D Loss: 0.10299463585953317, G Loss: 21.951597213745117\n",
      "Epoch: 41, Batch: 187, D Loss: 0.09974901390878198, G Loss: 22.21743392944336\n",
      "Epoch: 41, Batch: 188, D Loss: 0.10218535373285946, G Loss: 22.510879516601562\n",
      "Epoch: 41, Batch: 189, D Loss: 0.09588635720695395, G Loss: 22.636213302612305\n",
      "Epoch: 41, Batch: 190, D Loss: 0.09881493456658604, G Loss: 22.619510650634766\n",
      "Epoch: 41, Batch: 191, D Loss: 0.10014517613247353, G Loss: 22.512104034423828\n",
      "Epoch: 41, Batch: 192, D Loss: 0.09837541738314542, G Loss: 22.349578857421875\n",
      "Epoch: 41, Batch: 193, D Loss: 0.10157581429131045, G Loss: 22.246875762939453\n",
      "Epoch: 41, Batch: 194, D Loss: 0.10161066066306113, G Loss: 22.227495193481445\n",
      "Epoch: 41, Batch: 195, D Loss: 0.10239345591073876, G Loss: 22.292766571044922\n",
      "Epoch: 41, Batch: 196, D Loss: 0.10238330821069416, G Loss: 22.40557098388672\n",
      "Epoch: 41, Batch: 197, D Loss: 0.09885180750523678, G Loss: 22.47258949279785\n",
      "Epoch: 41, Batch: 198, D Loss: 0.10226918765420602, G Loss: 22.524864196777344\n",
      "Epoch: 41, Batch: 199, D Loss: 0.09954196968061745, G Loss: 22.507471084594727\n",
      "Epoch: 41, Batch: 200, D Loss: 0.09284149119471834, G Loss: 22.34296226501465\n",
      "Epoch: 41, Batch: 201, D Loss: 0.10133399824805782, G Loss: 22.241857528686523\n",
      "Epoch: 41, Batch: 202, D Loss: 0.10413612436086855, G Loss: 22.275421142578125\n",
      "Epoch: 41, Batch: 203, D Loss: 0.09509812306026189, G Loss: 22.2755184173584\n",
      "Epoch: 41, Batch: 204, D Loss: 0.09672878693195858, G Loss: 22.27665901184082\n",
      "Epoch: 41, Batch: 205, D Loss: 0.09979726384474405, G Loss: 22.32241439819336\n",
      "Epoch: 41, Batch: 206, D Loss: 0.10196796814310402, G Loss: 22.41084861755371\n",
      "Epoch: 41, Batch: 207, D Loss: 0.09511572131851964, G Loss: 22.40478515625\n",
      "Epoch: 41, Batch: 208, D Loss: 0.09858924159872355, G Loss: 22.38434410095215\n",
      "Epoch: 41, Batch: 209, D Loss: 0.09689426431858275, G Loss: 22.336484909057617\n",
      "Epoch: 41, Batch: 210, D Loss: 0.10196421305282853, G Loss: 22.35260772705078\n",
      "Epoch: 41, Batch: 211, D Loss: 0.10870660105462657, G Loss: 22.503089904785156\n",
      "Epoch: 41, Batch: 212, D Loss: 0.09692770250943225, G Loss: 22.54440689086914\n",
      "Epoch: 41, Batch: 213, D Loss: 0.10691424466944605, G Loss: 22.63245391845703\n",
      "Epoch: 41, Batch: 214, D Loss: 0.10111153133111453, G Loss: 22.648347854614258\n",
      "Epoch: 41, Batch: 215, D Loss: 0.10604465015007342, G Loss: 22.666147232055664\n",
      "Epoch: 41, Batch: 216, D Loss: 0.09867326177725376, G Loss: 22.57423973083496\n",
      "Epoch: 41, Batch: 217, D Loss: 0.104346029541763, G Loss: 22.50787925720215\n",
      "Epoch: 41, Batch: 218, D Loss: 0.10208752759953951, G Loss: 22.460840225219727\n",
      "Epoch: 41, Batch: 219, D Loss: 0.09260848919098152, G Loss: 22.31830406188965\n",
      "Epoch: 41, Batch: 220, D Loss: 0.09515730302494246, G Loss: 22.18362808227539\n",
      "Epoch: 41, Batch: 221, D Loss: 0.10179473471254706, G Loss: 22.195758819580078\n",
      "Epoch: 41, Batch: 222, D Loss: 0.09440236549989746, G Loss: 22.216903686523438\n",
      "Epoch: 41, Batch: 223, D Loss: 0.1003961117137904, G Loss: 22.321910858154297\n",
      "Epoch: 41, Batch: 224, D Loss: 0.0961555169000351, G Loss: 22.404788970947266\n",
      "Epoch: 41, Batch: 225, D Loss: 0.09906332203781228, G Loss: 22.473085403442383\n",
      "Epoch: 41, Batch: 226, D Loss: 0.09417471298465004, G Loss: 22.442731857299805\n",
      "Epoch: 41, Batch: 227, D Loss: 0.09420898566163738, G Loss: 22.340185165405273\n",
      "Epoch: 41, Batch: 228, D Loss: 0.0964841843693211, G Loss: 22.248050689697266\n",
      "Epoch: 41, Batch: 229, D Loss: 0.0952147991594329, G Loss: 22.17808723449707\n",
      "Epoch: 41, Batch: 230, D Loss: 0.10112287115507354, G Loss: 22.226699829101562\n",
      "Epoch: 41, Batch: 231, D Loss: 0.10158948610667057, G Loss: 22.358081817626953\n",
      "Epoch: 41, Batch: 232, D Loss: 0.09997589150197866, G Loss: 22.49574089050293\n",
      "Epoch: 41, Batch: 233, D Loss: 0.1023159921964929, G Loss: 22.62021827697754\n",
      "Epoch: 41, Batch: 234, D Loss: 0.09785077728343788, G Loss: 22.629898071289062\n",
      "Epoch: 41, Batch: 235, D Loss: 0.09315393873171635, G Loss: 22.47400665283203\n",
      "Epoch: 41, Batch: 236, D Loss: 0.09799662241901325, G Loss: 22.302215576171875\n",
      "Epoch: 41, Batch: 237, D Loss: 0.10581466565977157, G Loss: 22.289018630981445\n",
      "Epoch: 41, Batch: 238, D Loss: 0.0975262523741367, G Loss: 22.290430068969727\n",
      "Epoch: 41, Batch: 239, D Loss: 0.10613166550529066, G Loss: 22.434783935546875\n",
      "Epoch: 41, Batch: 240, D Loss: 0.1046285928116854, G Loss: 22.614931106567383\n",
      "Epoch: 41, Batch: 241, D Loss: 0.09810946889145322, G Loss: 22.657466888427734\n",
      "Epoch: 41, Batch: 242, D Loss: 0.0987045467650875, G Loss: 22.584461212158203\n",
      "Epoch: 41, Batch: 243, D Loss: 0.0944021345049097, G Loss: 22.38296890258789\n",
      "Epoch: 41, Batch: 244, D Loss: 0.09956368814309177, G Loss: 22.225322723388672\n",
      "Epoch: 41, Batch: 245, D Loss: 0.09800265741128752, G Loss: 22.130769729614258\n",
      "Epoch: 41, Batch: 246, D Loss: 0.10796055209096923, G Loss: 22.26853370666504\n",
      "Epoch: 41, Batch: 247, D Loss: 0.09910310814731765, G Loss: 22.41175651550293\n",
      "Epoch: 41, Batch: 248, D Loss: 0.09863661238430341, G Loss: 22.500141143798828\n",
      "Epoch: 41, Batch: 249, D Loss: 0.09985563167306305, G Loss: 22.532108306884766\n",
      "Epoch: 41, Batch: 250, D Loss: 0.10095841445809259, G Loss: 22.523157119750977\n",
      "Epoch: 41, Batch: 251, D Loss: 0.09464184948696466, G Loss: 22.39647674560547\n",
      "Epoch: 41, Batch: 252, D Loss: 0.09933825592196772, G Loss: 22.28839111328125\n",
      "Epoch: 41, Batch: 253, D Loss: 0.09834057848590429, G Loss: 22.214820861816406\n",
      "Epoch: 41, Batch: 254, D Loss: 0.10127533238321991, G Loss: 22.23772430419922\n",
      "Epoch: 41, Batch: 255, D Loss: 0.09056983899521856, G Loss: 22.173818588256836\n",
      "Epoch: 41, Batch: 256, D Loss: 0.0874470473609896, G Loss: 22.015254974365234\n",
      "Epoch: 41, Batch: 257, D Loss: 0.10523512972694306, G Loss: 22.088926315307617\n",
      "Epoch: 41, Batch: 258, D Loss: 0.09903708112089088, G Loss: 22.24228286743164\n",
      "Epoch: 41, Batch: 259, D Loss: 0.09644185016846618, G Loss: 22.37112808227539\n",
      "Epoch: 41, Batch: 260, D Loss: 0.09953897455497135, G Loss: 22.47661018371582\n",
      "Epoch: 41, Batch: 261, D Loss: 0.10308875896788361, G Loss: 22.579681396484375\n",
      "Epoch: 41, Batch: 262, D Loss: 0.10275591917454702, G Loss: 22.63958168029785\n",
      "Epoch: 41, Batch: 263, D Loss: 0.10341000564255019, G Loss: 22.652101516723633\n",
      "Epoch: 41, Batch: 264, D Loss: 0.09482295819041658, G Loss: 22.501220703125\n",
      "Epoch: 41, Batch: 265, D Loss: 0.09823097297919955, G Loss: 22.316242218017578\n",
      "Epoch: 41, Batch: 266, D Loss: 0.1010219604849627, G Loss: 22.214122772216797\n",
      "Epoch: 41, Batch: 267, D Loss: 0.10190400492385882, G Loss: 22.230648040771484\n",
      "Epoch: 41, Batch: 268, D Loss: 0.10211332152824248, G Loss: 22.33704948425293\n",
      "Epoch: 41, Batch: 269, D Loss: 0.09454952190196561, G Loss: 22.3651180267334\n",
      "Epoch: 41, Batch: 270, D Loss: 0.09817738840640315, G Loss: 22.381736755371094\n",
      "Epoch: 41, Batch: 271, D Loss: 0.09831681857078253, G Loss: 22.384899139404297\n",
      "Epoch: 41, Batch: 272, D Loss: 0.1000981108299297, G Loss: 22.392993927001953\n",
      "Epoch: 41, Batch: 273, D Loss: 0.0981251002305969, G Loss: 22.38007354736328\n",
      "Epoch: 41, Batch: 274, D Loss: 0.09505970785986087, G Loss: 22.308191299438477\n",
      "Epoch: 41, Batch: 275, D Loss: 0.0947341845519119, G Loss: 22.209165573120117\n",
      "Epoch: 41, Batch: 276, D Loss: 0.09530026477452626, G Loss: 22.12969398498535\n",
      "Epoch: 41, Batch: 277, D Loss: 0.09971477103401903, G Loss: 22.154964447021484\n",
      "Epoch: 41, Batch: 278, D Loss: 0.0963305832117119, G Loss: 22.20806884765625\n",
      "Epoch: 41, Batch: 279, D Loss: 0.10800240943959877, G Loss: 22.432193756103516\n",
      "Epoch: 41, Batch: 280, D Loss: 0.10431314267805711, G Loss: 22.65765380859375\n",
      "Epoch: 41, Batch: 281, D Loss: 0.10088310397579459, G Loss: 22.753890991210938\n",
      "Epoch: 41, Batch: 282, D Loss: 0.0901916474829989, G Loss: 22.561452865600586\n",
      "Epoch: 41, Batch: 283, D Loss: 0.09243909279019769, G Loss: 22.23347282409668\n",
      "Epoch: 41, Batch: 284, D Loss: 0.10116358113608868, G Loss: 22.037439346313477\n",
      "Epoch: 41, Batch: 285, D Loss: 0.10206699384799639, G Loss: 22.033723831176758\n",
      "Epoch: 41, Batch: 286, D Loss: 0.09398147477004028, G Loss: 22.073570251464844\n",
      "Epoch: 41, Batch: 287, D Loss: 0.10201331984893329, G Loss: 22.24843406677246\n",
      "Epoch: 41, Batch: 288, D Loss: 0.10045766095128142, G Loss: 22.4578914642334\n",
      "Epoch: 41, Batch: 289, D Loss: 0.10037414737690753, G Loss: 22.621257781982422\n",
      "Epoch: 41, Batch: 290, D Loss: 0.10139338679325503, G Loss: 22.706562042236328\n",
      "Epoch: 41, Batch: 291, D Loss: 0.09741015739395409, G Loss: 22.64506721496582\n",
      "Epoch: 41, Batch: 292, D Loss: 0.09325827666421024, G Loss: 22.417789459228516\n",
      "Epoch: 41, Batch: 293, D Loss: 0.1023606360949523, G Loss: 22.273351669311523\n",
      "Epoch: 41, Batch: 294, D Loss: 0.10974679897447319, G Loss: 22.35736083984375\n",
      "Epoch: 41, Batch: 295, D Loss: 0.0991306156848369, G Loss: 22.45177459716797\n",
      "Epoch: 41, Batch: 296, D Loss: 0.10014630862618164, G Loss: 22.536935806274414\n",
      "Epoch: 41, Batch: 297, D Loss: 0.0944497586126824, G Loss: 22.502498626708984\n",
      "Epoch: 41, Batch: 298, D Loss: 0.10045904674761058, G Loss: 22.47187614440918\n",
      "Epoch: 41, Batch: 299, D Loss: 0.09717988976883343, G Loss: 22.410198211669922\n",
      "Epoch: 41, Batch: 300, D Loss: 0.09839612255052954, G Loss: 22.361778259277344\n",
      "Epoch: 41, Batch: 301, D Loss: 0.10304141054088349, G Loss: 22.409692764282227\n",
      "Epoch: 41, Batch: 302, D Loss: 0.09458191702162033, G Loss: 22.39463996887207\n",
      "Epoch: 41, Batch: 303, D Loss: 0.10113234827188647, G Loss: 22.43401336669922\n",
      "Epoch: 41, Batch: 304, D Loss: 0.0899880082367239, G Loss: 22.334800720214844\n",
      "Epoch: 41, Batch: 305, D Loss: 0.1005454436950765, G Loss: 22.319122314453125\n",
      "Epoch: 41, Batch: 306, D Loss: 0.09772716472657852, G Loss: 22.33631706237793\n",
      "Epoch: 41, Batch: 307, D Loss: 0.10260483631968949, G Loss: 22.44334602355957\n",
      "Epoch: 41, Batch: 308, D Loss: 0.09778845318812088, G Loss: 22.519500732421875\n",
      "Epoch: 41, Batch: 309, D Loss: 0.0996487513993223, G Loss: 22.568113327026367\n",
      "Epoch: 41, Batch: 310, D Loss: 0.10082706816828173, G Loss: 22.596786499023438\n",
      "Epoch: 41, Batch: 311, D Loss: 0.09752464302300842, G Loss: 22.550804138183594\n",
      "Epoch: 41, Batch: 312, D Loss: 0.10134214916069036, G Loss: 22.517105102539062\n",
      "Epoch: 41, Batch: 313, D Loss: 0.10144478836084805, G Loss: 22.504892349243164\n",
      "Epoch: 41, Batch: 314, D Loss: 0.09598398962385654, G Loss: 22.44027328491211\n",
      "Epoch: 41, Batch: 315, D Loss: 0.09613838056161422, G Loss: 22.35904884338379\n",
      "Epoch: 41, Batch: 316, D Loss: 0.10109303156329943, G Loss: 22.361217498779297\n",
      "Epoch: 41, Batch: 317, D Loss: 0.09422739605058014, G Loss: 22.32941436767578\n",
      "Epoch: 41, Batch: 318, D Loss: 0.1024567709336061, G Loss: 22.407333374023438\n",
      "Epoch: 41, Batch: 319, D Loss: 0.10553489633856544, G Loss: 22.595979690551758\n",
      "Epoch: 41, Batch: 320, D Loss: 0.09968279309325227, G Loss: 22.7185115814209\n",
      "Epoch: 41, Batch: 321, D Loss: 0.1001797095609382, G Loss: 22.751419067382812\n",
      "Epoch: 41, Batch: 322, D Loss: 0.09728870547765939, G Loss: 22.65843391418457\n",
      "Epoch: 41, Batch: 323, D Loss: 0.10594795651604191, G Loss: 22.632112503051758\n",
      "Epoch: 41, Batch: 324, D Loss: 0.09721485533141144, G Loss: 22.542207717895508\n",
      "Epoch: 41, Batch: 325, D Loss: 0.09657263019377996, G Loss: 22.422279357910156\n",
      "Epoch: 41, Batch: 326, D Loss: 0.09891463825623781, G Loss: 22.35798454284668\n",
      "Epoch: 41, Batch: 327, D Loss: 0.10414708415061258, G Loss: 22.442113876342773\n",
      "Epoch: 41, Batch: 328, D Loss: 0.09910754867952025, G Loss: 22.5419921875\n",
      "Epoch: 41, Batch: 329, D Loss: 0.09486963607968868, G Loss: 22.55687141418457\n",
      "Epoch: 41, Batch: 330, D Loss: 0.10234407343300739, G Loss: 22.607711791992188\n",
      "Epoch: 41, Batch: 331, D Loss: 0.10331882543735492, G Loss: 22.676876068115234\n",
      "Epoch: 41, Batch: 332, D Loss: 0.09439235932993842, G Loss: 22.61585807800293\n",
      "Epoch: 41, Batch: 333, D Loss: 0.0955273807854213, G Loss: 22.488876342773438\n",
      "Epoch: 41, Batch: 334, D Loss: 0.09757252791624614, G Loss: 22.383546829223633\n",
      "Epoch: 41, Batch: 335, D Loss: 0.09213000546128752, G Loss: 22.255943298339844\n",
      "Epoch: 41, Batch: 336, D Loss: 0.11432480076538026, G Loss: 22.494152069091797\n",
      "Epoch: 41, Batch: 337, D Loss: 0.09828771658438609, G Loss: 22.696691513061523\n",
      "Epoch: 41, Batch: 338, D Loss: 0.09644063568823269, G Loss: 22.77497100830078\n",
      "Epoch: 41, Batch: 339, D Loss: 0.10039009160243409, G Loss: 22.782514572143555\n",
      "Epoch: 41, Batch: 340, D Loss: 0.09949182725591432, G Loss: 22.717575073242188\n",
      "Epoch: 41, Batch: 341, D Loss: 0.10174772150397693, G Loss: 22.654865264892578\n",
      "Epoch: 41, Batch: 342, D Loss: 0.10124799616609918, G Loss: 22.608306884765625\n",
      "Epoch: 41, Batch: 343, D Loss: 0.1059560105940289, G Loss: 22.667850494384766\n",
      "Epoch: 41, Batch: 344, D Loss: 0.10444496578803843, G Loss: 22.767683029174805\n",
      "Epoch: 41, Batch: 345, D Loss: 0.10632935172405572, G Loss: 22.89700698852539\n",
      "Epoch: 41, Batch: 346, D Loss: 0.09862175589543994, G Loss: 22.891372680664062\n",
      "Epoch: 41, Batch: 347, D Loss: 0.09310332692026632, G Loss: 22.70207405090332\n",
      "Epoch: 41, Batch: 348, D Loss: 0.09797883041438164, G Loss: 22.49997329711914\n",
      "Epoch: 41, Batch: 349, D Loss: 0.0974568651039532, G Loss: 22.35474967956543\n",
      "Epoch: 41, Batch: 350, D Loss: 0.1031831354859983, G Loss: 22.396116256713867\n",
      "Epoch: 41, Batch: 351, D Loss: 0.10132893183497788, G Loss: 22.55961036682129\n",
      "Epoch: 41, Batch: 352, D Loss: 0.09898176796612082, G Loss: 22.718917846679688\n",
      "Epoch: 41, Batch: 353, D Loss: 0.09685392684323496, G Loss: 22.792089462280273\n",
      "Epoch: 41, Batch: 354, D Loss: 0.09951433545662404, G Loss: 22.805660247802734\n",
      "Epoch: 41, Batch: 355, D Loss: 0.09966988867909582, G Loss: 22.770294189453125\n",
      "Epoch: 41, Batch: 356, D Loss: 0.09294166422976197, G Loss: 22.603750228881836\n",
      "Epoch: 41, Batch: 357, D Loss: 0.10386528082549773, G Loss: 22.558815002441406\n",
      "Epoch: 41, Batch: 358, D Loss: 0.10271088786732381, G Loss: 22.61115074157715\n",
      "Epoch: 41, Batch: 359, D Loss: 0.10071007914677374, G Loss: 22.683507919311523\n",
      "Epoch: 41, Batch: 360, D Loss: 0.10574321455366772, G Loss: 22.81679344177246\n",
      "Epoch: 41, Batch: 361, D Loss: 0.10290797060618603, G Loss: 22.915328979492188\n",
      "Epoch: 41, Batch: 362, D Loss: 0.09526024764637461, G Loss: 22.8361873626709\n",
      "Epoch: 41, Batch: 363, D Loss: 0.10627587145780726, G Loss: 22.79576873779297\n",
      "Epoch: 41, Batch: 364, D Loss: 0.09838770336628146, G Loss: 22.683597564697266\n",
      "Epoch: 41, Batch: 365, D Loss: 0.09321963794923002, G Loss: 22.477855682373047\n",
      "Epoch: 41, Batch: 366, D Loss: 0.10209710905003294, G Loss: 22.404754638671875\n",
      "Epoch: 41, Batch: 367, D Loss: 0.10339138665775872, G Loss: 22.484739303588867\n",
      "Epoch: 41, Batch: 368, D Loss: 0.09753288336887908, G Loss: 22.563621520996094\n",
      "Epoch: 41, Batch: 369, D Loss: 0.10343166448070405, G Loss: 22.711008071899414\n",
      "Epoch: 41, Batch: 370, D Loss: 0.10008275515403951, G Loss: 22.803897857666016\n",
      "Epoch: 41, Batch: 371, D Loss: 0.08864732838474024, G Loss: 22.653076171875\n",
      "Epoch: 41, Batch: 372, D Loss: 0.09372878827844294, G Loss: 22.434843063354492\n",
      "Epoch: 41, Batch: 373, D Loss: 0.097670003868966, G Loss: 22.29488182067871\n",
      "Epoch: 41, Batch: 374, D Loss: 0.09679789106666534, G Loss: 22.265159606933594\n",
      "Epoch: 41, Batch: 375, D Loss: 0.09735944132369323, G Loss: 22.33861541748047\n",
      "Epoch: 41, Batch: 376, D Loss: 0.10374484965049656, G Loss: 22.573057174682617\n",
      "Epoch: 41, Batch: 377, D Loss: 0.1023012772888569, G Loss: 22.83169937133789\n",
      "Epoch: 41, Batch: 378, D Loss: 0.09940822428115967, G Loss: 22.981197357177734\n",
      "Epoch: 41, Batch: 379, D Loss: 0.10154588525674804, G Loss: 23.010684967041016\n",
      "Epoch: 41, Batch: 380, D Loss: 0.10007956629358886, G Loss: 22.91876983642578\n",
      "Epoch: 41, Batch: 381, D Loss: 0.09873616701493199, G Loss: 22.747493743896484\n",
      "Epoch: 41, Batch: 382, D Loss: 0.09835313267837878, G Loss: 22.561532974243164\n",
      "Epoch: 41, Batch: 383, D Loss: 0.10792733736789614, G Loss: 22.573713302612305\n",
      "Epoch: 41, Batch: 384, D Loss: 0.09628078349366881, G Loss: 22.567861557006836\n",
      "Epoch: 41, Batch: 385, D Loss: 0.09722125538143883, G Loss: 22.568761825561523\n",
      "Epoch: 41, Batch: 386, D Loss: 0.10504630960484877, G Loss: 22.689367294311523\n",
      "Epoch: 41, Batch: 387, D Loss: 0.09575580812416762, G Loss: 22.723190307617188\n",
      "Epoch: 41, Batch: 388, D Loss: 0.10002467788011402, G Loss: 22.74049186706543\n",
      "Epoch: 41, Batch: 389, D Loss: 0.09801937646502942, G Loss: 22.70136260986328\n",
      "Epoch: 41, Batch: 390, D Loss: 0.10492431379176823, G Loss: 22.741331100463867\n",
      "Epoch: 41, Batch: 391, D Loss: 0.09679798788650065, G Loss: 22.70379638671875\n",
      "Epoch: 41, Batch: 392, D Loss: 0.0993762017002208, G Loss: 22.66068458557129\n",
      "Epoch: 41, Batch: 393, D Loss: 0.10082847632275288, G Loss: 22.64645004272461\n",
      "Epoch: 41, Batch: 394, D Loss: 0.09986225522911439, G Loss: 22.64639663696289\n",
      "Epoch: 41, Batch: 395, D Loss: 0.10662847764216732, G Loss: 22.761606216430664\n",
      "Epoch: 41, Batch: 396, D Loss: 0.09488624340898125, G Loss: 22.746936798095703\n",
      "Epoch: 41, Batch: 397, D Loss: 0.10144734389293278, G Loss: 22.731115341186523\n",
      "Epoch: 41, Batch: 398, D Loss: 0.09457328177674118, G Loss: 22.615108489990234\n",
      "Epoch: 41, Batch: 399, D Loss: 0.09940269597298709, G Loss: 22.532495498657227\n",
      "Epoch: 41, Batch: 400, D Loss: 0.10268304505078814, G Loss: 22.559125900268555\n",
      "Epoch: 41, Batch: 401, D Loss: 0.09963954992882071, G Loss: 22.61561393737793\n",
      "Epoch: 41, Batch: 402, D Loss: 0.10104262836075203, G Loss: 22.68952751159668\n",
      "Epoch: 41, Batch: 403, D Loss: 0.10265520966765687, G Loss: 22.78008460998535\n",
      "Epoch: 41, Batch: 404, D Loss: 0.10655073827520256, G Loss: 22.90828514099121\n",
      "Epoch: 41, Batch: 405, D Loss: 0.10640613740030855, G Loss: 23.01777458190918\n",
      "Epoch: 41, Batch: 406, D Loss: 0.10138286655279466, G Loss: 22.996021270751953\n",
      "Epoch: 41, Batch: 407, D Loss: 0.09831780945928469, G Loss: 22.82551383972168\n",
      "Epoch: 41, Batch: 408, D Loss: 0.10078938312126069, G Loss: 22.636150360107422\n",
      "Epoch: 41, Batch: 409, D Loss: 0.09501126416879149, G Loss: 22.412673950195312\n",
      "Epoch: 41, Batch: 410, D Loss: 0.10020475099261311, G Loss: 22.31635856628418\n",
      "Epoch: 41, Batch: 411, D Loss: 0.1010533721243822, G Loss: 22.368623733520508\n",
      "Epoch: 41, Batch: 412, D Loss: 0.09468460092336728, G Loss: 22.432405471801758\n",
      "Epoch: 41, Batch: 413, D Loss: 0.09851332017428527, G Loss: 22.531747817993164\n",
      "Epoch: 41, Batch: 414, D Loss: 0.09950370349279108, G Loss: 22.640329360961914\n",
      "Epoch: 41, Batch: 415, D Loss: 0.09830318398429269, G Loss: 22.704946517944336\n",
      "Epoch: 41, Batch: 416, D Loss: 0.10168682045509342, G Loss: 22.751461029052734\n",
      "Epoch: 41, Batch: 417, D Loss: 0.100082613593795, G Loss: 22.744762420654297\n",
      "Epoch: 41, Batch: 418, D Loss: 0.09689509130529524, G Loss: 22.648799896240234\n",
      "Epoch: 41, Batch: 419, D Loss: 0.1038438678527619, G Loss: 22.620777130126953\n",
      "Epoch: 41, Batch: 420, D Loss: 0.09669505067504325, G Loss: 22.54909896850586\n",
      "Epoch: 41, Batch: 421, D Loss: 0.10293886073478686, G Loss: 22.56300926208496\n",
      "Epoch: 41, Batch: 422, D Loss: 0.10457602895852171, G Loss: 22.670351028442383\n",
      "Epoch: 41, Batch: 423, D Loss: 0.09817278392137484, G Loss: 22.71331024169922\n",
      "Epoch: 41, Batch: 424, D Loss: 0.0972937197191342, G Loss: 22.67277717590332\n",
      "Epoch: 41, Batch: 425, D Loss: 0.09866776324737106, G Loss: 22.60409927368164\n",
      "Epoch: 41, Batch: 426, D Loss: 0.09903205939076933, G Loss: 22.538658142089844\n",
      "Epoch: 41, Batch: 427, D Loss: 0.09844715156547303, G Loss: 22.492996215820312\n",
      "Epoch: 41, Batch: 428, D Loss: 0.09988507636886482, G Loss: 22.509483337402344\n",
      "Epoch: 41, Batch: 429, D Loss: 0.09928838916837421, G Loss: 22.55881118774414\n",
      "Epoch: 41, Batch: 430, D Loss: 0.10381435610341053, G Loss: 22.69158935546875\n",
      "Epoch: 41, Batch: 431, D Loss: 0.10275629169277897, G Loss: 22.831159591674805\n",
      "Epoch: 41, Batch: 432, D Loss: 0.09632361686368651, G Loss: 22.823469161987305\n",
      "Epoch: 41, Batch: 433, D Loss: 0.09846106178008832, G Loss: 22.738651275634766\n",
      "Epoch: 41, Batch: 434, D Loss: 0.10355886823780942, G Loss: 22.699419021606445\n",
      "Epoch: 41, Batch: 435, D Loss: 0.09593545652789166, G Loss: 22.59694480895996\n",
      "Epoch: 41, Batch: 436, D Loss: 0.0912132711067066, G Loss: 22.406387329101562\n",
      "Epoch: 41, Batch: 437, D Loss: 0.10276049384889951, G Loss: 22.392948150634766\n",
      "Epoch: 41, Batch: 438, D Loss: 0.09556576618889268, G Loss: 22.420982360839844\n",
      "Epoch: 41, Batch: 439, D Loss: 0.10042098918201757, G Loss: 22.543020248413086\n",
      "Epoch: 41, Batch: 440, D Loss: 0.09777587659820415, G Loss: 22.661314010620117\n",
      "Epoch: 41, Batch: 441, D Loss: 0.10430003709200253, G Loss: 22.837860107421875\n",
      "Epoch: 41, Batch: 442, D Loss: 0.09925964480469412, G Loss: 22.915884017944336\n",
      "Epoch: 41, Batch: 443, D Loss: 0.09683061396879, G Loss: 22.854700088500977\n",
      "Epoch: 41, Batch: 444, D Loss: 0.09696773446080659, G Loss: 22.700292587280273\n",
      "Epoch: 41, Batch: 445, D Loss: 0.0979084075249769, G Loss: 22.54178810119629\n",
      "Epoch: 41, Batch: 446, D Loss: 0.10231923320194872, G Loss: 22.510967254638672\n",
      "Epoch: 41, Batch: 447, D Loss: 0.09744764872802207, G Loss: 22.51323699951172\n",
      "Epoch: 41, Batch: 448, D Loss: 0.10606523610834173, G Loss: 22.683170318603516\n",
      "Epoch: 41, Batch: 449, D Loss: 0.09737308330050279, G Loss: 22.787538528442383\n",
      "Epoch: 41, Batch: 450, D Loss: 0.09890674060849315, G Loss: 22.82351303100586\n",
      "Epoch: 41, Batch: 451, D Loss: 0.10426811134827638, G Loss: 22.870187759399414\n",
      "Epoch: 41, Batch: 452, D Loss: 0.09567406779705415, G Loss: 22.77619743347168\n",
      "Epoch: 41, Batch: 453, D Loss: 0.09600000835520253, G Loss: 22.606733322143555\n",
      "Epoch: 41, Batch: 454, D Loss: 0.10867615051579016, G Loss: 22.64235496520996\n",
      "Epoch: 41, Batch: 455, D Loss: 0.10703492171358342, G Loss: 22.801618576049805\n",
      "Epoch: 41, Batch: 456, D Loss: 0.10572627937546947, G Loss: 22.97394371032715\n",
      "Epoch: 41, Batch: 457, D Loss: 0.09597439324238861, G Loss: 22.946338653564453\n",
      "Epoch: 41, Batch: 458, D Loss: 0.09851910179738349, G Loss: 22.80042266845703\n",
      "Epoch: 41, Batch: 459, D Loss: 0.10114374763562098, G Loss: 22.658628463745117\n",
      "Epoch: 41, Batch: 460, D Loss: 0.0921656192163336, G Loss: 22.429170608520508\n",
      "Epoch: 41, Batch: 461, D Loss: 0.09582160423160319, G Loss: 22.265716552734375\n",
      "Epoch: 41, Batch: 462, D Loss: 0.09920682023699368, G Loss: 22.27082633972168\n",
      "Epoch: 41, Batch: 463, D Loss: 0.10386621216569465, G Loss: 22.47147560119629\n",
      "Epoch: 41, Batch: 464, D Loss: 0.09545406707187978, G Loss: 22.629878997802734\n",
      "Epoch: 41, Batch: 465, D Loss: 0.10320114351057744, G Loss: 22.826059341430664\n",
      "Epoch: 41, Batch: 466, D Loss: 0.09306852525642564, G Loss: 22.81843376159668\n",
      "Epoch: 41, Batch: 467, D Loss: 0.09615691757832316, G Loss: 22.687585830688477\n",
      "Epoch: 42, Batch: 0, D Loss: 0.10063147552274322, G Loss: 22.581886291503906\n",
      "Epoch: 42, Batch: 1, D Loss: 0.1009232626160121, G Loss: 22.544681549072266\n",
      "Epoch: 42, Batch: 2, D Loss: 0.09854134925396087, G Loss: 22.533720016479492\n",
      "Epoch: 42, Batch: 3, D Loss: 0.0994719118686993, G Loss: 22.558975219726562\n",
      "Epoch: 42, Batch: 4, D Loss: 0.09893356271435488, G Loss: 22.601688385009766\n",
      "Epoch: 42, Batch: 5, D Loss: 0.09545014061295609, G Loss: 22.584192276000977\n",
      "Epoch: 42, Batch: 6, D Loss: 0.09875957675660224, G Loss: 22.57054901123047\n",
      "Epoch: 42, Batch: 7, D Loss: 0.10092766590702965, G Loss: 22.60614585876465\n",
      "Epoch: 42, Batch: 8, D Loss: 0.10010357208500206, G Loss: 22.658536911010742\n",
      "Epoch: 42, Batch: 9, D Loss: 0.09173336632675237, G Loss: 22.566848754882812\n",
      "Epoch: 42, Batch: 10, D Loss: 0.09349643447598577, G Loss: 22.420751571655273\n",
      "Epoch: 42, Batch: 11, D Loss: 0.10004179188968862, G Loss: 22.39128303527832\n",
      "Epoch: 42, Batch: 12, D Loss: 0.10060118147777349, G Loss: 22.48287582397461\n",
      "Epoch: 42, Batch: 13, D Loss: 0.10283153511928984, G Loss: 22.670440673828125\n",
      "Epoch: 42, Batch: 14, D Loss: 0.10092224187229873, G Loss: 22.837890625\n",
      "Epoch: 42, Batch: 15, D Loss: 0.1014174298024148, G Loss: 22.93880844116211\n",
      "Epoch: 42, Batch: 16, D Loss: 0.09296008950330611, G Loss: 22.815776824951172\n",
      "Epoch: 42, Batch: 17, D Loss: 0.0962190777752988, G Loss: 22.60359001159668\n",
      "Epoch: 42, Batch: 18, D Loss: 0.09575600185542511, G Loss: 22.398910522460938\n",
      "Epoch: 42, Batch: 19, D Loss: 0.10086103538339085, G Loss: 22.350513458251953\n",
      "Epoch: 42, Batch: 20, D Loss: 0.0967123658432937, G Loss: 22.37861442565918\n",
      "Epoch: 42, Batch: 21, D Loss: 0.10162505516208611, G Loss: 22.5472412109375\n",
      "Epoch: 42, Batch: 22, D Loss: 0.0890888572539551, G Loss: 22.562786102294922\n",
      "Epoch: 42, Batch: 23, D Loss: 0.10609497137207607, G Loss: 22.725919723510742\n",
      "Epoch: 42, Batch: 24, D Loss: 0.10130552953765642, G Loss: 22.873403549194336\n",
      "Epoch: 42, Batch: 25, D Loss: 0.09784126287472497, G Loss: 22.90277671813965\n",
      "Epoch: 42, Batch: 26, D Loss: 0.09161739057582098, G Loss: 22.715333938598633\n",
      "Epoch: 42, Batch: 27, D Loss: 0.09900574393566275, G Loss: 22.548324584960938\n",
      "Epoch: 42, Batch: 28, D Loss: 0.0907572285249725, G Loss: 22.319738388061523\n",
      "Epoch: 42, Batch: 29, D Loss: 0.09801732014204614, G Loss: 22.248815536499023\n",
      "Epoch: 42, Batch: 30, D Loss: 0.1019336582238198, G Loss: 22.392929077148438\n",
      "Epoch: 42, Batch: 31, D Loss: 0.09765934952648105, G Loss: 22.588123321533203\n",
      "Epoch: 42, Batch: 32, D Loss: 0.09651938087947674, G Loss: 22.737451553344727\n",
      "Epoch: 42, Batch: 33, D Loss: 0.10326205200093128, G Loss: 22.908437728881836\n",
      "Epoch: 42, Batch: 34, D Loss: 0.10396532719572008, G Loss: 23.05501937866211\n",
      "Epoch: 42, Batch: 35, D Loss: 0.10111732040652822, G Loss: 23.08612823486328\n",
      "Epoch: 42, Batch: 36, D Loss: 0.10350106661367675, G Loss: 23.042734146118164\n",
      "Epoch: 42, Batch: 37, D Loss: 0.101717211358141, G Loss: 22.934341430664062\n",
      "Epoch: 42, Batch: 38, D Loss: 0.09837079799210398, G Loss: 22.76288604736328\n",
      "Epoch: 42, Batch: 39, D Loss: 0.10187607265452181, G Loss: 22.652149200439453\n",
      "Epoch: 42, Batch: 40, D Loss: 0.09645804770529616, G Loss: 22.544349670410156\n",
      "Epoch: 42, Batch: 41, D Loss: 0.09510626652341728, G Loss: 22.46317481994629\n",
      "Epoch: 42, Batch: 42, D Loss: 0.09775864341624729, G Loss: 22.477680206298828\n",
      "Epoch: 42, Batch: 43, D Loss: 0.09896273174089398, G Loss: 22.59130096435547\n",
      "Epoch: 42, Batch: 44, D Loss: 0.10024207092436477, G Loss: 22.759803771972656\n",
      "Epoch: 42, Batch: 45, D Loss: 0.09569492197333218, G Loss: 22.839210510253906\n",
      "Epoch: 42, Batch: 46, D Loss: 0.10066251462559847, G Loss: 22.9045467376709\n",
      "Epoch: 42, Batch: 47, D Loss: 0.10114679491103556, G Loss: 22.938791275024414\n",
      "Epoch: 42, Batch: 48, D Loss: 0.10652455692717124, G Loss: 23.031763076782227\n",
      "Epoch: 42, Batch: 49, D Loss: 0.1013935134310347, G Loss: 23.03759002685547\n",
      "Epoch: 42, Batch: 50, D Loss: 0.10498645906615225, G Loss: 23.040096282958984\n",
      "Epoch: 42, Batch: 51, D Loss: 0.10176490252339264, G Loss: 22.979251861572266\n",
      "Epoch: 42, Batch: 52, D Loss: 0.09210835403204379, G Loss: 22.733245849609375\n",
      "Epoch: 42, Batch: 53, D Loss: 0.09535440810195359, G Loss: 22.48781967163086\n",
      "Epoch: 42, Batch: 54, D Loss: 0.09508910784545666, G Loss: 22.318326950073242\n",
      "Epoch: 42, Batch: 55, D Loss: 0.1024323404807777, G Loss: 22.39869499206543\n",
      "Epoch: 42, Batch: 56, D Loss: 0.0954536870995261, G Loss: 22.530649185180664\n",
      "Epoch: 42, Batch: 57, D Loss: 0.09353838868769906, G Loss: 22.631175994873047\n",
      "Epoch: 42, Batch: 58, D Loss: 0.09662280238776083, G Loss: 22.72503662109375\n",
      "Epoch: 42, Batch: 59, D Loss: 0.09554135806056568, G Loss: 22.755186080932617\n",
      "Epoch: 42, Batch: 60, D Loss: 0.10329677170810425, G Loss: 22.84368324279785\n",
      "Epoch: 42, Batch: 61, D Loss: 0.10165584093129562, G Loss: 22.92169952392578\n",
      "Epoch: 42, Batch: 62, D Loss: 0.09576059138508668, G Loss: 22.872554779052734\n",
      "Epoch: 42, Batch: 63, D Loss: 0.09968690580226183, G Loss: 22.79940414428711\n",
      "Epoch: 42, Batch: 64, D Loss: 0.09533479816545731, G Loss: 22.6495418548584\n",
      "Epoch: 42, Batch: 65, D Loss: 0.10661197460889345, G Loss: 22.684446334838867\n",
      "Epoch: 42, Batch: 66, D Loss: 0.09485538310954114, G Loss: 22.66636848449707\n",
      "Epoch: 42, Batch: 67, D Loss: 0.09732292599775869, G Loss: 22.643356323242188\n",
      "Epoch: 42, Batch: 68, D Loss: 0.10154578841906756, G Loss: 22.694650650024414\n",
      "Epoch: 42, Batch: 69, D Loss: 0.10159322626058499, G Loss: 22.790573120117188\n",
      "Epoch: 42, Batch: 70, D Loss: 0.09700369841172005, G Loss: 22.806976318359375\n",
      "Epoch: 42, Batch: 71, D Loss: 0.10440525418558116, G Loss: 22.87687873840332\n",
      "Epoch: 42, Batch: 72, D Loss: 0.10223019128730099, G Loss: 22.926830291748047\n",
      "Epoch: 42, Batch: 73, D Loss: 0.10100550955090204, G Loss: 22.92816162109375\n",
      "Epoch: 42, Batch: 74, D Loss: 0.09395372873566851, G Loss: 22.77265167236328\n",
      "Epoch: 42, Batch: 75, D Loss: 0.10769718891793247, G Loss: 22.79322052001953\n",
      "Epoch: 42, Batch: 76, D Loss: 0.10112664109762513, G Loss: 22.809911727905273\n",
      "Epoch: 42, Batch: 77, D Loss: 0.09566353267948813, G Loss: 22.72811508178711\n",
      "Epoch: 42, Batch: 78, D Loss: 0.10126726336202191, G Loss: 22.688623428344727\n",
      "Epoch: 42, Batch: 79, D Loss: 0.10364404327559712, G Loss: 22.733245849609375\n",
      "Epoch: 42, Batch: 80, D Loss: 0.10780118411970985, G Loss: 22.89507293701172\n",
      "Epoch: 42, Batch: 81, D Loss: 0.09891904151025971, G Loss: 22.94639778137207\n",
      "Epoch: 42, Batch: 82, D Loss: 0.09915581351108765, G Loss: 22.898876190185547\n",
      "Epoch: 42, Batch: 83, D Loss: 0.09851115203028353, G Loss: 22.76681900024414\n",
      "Epoch: 42, Batch: 84, D Loss: 0.09911450750642198, G Loss: 22.62851905822754\n",
      "Epoch: 42, Batch: 85, D Loss: 0.10022243865105981, G Loss: 22.557575225830078\n",
      "Epoch: 42, Batch: 86, D Loss: 0.1026678235118085, G Loss: 22.604082107543945\n",
      "Epoch: 42, Batch: 87, D Loss: 0.10598591722043284, G Loss: 22.780725479125977\n",
      "Epoch: 42, Batch: 88, D Loss: 0.09192766255604956, G Loss: 22.77002716064453\n",
      "Epoch: 42, Batch: 89, D Loss: 0.09718678153326601, G Loss: 22.69269561767578\n",
      "Epoch: 42, Batch: 90, D Loss: 0.09628953047057129, G Loss: 22.577913284301758\n",
      "Epoch: 42, Batch: 91, D Loss: 0.104833304958721, G Loss: 22.61678123474121\n",
      "Epoch: 42, Batch: 92, D Loss: 0.09896630801144904, G Loss: 22.665929794311523\n",
      "Epoch: 42, Batch: 93, D Loss: 0.10249502963691903, G Loss: 22.758668899536133\n",
      "Epoch: 42, Batch: 94, D Loss: 0.09521245963052652, G Loss: 22.72972869873047\n",
      "Epoch: 42, Batch: 95, D Loss: 0.09823340929571875, G Loss: 22.659059524536133\n",
      "Epoch: 42, Batch: 96, D Loss: 0.09920308001329253, G Loss: 22.600749969482422\n",
      "Epoch: 42, Batch: 97, D Loss: 0.0976443216986575, G Loss: 22.558855056762695\n",
      "Epoch: 42, Batch: 98, D Loss: 0.09842117883836243, G Loss: 22.548006057739258\n",
      "Epoch: 42, Batch: 99, D Loss: 0.09109760829368749, G Loss: 22.44695281982422\n",
      "Epoch: 42, Batch: 100, D Loss: 0.10272531220012834, G Loss: 22.5084228515625\n",
      "Epoch: 42, Batch: 101, D Loss: 0.10132899888173333, G Loss: 22.655324935913086\n",
      "Epoch: 42, Batch: 102, D Loss: 0.1018583030172143, G Loss: 22.82146453857422\n",
      "Epoch: 42, Batch: 103, D Loss: 0.10512183612221736, G Loss: 22.99526023864746\n",
      "Epoch: 42, Batch: 104, D Loss: 0.10208521788328828, G Loss: 23.062191009521484\n",
      "Epoch: 42, Batch: 105, D Loss: 0.09728509192830723, G Loss: 22.94339370727539\n",
      "Epoch: 42, Batch: 106, D Loss: 0.10506223892927703, G Loss: 22.843538284301758\n",
      "Epoch: 42, Batch: 107, D Loss: 0.0973373950186487, G Loss: 22.6657772064209\n",
      "Epoch: 42, Batch: 108, D Loss: 0.10051058985483954, G Loss: 22.54389190673828\n",
      "Epoch: 42, Batch: 109, D Loss: 0.09009929010399198, G Loss: 22.328166961669922\n",
      "Epoch: 42, Batch: 110, D Loss: 0.1063591689848572, G Loss: 22.380680084228516\n",
      "Epoch: 42, Batch: 111, D Loss: 0.09765836605471012, G Loss: 22.493488311767578\n",
      "Epoch: 42, Batch: 112, D Loss: 0.10082943745300618, G Loss: 22.66143798828125\n",
      "Epoch: 42, Batch: 113, D Loss: 0.10316678143095775, G Loss: 22.852567672729492\n",
      "Epoch: 42, Batch: 114, D Loss: 0.10369706159720948, G Loss: 22.88352394104004\n",
      "Epoch: 42, Batch: 115, D Loss: 0.10370430356210103, G Loss: 22.837562561035156\n",
      "Epoch: 42, Batch: 116, D Loss: 0.09825355566375346, G Loss: 22.61395263671875\n",
      "Epoch: 42, Batch: 117, D Loss: 0.09487097719601875, G Loss: 22.23015022277832\n",
      "Epoch: 42, Batch: 118, D Loss: 0.099366232883676, G Loss: 21.912803649902344\n",
      "Epoch: 42, Batch: 119, D Loss: 0.09246268886094094, G Loss: 21.63067054748535\n",
      "Epoch: 42, Batch: 120, D Loss: 0.10327564199805693, G Loss: 21.656448364257812\n",
      "Epoch: 42, Batch: 121, D Loss: 0.09681601840614851, G Loss: 21.799570083618164\n",
      "Epoch: 42, Batch: 122, D Loss: 0.09881760940338823, G Loss: 22.006338119506836\n",
      "Epoch: 42, Batch: 123, D Loss: 0.0966401846509524, G Loss: 22.138534545898438\n",
      "Epoch: 42, Batch: 124, D Loss: 0.09834659856453615, G Loss: 22.190357208251953\n",
      "Epoch: 42, Batch: 125, D Loss: 0.09775707137537343, G Loss: 22.134536743164062\n",
      "Epoch: 42, Batch: 126, D Loss: 0.0978634358749547, G Loss: 22.016643524169922\n",
      "Epoch: 42, Batch: 127, D Loss: 0.09706123187973935, G Loss: 21.880268096923828\n",
      "Epoch: 42, Batch: 128, D Loss: 0.09729525463516221, G Loss: 21.774127960205078\n",
      "Epoch: 42, Batch: 129, D Loss: 0.09791617113235666, G Loss: 21.743675231933594\n",
      "Epoch: 42, Batch: 130, D Loss: 0.09860086458569896, G Loss: 21.79642105102539\n",
      "Epoch: 42, Batch: 131, D Loss: 0.09909407810612839, G Loss: 21.90616798400879\n",
      "Epoch: 42, Batch: 132, D Loss: 0.09873474403772434, G Loss: 22.016178131103516\n",
      "Epoch: 42, Batch: 133, D Loss: 0.10130067182609093, G Loss: 22.127471923828125\n",
      "Epoch: 42, Batch: 134, D Loss: 0.10458874713948418, G Loss: 22.252704620361328\n",
      "Epoch: 42, Batch: 135, D Loss: 0.09261026244974252, G Loss: 22.13254165649414\n",
      "Epoch: 42, Batch: 136, D Loss: 0.09705791635902687, G Loss: 21.942033767700195\n",
      "Epoch: 42, Batch: 137, D Loss: 0.09627106802119559, G Loss: 21.750478744506836\n",
      "Epoch: 42, Batch: 138, D Loss: 0.09920516628627551, G Loss: 21.689777374267578\n",
      "Epoch: 42, Batch: 139, D Loss: 0.09319801647930266, G Loss: 21.65815544128418\n",
      "Epoch: 42, Batch: 140, D Loss: 0.09549054522722855, G Loss: 21.692401885986328\n",
      "Epoch: 42, Batch: 141, D Loss: 0.09807153063907252, G Loss: 21.815988540649414\n",
      "Epoch: 42, Batch: 142, D Loss: 0.09653902814591728, G Loss: 21.94063377380371\n",
      "Epoch: 42, Batch: 143, D Loss: 0.1053260566101922, G Loss: 22.189876556396484\n",
      "Epoch: 42, Batch: 144, D Loss: 0.09417020540709525, G Loss: 22.24583625793457\n",
      "Epoch: 42, Batch: 145, D Loss: 0.09658898424550255, G Loss: 22.167112350463867\n",
      "Epoch: 42, Batch: 146, D Loss: 0.09559817625103044, G Loss: 21.99302101135254\n",
      "Epoch: 42, Batch: 147, D Loss: 0.1042423026197545, G Loss: 21.966976165771484\n",
      "Epoch: 42, Batch: 148, D Loss: 0.09685060396533293, G Loss: 21.937185287475586\n",
      "Epoch: 42, Batch: 149, D Loss: 0.1020800919770457, G Loss: 22.00945281982422\n",
      "Epoch: 42, Batch: 150, D Loss: 0.09144213809882265, G Loss: 21.954702377319336\n",
      "Epoch: 42, Batch: 151, D Loss: 0.10158838345970875, G Loss: 21.997194290161133\n",
      "Epoch: 42, Batch: 152, D Loss: 0.09269481911748129, G Loss: 21.942691802978516\n",
      "Epoch: 42, Batch: 153, D Loss: 0.09441028550766684, G Loss: 21.863277435302734\n",
      "Epoch: 42, Batch: 154, D Loss: 0.09938409940327321, G Loss: 21.883756637573242\n",
      "Epoch: 42, Batch: 155, D Loss: 0.0978421495875607, G Loss: 21.952728271484375\n",
      "Epoch: 42, Batch: 156, D Loss: 0.09653150304501065, G Loss: 22.001802444458008\n",
      "Epoch: 42, Batch: 157, D Loss: 0.10124510539817776, G Loss: 22.108705520629883\n",
      "Epoch: 42, Batch: 158, D Loss: 0.10221353184888485, G Loss: 22.246932983398438\n",
      "Epoch: 42, Batch: 159, D Loss: 0.09692569087864514, G Loss: 22.255027770996094\n",
      "Epoch: 42, Batch: 160, D Loss: 0.09667524706820825, G Loss: 22.149539947509766\n",
      "Epoch: 42, Batch: 161, D Loss: 0.10157479358171283, G Loss: 22.093040466308594\n",
      "Epoch: 42, Batch: 162, D Loss: 0.09150560214211295, G Loss: 21.909282684326172\n",
      "Epoch: 42, Batch: 163, D Loss: 0.0982925148423092, G Loss: 21.814912796020508\n",
      "Epoch: 42, Batch: 164, D Loss: 0.09974569098712775, G Loss: 21.85280990600586\n",
      "Epoch: 42, Batch: 165, D Loss: 0.09265545026664032, G Loss: 21.86017417907715\n",
      "Epoch: 42, Batch: 166, D Loss: 0.10709808035871479, G Loss: 22.106491088867188\n",
      "Epoch: 42, Batch: 167, D Loss: 0.09810948383276885, G Loss: 22.288911819458008\n",
      "Epoch: 42, Batch: 168, D Loss: 0.09670123468152642, G Loss: 22.326374053955078\n",
      "Epoch: 42, Batch: 169, D Loss: 0.09563478838141862, G Loss: 22.215951919555664\n",
      "Epoch: 42, Batch: 170, D Loss: 0.09528611612825186, G Loss: 22.024791717529297\n",
      "Epoch: 42, Batch: 171, D Loss: 0.10403303815852911, G Loss: 21.99249839782715\n",
      "Epoch: 42, Batch: 172, D Loss: 0.09530418380636616, G Loss: 21.940475463867188\n",
      "Epoch: 42, Batch: 173, D Loss: 0.10071390136508453, G Loss: 22.001806259155273\n",
      "Epoch: 42, Batch: 174, D Loss: 0.10540822160753328, G Loss: 22.216938018798828\n",
      "Epoch: 42, Batch: 175, D Loss: 0.10241014520522579, G Loss: 22.412275314331055\n",
      "Epoch: 42, Batch: 176, D Loss: 0.09690640875917156, G Loss: 22.42770004272461\n",
      "Epoch: 42, Batch: 177, D Loss: 0.09138644496935933, G Loss: 22.196096420288086\n",
      "Epoch: 42, Batch: 178, D Loss: 0.09800614429515368, G Loss: 21.969058990478516\n",
      "Epoch: 42, Batch: 179, D Loss: 0.09314657763892004, G Loss: 21.749309539794922\n",
      "Epoch: 42, Batch: 180, D Loss: 0.10476105677405155, G Loss: 21.826889038085938\n",
      "Epoch: 42, Batch: 181, D Loss: 0.10164192333500204, G Loss: 22.07068634033203\n",
      "Epoch: 42, Batch: 182, D Loss: 0.10555807511790312, G Loss: 22.43684959411621\n",
      "Epoch: 42, Batch: 183, D Loss: 0.10607120402262707, G Loss: 22.770709991455078\n",
      "Epoch: 42, Batch: 184, D Loss: 0.10242114222158659, G Loss: 22.88730812072754\n",
      "Epoch: 42, Batch: 185, D Loss: 0.09596687561745068, G Loss: 22.67179298400879\n",
      "Epoch: 42, Batch: 186, D Loss: 0.09711083778532531, G Loss: 22.283384323120117\n",
      "Epoch: 42, Batch: 187, D Loss: 0.09509769095107344, G Loss: 21.871681213378906\n",
      "Epoch: 42, Batch: 188, D Loss: 0.09593474883088547, G Loss: 21.61681365966797\n",
      "Epoch: 42, Batch: 189, D Loss: 0.10964306462217459, G Loss: 21.829896926879883\n",
      "Epoch: 42, Batch: 190, D Loss: 0.10834444327071005, G Loss: 22.3101863861084\n",
      "Epoch: 42, Batch: 191, D Loss: 0.10239370175457592, G Loss: 22.728261947631836\n",
      "Epoch: 42, Batch: 192, D Loss: 0.10426802939122154, G Loss: 22.977188110351562\n",
      "Epoch: 42, Batch: 193, D Loss: 0.10263602440848853, G Loss: 22.973377227783203\n",
      "Epoch: 42, Batch: 194, D Loss: 0.09887878602869715, G Loss: 22.698974609375\n",
      "Epoch: 42, Batch: 195, D Loss: 0.10010980078061815, G Loss: 22.32769203186035\n",
      "Epoch: 42, Batch: 196, D Loss: 0.09407232714339311, G Loss: 21.902591705322266\n",
      "Epoch: 42, Batch: 197, D Loss: 0.09504546988066537, G Loss: 21.608989715576172\n",
      "Epoch: 42, Batch: 198, D Loss: 0.09559656701139754, G Loss: 21.528892517089844\n",
      "Epoch: 42, Batch: 199, D Loss: 0.0926043393387908, G Loss: 21.592906951904297\n",
      "Epoch: 42, Batch: 200, D Loss: 0.09675388801757565, G Loss: 21.825197219848633\n",
      "Epoch: 42, Batch: 201, D Loss: 0.1025205106882877, G Loss: 22.232688903808594\n",
      "Epoch: 42, Batch: 202, D Loss: 0.0977579952228339, G Loss: 22.53561782836914\n",
      "Epoch: 42, Batch: 203, D Loss: 0.10627681024006443, G Loss: 22.804513931274414\n",
      "Epoch: 42, Batch: 204, D Loss: 0.09703356033927918, G Loss: 22.77853012084961\n",
      "Epoch: 42, Batch: 205, D Loss: 0.09502101697023135, G Loss: 22.491125106811523\n",
      "Epoch: 42, Batch: 206, D Loss: 0.09403562556431988, G Loss: 22.068082809448242\n",
      "Epoch: 42, Batch: 207, D Loss: 0.09393496827317648, G Loss: 21.68537712097168\n",
      "Epoch: 42, Batch: 208, D Loss: 0.10031148811433536, G Loss: 21.58696174621582\n",
      "Epoch: 42, Batch: 209, D Loss: 0.1041092427443636, G Loss: 21.82571029663086\n",
      "Epoch: 42, Batch: 210, D Loss: 0.09259207561464088, G Loss: 22.049922943115234\n",
      "Epoch: 42, Batch: 211, D Loss: 0.10155136894662474, G Loss: 22.337167739868164\n",
      "Epoch: 42, Batch: 212, D Loss: 0.10132783660119696, G Loss: 22.578231811523438\n",
      "Epoch: 42, Batch: 213, D Loss: 0.09821473069570791, G Loss: 22.650190353393555\n",
      "Epoch: 42, Batch: 214, D Loss: 0.10402661569208202, G Loss: 22.660043716430664\n",
      "Epoch: 42, Batch: 215, D Loss: 0.09885887809363153, G Loss: 22.530637741088867\n",
      "Epoch: 42, Batch: 216, D Loss: 0.10152843603438447, G Loss: 22.37851333618164\n",
      "Epoch: 42, Batch: 217, D Loss: 0.09857533137504815, G Loss: 22.210309982299805\n",
      "Epoch: 42, Batch: 218, D Loss: 0.09884260606805345, G Loss: 22.10266876220703\n",
      "Epoch: 42, Batch: 219, D Loss: 0.09136512889212442, G Loss: 21.947643280029297\n",
      "Epoch: 42, Batch: 220, D Loss: 0.0934506879805361, G Loss: 21.848331451416016\n",
      "Epoch: 42, Batch: 221, D Loss: 0.0965069832016423, G Loss: 21.877180099487305\n",
      "Epoch: 42, Batch: 222, D Loss: 0.09354197249027674, G Loss: 21.958173751831055\n",
      "Epoch: 42, Batch: 223, D Loss: 0.09791303439445494, G Loss: 22.111072540283203\n",
      "Epoch: 42, Batch: 224, D Loss: 0.10451050858461092, G Loss: 22.404489517211914\n",
      "Epoch: 42, Batch: 225, D Loss: 0.09701900937746462, G Loss: 22.569215774536133\n",
      "Epoch: 42, Batch: 226, D Loss: 0.0968401879860257, G Loss: 22.57242774963379\n",
      "Epoch: 42, Batch: 227, D Loss: 0.09658967712031767, G Loss: 22.436626434326172\n",
      "Epoch: 42, Batch: 228, D Loss: 0.09634625921730641, G Loss: 22.235464096069336\n",
      "Epoch: 42, Batch: 229, D Loss: 0.1025015936445577, G Loss: 22.16496467590332\n",
      "Epoch: 42, Batch: 230, D Loss: 0.10940571885092301, G Loss: 22.352811813354492\n",
      "Epoch: 42, Batch: 231, D Loss: 0.09750770041683929, G Loss: 22.45697593688965\n",
      "Epoch: 42, Batch: 232, D Loss: 0.09775363662655509, G Loss: 22.47304344177246\n",
      "Epoch: 42, Batch: 233, D Loss: 0.10030402251908371, G Loss: 22.455596923828125\n",
      "Epoch: 42, Batch: 234, D Loss: 0.09659005710914476, G Loss: 22.345172882080078\n",
      "Epoch: 42, Batch: 235, D Loss: 0.0978547782758456, G Loss: 22.22400665283203\n",
      "Epoch: 42, Batch: 236, D Loss: 0.09747736167698473, G Loss: 22.13031768798828\n",
      "Epoch: 42, Batch: 237, D Loss: 0.10042577249041966, G Loss: 22.14473533630371\n",
      "Epoch: 42, Batch: 238, D Loss: 0.10445860039272398, G Loss: 22.319721221923828\n",
      "Epoch: 42, Batch: 239, D Loss: 0.09857329735672671, G Loss: 22.45113754272461\n",
      "Epoch: 42, Batch: 240, D Loss: 0.10057760783605822, G Loss: 22.531227111816406\n",
      "Epoch: 42, Batch: 241, D Loss: 0.09936587520733083, G Loss: 22.521907806396484\n",
      "Epoch: 42, Batch: 242, D Loss: 0.09469227501846621, G Loss: 22.35454750061035\n",
      "Epoch: 42, Batch: 243, D Loss: 0.11138297626818458, G Loss: 22.4340877532959\n",
      "Epoch: 42, Batch: 244, D Loss: 0.10309958466570796, G Loss: 22.522748947143555\n",
      "Epoch: 42, Batch: 245, D Loss: 0.10203994818639633, G Loss: 22.571847915649414\n",
      "Epoch: 42, Batch: 246, D Loss: 0.09640577443814186, G Loss: 22.46671485900879\n",
      "Epoch: 42, Batch: 247, D Loss: 0.09795284280824923, G Loss: 22.2924747467041\n",
      "Epoch: 42, Batch: 248, D Loss: 0.0993284658716019, G Loss: 22.15608787536621\n",
      "Epoch: 42, Batch: 249, D Loss: 0.09748353076543392, G Loss: 22.07025909423828\n",
      "Epoch: 42, Batch: 250, D Loss: 0.10236845923025299, G Loss: 22.148635864257812\n",
      "Epoch: 42, Batch: 251, D Loss: 0.09675663721205349, G Loss: 22.22220230102539\n",
      "Epoch: 42, Batch: 252, D Loss: 0.09994487474970622, G Loss: 22.331750869750977\n",
      "Epoch: 42, Batch: 253, D Loss: 0.09491689513160312, G Loss: 22.33981704711914\n",
      "Epoch: 42, Batch: 254, D Loss: 0.09567123661769983, G Loss: 22.27654266357422\n",
      "Epoch: 42, Batch: 255, D Loss: 0.10063568513235047, G Loss: 22.27791976928711\n",
      "Epoch: 42, Batch: 256, D Loss: 0.0983652026509393, G Loss: 22.29265022277832\n",
      "Epoch: 42, Batch: 257, D Loss: 0.09831336896003334, G Loss: 22.310331344604492\n",
      "Epoch: 42, Batch: 258, D Loss: 0.10149173448383994, G Loss: 22.384511947631836\n",
      "Epoch: 42, Batch: 259, D Loss: 0.09461341807914234, G Loss: 22.361970901489258\n",
      "Epoch: 42, Batch: 260, D Loss: 0.09372259686772579, G Loss: 22.247169494628906\n",
      "Epoch: 42, Batch: 261, D Loss: 0.10289424668557388, G Loss: 22.274858474731445\n",
      "Epoch: 42, Batch: 262, D Loss: 0.09426818798778128, G Loss: 22.251567840576172\n",
      "Epoch: 42, Batch: 263, D Loss: 0.10527936379199038, G Loss: 22.402183532714844\n",
      "Epoch: 42, Batch: 264, D Loss: 0.10158277311484384, G Loss: 22.57795524597168\n",
      "Epoch: 42, Batch: 265, D Loss: 0.103878870677781, G Loss: 22.753015518188477\n",
      "Epoch: 42, Batch: 266, D Loss: 0.09541749960960619, G Loss: 22.704858779907227\n",
      "Epoch: 42, Batch: 267, D Loss: 0.1020747870925859, G Loss: 22.624467849731445\n",
      "Epoch: 42, Batch: 268, D Loss: 0.10290504999726088, G Loss: 22.562299728393555\n",
      "Epoch: 42, Batch: 269, D Loss: 0.1030382067768262, G Loss: 22.542604446411133\n",
      "Epoch: 42, Batch: 270, D Loss: 0.10162365444680914, G Loss: 22.53790283203125\n",
      "Epoch: 42, Batch: 271, D Loss: 0.09595683970634933, G Loss: 22.45049285888672\n",
      "Epoch: 42, Batch: 272, D Loss: 0.10661979773283553, G Loss: 22.516921997070312\n",
      "Epoch: 42, Batch: 273, D Loss: 0.09638459243828193, G Loss: 22.49859046936035\n",
      "Epoch: 42, Batch: 274, D Loss: 0.09979414203317696, G Loss: 22.49327278137207\n",
      "Epoch: 42, Batch: 275, D Loss: 0.09845978775251485, G Loss: 22.481075286865234\n",
      "Epoch: 42, Batch: 276, D Loss: 0.09539261469326327, G Loss: 22.394676208496094\n",
      "Epoch: 42, Batch: 277, D Loss: 0.10023027667922277, G Loss: 22.382516860961914\n",
      "Epoch: 42, Batch: 278, D Loss: 0.10226845750311539, G Loss: 22.47972869873047\n",
      "Epoch: 42, Batch: 279, D Loss: 0.09843826302298277, G Loss: 22.542362213134766\n",
      "Epoch: 42, Batch: 280, D Loss: 0.09918060906715857, G Loss: 22.583528518676758\n",
      "Epoch: 42, Batch: 281, D Loss: 0.10070008047134395, G Loss: 22.613515853881836\n",
      "Epoch: 42, Batch: 282, D Loss: 0.10470901436860248, G Loss: 22.7022647857666\n",
      "Epoch: 42, Batch: 283, D Loss: 0.10176958150428443, G Loss: 22.75613021850586\n",
      "Epoch: 42, Batch: 284, D Loss: 0.09316832579359954, G Loss: 22.591947555541992\n",
      "Epoch: 42, Batch: 285, D Loss: 0.09175629177765071, G Loss: 22.295455932617188\n",
      "Epoch: 42, Batch: 286, D Loss: 0.10736582438640976, G Loss: 22.287382125854492\n",
      "Epoch: 42, Batch: 287, D Loss: 0.09698612998269801, G Loss: 22.322092056274414\n",
      "Epoch: 42, Batch: 288, D Loss: 0.09718942651977984, G Loss: 22.387279510498047\n",
      "Epoch: 42, Batch: 289, D Loss: 0.1040174887438412, G Loss: 22.582971572875977\n",
      "Epoch: 42, Batch: 290, D Loss: 0.09697146721137052, G Loss: 22.678695678710938\n",
      "Epoch: 42, Batch: 291, D Loss: 0.10594109452342344, G Loss: 22.830373764038086\n",
      "Epoch: 42, Batch: 292, D Loss: 0.10046223556983029, G Loss: 22.871904373168945\n",
      "Epoch: 42, Batch: 293, D Loss: 0.09832221275806824, G Loss: 22.755826950073242\n",
      "Epoch: 42, Batch: 294, D Loss: 0.1038254127592149, G Loss: 22.668609619140625\n",
      "Epoch: 42, Batch: 295, D Loss: 0.0976029337221036, G Loss: 22.530441284179688\n",
      "Epoch: 42, Batch: 296, D Loss: 0.09898459920028847, G Loss: 22.42313003540039\n",
      "Epoch: 42, Batch: 297, D Loss: 0.09939236203208468, G Loss: 22.386568069458008\n",
      "Epoch: 42, Batch: 298, D Loss: 0.10099370786737887, G Loss: 22.45702362060547\n",
      "Epoch: 42, Batch: 299, D Loss: 0.09974226363921154, G Loss: 22.559240341186523\n",
      "Epoch: 42, Batch: 300, D Loss: 0.10389877863062005, G Loss: 22.730743408203125\n",
      "Epoch: 42, Batch: 301, D Loss: 0.10005915171346333, G Loss: 22.822772979736328\n",
      "Epoch: 42, Batch: 302, D Loss: 0.1006352902067318, G Loss: 22.83529281616211\n",
      "Epoch: 42, Batch: 303, D Loss: 0.09970082348936828, G Loss: 22.754545211791992\n",
      "Epoch: 42, Batch: 304, D Loss: 0.09719101346754011, G Loss: 22.58348274230957\n",
      "Epoch: 42, Batch: 305, D Loss: 0.10723450042570981, G Loss: 22.600160598754883\n",
      "Epoch: 42, Batch: 306, D Loss: 0.10121601827448673, G Loss: 22.649677276611328\n",
      "Epoch: 42, Batch: 307, D Loss: 0.10038575537188518, G Loss: 22.688514709472656\n",
      "Epoch: 42, Batch: 308, D Loss: 0.09951020784216047, G Loss: 22.692760467529297\n",
      "Epoch: 42, Batch: 309, D Loss: 0.10177949077857193, G Loss: 22.706382751464844\n",
      "Epoch: 42, Batch: 310, D Loss: 0.10279870785035244, G Loss: 22.753660202026367\n",
      "Epoch: 42, Batch: 311, D Loss: 0.09225425876283525, G Loss: 22.6159610748291\n",
      "Epoch: 42, Batch: 312, D Loss: 0.09878618278190233, G Loss: 22.494197845458984\n",
      "Epoch: 42, Batch: 313, D Loss: 0.10067471870460007, G Loss: 22.46940040588379\n",
      "Epoch: 42, Batch: 314, D Loss: 0.09985748686921828, G Loss: 22.523876190185547\n",
      "Epoch: 42, Batch: 315, D Loss: 0.09746651359511375, G Loss: 22.57059669494629\n",
      "Epoch: 42, Batch: 316, D Loss: 0.08947271117044608, G Loss: 22.44588851928711\n",
      "Epoch: 42, Batch: 317, D Loss: 0.10197863736649859, G Loss: 22.46476173400879\n",
      "Epoch: 42, Batch: 318, D Loss: 0.09984414287779053, G Loss: 22.56374740600586\n",
      "Epoch: 42, Batch: 319, D Loss: 0.09438551970250081, G Loss: 22.578842163085938\n",
      "Epoch: 42, Batch: 320, D Loss: 0.09549683340432412, G Loss: 22.537776947021484\n",
      "Epoch: 42, Batch: 321, D Loss: 0.09844912596755703, G Loss: 22.53468894958496\n",
      "Epoch: 42, Batch: 322, D Loss: 0.09590613850279164, G Loss: 22.512184143066406\n",
      "Epoch: 42, Batch: 323, D Loss: 0.0927673132103436, G Loss: 22.422815322875977\n",
      "Epoch: 42, Batch: 324, D Loss: 0.10283914217108504, G Loss: 22.517026901245117\n",
      "Epoch: 42, Batch: 325, D Loss: 0.10717093206615486, G Loss: 22.810626983642578\n",
      "Epoch: 42, Batch: 326, D Loss: 0.10028175270164727, G Loss: 23.014968872070312\n",
      "Epoch: 42, Batch: 327, D Loss: 0.10095962886895603, G Loss: 23.0921573638916\n",
      "Epoch: 42, Batch: 328, D Loss: 0.10196957741987622, G Loss: 23.05161476135254\n",
      "Epoch: 42, Batch: 329, D Loss: 0.09890199458001783, G Loss: 22.869178771972656\n",
      "Epoch: 42, Batch: 330, D Loss: 0.09329451627552846, G Loss: 22.533727645874023\n",
      "Epoch: 42, Batch: 331, D Loss: 0.09852859387073976, G Loss: 22.307153701782227\n",
      "Epoch: 42, Batch: 332, D Loss: 0.0986016393761051, G Loss: 22.257204055786133\n",
      "Epoch: 42, Batch: 333, D Loss: 0.10502117136667714, G Loss: 22.500293731689453\n",
      "Epoch: 42, Batch: 334, D Loss: 0.09998834885476235, G Loss: 22.787189483642578\n",
      "Epoch: 42, Batch: 335, D Loss: 0.0883995891251898, G Loss: 22.78797721862793\n",
      "Epoch: 42, Batch: 336, D Loss: 0.1023311690114255, G Loss: 22.83675765991211\n",
      "Epoch: 42, Batch: 337, D Loss: 0.09799639886787945, G Loss: 22.80870246887207\n",
      "Epoch: 42, Batch: 338, D Loss: 0.10164865857603514, G Loss: 22.812236785888672\n",
      "Epoch: 42, Batch: 339, D Loss: 0.10469715303156969, G Loss: 22.892457962036133\n",
      "Epoch: 42, Batch: 340, D Loss: 0.10329575842096148, G Loss: 22.98647117614746\n",
      "Epoch: 42, Batch: 341, D Loss: 0.10375710581781886, G Loss: 23.057832717895508\n",
      "Epoch: 42, Batch: 342, D Loss: 0.09761366998261782, G Loss: 22.969520568847656\n",
      "Epoch: 42, Batch: 343, D Loss: 0.1007702574696869, G Loss: 22.85098648071289\n",
      "Epoch: 42, Batch: 344, D Loss: 0.09820622957207487, G Loss: 22.70955467224121\n",
      "Epoch: 42, Batch: 345, D Loss: 0.1005990133397329, G Loss: 22.650041580200195\n",
      "Epoch: 42, Batch: 346, D Loss: 0.10605604208359219, G Loss: 22.778715133666992\n",
      "Epoch: 42, Batch: 347, D Loss: 0.10709938412541846, G Loss: 23.03339385986328\n",
      "Epoch: 42, Batch: 348, D Loss: 0.10052400832028796, G Loss: 23.168916702270508\n",
      "Epoch: 42, Batch: 349, D Loss: 0.0993318483675926, G Loss: 23.12933921813965\n",
      "Epoch: 42, Batch: 350, D Loss: 0.098987251569506, G Loss: 22.95746612548828\n",
      "Epoch: 42, Batch: 351, D Loss: 0.10550090676197174, G Loss: 22.86810874938965\n",
      "Epoch: 42, Batch: 352, D Loss: 0.09893353289627077, G Loss: 22.752351760864258\n",
      "Epoch: 42, Batch: 353, D Loss: 0.0998238102282388, G Loss: 22.685579299926758\n",
      "Epoch: 42, Batch: 354, D Loss: 0.10301178700635891, G Loss: 22.729976654052734\n",
      "Epoch: 42, Batch: 355, D Loss: 0.10010112828541586, G Loss: 22.797832489013672\n",
      "Epoch: 42, Batch: 356, D Loss: 0.10276917374107253, G Loss: 22.905759811401367\n",
      "Epoch: 42, Batch: 357, D Loss: 0.09871083503550206, G Loss: 22.935989379882812\n",
      "Epoch: 42, Batch: 358, D Loss: 0.10258775209785886, G Loss: 22.972612380981445\n",
      "Epoch: 42, Batch: 359, D Loss: 0.09383425122248815, G Loss: 22.821382522583008\n",
      "Epoch: 42, Batch: 360, D Loss: 0.09829156107427009, G Loss: 22.66012191772461\n",
      "Epoch: 42, Batch: 361, D Loss: 0.09916242219605921, G Loss: 22.572277069091797\n",
      "Epoch: 42, Batch: 362, D Loss: 0.10173559941503754, G Loss: 22.63782501220703\n",
      "Epoch: 42, Batch: 363, D Loss: 0.09623013443988095, G Loss: 22.683927536010742\n",
      "Epoch: 42, Batch: 364, D Loss: 0.100835919446867, G Loss: 22.78664207458496\n",
      "Epoch: 42, Batch: 365, D Loss: 0.09856329864412679, G Loss: 22.860361099243164\n",
      "Epoch: 42, Batch: 366, D Loss: 0.10115195816468243, G Loss: 22.93474006652832\n",
      "Epoch: 42, Batch: 367, D Loss: 0.0999766812266885, G Loss: 22.9672794342041\n",
      "Epoch: 42, Batch: 368, D Loss: 0.1013318151764315, G Loss: 22.9724178314209\n",
      "Epoch: 42, Batch: 369, D Loss: 0.10454560821444776, G Loss: 23.015310287475586\n",
      "Epoch: 42, Batch: 370, D Loss: 0.0998987705029466, G Loss: 22.98284339904785\n",
      "Epoch: 42, Batch: 371, D Loss: 0.09656438237114841, G Loss: 22.83330535888672\n",
      "Epoch: 42, Batch: 372, D Loss: 0.09936153895242447, G Loss: 22.688831329345703\n",
      "Epoch: 42, Batch: 373, D Loss: 0.0993789584172412, G Loss: 22.61581802368164\n",
      "Epoch: 42, Batch: 374, D Loss: 0.09270671018070259, G Loss: 22.48927879333496\n",
      "Epoch: 42, Batch: 375, D Loss: 0.1011265666130241, G Loss: 22.528783798217773\n",
      "Epoch: 42, Batch: 376, D Loss: 0.10171180971031857, G Loss: 22.69875144958496\n",
      "Epoch: 42, Batch: 377, D Loss: 0.0989370495720125, G Loss: 22.853544235229492\n",
      "Epoch: 42, Batch: 378, D Loss: 0.09753395622754579, G Loss: 22.916610717773438\n",
      "Epoch: 42, Batch: 379, D Loss: 0.0994324312171555, G Loss: 22.91731834411621\n",
      "Epoch: 42, Batch: 380, D Loss: 0.10064192866953307, G Loss: 22.89649200439453\n",
      "Epoch: 42, Batch: 381, D Loss: 0.09470526880217467, G Loss: 22.748144149780273\n",
      "Epoch: 42, Batch: 382, D Loss: 0.1006063670609511, G Loss: 22.665069580078125\n",
      "Epoch: 42, Batch: 383, D Loss: 0.10430071509785616, G Loss: 22.749208450317383\n",
      "Epoch: 42, Batch: 384, D Loss: 0.09851633018659607, G Loss: 22.816293716430664\n",
      "Epoch: 42, Batch: 385, D Loss: 0.09605930006751902, G Loss: 22.8032283782959\n",
      "Epoch: 42, Batch: 386, D Loss: 0.09900511807562569, G Loss: 22.78119659423828\n",
      "Epoch: 42, Batch: 387, D Loss: 0.10380616790232293, G Loss: 22.856895446777344\n",
      "Epoch: 42, Batch: 388, D Loss: 0.10243982082260283, G Loss: 22.957353591918945\n",
      "Epoch: 42, Batch: 389, D Loss: 0.10388179128487897, G Loss: 23.05498504638672\n",
      "Epoch: 42, Batch: 390, D Loss: 0.09548484539186393, G Loss: 22.939271926879883\n",
      "Epoch: 42, Batch: 391, D Loss: 0.09615123278095475, G Loss: 22.709054946899414\n",
      "Epoch: 42, Batch: 392, D Loss: 0.099639318958051, G Loss: 22.54977798461914\n",
      "Epoch: 42, Batch: 393, D Loss: 0.09911848612978696, G Loss: 22.491491317749023\n",
      "Epoch: 42, Batch: 394, D Loss: 0.09672141828764484, G Loss: 22.482572555541992\n",
      "Epoch: 42, Batch: 395, D Loss: 0.10260848708940531, G Loss: 22.635934829711914\n",
      "Epoch: 42, Batch: 396, D Loss: 0.0959758461229821, G Loss: 22.715579986572266\n",
      "Epoch: 42, Batch: 397, D Loss: 0.09963512427246765, G Loss: 22.77980613708496\n",
      "Epoch: 42, Batch: 398, D Loss: 0.10242745286377852, G Loss: 22.86573600769043\n",
      "Epoch: 42, Batch: 399, D Loss: 0.09850820904917959, G Loss: 22.85285186767578\n",
      "Epoch: 42, Batch: 400, D Loss: 0.10355032241242018, G Loss: 22.880680084228516\n",
      "Epoch: 42, Batch: 401, D Loss: 0.09328474855780719, G Loss: 22.71169090270996\n",
      "Epoch: 42, Batch: 402, D Loss: 0.10291724659181878, G Loss: 22.634319305419922\n",
      "Epoch: 42, Batch: 403, D Loss: 0.10090833909759733, G Loss: 22.63320541381836\n",
      "Epoch: 42, Batch: 404, D Loss: 0.09928220517809538, G Loss: 22.653308868408203\n",
      "Epoch: 42, Batch: 405, D Loss: 0.09967374808724175, G Loss: 22.69803810119629\n",
      "Epoch: 42, Batch: 406, D Loss: 0.09957249469391265, G Loss: 22.740421295166016\n",
      "Epoch: 42, Batch: 407, D Loss: 0.0996848047433824, G Loss: 22.772071838378906\n",
      "Epoch: 42, Batch: 408, D Loss: 0.10270871228227124, G Loss: 22.843122482299805\n",
      "Epoch: 42, Batch: 409, D Loss: 0.09376655525404384, G Loss: 22.72243881225586\n",
      "Epoch: 42, Batch: 410, D Loss: 0.09208904214527658, G Loss: 22.45965576171875\n",
      "Epoch: 42, Batch: 411, D Loss: 0.09378694752859679, G Loss: 22.229183197021484\n",
      "Epoch: 42, Batch: 412, D Loss: 0.09692516934370615, G Loss: 22.173664093017578\n",
      "Epoch: 42, Batch: 413, D Loss: 0.09800297777939328, G Loss: 22.29212188720703\n",
      "Epoch: 42, Batch: 414, D Loss: 0.09138034294118244, G Loss: 22.368614196777344\n",
      "Epoch: 42, Batch: 415, D Loss: 0.10062826433465508, G Loss: 22.580469131469727\n",
      "Epoch: 42, Batch: 416, D Loss: 0.09974399215986167, G Loss: 22.797046661376953\n",
      "Epoch: 42, Batch: 417, D Loss: 0.10227616882054355, G Loss: 22.98578453063965\n",
      "Epoch: 42, Batch: 418, D Loss: 0.09828116004847176, G Loss: 23.00631332397461\n",
      "Epoch: 42, Batch: 419, D Loss: 0.10529807960106947, G Loss: 23.013187408447266\n",
      "Epoch: 42, Batch: 420, D Loss: 0.09993481641428995, G Loss: 22.897411346435547\n",
      "Epoch: 42, Batch: 421, D Loss: 0.10246087616746868, G Loss: 22.78697395324707\n",
      "Epoch: 42, Batch: 422, D Loss: 0.09602545208826642, G Loss: 22.588226318359375\n",
      "Epoch: 42, Batch: 423, D Loss: 0.10314306624745345, G Loss: 22.53573226928711\n",
      "Epoch: 42, Batch: 424, D Loss: 0.09703528144326312, G Loss: 22.501445770263672\n",
      "Epoch: 42, Batch: 425, D Loss: 0.09928809114682191, G Loss: 22.52756118774414\n",
      "Epoch: 42, Batch: 426, D Loss: 0.09755004950573672, G Loss: 22.5445556640625\n",
      "Epoch: 42, Batch: 427, D Loss: 0.10492756970171885, G Loss: 22.715120315551758\n",
      "Epoch: 42, Batch: 428, D Loss: 0.09883110231655397, G Loss: 22.820280075073242\n",
      "Epoch: 42, Batch: 429, D Loss: 0.10236455506007998, G Loss: 22.902164459228516\n",
      "Epoch: 42, Batch: 430, D Loss: 0.10381022101163209, G Loss: 22.96198844909668\n",
      "Epoch: 42, Batch: 431, D Loss: 0.09483669704062211, G Loss: 22.7933292388916\n",
      "Epoch: 42, Batch: 432, D Loss: 0.09319923080534727, G Loss: 22.46870994567871\n",
      "Epoch: 42, Batch: 433, D Loss: 0.1018720493666038, G Loss: 22.316787719726562\n",
      "Epoch: 42, Batch: 434, D Loss: 0.10062731812566919, G Loss: 22.327579498291016\n",
      "Epoch: 42, Batch: 435, D Loss: 0.09571853289922772, G Loss: 22.365074157714844\n",
      "Epoch: 42, Batch: 436, D Loss: 0.0998044461912996, G Loss: 22.501367568969727\n",
      "Epoch: 42, Batch: 437, D Loss: 0.10067753501464313, G Loss: 22.682689666748047\n",
      "Epoch: 42, Batch: 438, D Loss: 0.09888152784803186, G Loss: 22.79155158996582\n",
      "Epoch: 42, Batch: 439, D Loss: 0.0980395675338174, G Loss: 22.789615631103516\n",
      "Epoch: 42, Batch: 440, D Loss: 0.10227879888193023, G Loss: 22.789098739624023\n",
      "Epoch: 42, Batch: 441, D Loss: 0.09636431939227144, G Loss: 22.660812377929688\n",
      "Epoch: 42, Batch: 442, D Loss: 0.09393239774463363, G Loss: 22.436460494995117\n",
      "Epoch: 42, Batch: 443, D Loss: 0.09677371392496092, G Loss: 22.28091049194336\n",
      "Epoch: 42, Batch: 444, D Loss: 0.10099694143051363, G Loss: 22.333126068115234\n",
      "Epoch: 42, Batch: 445, D Loss: 0.09783042976578224, G Loss: 22.478633880615234\n",
      "Epoch: 42, Batch: 446, D Loss: 0.1027546972787435, G Loss: 22.744890213012695\n",
      "Epoch: 42, Batch: 447, D Loss: 0.09270341700796508, G Loss: 22.797435760498047\n",
      "Epoch: 42, Batch: 448, D Loss: 0.099480927053122, G Loss: 22.80406379699707\n",
      "Epoch: 42, Batch: 449, D Loss: 0.09761046624691638, G Loss: 22.736217498779297\n",
      "Epoch: 42, Batch: 450, D Loss: 0.10196983820945796, G Loss: 22.728721618652344\n",
      "Epoch: 42, Batch: 451, D Loss: 0.09727416939518863, G Loss: 22.671436309814453\n",
      "Epoch: 42, Batch: 452, D Loss: 0.0932053924378472, G Loss: 22.52033233642578\n",
      "Epoch: 42, Batch: 453, D Loss: 0.09521890440462866, G Loss: 22.40226936340332\n",
      "Epoch: 42, Batch: 454, D Loss: 0.09966061273369123, G Loss: 22.450885772705078\n",
      "Epoch: 42, Batch: 455, D Loss: 0.10324391730594416, G Loss: 22.67031478881836\n",
      "Epoch: 42, Batch: 456, D Loss: 0.09588427103267749, G Loss: 22.800386428833008\n",
      "Epoch: 42, Batch: 457, D Loss: 0.0941899121442502, G Loss: 22.77511978149414\n",
      "Epoch: 42, Batch: 458, D Loss: 0.09306865937563956, G Loss: 22.6102237701416\n",
      "Epoch: 42, Batch: 459, D Loss: 0.09907807417720453, G Loss: 22.517099380493164\n",
      "Epoch: 42, Batch: 460, D Loss: 0.1006090343810889, G Loss: 22.561603546142578\n",
      "Epoch: 42, Batch: 461, D Loss: 0.101079031898761, G Loss: 22.706588745117188\n",
      "Epoch: 42, Batch: 462, D Loss: 0.09814202046916079, G Loss: 22.81989288330078\n",
      "Epoch: 42, Batch: 463, D Loss: 0.10212883359029273, G Loss: 22.93053436279297\n",
      "Epoch: 42, Batch: 464, D Loss: 0.09824781870408493, G Loss: 22.92128562927246\n",
      "Epoch: 42, Batch: 465, D Loss: 0.10823135083125843, G Loss: 23.05546760559082\n",
      "Epoch: 42, Batch: 466, D Loss: 0.09955312316473368, G Loss: 23.067304611206055\n",
      "Epoch: 42, Batch: 467, D Loss: 0.09742170577462858, G Loss: 22.920448303222656\n",
      "Epoch: 43, Batch: 0, D Loss: 0.09597395366776265, G Loss: 22.679201126098633\n",
      "Epoch: 43, Batch: 1, D Loss: 0.10236468173463711, G Loss: 22.605615615844727\n",
      "Epoch: 43, Batch: 2, D Loss: 0.10360434658497987, G Loss: 22.731599807739258\n",
      "Epoch: 43, Batch: 3, D Loss: 0.09805607802006461, G Loss: 22.854223251342773\n",
      "Epoch: 43, Batch: 4, D Loss: 0.09872487938134068, G Loss: 22.93455696105957\n",
      "Epoch: 43, Batch: 5, D Loss: 0.09498670702849916, G Loss: 22.879959106445312\n",
      "Epoch: 43, Batch: 6, D Loss: 0.09903880959732368, G Loss: 22.828676223754883\n",
      "Epoch: 43, Batch: 7, D Loss: 0.09255713231074461, G Loss: 22.657424926757812\n",
      "Epoch: 43, Batch: 8, D Loss: 0.10303075618675271, G Loss: 22.695539474487305\n",
      "Epoch: 43, Batch: 9, D Loss: 0.10379634803864494, G Loss: 22.886463165283203\n",
      "Epoch: 43, Batch: 10, D Loss: 0.0911992937904755, G Loss: 22.87483787536621\n",
      "Epoch: 43, Batch: 11, D Loss: 0.10039341455444149, G Loss: 22.910646438598633\n",
      "Epoch: 43, Batch: 12, D Loss: 0.10523108398127867, G Loss: 23.0644474029541\n",
      "Epoch: 43, Batch: 13, D Loss: 0.10153163974059265, G Loss: 23.173423767089844\n",
      "Epoch: 43, Batch: 14, D Loss: 0.1044201180748943, G Loss: 23.269697189331055\n",
      "Epoch: 43, Batch: 15, D Loss: 0.10008119050723974, G Loss: 23.213382720947266\n",
      "Epoch: 43, Batch: 16, D Loss: 0.10254942630110442, G Loss: 23.12198829650879\n",
      "Epoch: 43, Batch: 17, D Loss: 0.10163431619445061, G Loss: 23.013765335083008\n",
      "Epoch: 43, Batch: 18, D Loss: 0.0968282372314786, G Loss: 22.836956024169922\n",
      "Epoch: 43, Batch: 19, D Loss: 0.10060767090662229, G Loss: 22.756092071533203\n",
      "Epoch: 43, Batch: 20, D Loss: 0.1055567861213845, G Loss: 22.889205932617188\n",
      "Epoch: 43, Batch: 21, D Loss: 0.09267992532103347, G Loss: 22.863414764404297\n",
      "Epoch: 43, Batch: 22, D Loss: 0.09550876921569393, G Loss: 22.789691925048828\n",
      "Epoch: 43, Batch: 23, D Loss: 0.10105068987864413, G Loss: 22.824562072753906\n",
      "Epoch: 43, Batch: 24, D Loss: 0.1009287909250551, G Loss: 22.933988571166992\n",
      "Epoch: 43, Batch: 25, D Loss: 0.09070082759649026, G Loss: 22.8421688079834\n",
      "Epoch: 43, Batch: 26, D Loss: 0.09629285341884108, G Loss: 22.738981246948242\n",
      "Epoch: 43, Batch: 27, D Loss: 0.0981720835645625, G Loss: 22.713451385498047\n",
      "Epoch: 43, Batch: 28, D Loss: 0.10040429986093552, G Loss: 22.799564361572266\n",
      "Epoch: 43, Batch: 29, D Loss: 0.09117011732383071, G Loss: 22.736759185791016\n",
      "Epoch: 43, Batch: 30, D Loss: 0.09808930761325368, G Loss: 22.740304946899414\n",
      "Epoch: 43, Batch: 31, D Loss: 0.10010870552446817, G Loss: 22.830429077148438\n",
      "Epoch: 43, Batch: 32, D Loss: 0.09675721084982519, G Loss: 22.89649772644043\n",
      "Epoch: 43, Batch: 33, D Loss: 0.10414733742919068, G Loss: 23.06329345703125\n",
      "Epoch: 43, Batch: 34, D Loss: 0.09716979418950432, G Loss: 23.09935188293457\n",
      "Epoch: 43, Batch: 35, D Loss: 0.10027024154597386, G Loss: 23.076208114624023\n",
      "Epoch: 43, Batch: 36, D Loss: 0.09467749302833202, G Loss: 22.90054702758789\n",
      "Epoch: 43, Batch: 37, D Loss: 0.10383368289290831, G Loss: 22.863004684448242\n",
      "Epoch: 43, Batch: 38, D Loss: 0.10604161029578274, G Loss: 22.996570587158203\n",
      "Epoch: 43, Batch: 39, D Loss: 0.09726620470564863, G Loss: 23.034141540527344\n",
      "Epoch: 43, Batch: 40, D Loss: 0.09888906781912249, G Loss: 23.01569175720215\n",
      "Epoch: 43, Batch: 41, D Loss: 0.0966025442418421, G Loss: 22.911972045898438\n",
      "Epoch: 43, Batch: 42, D Loss: 0.09674963361070579, G Loss: 22.77984046936035\n",
      "Epoch: 43, Batch: 43, D Loss: 0.10443738109082021, G Loss: 22.84807586669922\n",
      "Epoch: 43, Batch: 44, D Loss: 0.09852113580504786, G Loss: 22.916532516479492\n",
      "Epoch: 43, Batch: 45, D Loss: 0.10459212963903715, G Loss: 23.089834213256836\n",
      "Epoch: 43, Batch: 46, D Loss: 0.10065785799886648, G Loss: 23.195552825927734\n",
      "Epoch: 43, Batch: 47, D Loss: 0.09410980348310592, G Loss: 23.076704025268555\n",
      "Epoch: 43, Batch: 48, D Loss: 0.09886789327072965, G Loss: 22.915061950683594\n",
      "Epoch: 43, Batch: 49, D Loss: 0.10071048146425685, G Loss: 22.81106948852539\n",
      "Epoch: 43, Batch: 50, D Loss: 0.09506121284443983, G Loss: 22.681562423706055\n",
      "Epoch: 43, Batch: 51, D Loss: 0.09581331916044217, G Loss: 22.605934143066406\n",
      "Epoch: 43, Batch: 52, D Loss: 0.10030209280344246, G Loss: 22.699308395385742\n",
      "Epoch: 43, Batch: 53, D Loss: 0.09585191316023735, G Loss: 22.80042839050293\n",
      "Epoch: 43, Batch: 54, D Loss: 0.09232188767566572, G Loss: 22.779932022094727\n",
      "Epoch: 43, Batch: 55, D Loss: 0.09509140259595045, G Loss: 22.740524291992188\n",
      "Epoch: 43, Batch: 56, D Loss: 0.09547007835722598, G Loss: 22.70638084411621\n",
      "Epoch: 43, Batch: 57, D Loss: 0.09675800062092312, G Loss: 22.721708297729492\n",
      "Epoch: 43, Batch: 58, D Loss: 0.10153989500098096, G Loss: 22.87516212463379\n",
      "Epoch: 43, Batch: 59, D Loss: 0.09644716238559375, G Loss: 22.965150833129883\n",
      "Epoch: 43, Batch: 60, D Loss: 0.09575108444055021, G Loss: 22.96095848083496\n",
      "Epoch: 43, Batch: 61, D Loss: 0.10241363947781869, G Loss: 23.02490234375\n",
      "Epoch: 43, Batch: 62, D Loss: 0.0975865573193748, G Loss: 23.016185760498047\n",
      "Epoch: 43, Batch: 63, D Loss: 0.10267524426170495, G Loss: 23.051584243774414\n",
      "Epoch: 43, Batch: 64, D Loss: 0.09722593431707471, G Loss: 23.001543045043945\n",
      "Epoch: 43, Batch: 65, D Loss: 0.0960714519572341, G Loss: 22.871906280517578\n",
      "Epoch: 43, Batch: 66, D Loss: 0.11292900895300109, G Loss: 23.093923568725586\n",
      "Epoch: 43, Batch: 67, D Loss: 0.10217513893323629, G Loss: 23.27373695373535\n",
      "Epoch: 43, Batch: 68, D Loss: 0.0967041403457385, G Loss: 23.216331481933594\n",
      "Epoch: 43, Batch: 69, D Loss: 0.10201808814578048, G Loss: 23.12167739868164\n",
      "Epoch: 43, Batch: 70, D Loss: 0.10467404131757141, G Loss: 23.083166122436523\n",
      "Epoch: 43, Batch: 71, D Loss: 0.10002627973724651, G Loss: 22.998517990112305\n",
      "Epoch: 43, Batch: 72, D Loss: 0.1071545035143924, G Loss: 23.06214714050293\n",
      "Epoch: 43, Batch: 73, D Loss: 0.09609975670809177, G Loss: 22.99262809753418\n",
      "Epoch: 43, Batch: 74, D Loss: 0.09873921429627994, G Loss: 22.882389068603516\n",
      "Epoch: 43, Batch: 75, D Loss: 0.10112866765226647, G Loss: 22.832021713256836\n",
      "Epoch: 43, Batch: 76, D Loss: 0.09809945529932065, G Loss: 22.793704986572266\n",
      "Epoch: 43, Batch: 77, D Loss: 0.11051014816329227, G Loss: 23.04346466064453\n",
      "Epoch: 43, Batch: 78, D Loss: 0.10280631486978346, G Loss: 23.262746810913086\n",
      "Epoch: 43, Batch: 79, D Loss: 0.10560973737273316, G Loss: 23.43158721923828\n",
      "Epoch: 43, Batch: 80, D Loss: 0.09696613255740905, G Loss: 23.29643440246582\n",
      "Epoch: 43, Batch: 81, D Loss: 0.09645813708071793, G Loss: 22.967363357543945\n",
      "Epoch: 43, Batch: 82, D Loss: 0.09864953166504675, G Loss: 22.663360595703125\n",
      "Epoch: 43, Batch: 83, D Loss: 0.10241518177172283, G Loss: 22.573917388916016\n",
      "Epoch: 43, Batch: 84, D Loss: 0.09916754074587858, G Loss: 22.626192092895508\n",
      "Epoch: 43, Batch: 85, D Loss: 0.10758535570156505, G Loss: 22.97287940979004\n",
      "Epoch: 43, Batch: 86, D Loss: 0.09652855252003172, G Loss: 23.173185348510742\n",
      "Epoch: 43, Batch: 87, D Loss: 0.10255721960498952, G Loss: 23.31367301940918\n",
      "Epoch: 43, Batch: 88, D Loss: 0.09842042628809597, G Loss: 23.258867263793945\n",
      "Epoch: 43, Batch: 89, D Loss: 0.09811605517496476, G Loss: 23.05858612060547\n",
      "Epoch: 43, Batch: 90, D Loss: 0.10220986609887542, G Loss: 22.922834396362305\n",
      "Epoch: 43, Batch: 91, D Loss: 0.1033678278882352, G Loss: 22.91908836364746\n",
      "Epoch: 43, Batch: 92, D Loss: 0.10240460937598639, G Loss: 22.995601654052734\n",
      "Epoch: 43, Batch: 93, D Loss: 0.09429025655351744, G Loss: 22.93259048461914\n",
      "Epoch: 43, Batch: 94, D Loss: 0.09588379418687705, G Loss: 22.82831382751465\n",
      "Epoch: 43, Batch: 95, D Loss: 0.09416505700974635, G Loss: 22.680221557617188\n",
      "Epoch: 43, Batch: 96, D Loss: 0.0973700136669782, G Loss: 22.634902954101562\n",
      "Epoch: 43, Batch: 97, D Loss: 0.1036846936414609, G Loss: 22.834135055541992\n",
      "Epoch: 43, Batch: 98, D Loss: 0.10541367535850309, G Loss: 23.187223434448242\n",
      "Epoch: 43, Batch: 99, D Loss: 0.09474612776520037, G Loss: 23.278583526611328\n",
      "Epoch: 43, Batch: 100, D Loss: 0.09881877903186863, G Loss: 23.21435546875\n",
      "Epoch: 43, Batch: 101, D Loss: 0.10264949504858907, G Loss: 23.143552780151367\n",
      "Epoch: 43, Batch: 102, D Loss: 0.09908021991247182, G Loss: 23.012216567993164\n",
      "Epoch: 43, Batch: 103, D Loss: 0.10089451079927347, G Loss: 22.91768455505371\n",
      "Epoch: 43, Batch: 104, D Loss: 0.0941125006095275, G Loss: 22.740074157714844\n",
      "Epoch: 43, Batch: 105, D Loss: 0.09206065543013571, G Loss: 22.52044677734375\n",
      "Epoch: 43, Batch: 106, D Loss: 0.09232885399615888, G Loss: 22.34364128112793\n",
      "Epoch: 43, Batch: 107, D Loss: 0.09930902728935266, G Loss: 22.432889938354492\n",
      "Epoch: 43, Batch: 108, D Loss: 0.10170984275826646, G Loss: 22.753904342651367\n",
      "Epoch: 43, Batch: 109, D Loss: 0.0974107832284846, G Loss: 23.026906967163086\n",
      "Epoch: 43, Batch: 110, D Loss: 0.08851715182465304, G Loss: 22.96222686767578\n",
      "Epoch: 43, Batch: 111, D Loss: 0.10030619060510026, G Loss: 22.909910202026367\n",
      "Epoch: 43, Batch: 112, D Loss: 0.10652931039840702, G Loss: 23.028154373168945\n",
      "Epoch: 43, Batch: 113, D Loss: 0.09355542813985071, G Loss: 22.94414710998535\n",
      "Epoch: 43, Batch: 114, D Loss: 0.09799165284452395, G Loss: 22.82413101196289\n",
      "Epoch: 43, Batch: 115, D Loss: 0.1050048620104313, G Loss: 22.875110626220703\n",
      "Epoch: 43, Batch: 116, D Loss: 0.10649836813641625, G Loss: 23.087316513061523\n",
      "Epoch: 43, Batch: 117, D Loss: 0.09780158107104, G Loss: 23.132448196411133\n",
      "Epoch: 43, Batch: 118, D Loss: 0.09927275781538367, G Loss: 23.057483673095703\n",
      "Epoch: 43, Batch: 119, D Loss: 0.09660110628019328, G Loss: 22.859760284423828\n",
      "Epoch: 43, Batch: 120, D Loss: 0.09406130767727333, G Loss: 22.585250854492188\n",
      "Epoch: 43, Batch: 121, D Loss: 0.09674380728201955, G Loss: 22.405040740966797\n",
      "Epoch: 43, Batch: 122, D Loss: 0.10471871503828425, G Loss: 22.55819320678711\n",
      "Epoch: 43, Batch: 123, D Loss: 0.09294599302237432, G Loss: 22.657493591308594\n",
      "Epoch: 43, Batch: 124, D Loss: 0.1011484564003935, G Loss: 22.849227905273438\n",
      "Epoch: 43, Batch: 125, D Loss: 0.09862889355045258, G Loss: 22.974653244018555\n",
      "Epoch: 43, Batch: 126, D Loss: 0.09774152939779357, G Loss: 22.987211227416992\n",
      "Epoch: 43, Batch: 127, D Loss: 0.09448291367006922, G Loss: 22.819847106933594\n",
      "Epoch: 43, Batch: 128, D Loss: 0.09437367327076368, G Loss: 22.567296981811523\n",
      "Epoch: 43, Batch: 129, D Loss: 0.10277569302005043, G Loss: 22.538654327392578\n",
      "Epoch: 43, Batch: 130, D Loss: 0.09701713182657463, G Loss: 22.553436279296875\n",
      "Epoch: 43, Batch: 131, D Loss: 0.1036564410454546, G Loss: 22.75346565246582\n",
      "Epoch: 43, Batch: 132, D Loss: 0.09571120894264273, G Loss: 22.841094970703125\n",
      "Epoch: 43, Batch: 133, D Loss: 0.09693931049217602, G Loss: 22.8238525390625\n",
      "Epoch: 43, Batch: 134, D Loss: 0.09481075412650139, G Loss: 22.68707275390625\n",
      "Epoch: 43, Batch: 135, D Loss: 0.1014851183416189, G Loss: 22.645936965942383\n",
      "Epoch: 43, Batch: 136, D Loss: 0.09597742565107442, G Loss: 22.576807022094727\n",
      "Epoch: 43, Batch: 137, D Loss: 0.0969527066554059, G Loss: 22.536746978759766\n",
      "Epoch: 43, Batch: 138, D Loss: 0.10033954687843238, G Loss: 22.60247802734375\n",
      "Epoch: 43, Batch: 139, D Loss: 0.10182940221838968, G Loss: 22.77657127380371\n",
      "Epoch: 43, Batch: 140, D Loss: 0.10222826903919421, G Loss: 22.9610652923584\n",
      "Epoch: 43, Batch: 141, D Loss: 0.09940996771246202, G Loss: 23.025869369506836\n",
      "Epoch: 43, Batch: 142, D Loss: 0.09852282708130984, G Loss: 22.948301315307617\n",
      "Epoch: 43, Batch: 143, D Loss: 0.10235993569732749, G Loss: 22.87899398803711\n",
      "Epoch: 43, Batch: 144, D Loss: 0.10467717057219134, G Loss: 22.904752731323242\n",
      "Epoch: 43, Batch: 145, D Loss: 0.09660038357938519, G Loss: 22.811992645263672\n",
      "Epoch: 43, Batch: 146, D Loss: 0.09492021805954777, G Loss: 22.61515998840332\n",
      "Epoch: 43, Batch: 147, D Loss: 0.106059402300373, G Loss: 22.67724609375\n",
      "Epoch: 43, Batch: 148, D Loss: 0.10138188309101476, G Loss: 22.816511154174805\n",
      "Epoch: 43, Batch: 149, D Loss: 0.1051333845206687, G Loss: 23.050350189208984\n",
      "Epoch: 43, Batch: 150, D Loss: 0.0968312025551762, G Loss: 23.0751953125\n",
      "Epoch: 43, Batch: 151, D Loss: 0.0984113514925229, G Loss: 22.974348068237305\n",
      "Epoch: 43, Batch: 152, D Loss: 0.10171211516451761, G Loss: 22.872135162353516\n",
      "Epoch: 43, Batch: 153, D Loss: 0.09797011322091403, G Loss: 22.734392166137695\n",
      "Epoch: 43, Batch: 154, D Loss: 0.09657307721413477, G Loss: 22.597986221313477\n",
      "Epoch: 43, Batch: 155, D Loss: 0.10327701278013866, G Loss: 22.657501220703125\n",
      "Epoch: 43, Batch: 156, D Loss: 0.10052956647450481, G Loss: 22.792743682861328\n",
      "Epoch: 43, Batch: 157, D Loss: 0.09833842521949893, G Loss: 22.887840270996094\n",
      "Epoch: 43, Batch: 158, D Loss: 0.09462021297188893, G Loss: 22.825021743774414\n",
      "Epoch: 43, Batch: 159, D Loss: 0.09589527553888516, G Loss: 22.699565887451172\n",
      "Epoch: 43, Batch: 160, D Loss: 0.101146176527081, G Loss: 22.689083099365234\n",
      "Epoch: 43, Batch: 161, D Loss: 0.09636031843364196, G Loss: 22.664644241333008\n",
      "Epoch: 43, Batch: 162, D Loss: 0.09182854004429103, G Loss: 22.53653907775879\n",
      "Epoch: 43, Batch: 163, D Loss: 0.10077033944962507, G Loss: 22.576824188232422\n",
      "Epoch: 43, Batch: 164, D Loss: 0.10310122377688298, G Loss: 22.799074172973633\n",
      "Epoch: 43, Batch: 165, D Loss: 0.10305432980733942, G Loss: 23.06875228881836\n",
      "Epoch: 43, Batch: 166, D Loss: 0.10118414465997687, G Loss: 23.236587524414062\n",
      "Epoch: 43, Batch: 167, D Loss: 0.09374705706468443, G Loss: 23.07809066772461\n",
      "Epoch: 43, Batch: 168, D Loss: 0.09816031163365935, G Loss: 22.833784103393555\n",
      "Epoch: 43, Batch: 169, D Loss: 0.09747999913380606, G Loss: 22.60280418395996\n",
      "Epoch: 43, Batch: 170, D Loss: 0.10157134391697997, G Loss: 22.566320419311523\n",
      "Epoch: 43, Batch: 171, D Loss: 0.10035833723925144, G Loss: 22.660823822021484\n",
      "Epoch: 43, Batch: 172, D Loss: 0.09763403243638308, G Loss: 22.77789306640625\n",
      "Epoch: 43, Batch: 173, D Loss: 0.10556928073932925, G Loss: 23.055984497070312\n",
      "Epoch: 43, Batch: 174, D Loss: 0.10259816054837287, G Loss: 23.281803131103516\n",
      "Epoch: 43, Batch: 175, D Loss: 0.09884408120228966, G Loss: 23.273290634155273\n",
      "Epoch: 43, Batch: 176, D Loss: 0.09764866535272129, G Loss: 23.055864334106445\n",
      "Epoch: 43, Batch: 177, D Loss: 0.09867273276659282, G Loss: 22.79139518737793\n",
      "Epoch: 43, Batch: 178, D Loss: 0.09722156829841483, G Loss: 22.554243087768555\n",
      "Epoch: 43, Batch: 179, D Loss: 0.10238897808417971, G Loss: 22.563922882080078\n",
      "Epoch: 43, Batch: 180, D Loss: 0.09779497243548066, G Loss: 22.662477493286133\n",
      "Epoch: 43, Batch: 181, D Loss: 0.10177045321898517, G Loss: 22.885299682617188\n",
      "Epoch: 43, Batch: 182, D Loss: 0.10170125221331566, G Loss: 23.119741439819336\n",
      "Epoch: 43, Batch: 183, D Loss: 0.09505058084526095, G Loss: 23.113008499145508\n",
      "Epoch: 43, Batch: 184, D Loss: 0.10411228244066605, G Loss: 23.134862899780273\n",
      "Epoch: 43, Batch: 185, D Loss: 0.09646080439160713, G Loss: 22.990055084228516\n",
      "Epoch: 43, Batch: 186, D Loss: 0.10176830744285395, G Loss: 22.876056671142578\n",
      "Epoch: 43, Batch: 187, D Loss: 0.08882011480155444, G Loss: 22.526960372924805\n",
      "Epoch: 43, Batch: 188, D Loss: 0.0951632560240264, G Loss: 22.273468017578125\n",
      "Epoch: 43, Batch: 189, D Loss: 0.09157124173274474, G Loss: 22.111440658569336\n",
      "Epoch: 43, Batch: 190, D Loss: 0.10418032120565177, G Loss: 22.380414962768555\n",
      "Epoch: 43, Batch: 191, D Loss: 0.09418262549589333, G Loss: 22.64453887939453\n",
      "Epoch: 43, Batch: 192, D Loss: 0.09701536602291669, G Loss: 22.87898826599121\n",
      "Epoch: 43, Batch: 193, D Loss: 0.0954707116443191, G Loss: 22.96114158630371\n",
      "Epoch: 43, Batch: 194, D Loss: 0.10146772121582721, G Loss: 23.02424430847168\n",
      "Epoch: 43, Batch: 195, D Loss: 0.10038502519350156, G Loss: 23.031967163085938\n",
      "Epoch: 43, Batch: 196, D Loss: 0.09563948219457287, G Loss: 22.87284278869629\n",
      "Epoch: 43, Batch: 197, D Loss: 0.09494291252572061, G Loss: 22.625688552856445\n",
      "Epoch: 43, Batch: 198, D Loss: 0.09963427492023112, G Loss: 22.495878219604492\n",
      "Epoch: 43, Batch: 199, D Loss: 0.10003738113607243, G Loss: 22.53761863708496\n",
      "Epoch: 43, Batch: 200, D Loss: 0.09844955809631607, G Loss: 22.65284538269043\n",
      "Epoch: 43, Batch: 201, D Loss: 0.0968064815494139, G Loss: 22.75469207763672\n",
      "Epoch: 43, Batch: 202, D Loss: 0.09675396985261087, G Loss: 22.799144744873047\n",
      "Epoch: 43, Batch: 203, D Loss: 0.10298611229539659, G Loss: 22.93414878845215\n",
      "Epoch: 43, Batch: 204, D Loss: 0.09462335711408004, G Loss: 22.875890731811523\n",
      "Epoch: 43, Batch: 205, D Loss: 0.10419652616690489, G Loss: 22.92083168029785\n",
      "Epoch: 43, Batch: 206, D Loss: 0.09764456754683193, G Loss: 22.864511489868164\n",
      "Epoch: 43, Batch: 207, D Loss: 0.10061170166746697, G Loss: 22.83220863342285\n",
      "Epoch: 43, Batch: 208, D Loss: 0.09319329268491235, G Loss: 22.64059829711914\n",
      "Epoch: 43, Batch: 209, D Loss: 0.09400810309584018, G Loss: 22.413867950439453\n",
      "Epoch: 43, Batch: 210, D Loss: 0.10309458532950419, G Loss: 22.46800422668457\n",
      "Epoch: 43, Batch: 211, D Loss: 0.10930059857285024, G Loss: 22.86909294128418\n",
      "Epoch: 43, Batch: 212, D Loss: 0.1008273065582954, G Loss: 23.19403839111328\n",
      "Epoch: 43, Batch: 213, D Loss: 0.1008712724244522, G Loss: 23.330554962158203\n",
      "Epoch: 43, Batch: 214, D Loss: 0.09282501046121726, G Loss: 23.068010330200195\n",
      "Epoch: 43, Batch: 215, D Loss: 0.10601462429028294, G Loss: 22.90342903137207\n",
      "Epoch: 43, Batch: 216, D Loss: 0.10262017703010677, G Loss: 22.816749572753906\n",
      "Epoch: 43, Batch: 217, D Loss: 0.10100946581675244, G Loss: 22.783409118652344\n",
      "Epoch: 43, Batch: 218, D Loss: 0.09813876456571363, G Loss: 22.74280548095703\n",
      "Epoch: 43, Batch: 219, D Loss: 0.0961874277084786, G Loss: 22.682008743286133\n",
      "Epoch: 43, Batch: 220, D Loss: 0.10165522254342825, G Loss: 22.753957748413086\n",
      "Epoch: 43, Batch: 221, D Loss: 0.098488703433118, G Loss: 22.830766677856445\n",
      "Epoch: 43, Batch: 222, D Loss: 0.10000021761465919, G Loss: 22.929101943969727\n",
      "Epoch: 43, Batch: 223, D Loss: 0.10212469106146106, G Loss: 23.040605545043945\n",
      "Epoch: 43, Batch: 224, D Loss: 0.10406778012343325, G Loss: 23.171953201293945\n",
      "Epoch: 43, Batch: 225, D Loss: 0.0980648696862336, G Loss: 23.138301849365234\n",
      "Epoch: 43, Batch: 226, D Loss: 0.10312744979632771, G Loss: 23.10688591003418\n",
      "Epoch: 43, Batch: 227, D Loss: 0.09989705686658182, G Loss: 23.00786590576172\n",
      "Epoch: 43, Batch: 228, D Loss: 0.09561876213251506, G Loss: 22.805715560913086\n",
      "Epoch: 43, Batch: 229, D Loss: 0.09702392674349991, G Loss: 22.634552001953125\n",
      "Epoch: 43, Batch: 230, D Loss: 0.10001885153320175, G Loss: 22.62870216369629\n",
      "Epoch: 43, Batch: 231, D Loss: 0.09431724257802568, G Loss: 22.616519927978516\n",
      "Epoch: 43, Batch: 232, D Loss: 0.09407245375349188, G Loss: 22.602815628051758\n",
      "Epoch: 43, Batch: 233, D Loss: 0.09351979203805891, G Loss: 22.57782554626465\n",
      "Epoch: 43, Batch: 234, D Loss: 0.10091798759721665, G Loss: 22.742708206176758\n",
      "Epoch: 43, Batch: 235, D Loss: 0.10220935201385137, G Loss: 23.03110122680664\n",
      "Epoch: 43, Batch: 236, D Loss: 0.10335519169055105, G Loss: 23.32758140563965\n",
      "Epoch: 43, Batch: 237, D Loss: 0.10279953483130977, G Loss: 23.507097244262695\n",
      "Epoch: 43, Batch: 238, D Loss: 0.10016787800403747, G Loss: 23.4459285736084\n",
      "Epoch: 43, Batch: 239, D Loss: 0.09696635607770049, G Loss: 23.136585235595703\n",
      "Epoch: 43, Batch: 240, D Loss: 0.09249880915699006, G Loss: 22.649457931518555\n",
      "Epoch: 43, Batch: 241, D Loss: 0.09386005261621128, G Loss: 22.242267608642578\n",
      "Epoch: 43, Batch: 242, D Loss: 0.09812337916470697, G Loss: 22.18158721923828\n",
      "Epoch: 43, Batch: 243, D Loss: 0.09523198019227766, G Loss: 22.34183120727539\n",
      "Epoch: 43, Batch: 244, D Loss: 0.09450782844071737, G Loss: 22.61338996887207\n",
      "Epoch: 43, Batch: 245, D Loss: 0.09981143480785874, G Loss: 22.98551368713379\n",
      "Epoch: 43, Batch: 246, D Loss: 0.09091471140550313, G Loss: 23.087400436401367\n",
      "Epoch: 43, Batch: 247, D Loss: 0.1054282114335191, G Loss: 23.277015686035156\n",
      "Epoch: 43, Batch: 248, D Loss: 0.10090965781384112, G Loss: 23.347171783447266\n",
      "Epoch: 43, Batch: 249, D Loss: 0.10145292434810788, G Loss: 23.31151008605957\n",
      "Epoch: 43, Batch: 250, D Loss: 0.09638869766605739, G Loss: 23.106571197509766\n",
      "Epoch: 43, Batch: 251, D Loss: 0.09808264677978831, G Loss: 22.870084762573242\n",
      "Epoch: 43, Batch: 252, D Loss: 0.10095393663796115, G Loss: 22.784543991088867\n",
      "Epoch: 43, Batch: 253, D Loss: 0.09559419757785417, G Loss: 22.710325241088867\n",
      "Epoch: 43, Batch: 254, D Loss: 0.09770715988525845, G Loss: 22.72456169128418\n",
      "Epoch: 43, Batch: 255, D Loss: 0.10199189937267286, G Loss: 22.915002822875977\n",
      "Epoch: 43, Batch: 256, D Loss: 0.1066257209044385, G Loss: 23.28896713256836\n",
      "Epoch: 43, Batch: 257, D Loss: 0.106009699436128, G Loss: 23.643156051635742\n",
      "Epoch: 43, Batch: 258, D Loss: 0.10023242982852096, G Loss: 23.70523452758789\n",
      "Epoch: 43, Batch: 259, D Loss: 0.10079614075825745, G Loss: 23.52423095703125\n",
      "Epoch: 43, Batch: 260, D Loss: 0.09444646541192098, G Loss: 23.054210662841797\n",
      "Epoch: 43, Batch: 261, D Loss: 0.10142953699691902, G Loss: 22.70932960510254\n",
      "Epoch: 43, Batch: 262, D Loss: 0.10097341246714861, G Loss: 22.601428985595703\n",
      "Epoch: 43, Batch: 263, D Loss: 0.09422379739842246, G Loss: 22.584972381591797\n",
      "Epoch: 43, Batch: 264, D Loss: 0.09451010085646147, G Loss: 22.663908004760742\n",
      "Epoch: 43, Batch: 265, D Loss: 0.10331350570964971, G Loss: 23.0020751953125\n",
      "Epoch: 43, Batch: 266, D Loss: 0.09502120320622215, G Loss: 23.20816993713379\n",
      "Epoch: 43, Batch: 267, D Loss: 0.09062552456447551, G Loss: 23.121889114379883\n",
      "Epoch: 43, Batch: 268, D Loss: 0.1035131961551288, G Loss: 23.164989471435547\n",
      "Epoch: 43, Batch: 269, D Loss: 0.10119296614539129, G Loss: 23.239267349243164\n",
      "Epoch: 43, Batch: 270, D Loss: 0.10060061518302284, G Loss: 23.293899536132812\n",
      "Epoch: 43, Batch: 271, D Loss: 0.09424398843573238, G Loss: 23.161821365356445\n",
      "Epoch: 43, Batch: 272, D Loss: 0.09763804082855754, G Loss: 22.999343872070312\n",
      "Epoch: 43, Batch: 273, D Loss: 0.09420710062714774, G Loss: 22.802364349365234\n",
      "Epoch: 43, Batch: 274, D Loss: 0.09824013716418172, G Loss: 22.759130477905273\n",
      "Epoch: 43, Batch: 275, D Loss: 0.10514178877806066, G Loss: 23.01746368408203\n",
      "Epoch: 43, Batch: 276, D Loss: 0.09649279718174149, G Loss: 23.215185165405273\n",
      "Epoch: 43, Batch: 277, D Loss: 0.1019098759069323, G Loss: 23.418115615844727\n",
      "Epoch: 43, Batch: 278, D Loss: 0.09911014142926441, G Loss: 23.477251052856445\n",
      "Epoch: 43, Batch: 279, D Loss: 0.09872463348874998, G Loss: 23.38207244873047\n",
      "Epoch: 43, Batch: 280, D Loss: 0.0928707197724718, G Loss: 23.05329132080078\n",
      "Epoch: 43, Batch: 281, D Loss: 0.09882844990052754, G Loss: 22.81232452392578\n",
      "Epoch: 43, Batch: 282, D Loss: 0.09544698900638582, G Loss: 22.68621826171875\n",
      "Epoch: 43, Batch: 283, D Loss: 0.1033408791459803, G Loss: 22.883237838745117\n",
      "Epoch: 43, Batch: 284, D Loss: 0.10378491138129799, G Loss: 23.279800415039062\n",
      "Epoch: 43, Batch: 285, D Loss: 0.10406763854753376, G Loss: 23.698434829711914\n",
      "Epoch: 43, Batch: 286, D Loss: 0.09637597950713811, G Loss: 23.814224243164062\n",
      "Epoch: 43, Batch: 287, D Loss: 0.09687294068438848, G Loss: 23.64333152770996\n",
      "Epoch: 43, Batch: 288, D Loss: 0.08976169679125576, G Loss: 23.126602172851562\n",
      "Epoch: 43, Batch: 289, D Loss: 0.10571733122117112, G Loss: 22.929759979248047\n",
      "Epoch: 43, Batch: 290, D Loss: 0.09219678497393327, G Loss: 22.753313064575195\n",
      "Epoch: 43, Batch: 291, D Loss: 0.10675242548993849, G Loss: 22.9976806640625\n",
      "Epoch: 43, Batch: 292, D Loss: 0.10197730366638405, G Loss: 23.371477127075195\n",
      "Epoch: 43, Batch: 293, D Loss: 0.09699718657317813, G Loss: 23.58542823791504\n",
      "Epoch: 43, Batch: 294, D Loss: 0.1007804051313462, G Loss: 23.679948806762695\n",
      "Epoch: 43, Batch: 295, D Loss: 0.10081538560614617, G Loss: 23.673566818237305\n",
      "Epoch: 43, Batch: 296, D Loss: 0.0983412862108188, G Loss: 23.51641082763672\n",
      "Epoch: 43, Batch: 297, D Loss: 0.10803420099689263, G Loss: 23.52138900756836\n",
      "Epoch: 43, Batch: 298, D Loss: 0.10645113143184698, G Loss: 23.654478073120117\n",
      "Epoch: 43, Batch: 299, D Loss: 0.1031220704571755, G Loss: 23.741952896118164\n",
      "Epoch: 43, Batch: 300, D Loss: 0.10239729287695339, G Loss: 23.732746124267578\n",
      "Epoch: 43, Batch: 301, D Loss: 0.09487613293364378, G Loss: 23.480133056640625\n",
      "Epoch: 43, Batch: 302, D Loss: 0.0974966735017885, G Loss: 23.18791961669922\n",
      "Epoch: 43, Batch: 303, D Loss: 0.09176497166493196, G Loss: 22.83986473083496\n",
      "Epoch: 43, Batch: 304, D Loss: 0.09677073365996708, G Loss: 22.69253158569336\n",
      "Epoch: 43, Batch: 305, D Loss: 0.0995551348378022, G Loss: 22.840564727783203\n",
      "Epoch: 43, Batch: 306, D Loss: 0.09866051380947663, G Loss: 23.161338806152344\n",
      "Epoch: 43, Batch: 307, D Loss: 0.1086153090326346, G Loss: 23.71430778503418\n",
      "Epoch: 43, Batch: 308, D Loss: 0.09691307695929538, G Loss: 23.957843780517578\n",
      "Epoch: 43, Batch: 309, D Loss: 0.09845416994952637, G Loss: 23.881513595581055\n",
      "Epoch: 43, Batch: 310, D Loss: 0.09355445953900882, G Loss: 23.441421508789062\n",
      "Epoch: 43, Batch: 311, D Loss: 0.09562282268555282, G Loss: 22.927043914794922\n",
      "Epoch: 43, Batch: 312, D Loss: 0.09569674736998708, G Loss: 22.55855369567871\n",
      "Epoch: 43, Batch: 313, D Loss: 0.09193870434093426, G Loss: 22.357269287109375\n",
      "Epoch: 43, Batch: 314, D Loss: 0.10259020337054123, G Loss: 22.611921310424805\n",
      "Epoch: 43, Batch: 315, D Loss: 0.09527514881204299, G Loss: 22.96800994873047\n",
      "Epoch: 43, Batch: 316, D Loss: 0.10146576170370822, G Loss: 23.400239944458008\n",
      "Epoch: 43, Batch: 317, D Loss: 0.10225316884988536, G Loss: 23.753149032592773\n",
      "Epoch: 43, Batch: 318, D Loss: 0.09866596760706976, G Loss: 23.812833786010742\n",
      "Epoch: 43, Batch: 319, D Loss: 0.0965858400128945, G Loss: 23.552797317504883\n",
      "Epoch: 43, Batch: 320, D Loss: 0.09734217081142564, G Loss: 23.149259567260742\n",
      "Epoch: 43, Batch: 321, D Loss: 0.09855459635758512, G Loss: 22.814611434936523\n",
      "Epoch: 43, Batch: 322, D Loss: 0.09972768283540631, G Loss: 22.685314178466797\n",
      "Epoch: 43, Batch: 323, D Loss: 0.09746892757181978, G Loss: 22.715272903442383\n",
      "Epoch: 43, Batch: 324, D Loss: 0.10012755549038278, G Loss: 22.94464683532715\n",
      "Epoch: 43, Batch: 325, D Loss: 0.096007950653199, G Loss: 23.12808609008789\n",
      "Epoch: 43, Batch: 326, D Loss: 0.09769151364025419, G Loss: 23.252063751220703\n",
      "Epoch: 43, Batch: 327, D Loss: 0.10289627317295091, G Loss: 23.40396499633789\n",
      "Epoch: 43, Batch: 328, D Loss: 0.10612896832934221, G Loss: 23.599571228027344\n",
      "Epoch: 43, Batch: 329, D Loss: 0.1047057137158446, G Loss: 23.71449851989746\n",
      "Epoch: 43, Batch: 330, D Loss: 0.09236382696002972, G Loss: 23.407764434814453\n",
      "Epoch: 43, Batch: 331, D Loss: 0.09831899408758647, G Loss: 22.997600555419922\n",
      "Epoch: 43, Batch: 332, D Loss: 0.10038393741809719, G Loss: 22.72869110107422\n",
      "Epoch: 43, Batch: 333, D Loss: 0.10053259141166931, G Loss: 22.688461303710938\n",
      "Epoch: 43, Batch: 334, D Loss: 0.09478335089533285, G Loss: 22.689624786376953\n",
      "Epoch: 43, Batch: 335, D Loss: 0.09859815246426723, G Loss: 22.823989868164062\n",
      "Epoch: 43, Batch: 336, D Loss: 0.09892695402651686, G Loss: 23.021839141845703\n",
      "Epoch: 43, Batch: 337, D Loss: 0.10684878383252414, G Loss: 23.38472557067871\n",
      "Epoch: 43, Batch: 338, D Loss: 0.0981288999643774, G Loss: 23.523197174072266\n",
      "Epoch: 43, Batch: 339, D Loss: 0.1019892692870209, G Loss: 23.5218563079834\n",
      "Epoch: 43, Batch: 340, D Loss: 0.10470343384289234, G Loss: 23.473819732666016\n",
      "Epoch: 43, Batch: 341, D Loss: 0.10303254428911897, G Loss: 23.36307716369629\n",
      "Epoch: 43, Batch: 342, D Loss: 0.09806960825207615, G Loss: 23.119592666625977\n",
      "Epoch: 43, Batch: 343, D Loss: 0.09570398187018399, G Loss: 22.815444946289062\n",
      "Epoch: 43, Batch: 344, D Loss: 0.10094922787535585, G Loss: 22.703582763671875\n",
      "Epoch: 43, Batch: 345, D Loss: 0.10381554818599653, G Loss: 22.844833374023438\n",
      "Epoch: 43, Batch: 346, D Loss: 0.10198342805361793, G Loss: 23.106189727783203\n",
      "Epoch: 43, Batch: 347, D Loss: 0.10117222372778827, G Loss: 23.348237991333008\n",
      "Epoch: 43, Batch: 348, D Loss: 0.09368042651524541, G Loss: 23.31505584716797\n",
      "Epoch: 43, Batch: 349, D Loss: 0.09623047713614194, G Loss: 23.119733810424805\n",
      "Epoch: 43, Batch: 350, D Loss: 0.10407070820240799, G Loss: 23.068004608154297\n",
      "Epoch: 43, Batch: 351, D Loss: 0.0940877199695312, G Loss: 22.904720306396484\n",
      "Epoch: 43, Batch: 352, D Loss: 0.10192415123851811, G Loss: 22.907974243164062\n",
      "Epoch: 43, Batch: 353, D Loss: 0.09870635723539926, G Loss: 22.97428321838379\n",
      "Epoch: 43, Batch: 354, D Loss: 0.10432223980319252, G Loss: 23.205551147460938\n",
      "Epoch: 43, Batch: 355, D Loss: 0.09422176335403104, G Loss: 23.231311798095703\n",
      "Epoch: 43, Batch: 356, D Loss: 0.10575331006278199, G Loss: 23.360151290893555\n",
      "Epoch: 43, Batch: 357, D Loss: 0.09018164877096364, G Loss: 23.161479949951172\n",
      "Epoch: 43, Batch: 358, D Loss: 0.09839819376524332, G Loss: 22.97162628173828\n",
      "Epoch: 43, Batch: 359, D Loss: 0.09798142319590869, G Loss: 22.847911834716797\n",
      "Epoch: 43, Batch: 360, D Loss: 0.10508624469793203, G Loss: 22.998088836669922\n",
      "Epoch: 43, Batch: 361, D Loss: 0.10485912863800473, G Loss: 23.31036949157715\n",
      "Epoch: 43, Batch: 362, D Loss: 0.10282161835105524, G Loss: 23.588239669799805\n",
      "Epoch: 43, Batch: 363, D Loss: 0.10189396890689775, G Loss: 23.710142135620117\n",
      "Epoch: 43, Batch: 364, D Loss: 0.09829753640020238, G Loss: 23.576141357421875\n",
      "Epoch: 43, Batch: 365, D Loss: 0.10116750005128969, G Loss: 23.36558723449707\n",
      "Epoch: 43, Batch: 366, D Loss: 0.09709812704907776, G Loss: 23.069326400756836\n",
      "Epoch: 43, Batch: 367, D Loss: 0.10080324118609206, G Loss: 22.897436141967773\n",
      "Epoch: 43, Batch: 368, D Loss: 0.09531863039899575, G Loss: 22.75482940673828\n",
      "Epoch: 43, Batch: 369, D Loss: 0.0963781327678726, G Loss: 22.715084075927734\n",
      "Epoch: 43, Batch: 370, D Loss: 0.10211294895630935, G Loss: 22.902639389038086\n",
      "Epoch: 43, Batch: 371, D Loss: 0.09929803763871181, G Loss: 23.13214874267578\n",
      "Epoch: 43, Batch: 372, D Loss: 0.09928694371493219, G Loss: 23.3143367767334\n",
      "Epoch: 43, Batch: 373, D Loss: 0.10127098861866582, G Loss: 23.438386917114258\n",
      "Epoch: 43, Batch: 374, D Loss: 0.10037016126845275, G Loss: 23.437171936035156\n",
      "Epoch: 43, Batch: 375, D Loss: 0.09705245498484341, G Loss: 23.257694244384766\n",
      "Epoch: 43, Batch: 376, D Loss: 0.09515340630903947, G Loss: 22.948719024658203\n",
      "Epoch: 43, Batch: 377, D Loss: 0.09803336864829808, G Loss: 22.723377227783203\n",
      "Epoch: 43, Batch: 378, D Loss: 0.09863690293878363, G Loss: 22.6578369140625\n",
      "Epoch: 43, Batch: 379, D Loss: 0.10628289735641058, G Loss: 22.922483444213867\n",
      "Epoch: 43, Batch: 380, D Loss: 0.09504689281329215, G Loss: 23.077173233032227\n",
      "Epoch: 43, Batch: 381, D Loss: 0.09720431272805094, G Loss: 23.142288208007812\n",
      "Epoch: 43, Batch: 382, D Loss: 0.10302095119426508, G Loss: 23.233549118041992\n",
      "Epoch: 43, Batch: 383, D Loss: 0.10122211281493493, G Loss: 23.258840560913086\n",
      "Epoch: 43, Batch: 384, D Loss: 0.09775908295562444, G Loss: 23.137178421020508\n",
      "Epoch: 43, Batch: 385, D Loss: 0.09012090420218472, G Loss: 22.759035110473633\n",
      "Epoch: 43, Batch: 386, D Loss: 0.09926832474719477, G Loss: 22.52033233642578\n",
      "Epoch: 43, Batch: 387, D Loss: 0.1054321155725861, G Loss: 22.651060104370117\n",
      "Epoch: 43, Batch: 388, D Loss: 0.09478185332725911, G Loss: 22.76088523864746\n",
      "Epoch: 43, Batch: 389, D Loss: 0.09739324456587825, G Loss: 22.888065338134766\n",
      "Epoch: 43, Batch: 390, D Loss: 0.09886334841828745, G Loss: 23.022790908813477\n",
      "Epoch: 43, Batch: 391, D Loss: 0.10265848045085599, G Loss: 23.22663688659668\n",
      "Epoch: 43, Batch: 392, D Loss: 0.09555255625791775, G Loss: 23.212940216064453\n",
      "Epoch: 43, Batch: 393, D Loss: 0.09809249643929768, G Loss: 23.092243194580078\n",
      "Epoch: 43, Batch: 394, D Loss: 0.09895841782347352, G Loss: 22.957414627075195\n",
      "Epoch: 43, Batch: 395, D Loss: 0.09452552354336279, G Loss: 22.753231048583984\n",
      "Epoch: 43, Batch: 396, D Loss: 0.10065111524538954, G Loss: 22.734357833862305\n",
      "Epoch: 43, Batch: 397, D Loss: 0.09398421651908545, G Loss: 22.719717025756836\n",
      "Epoch: 43, Batch: 398, D Loss: 0.10061886912914873, G Loss: 22.864988327026367\n",
      "Epoch: 43, Batch: 399, D Loss: 0.09921108191604042, G Loss: 23.038799285888672\n",
      "Epoch: 43, Batch: 400, D Loss: 0.10319139812770797, G Loss: 23.276643753051758\n",
      "Epoch: 43, Batch: 401, D Loss: 0.10135822001701164, G Loss: 23.433866500854492\n",
      "Epoch: 43, Batch: 402, D Loss: 0.10086908194745084, G Loss: 23.446643829345703\n",
      "Epoch: 43, Batch: 403, D Loss: 0.09241554889982781, G Loss: 23.128334045410156\n",
      "Epoch: 43, Batch: 404, D Loss: 0.10160258417516738, G Loss: 22.875043869018555\n",
      "Epoch: 43, Batch: 405, D Loss: 0.1016737744816745, G Loss: 22.800676345825195\n",
      "Epoch: 43, Batch: 406, D Loss: 0.10452295845506512, G Loss: 22.972829818725586\n",
      "Epoch: 43, Batch: 407, D Loss: 0.09527745848060623, G Loss: 23.025972366333008\n",
      "Epoch: 43, Batch: 408, D Loss: 0.09657099103010579, G Loss: 23.009361267089844\n",
      "Epoch: 43, Batch: 409, D Loss: 0.10189666603909307, G Loss: 23.089204788208008\n",
      "Epoch: 43, Batch: 410, D Loss: 0.09811687474129303, G Loss: 23.108036041259766\n",
      "Epoch: 43, Batch: 411, D Loss: 0.09913505618418955, G Loss: 23.104135513305664\n",
      "Epoch: 43, Batch: 412, D Loss: 0.0994843617548303, G Loss: 23.086538314819336\n",
      "Epoch: 43, Batch: 413, D Loss: 0.10271645341911419, G Loss: 23.14287757873535\n",
      "Epoch: 43, Batch: 414, D Loss: 0.09948465232485408, G Loss: 23.16145133972168\n",
      "Epoch: 43, Batch: 415, D Loss: 0.10016524796100709, G Loss: 23.154016494750977\n",
      "Epoch: 43, Batch: 416, D Loss: 0.09392175083218945, G Loss: 22.97725486755371\n",
      "Epoch: 43, Batch: 417, D Loss: 0.10418066387625781, G Loss: 22.98868179321289\n",
      "Epoch: 43, Batch: 418, D Loss: 0.09764109557097414, G Loss: 22.988204956054688\n",
      "Epoch: 43, Batch: 419, D Loss: 0.09477559482520762, G Loss: 22.90299415588379\n",
      "Epoch: 43, Batch: 420, D Loss: 0.09989255672331544, G Loss: 22.921579360961914\n",
      "Epoch: 43, Batch: 421, D Loss: 0.10070528095254291, G Loss: 23.025495529174805\n",
      "Epoch: 43, Batch: 422, D Loss: 0.1005030572881809, G Loss: 23.154193878173828\n",
      "Epoch: 43, Batch: 423, D Loss: 0.09842450921032031, G Loss: 23.212507247924805\n",
      "Epoch: 43, Batch: 424, D Loss: 0.09606482092858247, G Loss: 23.147790908813477\n",
      "Epoch: 43, Batch: 425, D Loss: 0.09762135152751215, G Loss: 23.032472610473633\n",
      "Epoch: 43, Batch: 426, D Loss: 0.09138232475270924, G Loss: 22.766483306884766\n",
      "Epoch: 43, Batch: 427, D Loss: 0.09328151501638458, G Loss: 22.520828247070312\n",
      "Epoch: 43, Batch: 428, D Loss: 0.09951388844057538, G Loss: 22.55200958251953\n",
      "Epoch: 43, Batch: 429, D Loss: 0.09775719798982513, G Loss: 22.724985122680664\n",
      "Epoch: 43, Batch: 430, D Loss: 0.1017153859704532, G Loss: 23.060426712036133\n",
      "Epoch: 43, Batch: 431, D Loss: 0.09929323200548035, G Loss: 23.354398727416992\n",
      "Epoch: 43, Batch: 432, D Loss: 0.10298213365869438, G Loss: 23.592613220214844\n",
      "Epoch: 43, Batch: 433, D Loss: 0.09809369596742706, G Loss: 23.561290740966797\n",
      "Epoch: 43, Batch: 434, D Loss: 0.10123915973494652, G Loss: 23.410255432128906\n",
      "Epoch: 43, Batch: 435, D Loss: 0.09624294195599326, G Loss: 23.10306739807129\n",
      "Epoch: 43, Batch: 436, D Loss: 0.09173969930279571, G Loss: 22.66363525390625\n",
      "Epoch: 43, Batch: 437, D Loss: 0.10543829209927022, G Loss: 22.639389038085938\n",
      "Epoch: 43, Batch: 438, D Loss: 0.10034371919182777, G Loss: 22.816638946533203\n",
      "Epoch: 43, Batch: 439, D Loss: 0.10306949173562548, G Loss: 23.168960571289062\n",
      "Epoch: 43, Batch: 440, D Loss: 0.10120122138363592, G Loss: 23.48001480102539\n",
      "Epoch: 43, Batch: 441, D Loss: 0.10010879489800803, G Loss: 23.586748123168945\n",
      "Epoch: 43, Batch: 442, D Loss: 0.09569884839843662, G Loss: 23.386850357055664\n",
      "Epoch: 43, Batch: 443, D Loss: 0.0977758989145377, G Loss: 23.0899715423584\n",
      "Epoch: 43, Batch: 444, D Loss: 0.09804145997179374, G Loss: 22.829570770263672\n",
      "Epoch: 43, Batch: 445, D Loss: 0.10266989475667596, G Loss: 22.81250762939453\n",
      "Epoch: 43, Batch: 446, D Loss: 0.10517564421366685, G Loss: 23.059158325195312\n",
      "Epoch: 43, Batch: 447, D Loss: 0.09957763556958286, G Loss: 23.28554916381836\n",
      "Epoch: 43, Batch: 448, D Loss: 0.0924537182250567, G Loss: 23.233678817749023\n",
      "Epoch: 43, Batch: 449, D Loss: 0.10188318793107672, G Loss: 23.21478271484375\n",
      "Epoch: 43, Batch: 450, D Loss: 0.09809159491798897, G Loss: 23.136606216430664\n",
      "Epoch: 43, Batch: 451, D Loss: 0.0965181217076255, G Loss: 23.008813858032227\n",
      "Epoch: 43, Batch: 452, D Loss: 0.1064671725509335, G Loss: 23.140148162841797\n",
      "Epoch: 43, Batch: 453, D Loss: 0.09136941288651768, G Loss: 23.036264419555664\n",
      "Epoch: 43, Batch: 454, D Loss: 0.09766966854754591, G Loss: 22.945940017700195\n",
      "Epoch: 43, Batch: 455, D Loss: 0.09672034537478877, G Loss: 22.86652183532715\n",
      "Epoch: 43, Batch: 456, D Loss: 0.0939902663842532, G Loss: 22.786352157592773\n",
      "Epoch: 43, Batch: 457, D Loss: 0.09838268166993987, G Loss: 22.840740203857422\n",
      "Epoch: 43, Batch: 458, D Loss: 0.10238716011570766, G Loss: 23.084495544433594\n",
      "Epoch: 43, Batch: 459, D Loss: 0.10206695650092912, G Loss: 23.375301361083984\n",
      "Epoch: 43, Batch: 460, D Loss: 0.09790708127949427, G Loss: 23.49401092529297\n",
      "Epoch: 43, Batch: 461, D Loss: 0.0981999636019715, G Loss: 23.432926177978516\n",
      "Epoch: 43, Batch: 462, D Loss: 0.09675949815622364, G Loss: 23.238069534301758\n",
      "Epoch: 43, Batch: 463, D Loss: 0.10138721768425057, G Loss: 23.104896545410156\n",
      "Epoch: 43, Batch: 464, D Loss: 0.09606628124959836, G Loss: 22.949193954467773\n",
      "Epoch: 43, Batch: 465, D Loss: 0.10359296207841631, G Loss: 23.026939392089844\n",
      "Epoch: 43, Batch: 466, D Loss: 0.09244875615109249, G Loss: 22.93777847290039\n",
      "Epoch: 43, Batch: 467, D Loss: 0.09528705483507867, G Loss: 22.825294494628906\n",
      "Epoch: 44, Batch: 0, D Loss: 0.1017223522654381, G Loss: 22.900598526000977\n",
      "Epoch: 44, Batch: 1, D Loss: 0.09673263883101997, G Loss: 22.967309951782227\n",
      "Epoch: 44, Batch: 2, D Loss: 0.10338641707875906, G Loss: 23.177003860473633\n",
      "Epoch: 44, Batch: 3, D Loss: 0.10164777193416627, G Loss: 23.350421905517578\n",
      "Epoch: 44, Batch: 4, D Loss: 0.09999298307879932, G Loss: 23.378887176513672\n",
      "Epoch: 44, Batch: 5, D Loss: 0.09929610792549182, G Loss: 23.266334533691406\n",
      "Epoch: 44, Batch: 6, D Loss: 0.09258963917470439, G Loss: 22.908161163330078\n",
      "Epoch: 44, Batch: 7, D Loss: 0.10013829178032861, G Loss: 22.6697998046875\n",
      "Epoch: 44, Batch: 8, D Loss: 0.10140704370727524, G Loss: 22.66864013671875\n",
      "Epoch: 44, Batch: 9, D Loss: 0.09624021507272112, G Loss: 22.729093551635742\n",
      "Epoch: 44, Batch: 10, D Loss: 0.09098572290821884, G Loss: 22.69799041748047\n",
      "Epoch: 44, Batch: 11, D Loss: 0.09718063480495576, G Loss: 22.738420486450195\n",
      "Epoch: 44, Batch: 12, D Loss: 0.10106597846825666, G Loss: 22.92551612854004\n",
      "Epoch: 44, Batch: 13, D Loss: 0.09799695765124881, G Loss: 23.073566436767578\n",
      "Epoch: 44, Batch: 14, D Loss: 0.10139103983231508, G Loss: 23.243412017822266\n",
      "Epoch: 44, Batch: 15, D Loss: 0.09409006689165159, G Loss: 23.185625076293945\n",
      "Epoch: 44, Batch: 16, D Loss: 0.09617795054797286, G Loss: 23.01850700378418\n",
      "Epoch: 44, Batch: 17, D Loss: 0.10378902410572194, G Loss: 23.00541877746582\n",
      "Epoch: 44, Batch: 18, D Loss: 0.09983954583677632, G Loss: 23.02933120727539\n",
      "Epoch: 44, Batch: 19, D Loss: 0.09560884540515921, G Loss: 22.947011947631836\n",
      "Epoch: 44, Batch: 20, D Loss: 0.10116377478213426, G Loss: 22.973312377929688\n",
      "Epoch: 44, Batch: 21, D Loss: 0.09518667315929458, G Loss: 22.90830421447754\n",
      "Epoch: 44, Batch: 22, D Loss: 0.10263355081706191, G Loss: 22.987855911254883\n",
      "Epoch: 44, Batch: 23, D Loss: 0.10261274878954932, G Loss: 23.159605026245117\n",
      "Epoch: 44, Batch: 24, D Loss: 0.09909455482356519, G Loss: 23.25259780883789\n",
      "Epoch: 44, Batch: 25, D Loss: 0.0970954001361494, G Loss: 23.191293716430664\n",
      "Epoch: 44, Batch: 26, D Loss: 0.10751176629497801, G Loss: 23.29733657836914\n",
      "Epoch: 44, Batch: 27, D Loss: 0.09859785441457707, G Loss: 23.26645278930664\n",
      "Epoch: 44, Batch: 28, D Loss: 0.09601092342968662, G Loss: 23.049076080322266\n",
      "Epoch: 44, Batch: 29, D Loss: 0.10288025443891266, G Loss: 22.965206146240234\n",
      "Epoch: 44, Batch: 30, D Loss: 0.1005169451765656, G Loss: 22.973615646362305\n",
      "Epoch: 44, Batch: 31, D Loss: 0.10025662188836078, G Loss: 23.0448055267334\n",
      "Epoch: 44, Batch: 32, D Loss: 0.09237141912449043, G Loss: 22.921846389770508\n",
      "Epoch: 44, Batch: 33, D Loss: 0.0968099982140728, G Loss: 22.79103660583496\n",
      "Epoch: 44, Batch: 34, D Loss: 0.1006759182240436, G Loss: 22.823183059692383\n",
      "Epoch: 44, Batch: 35, D Loss: 0.1029621065210167, G Loss: 23.03659439086914\n",
      "Epoch: 44, Batch: 36, D Loss: 0.10005937521142617, G Loss: 23.236066818237305\n",
      "Epoch: 44, Batch: 37, D Loss: 0.09238776568900266, G Loss: 23.1221981048584\n",
      "Epoch: 44, Batch: 38, D Loss: 0.0988250375287815, G Loss: 22.962688446044922\n",
      "Epoch: 44, Batch: 39, D Loss: 0.10380537813212651, G Loss: 22.982379913330078\n",
      "Epoch: 44, Batch: 40, D Loss: 0.09265711164159575, G Loss: 22.834163665771484\n",
      "Epoch: 44, Batch: 41, D Loss: 0.10080824798462598, G Loss: 22.827632904052734\n",
      "Epoch: 44, Batch: 42, D Loss: 0.09613899147701568, G Loss: 22.810516357421875\n",
      "Epoch: 44, Batch: 43, D Loss: 0.09867387271002862, G Loss: 22.861957550048828\n",
      "Epoch: 44, Batch: 44, D Loss: 0.09454058116675201, G Loss: 22.839305877685547\n",
      "Epoch: 44, Batch: 45, D Loss: 0.0931270719215387, G Loss: 22.722095489501953\n",
      "Epoch: 44, Batch: 46, D Loss: 0.09955139464834847, G Loss: 22.75591468811035\n",
      "Epoch: 44, Batch: 47, D Loss: 0.10111545032247263, G Loss: 22.939817428588867\n",
      "Epoch: 44, Batch: 48, D Loss: 0.09652022277515515, G Loss: 23.04083251953125\n",
      "Epoch: 44, Batch: 49, D Loss: 0.09822797780110354, G Loss: 23.073501586914062\n",
      "Epoch: 44, Batch: 50, D Loss: 0.09829393779133068, G Loss: 23.036155700683594\n",
      "Epoch: 44, Batch: 51, D Loss: 0.10263666515435124, G Loss: 23.07326316833496\n",
      "Epoch: 44, Batch: 52, D Loss: 0.10119683300149016, G Loss: 23.11675262451172\n",
      "Epoch: 44, Batch: 53, D Loss: 0.10108828549113204, G Loss: 23.14575958251953\n",
      "Epoch: 44, Batch: 54, D Loss: 0.107747219543353, G Loss: 23.321653366088867\n",
      "Epoch: 44, Batch: 55, D Loss: 0.09471325580302292, G Loss: 23.18498420715332\n",
      "Epoch: 44, Batch: 56, D Loss: 0.09980005030639483, G Loss: 22.969547271728516\n",
      "Epoch: 44, Batch: 57, D Loss: 0.09318141645667466, G Loss: 22.596473693847656\n",
      "Epoch: 44, Batch: 58, D Loss: 0.09316166499467102, G Loss: 22.26347541809082\n",
      "Epoch: 44, Batch: 59, D Loss: 0.1033511237329055, G Loss: 22.359224319458008\n",
      "Epoch: 44, Batch: 60, D Loss: 0.10542115576845515, G Loss: 22.79700469970703\n",
      "Epoch: 44, Batch: 61, D Loss: 0.09778584545097102, G Loss: 23.154279708862305\n",
      "Epoch: 44, Batch: 62, D Loss: 0.10065846894137996, G Loss: 23.369123458862305\n",
      "Epoch: 44, Batch: 63, D Loss: 0.0971989781032356, G Loss: 23.29974937438965\n",
      "Epoch: 44, Batch: 64, D Loss: 0.09962774817417071, G Loss: 23.091510772705078\n",
      "Epoch: 44, Batch: 65, D Loss: 0.09156471496829477, G Loss: 22.62883758544922\n",
      "Epoch: 44, Batch: 66, D Loss: 0.10228666671434143, G Loss: 22.428251266479492\n",
      "Epoch: 44, Batch: 67, D Loss: 0.10264141866218104, G Loss: 22.534639358520508\n",
      "Epoch: 44, Batch: 68, D Loss: 0.10197006172968501, G Loss: 22.831806182861328\n",
      "Epoch: 44, Batch: 69, D Loss: 0.09356067335378956, G Loss: 22.940319061279297\n",
      "Epoch: 44, Batch: 70, D Loss: 0.09687086200202394, G Loss: 22.939590454101562\n",
      "Epoch: 44, Batch: 71, D Loss: 0.10059212153547732, G Loss: 22.972095489501953\n",
      "Epoch: 44, Batch: 72, D Loss: 0.09590669726898651, G Loss: 22.881532669067383\n",
      "Epoch: 44, Batch: 73, D Loss: 0.09304617351915742, G Loss: 22.632936477661133\n",
      "Epoch: 44, Batch: 74, D Loss: 0.09346478440970982, G Loss: 22.35886573791504\n",
      "Epoch: 44, Batch: 75, D Loss: 0.10129160443686724, G Loss: 22.371232986450195\n",
      "Epoch: 44, Batch: 76, D Loss: 0.10517443724516426, G Loss: 22.723791122436523\n",
      "Epoch: 44, Batch: 77, D Loss: 0.10355159645689692, G Loss: 23.158540725708008\n",
      "Epoch: 44, Batch: 78, D Loss: 0.09992396835386079, G Loss: 23.391178131103516\n",
      "Epoch: 44, Batch: 79, D Loss: 0.10317294302933774, G Loss: 23.46870994567871\n",
      "Epoch: 44, Batch: 80, D Loss: 0.09869467470660157, G Loss: 23.256240844726562\n",
      "Epoch: 44, Batch: 81, D Loss: 0.10194568340572574, G Loss: 22.992033004760742\n",
      "Epoch: 44, Batch: 82, D Loss: 0.09523923701345173, G Loss: 22.629196166992188\n",
      "Epoch: 44, Batch: 83, D Loss: 0.09855833657941301, G Loss: 22.41830062866211\n",
      "Epoch: 44, Batch: 84, D Loss: 0.0938423649458617, G Loss: 22.290128707885742\n",
      "Epoch: 44, Batch: 85, D Loss: 0.09679012010508722, G Loss: 22.381032943725586\n",
      "Epoch: 44, Batch: 86, D Loss: 0.11024007208160547, G Loss: 22.974706649780273\n",
      "Epoch: 44, Batch: 87, D Loss: 0.09149119262498448, G Loss: 23.241878509521484\n",
      "Epoch: 44, Batch: 88, D Loss: 0.0900226235820657, G Loss: 23.11371612548828\n",
      "Epoch: 44, Batch: 89, D Loss: 0.09771949057838798, G Loss: 22.935949325561523\n",
      "Epoch: 44, Batch: 90, D Loss: 0.10152207320608678, G Loss: 22.877750396728516\n",
      "Epoch: 44, Batch: 91, D Loss: 0.09572901582828439, G Loss: 22.79037857055664\n",
      "Epoch: 44, Batch: 92, D Loss: 0.09864437586394183, G Loss: 22.803102493286133\n",
      "Epoch: 44, Batch: 93, D Loss: 0.10439768439076366, G Loss: 23.04316520690918\n",
      "Epoch: 44, Batch: 94, D Loss: 0.10002639894072281, G Loss: 23.272443771362305\n",
      "Epoch: 44, Batch: 95, D Loss: 0.09719675038111031, G Loss: 23.312213897705078\n",
      "Epoch: 44, Batch: 96, D Loss: 0.09917363528339121, G Loss: 23.23910903930664\n",
      "Epoch: 44, Batch: 97, D Loss: 0.10372072462309817, G Loss: 23.23780632019043\n",
      "Epoch: 44, Batch: 98, D Loss: 0.10023675863109749, G Loss: 23.19587516784668\n",
      "Epoch: 44, Batch: 99, D Loss: 0.09964456413581135, G Loss: 23.13079261779785\n",
      "Epoch: 44, Batch: 100, D Loss: 0.10552142564754108, G Loss: 23.230356216430664\n",
      "Epoch: 44, Batch: 101, D Loss: 0.09643466774808893, G Loss: 23.191301345825195\n",
      "Epoch: 44, Batch: 102, D Loss: 0.1005620807836419, G Loss: 23.176259994506836\n",
      "Epoch: 44, Batch: 103, D Loss: 0.09892904762837862, G Loss: 23.140092849731445\n",
      "Epoch: 44, Batch: 104, D Loss: 0.10488820825178141, G Loss: 23.285619735717773\n",
      "Epoch: 44, Batch: 105, D Loss: 0.10042221847846497, G Loss: 23.389925003051758\n",
      "Epoch: 44, Batch: 106, D Loss: 0.09402442727261345, G Loss: 23.245323181152344\n",
      "Epoch: 44, Batch: 107, D Loss: 0.09320110087359204, G Loss: 22.932144165039062\n",
      "Epoch: 44, Batch: 108, D Loss: 0.09176619357560649, G Loss: 22.567548751831055\n",
      "Epoch: 44, Batch: 109, D Loss: 0.09676455714863394, G Loss: 22.42887306213379\n",
      "Epoch: 44, Batch: 110, D Loss: 0.10551743962055127, G Loss: 22.758445739746094\n",
      "Epoch: 44, Batch: 111, D Loss: 0.1020184904842055, G Loss: 23.24607276916504\n",
      "Epoch: 44, Batch: 112, D Loss: 0.10489745441167966, G Loss: 23.753864288330078\n",
      "Epoch: 44, Batch: 113, D Loss: 0.09676983209758777, G Loss: 23.850522994995117\n",
      "Epoch: 44, Batch: 114, D Loss: 0.09791894259554967, G Loss: 23.610685348510742\n",
      "Epoch: 44, Batch: 115, D Loss: 0.10007247332128016, G Loss: 23.248598098754883\n",
      "Epoch: 44, Batch: 116, D Loss: 0.10342212770903976, G Loss: 23.02740478515625\n",
      "Epoch: 44, Batch: 117, D Loss: 0.10011512791431156, G Loss: 22.920461654663086\n",
      "Epoch: 44, Batch: 118, D Loss: 0.1045632809917649, G Loss: 23.056827545166016\n",
      "Epoch: 44, Batch: 119, D Loss: 0.09872247283198643, G Loss: 23.19462776184082\n",
      "Epoch: 44, Batch: 120, D Loss: 0.09634575996999917, G Loss: 23.21558952331543\n",
      "Epoch: 44, Batch: 121, D Loss: 0.09380847965191927, G Loss: 23.063026428222656\n",
      "Epoch: 44, Batch: 122, D Loss: 0.10291668032436953, G Loss: 23.070968627929688\n",
      "Epoch: 44, Batch: 123, D Loss: 0.10106582944212505, G Loss: 23.148778915405273\n",
      "Epoch: 44, Batch: 124, D Loss: 0.09666842226651765, G Loss: 23.141782760620117\n",
      "Epoch: 44, Batch: 125, D Loss: 0.10126651827836124, G Loss: 23.2012939453125\n",
      "Epoch: 44, Batch: 126, D Loss: 0.09206184749417921, G Loss: 23.033267974853516\n",
      "Epoch: 44, Batch: 127, D Loss: 0.09677068149472728, G Loss: 22.876461029052734\n",
      "Epoch: 44, Batch: 128, D Loss: 0.09802445030196535, G Loss: 22.83155632019043\n",
      "Epoch: 44, Batch: 129, D Loss: 0.09600687033051361, G Loss: 22.831125259399414\n",
      "Epoch: 44, Batch: 130, D Loss: 0.09817562258099365, G Loss: 22.91382598876953\n",
      "Epoch: 44, Batch: 131, D Loss: 0.10174769168139171, G Loss: 23.12371063232422\n",
      "Epoch: 44, Batch: 132, D Loss: 0.1005137861179834, G Loss: 23.3387451171875\n",
      "Epoch: 44, Batch: 133, D Loss: 0.1027042717072414, G Loss: 23.528732299804688\n",
      "Epoch: 44, Batch: 134, D Loss: 0.11016084256372781, G Loss: 23.82644271850586\n",
      "Epoch: 44, Batch: 135, D Loss: 0.1002316549646045, G Loss: 23.81671142578125\n",
      "Epoch: 44, Batch: 136, D Loss: 0.10396857562137313, G Loss: 23.664365768432617\n",
      "Epoch: 44, Batch: 137, D Loss: 0.09677375111246295, G Loss: 23.27315330505371\n",
      "Epoch: 44, Batch: 138, D Loss: 0.1020692736363021, G Loss: 22.9920654296875\n",
      "Epoch: 44, Batch: 139, D Loss: 0.10194640612004036, G Loss: 22.923362731933594\n",
      "Epoch: 44, Batch: 140, D Loss: 0.09553978597867188, G Loss: 22.865890502929688\n",
      "Epoch: 44, Batch: 141, D Loss: 0.09638354188111734, G Loss: 22.86561393737793\n",
      "Epoch: 44, Batch: 142, D Loss: 0.1033291370193722, G Loss: 23.10586929321289\n",
      "Epoch: 44, Batch: 143, D Loss: 0.10622844848715612, G Loss: 23.546239852905273\n",
      "Epoch: 44, Batch: 144, D Loss: 0.09874099495681056, G Loss: 23.760478973388672\n",
      "Epoch: 44, Batch: 145, D Loss: 0.10026773067729045, G Loss: 23.75889778137207\n",
      "Epoch: 44, Batch: 146, D Loss: 0.107178308093707, G Loss: 23.760595321655273\n",
      "Epoch: 44, Batch: 147, D Loss: 0.10239197316363761, G Loss: 23.622928619384766\n",
      "Epoch: 44, Batch: 148, D Loss: 0.09953591975753782, G Loss: 23.357389450073242\n",
      "Epoch: 44, Batch: 149, D Loss: 0.10564771298366471, G Loss: 23.262592315673828\n",
      "Epoch: 44, Batch: 150, D Loss: 0.09761318568644552, G Loss: 23.13065528869629\n",
      "Epoch: 44, Batch: 151, D Loss: 0.10392975811551695, G Loss: 23.19103240966797\n",
      "Epoch: 44, Batch: 152, D Loss: 0.1041089743761327, G Loss: 23.3709774017334\n",
      "Epoch: 44, Batch: 153, D Loss: 0.09494237605355835, G Loss: 23.340044021606445\n",
      "Epoch: 44, Batch: 154, D Loss: 0.09636721018904201, G Loss: 23.201610565185547\n",
      "Epoch: 44, Batch: 155, D Loss: 0.0978455245948273, G Loss: 23.053316116333008\n",
      "Epoch: 44, Batch: 156, D Loss: 0.0977642834699018, G Loss: 22.954315185546875\n",
      "Epoch: 44, Batch: 157, D Loss: 0.10204964881267034, G Loss: 23.05557632446289\n",
      "Epoch: 44, Batch: 158, D Loss: 0.10261827711519295, G Loss: 23.317249298095703\n",
      "Epoch: 44, Batch: 159, D Loss: 0.09774617854240045, G Loss: 23.463321685791016\n",
      "Epoch: 44, Batch: 160, D Loss: 0.09640629592823242, G Loss: 23.441547393798828\n",
      "Epoch: 44, Batch: 161, D Loss: 0.09934102002224215, G Loss: 23.37432289123535\n",
      "Epoch: 44, Batch: 162, D Loss: 0.10078381005582074, G Loss: 23.319171905517578\n",
      "Epoch: 44, Batch: 163, D Loss: 0.0951174199986517, G Loss: 23.16036605834961\n",
      "Epoch: 44, Batch: 164, D Loss: 0.09805667404943252, G Loss: 23.07016944885254\n",
      "Epoch: 44, Batch: 165, D Loss: 0.09880140428493474, G Loss: 23.096006393432617\n",
      "Epoch: 44, Batch: 166, D Loss: 0.09252260630201711, G Loss: 23.024776458740234\n",
      "Epoch: 44, Batch: 167, D Loss: 0.09474998717651477, G Loss: 22.98482894897461\n",
      "Epoch: 44, Batch: 168, D Loss: 0.09299089764943425, G Loss: 22.93242073059082\n",
      "Epoch: 44, Batch: 169, D Loss: 0.09850551193088498, G Loss: 23.07364273071289\n",
      "Epoch: 44, Batch: 170, D Loss: 0.10253947977288091, G Loss: 23.38905143737793\n",
      "Epoch: 44, Batch: 171, D Loss: 0.10441702607105476, G Loss: 23.792043685913086\n",
      "Epoch: 44, Batch: 172, D Loss: 0.09388242664235322, G Loss: 23.826339721679688\n",
      "Epoch: 44, Batch: 173, D Loss: 0.09767021986323207, G Loss: 23.651830673217773\n",
      "Epoch: 44, Batch: 174, D Loss: 0.10301418605310293, G Loss: 23.534692764282227\n",
      "Epoch: 44, Batch: 175, D Loss: 0.0916534960631735, G Loss: 23.181856155395508\n",
      "Epoch: 44, Batch: 176, D Loss: 0.1039048135723955, G Loss: 23.113948822021484\n",
      "Epoch: 44, Batch: 177, D Loss: 0.09743368630168105, G Loss: 23.13532829284668\n",
      "Epoch: 44, Batch: 178, D Loss: 0.09685347233511035, G Loss: 23.227800369262695\n",
      "Epoch: 44, Batch: 179, D Loss: 0.10123466703979778, G Loss: 23.434497833251953\n",
      "Epoch: 44, Batch: 180, D Loss: 0.09647770229119998, G Loss: 23.55518913269043\n",
      "Epoch: 44, Batch: 181, D Loss: 0.10014555606066292, G Loss: 23.65081024169922\n",
      "Epoch: 44, Batch: 182, D Loss: 0.10476739707034938, G Loss: 23.837276458740234\n",
      "Epoch: 44, Batch: 183, D Loss: 0.10462387653232465, G Loss: 24.010570526123047\n",
      "Epoch: 44, Batch: 184, D Loss: 0.10133772345253583, G Loss: 24.022090911865234\n",
      "Epoch: 44, Batch: 185, D Loss: 0.10469112547126483, G Loss: 23.993192672729492\n",
      "Epoch: 44, Batch: 186, D Loss: 0.09779244663480409, G Loss: 23.75914192199707\n",
      "Epoch: 44, Batch: 187, D Loss: 0.09746466579893387, G Loss: 23.439712524414062\n",
      "Epoch: 44, Batch: 188, D Loss: 0.10028387609749642, G Loss: 23.274396896362305\n",
      "Epoch: 44, Batch: 189, D Loss: 0.10179506246038125, G Loss: 23.342266082763672\n",
      "Epoch: 44, Batch: 190, D Loss: 0.10350845757310945, G Loss: 23.610055923461914\n",
      "Epoch: 44, Batch: 191, D Loss: 0.09024011346570325, G Loss: 23.566267013549805\n",
      "Epoch: 44, Batch: 192, D Loss: 0.10752604904393319, G Loss: 23.779850006103516\n",
      "Epoch: 44, Batch: 193, D Loss: 0.1026702672453375, G Loss: 23.993043899536133\n",
      "Epoch: 44, Batch: 194, D Loss: 0.0902225747919645, G Loss: 23.757389068603516\n",
      "Epoch: 44, Batch: 195, D Loss: 0.1028216853995611, G Loss: 23.626178741455078\n",
      "Epoch: 44, Batch: 196, D Loss: 0.09367329630406383, G Loss: 23.37458038330078\n",
      "Epoch: 44, Batch: 197, D Loss: 0.10325616601629939, G Loss: 23.389352798461914\n",
      "Epoch: 44, Batch: 198, D Loss: 0.10250889513022643, G Loss: 23.602954864501953\n",
      "Epoch: 44, Batch: 199, D Loss: 0.09500123563140617, G Loss: 23.6688232421875\n",
      "Epoch: 44, Batch: 200, D Loss: 0.10144682976120564, G Loss: 23.766220092773438\n",
      "Epoch: 44, Batch: 201, D Loss: 0.09647676351121343, G Loss: 23.726455688476562\n",
      "Epoch: 44, Batch: 202, D Loss: 0.0943605602064169, G Loss: 23.51981544494629\n",
      "Epoch: 44, Batch: 203, D Loss: 0.09591279927329813, G Loss: 23.306015014648438\n",
      "Epoch: 44, Batch: 204, D Loss: 0.1000695825006549, G Loss: 23.278032302856445\n",
      "Epoch: 44, Batch: 205, D Loss: 0.10265994075404963, G Loss: 23.506746292114258\n",
      "Epoch: 44, Batch: 206, D Loss: 0.09743250909269731, G Loss: 23.69287109375\n",
      "Epoch: 44, Batch: 207, D Loss: 0.10128016772188765, G Loss: 23.89855194091797\n",
      "Epoch: 44, Batch: 208, D Loss: 0.10063561799121425, G Loss: 24.00103187561035\n",
      "Epoch: 44, Batch: 209, D Loss: 0.10114497693288577, G Loss: 23.990962982177734\n",
      "Epoch: 44, Batch: 210, D Loss: 0.10219102354817342, G Loss: 23.936832427978516\n",
      "Epoch: 44, Batch: 211, D Loss: 0.09650623800648175, G Loss: 23.69947624206543\n",
      "Epoch: 44, Batch: 212, D Loss: 0.0963523686226691, G Loss: 23.424501419067383\n",
      "Epoch: 44, Batch: 213, D Loss: 0.09113737944828168, G Loss: 23.07151222229004\n",
      "Epoch: 44, Batch: 214, D Loss: 0.10005955402915251, G Loss: 23.04953956604004\n",
      "Epoch: 44, Batch: 215, D Loss: 0.1018460169846101, G Loss: 23.37403106689453\n",
      "Epoch: 44, Batch: 216, D Loss: 0.10638491066899652, G Loss: 23.961000442504883\n",
      "Epoch: 44, Batch: 217, D Loss: 0.09868719430409442, G Loss: 24.313201904296875\n",
      "Epoch: 44, Batch: 218, D Loss: 0.10180701316707298, G Loss: 24.420373916625977\n",
      "Epoch: 44, Batch: 219, D Loss: 0.09419212491806614, G Loss: 24.07612419128418\n",
      "Epoch: 44, Batch: 220, D Loss: 0.10196454825106546, G Loss: 23.737821578979492\n",
      "Epoch: 44, Batch: 221, D Loss: 0.10620815309473254, G Loss: 23.648639678955078\n",
      "Epoch: 44, Batch: 222, D Loss: 0.10301057251904466, G Loss: 23.710140228271484\n",
      "Epoch: 44, Batch: 223, D Loss: 0.10141136499630413, G Loss: 23.827417373657227\n",
      "Epoch: 44, Batch: 224, D Loss: 0.09817697110011049, G Loss: 23.84786033630371\n",
      "Epoch: 44, Batch: 225, D Loss: 0.09756010028014123, G Loss: 23.78266716003418\n",
      "Epoch: 44, Batch: 226, D Loss: 0.09716753664135726, G Loss: 23.659320831298828\n",
      "Epoch: 44, Batch: 227, D Loss: 0.10665944966151909, G Loss: 23.804786682128906\n",
      "Epoch: 44, Batch: 228, D Loss: 0.09935431929620758, G Loss: 23.903594970703125\n",
      "Epoch: 44, Batch: 229, D Loss: 0.09949630500912181, G Loss: 23.9522647857666\n",
      "Epoch: 44, Batch: 230, D Loss: 0.10268594326502842, G Loss: 24.016510009765625\n",
      "Epoch: 44, Batch: 231, D Loss: 0.10067991169173811, G Loss: 24.006065368652344\n",
      "Epoch: 44, Batch: 232, D Loss: 0.1028676554747081, G Loss: 24.018224716186523\n",
      "Epoch: 44, Batch: 233, D Loss: 0.09503728898412565, G Loss: 23.84229850769043\n",
      "Epoch: 44, Batch: 234, D Loss: 0.10293772818918814, G Loss: 23.799114227294922\n",
      "Epoch: 44, Batch: 235, D Loss: 0.1042511612393064, G Loss: 23.92313575744629\n",
      "Epoch: 44, Batch: 236, D Loss: 0.09673882277859153, G Loss: 23.92222785949707\n",
      "Epoch: 44, Batch: 237, D Loss: 0.09583267571689963, G Loss: 23.8243408203125\n",
      "Epoch: 44, Batch: 238, D Loss: 0.09689088168175261, G Loss: 23.689796447753906\n",
      "Epoch: 44, Batch: 239, D Loss: 0.09707050028173989, G Loss: 23.59130859375\n",
      "Epoch: 44, Batch: 240, D Loss: 0.09503666314466178, G Loss: 23.510602951049805\n",
      "Epoch: 44, Batch: 241, D Loss: 0.10139021280264833, G Loss: 23.666139602661133\n",
      "Epoch: 44, Batch: 242, D Loss: 0.10291425885991183, G Loss: 23.99103355407715\n",
      "Epoch: 44, Batch: 243, D Loss: 0.10158802570543121, G Loss: 24.2868709564209\n",
      "Epoch: 44, Batch: 244, D Loss: 0.0972491279383984, G Loss: 24.315568923950195\n",
      "Epoch: 44, Batch: 245, D Loss: 0.09924859555062758, G Loss: 24.169225692749023\n",
      "Epoch: 44, Batch: 246, D Loss: 0.09408243002445262, G Loss: 23.796958923339844\n",
      "Epoch: 44, Batch: 247, D Loss: 0.09867441656905221, G Loss: 23.502012252807617\n",
      "Epoch: 44, Batch: 248, D Loss: 0.10021819922557998, G Loss: 23.439205169677734\n",
      "Epoch: 44, Batch: 249, D Loss: 0.10044550898719776, G Loss: 23.606149673461914\n",
      "Epoch: 44, Batch: 250, D Loss: 0.09874674680335842, G Loss: 23.8303165435791\n",
      "Epoch: 44, Batch: 251, D Loss: 0.09335576000021265, G Loss: 23.868793487548828\n",
      "Epoch: 44, Batch: 252, D Loss: 0.09718619289189868, G Loss: 23.848031997680664\n",
      "Epoch: 44, Batch: 253, D Loss: 0.10259298982337699, G Loss: 23.932668685913086\n",
      "Epoch: 44, Batch: 254, D Loss: 0.10435931386379363, G Loss: 24.13399314880371\n",
      "Epoch: 44, Batch: 255, D Loss: 0.09648066760790276, G Loss: 24.099864959716797\n",
      "Epoch: 44, Batch: 256, D Loss: 0.10198645295459813, G Loss: 24.056955337524414\n",
      "Epoch: 44, Batch: 257, D Loss: 0.09724909069098592, G Loss: 23.891983032226562\n",
      "Epoch: 44, Batch: 258, D Loss: 0.1007783264143598, G Loss: 23.790149688720703\n",
      "Epoch: 44, Batch: 259, D Loss: 0.09582450243377941, G Loss: 23.634164810180664\n",
      "Epoch: 44, Batch: 260, D Loss: 0.09852626177497595, G Loss: 23.573772430419922\n",
      "Epoch: 44, Batch: 261, D Loss: 0.0973254218986585, G Loss: 23.57405662536621\n",
      "Epoch: 44, Batch: 262, D Loss: 0.0945831165007815, G Loss: 23.566564559936523\n",
      "Epoch: 44, Batch: 263, D Loss: 0.09746517243832936, G Loss: 23.619436264038086\n",
      "Epoch: 44, Batch: 264, D Loss: 0.09486255052470759, G Loss: 23.617033004760742\n",
      "Epoch: 44, Batch: 265, D Loss: 0.09880216422378042, G Loss: 23.677783966064453\n",
      "Epoch: 44, Batch: 266, D Loss: 0.0975172296419817, G Loss: 23.730510711669922\n",
      "Epoch: 44, Batch: 267, D Loss: 0.10051760079810498, G Loss: 23.83915901184082\n",
      "Epoch: 44, Batch: 268, D Loss: 0.09229974451047153, G Loss: 23.715232849121094\n",
      "Epoch: 44, Batch: 269, D Loss: 0.09971256556705582, G Loss: 23.663429260253906\n",
      "Epoch: 44, Batch: 270, D Loss: 0.10242817553407796, G Loss: 23.7613525390625\n",
      "Epoch: 44, Batch: 271, D Loss: 0.09881640973003425, G Loss: 23.842226028442383\n",
      "Epoch: 44, Batch: 272, D Loss: 0.09286495300536467, G Loss: 23.694068908691406\n",
      "Epoch: 44, Batch: 273, D Loss: 0.09707398715402615, G Loss: 23.547992706298828\n",
      "Epoch: 44, Batch: 274, D Loss: 0.094961568745483, G Loss: 23.386301040649414\n",
      "Epoch: 44, Batch: 275, D Loss: 0.10218057039653927, G Loss: 23.517539978027344\n",
      "Epoch: 44, Batch: 276, D Loss: 0.10236353429758589, G Loss: 23.83510971069336\n",
      "Epoch: 44, Batch: 277, D Loss: 0.09665483238347365, G Loss: 24.005908966064453\n",
      "Epoch: 44, Batch: 278, D Loss: 0.10166086258254241, G Loss: 24.138233184814453\n",
      "Epoch: 44, Batch: 279, D Loss: 0.09401671590206945, G Loss: 23.980449676513672\n",
      "Epoch: 44, Batch: 280, D Loss: 0.09826964142090708, G Loss: 23.767927169799805\n",
      "Epoch: 44, Batch: 281, D Loss: 0.10131381454565397, G Loss: 23.688913345336914\n",
      "Epoch: 44, Batch: 282, D Loss: 0.09643934669774615, G Loss: 23.625150680541992\n",
      "Epoch: 44, Batch: 283, D Loss: 0.10302864762680078, G Loss: 23.788604736328125\n",
      "Epoch: 44, Batch: 284, D Loss: 0.1010975539892446, G Loss: 24.004270553588867\n",
      "Epoch: 44, Batch: 285, D Loss: 0.09541878106084747, G Loss: 24.009037017822266\n",
      "Epoch: 44, Batch: 286, D Loss: 0.09979078175532985, G Loss: 23.98379898071289\n",
      "Epoch: 44, Batch: 287, D Loss: 0.10504502059857429, G Loss: 24.075225830078125\n",
      "Epoch: 44, Batch: 288, D Loss: 0.0971835628334993, G Loss: 23.990100860595703\n",
      "Epoch: 44, Batch: 289, D Loss: 0.09725961091242397, G Loss: 23.798704147338867\n",
      "Epoch: 44, Batch: 290, D Loss: 0.09579094501996187, G Loss: 23.53870391845703\n",
      "Epoch: 44, Batch: 291, D Loss: 0.10782267901099887, G Loss: 23.68024444580078\n",
      "Epoch: 44, Batch: 292, D Loss: 0.10198016467034464, G Loss: 23.89226531982422\n",
      "Epoch: 44, Batch: 293, D Loss: 0.10268190505017778, G Loss: 24.086997985839844\n",
      "Epoch: 44, Batch: 294, D Loss: 0.09872266651945352, G Loss: 24.0704402923584\n",
      "Epoch: 44, Batch: 295, D Loss: 0.09609621765252774, G Loss: 23.80421257019043\n",
      "Epoch: 44, Batch: 296, D Loss: 0.1020312011496697, G Loss: 23.60625457763672\n",
      "Epoch: 44, Batch: 297, D Loss: 0.09936539086721848, G Loss: 23.472211837768555\n",
      "Epoch: 44, Batch: 298, D Loss: 0.10288011285784796, G Loss: 23.53090476989746\n",
      "Epoch: 44, Batch: 299, D Loss: 0.09482192251182148, G Loss: 23.49424934387207\n",
      "Epoch: 44, Batch: 300, D Loss: 0.10302746298861412, G Loss: 23.618091583251953\n",
      "Epoch: 44, Batch: 301, D Loss: 0.09158997985703851, G Loss: 23.48659896850586\n",
      "Epoch: 44, Batch: 302, D Loss: 0.0951961875309424, G Loss: 23.30192756652832\n",
      "Epoch: 44, Batch: 303, D Loss: 0.10147891942407447, G Loss: 23.33872413635254\n",
      "Epoch: 44, Batch: 304, D Loss: 0.09512373808693565, G Loss: 23.34355354309082\n",
      "Epoch: 44, Batch: 305, D Loss: 0.10288541767255518, G Loss: 23.56707763671875\n",
      "Epoch: 44, Batch: 306, D Loss: 0.09975299986821218, G Loss: 23.777942657470703\n",
      "Epoch: 44, Batch: 307, D Loss: 0.0950162112950465, G Loss: 23.762588500976562\n",
      "Epoch: 44, Batch: 308, D Loss: 0.10234134646633972, G Loss: 23.786052703857422\n",
      "Epoch: 44, Batch: 309, D Loss: 0.10426232220948356, G Loss: 23.896358489990234\n",
      "Epoch: 44, Batch: 310, D Loss: 0.0971381962518706, G Loss: 23.807756423950195\n",
      "Epoch: 44, Batch: 311, D Loss: 0.09702473881432208, G Loss: 23.58526611328125\n",
      "Epoch: 44, Batch: 312, D Loss: 0.10359082373906023, G Loss: 23.551132202148438\n",
      "Epoch: 44, Batch: 313, D Loss: 0.09368143978951504, G Loss: 23.3908634185791\n",
      "Epoch: 44, Batch: 314, D Loss: 0.09748788926658568, G Loss: 23.303924560546875\n",
      "Epoch: 44, Batch: 315, D Loss: 0.10365276042065573, G Loss: 23.49773597717285\n",
      "Epoch: 44, Batch: 316, D Loss: 0.09391249719336629, G Loss: 23.53740119934082\n",
      "Epoch: 44, Batch: 317, D Loss: 0.09894979003009481, G Loss: 23.58877182006836\n",
      "Epoch: 44, Batch: 318, D Loss: 0.09433467689191716, G Loss: 23.47998046875\n",
      "Epoch: 44, Batch: 319, D Loss: 0.09558184448349064, G Loss: 23.3249568939209\n",
      "Epoch: 44, Batch: 320, D Loss: 0.0998367816580214, G Loss: 23.32663917541504\n",
      "Epoch: 44, Batch: 321, D Loss: 0.09343802932748249, G Loss: 23.264785766601562\n",
      "Epoch: 44, Batch: 322, D Loss: 0.10273891690967211, G Loss: 23.448640823364258\n",
      "Epoch: 44, Batch: 323, D Loss: 0.10046265277159595, G Loss: 23.697721481323242\n",
      "Epoch: 44, Batch: 324, D Loss: 0.0919315666222916, G Loss: 23.64470672607422\n",
      "Epoch: 44, Batch: 325, D Loss: 0.10008366408713651, G Loss: 23.6049861907959\n",
      "Epoch: 44, Batch: 326, D Loss: 0.09988687935316237, G Loss: 23.589462280273438\n",
      "Epoch: 44, Batch: 327, D Loss: 0.10152380171188, G Loss: 23.654537200927734\n",
      "Epoch: 44, Batch: 328, D Loss: 0.09708773347485214, G Loss: 23.609769821166992\n",
      "Epoch: 44, Batch: 329, D Loss: 0.10640539976519178, G Loss: 23.78335952758789\n",
      "Epoch: 44, Batch: 330, D Loss: 0.09685599806303757, G Loss: 23.755189895629883\n",
      "Epoch: 44, Batch: 331, D Loss: 0.09921853246831851, G Loss: 23.665834426879883\n",
      "Epoch: 44, Batch: 332, D Loss: 0.10657069834573105, G Loss: 23.77711296081543\n",
      "Epoch: 44, Batch: 333, D Loss: 0.10047063233768355, G Loss: 23.82501792907715\n",
      "Epoch: 44, Batch: 334, D Loss: 0.10214911403489242, G Loss: 23.85150146484375\n",
      "Epoch: 44, Batch: 335, D Loss: 0.09887658061872975, G Loss: 23.778112411499023\n",
      "Epoch: 44, Batch: 336, D Loss: 0.09715352955063333, G Loss: 23.603574752807617\n",
      "Epoch: 44, Batch: 337, D Loss: 0.10029523077563958, G Loss: 23.516742706298828\n",
      "Epoch: 44, Batch: 338, D Loss: 0.09934831413738719, G Loss: 23.497066497802734\n",
      "Epoch: 44, Batch: 339, D Loss: 0.0999261588159676, G Loss: 23.562955856323242\n",
      "Epoch: 44, Batch: 340, D Loss: 0.10038567337143955, G Loss: 23.692045211791992\n",
      "Epoch: 44, Batch: 341, D Loss: 0.10363937171583693, G Loss: 23.926246643066406\n",
      "Epoch: 44, Batch: 342, D Loss: 0.1003226340009116, G Loss: 24.033309936523438\n",
      "Epoch: 44, Batch: 343, D Loss: 0.10479633511842976, G Loss: 24.135726928710938\n",
      "Epoch: 44, Batch: 344, D Loss: 0.10333022476894803, G Loss: 24.130922317504883\n",
      "Epoch: 44, Batch: 345, D Loss: 0.1017388478100305, G Loss: 23.985118865966797\n",
      "Epoch: 44, Batch: 346, D Loss: 0.10208673777304855, G Loss: 23.80267333984375\n",
      "Epoch: 44, Batch: 347, D Loss: 0.10310004653991754, G Loss: 23.685688018798828\n",
      "Epoch: 44, Batch: 348, D Loss: 0.10263645651578557, G Loss: 23.658287048339844\n",
      "Epoch: 44, Batch: 349, D Loss: 0.09999716284598287, G Loss: 23.62220573425293\n",
      "Epoch: 44, Batch: 350, D Loss: 0.10018751773030857, G Loss: 23.60928726196289\n",
      "Epoch: 44, Batch: 351, D Loss: 0.10063870998974665, G Loss: 23.645082473754883\n",
      "Epoch: 44, Batch: 352, D Loss: 0.10080002995986508, G Loss: 23.681129455566406\n",
      "Epoch: 44, Batch: 353, D Loss: 0.10216341170180088, G Loss: 23.7593994140625\n",
      "Epoch: 44, Batch: 354, D Loss: 0.10420569779702028, G Loss: 23.914005279541016\n",
      "Epoch: 44, Batch: 355, D Loss: 0.09236922862464086, G Loss: 23.686405181884766\n",
      "Epoch: 44, Batch: 356, D Loss: 0.10205060246377005, G Loss: 23.55321502685547\n",
      "Epoch: 44, Batch: 357, D Loss: 0.10067231956114155, G Loss: 23.540851593017578\n",
      "Epoch: 44, Batch: 358, D Loss: 0.09565718475114074, G Loss: 23.464313507080078\n",
      "Epoch: 44, Batch: 359, D Loss: 0.09223130348933622, G Loss: 23.26094627380371\n",
      "Epoch: 44, Batch: 360, D Loss: 0.10293932262777379, G Loss: 23.3891544342041\n",
      "Epoch: 44, Batch: 361, D Loss: 0.10148461911072536, G Loss: 23.68766975402832\n",
      "Epoch: 44, Batch: 362, D Loss: 0.10306157918917204, G Loss: 24.04840850830078\n",
      "Epoch: 44, Batch: 363, D Loss: 0.10140337051585026, G Loss: 24.242958068847656\n",
      "Epoch: 44, Batch: 364, D Loss: 0.09767507763308272, G Loss: 24.105609893798828\n",
      "Epoch: 44, Batch: 365, D Loss: 0.09561909737300237, G Loss: 23.703828811645508\n",
      "Epoch: 44, Batch: 366, D Loss: 0.09712634238781964, G Loss: 23.285457611083984\n",
      "Epoch: 44, Batch: 367, D Loss: 0.10209603611716181, G Loss: 23.18712043762207\n",
      "Epoch: 44, Batch: 368, D Loss: 0.09924612943384073, G Loss: 23.292232513427734\n",
      "Epoch: 44, Batch: 369, D Loss: 0.10002961013086793, G Loss: 23.54890251159668\n",
      "Epoch: 44, Batch: 370, D Loss: 0.09850010278471348, G Loss: 23.775346755981445\n",
      "Epoch: 44, Batch: 371, D Loss: 0.10132296385518291, G Loss: 23.965927124023438\n",
      "Epoch: 44, Batch: 372, D Loss: 0.09494512530268809, G Loss: 23.839065551757812\n",
      "Epoch: 44, Batch: 373, D Loss: 0.1023768335815031, G Loss: 23.734893798828125\n",
      "Epoch: 44, Batch: 374, D Loss: 0.09915220740082846, G Loss: 23.611555099487305\n",
      "Epoch: 44, Batch: 375, D Loss: 0.09645285460442221, G Loss: 23.425392150878906\n",
      "Epoch: 44, Batch: 376, D Loss: 0.1014110744334123, G Loss: 23.429241180419922\n",
      "Epoch: 44, Batch: 377, D Loss: 0.09366633001503291, G Loss: 23.33306312561035\n",
      "Epoch: 44, Batch: 378, D Loss: 0.10805097225459728, G Loss: 23.637706756591797\n",
      "Epoch: 44, Batch: 379, D Loss: 0.10466678442783434, G Loss: 24.0235595703125\n",
      "Epoch: 44, Batch: 380, D Loss: 0.10021577777184117, G Loss: 24.171939849853516\n",
      "Epoch: 44, Batch: 381, D Loss: 0.09908746929687796, G Loss: 24.03215217590332\n",
      "Epoch: 44, Batch: 382, D Loss: 0.10528177769976212, G Loss: 23.876100540161133\n",
      "Epoch: 44, Batch: 383, D Loss: 0.09405669572689312, G Loss: 23.416669845581055\n",
      "Epoch: 44, Batch: 384, D Loss: 0.0970394760793341, G Loss: 22.9906005859375\n",
      "Epoch: 44, Batch: 385, D Loss: 0.10604345803486068, G Loss: 23.060047149658203\n",
      "Epoch: 44, Batch: 386, D Loss: 0.09835872803588268, G Loss: 23.224925994873047\n",
      "Epoch: 44, Batch: 387, D Loss: 0.1026693210353992, G Loss: 23.533281326293945\n",
      "Epoch: 44, Batch: 388, D Loss: 0.10096201303239447, G Loss: 23.798059463500977\n",
      "Epoch: 44, Batch: 389, D Loss: 0.10084627570892347, G Loss: 23.916288375854492\n",
      "Epoch: 44, Batch: 390, D Loss: 0.09573023768574597, G Loss: 23.70343589782715\n",
      "Epoch: 44, Batch: 391, D Loss: 0.10559248926919955, G Loss: 23.611841201782227\n",
      "Epoch: 44, Batch: 392, D Loss: 0.09601826223891684, G Loss: 23.381650924682617\n",
      "Epoch: 44, Batch: 393, D Loss: 0.09467427436637593, G Loss: 23.081947326660156\n",
      "Epoch: 44, Batch: 394, D Loss: 0.09872484957207142, G Loss: 22.976959228515625\n",
      "Epoch: 44, Batch: 395, D Loss: 0.09390676026931949, G Loss: 22.939218521118164\n",
      "Epoch: 44, Batch: 396, D Loss: 0.09819468115791084, G Loss: 23.107120513916016\n",
      "Epoch: 44, Batch: 397, D Loss: 0.10739800337410822, G Loss: 23.664819717407227\n",
      "Epoch: 44, Batch: 398, D Loss: 0.10024058075910067, G Loss: 24.052879333496094\n",
      "Epoch: 44, Batch: 399, D Loss: 0.10190027953867613, G Loss: 24.181201934814453\n",
      "Epoch: 44, Batch: 400, D Loss: 0.09862658383223824, G Loss: 23.968791961669922\n",
      "Epoch: 44, Batch: 401, D Loss: 0.09189131858632733, G Loss: 23.369232177734375\n",
      "Epoch: 44, Batch: 402, D Loss: 0.10247942809530507, G Loss: 23.02935218811035\n",
      "Epoch: 44, Batch: 403, D Loss: 0.09711463754770824, G Loss: 22.889802932739258\n",
      "Epoch: 44, Batch: 404, D Loss: 0.10336823766460071, G Loss: 23.1492862701416\n",
      "Epoch: 44, Batch: 405, D Loss: 0.10622921589277852, G Loss: 23.7368106842041\n",
      "Epoch: 44, Batch: 406, D Loss: 0.09906361254064378, G Loss: 24.132225036621094\n",
      "Epoch: 44, Batch: 407, D Loss: 0.09437152000016408, G Loss: 24.041269302368164\n",
      "Epoch: 44, Batch: 408, D Loss: 0.09692451360024552, G Loss: 23.685894012451172\n",
      "Epoch: 44, Batch: 409, D Loss: 0.09690254929893512, G Loss: 23.271818161010742\n",
      "Epoch: 44, Batch: 410, D Loss: 0.09665663544923575, G Loss: 22.97897720336914\n",
      "Epoch: 44, Batch: 411, D Loss: 0.10375136886931548, G Loss: 23.120115280151367\n",
      "Epoch: 44, Batch: 412, D Loss: 0.10656780007960051, G Loss: 23.639726638793945\n",
      "Epoch: 44, Batch: 413, D Loss: 0.09539230170217335, G Loss: 23.906400680541992\n",
      "Epoch: 44, Batch: 414, D Loss: 0.10173328222766054, G Loss: 24.050182342529297\n",
      "Epoch: 44, Batch: 415, D Loss: 0.10304316135032739, G Loss: 24.074874877929688\n",
      "Epoch: 44, Batch: 416, D Loss: 0.10412664713276866, G Loss: 24.021419525146484\n",
      "Epoch: 44, Batch: 417, D Loss: 0.10048913957750136, G Loss: 23.81287384033203\n",
      "Epoch: 44, Batch: 418, D Loss: 0.09903674575338503, G Loss: 23.536304473876953\n",
      "Epoch: 44, Batch: 419, D Loss: 0.09973483536033936, G Loss: 23.317642211914062\n",
      "Epoch: 44, Batch: 420, D Loss: 0.10115328434895682, G Loss: 23.30166244506836\n",
      "Epoch: 44, Batch: 421, D Loss: 0.09860510382738301, G Loss: 23.369218826293945\n",
      "Epoch: 44, Batch: 422, D Loss: 0.09980618956991191, G Loss: 23.514179229736328\n",
      "Epoch: 44, Batch: 423, D Loss: 0.0977595225268426, G Loss: 23.609052658081055\n",
      "Epoch: 44, Batch: 424, D Loss: 0.09320528808211899, G Loss: 23.499544143676758\n",
      "Epoch: 44, Batch: 425, D Loss: 0.10216648879728552, G Loss: 23.53156089782715\n",
      "Epoch: 44, Batch: 426, D Loss: 0.09746887537871102, G Loss: 23.532276153564453\n",
      "Epoch: 44, Batch: 427, D Loss: 0.09695743027450004, G Loss: 23.477863311767578\n",
      "Epoch: 44, Batch: 428, D Loss: 0.0989777073582436, G Loss: 23.477062225341797\n",
      "Epoch: 44, Batch: 429, D Loss: 0.10226579013472582, G Loss: 23.59921646118164\n",
      "Epoch: 44, Batch: 430, D Loss: 0.09427651765871145, G Loss: 23.539052963256836\n",
      "Epoch: 44, Batch: 431, D Loss: 0.09669210764966783, G Loss: 23.423030853271484\n",
      "Epoch: 44, Batch: 432, D Loss: 0.09741052988697999, G Loss: 23.342464447021484\n",
      "Epoch: 44, Batch: 433, D Loss: 0.09777490798345882, G Loss: 23.319610595703125\n",
      "Epoch: 44, Batch: 434, D Loss: 0.09815730158157653, G Loss: 23.362934112548828\n",
      "Epoch: 44, Batch: 435, D Loss: 0.0964581966750135, G Loss: 23.400249481201172\n",
      "Epoch: 44, Batch: 436, D Loss: 0.09933865073611733, G Loss: 23.496488571166992\n",
      "Epoch: 44, Batch: 437, D Loss: 0.10156990590570418, G Loss: 23.664274215698242\n",
      "Epoch: 44, Batch: 438, D Loss: 0.09391483667286864, G Loss: 23.570547103881836\n",
      "Epoch: 44, Batch: 439, D Loss: 0.09203230593069515, G Loss: 23.244869232177734\n",
      "Epoch: 44, Batch: 440, D Loss: 0.09685744349678782, G Loss: 23.032695770263672\n",
      "Epoch: 44, Batch: 441, D Loss: 0.10625736419786123, G Loss: 23.262460708618164\n",
      "Epoch: 44, Batch: 442, D Loss: 0.09725444022325294, G Loss: 23.498851776123047\n",
      "Epoch: 44, Batch: 443, D Loss: 0.09916650506680098, G Loss: 23.697620391845703\n",
      "Epoch: 44, Batch: 444, D Loss: 0.09412032368465319, G Loss: 23.615806579589844\n",
      "Epoch: 44, Batch: 445, D Loss: 0.09434933218582123, G Loss: 23.341066360473633\n",
      "Epoch: 44, Batch: 446, D Loss: 0.10241509977756026, G Loss: 23.287151336669922\n",
      "Epoch: 44, Batch: 447, D Loss: 0.09729348126956022, G Loss: 23.271352767944336\n",
      "Epoch: 44, Batch: 448, D Loss: 0.10514995459152941, G Loss: 23.531267166137695\n",
      "Epoch: 44, Batch: 449, D Loss: 0.09611529114714328, G Loss: 23.63765525817871\n",
      "Epoch: 44, Batch: 450, D Loss: 0.09784860166648314, G Loss: 23.63113021850586\n",
      "Epoch: 44, Batch: 451, D Loss: 0.09953586759971682, G Loss: 23.590543746948242\n",
      "Epoch: 44, Batch: 452, D Loss: 0.09945140036903227, G Loss: 23.524707794189453\n",
      "Epoch: 44, Batch: 453, D Loss: 0.10135447982019924, G Loss: 23.51820945739746\n",
      "Epoch: 44, Batch: 454, D Loss: 0.0937921181654665, G Loss: 23.351913452148438\n",
      "Epoch: 44, Batch: 455, D Loss: 0.09697153423124101, G Loss: 23.220008850097656\n",
      "Epoch: 44, Batch: 456, D Loss: 0.10094421360917541, G Loss: 23.2745304107666\n",
      "Epoch: 44, Batch: 457, D Loss: 0.09847924861978545, G Loss: 23.401607513427734\n",
      "Epoch: 44, Batch: 458, D Loss: 0.09765128049497508, G Loss: 23.521812438964844\n",
      "Epoch: 44, Batch: 459, D Loss: 0.09653959426329015, G Loss: 23.53406524658203\n",
      "Epoch: 44, Batch: 460, D Loss: 0.10516797753891474, G Loss: 23.737043380737305\n",
      "Epoch: 44, Batch: 461, D Loss: 0.1029881388168925, G Loss: 23.94609832763672\n",
      "Epoch: 44, Batch: 462, D Loss: 0.0971899181809755, G Loss: 23.888240814208984\n",
      "Epoch: 44, Batch: 463, D Loss: 0.10096907617911768, G Loss: 23.76665687561035\n",
      "Epoch: 44, Batch: 464, D Loss: 0.09503141048352695, G Loss: 23.472623825073242\n",
      "Epoch: 44, Batch: 465, D Loss: 0.09305000309057397, G Loss: 23.103633880615234\n",
      "Epoch: 44, Batch: 466, D Loss: 0.10294701163567738, G Loss: 23.12786865234375\n",
      "Epoch: 44, Batch: 467, D Loss: 0.10320697728594917, G Loss: 23.46681022644043\n",
      "Epoch: 45, Batch: 0, D Loss: 0.09828285875675523, G Loss: 23.77229118347168\n",
      "Epoch: 45, Batch: 1, D Loss: 0.1085092798059109, G Loss: 24.258201599121094\n",
      "Epoch: 45, Batch: 2, D Loss: 0.10055787117623699, G Loss: 24.426246643066406\n",
      "Epoch: 45, Batch: 3, D Loss: 0.09926470370486487, G Loss: 24.20311164855957\n",
      "Epoch: 45, Batch: 4, D Loss: 0.0911687165720714, G Loss: 23.508991241455078\n",
      "Epoch: 45, Batch: 5, D Loss: 0.09702155743320753, G Loss: 22.8967342376709\n",
      "Epoch: 45, Batch: 6, D Loss: 0.10059013968967642, G Loss: 22.7265567779541\n",
      "Epoch: 45, Batch: 7, D Loss: 0.10229289537435302, G Loss: 23.03683090209961\n",
      "Epoch: 45, Batch: 8, D Loss: 0.09520307187360261, G Loss: 23.39473533630371\n",
      "Epoch: 45, Batch: 9, D Loss: 0.1027987003595518, G Loss: 23.87052345275879\n",
      "Epoch: 45, Batch: 10, D Loss: 0.10024391861609293, G Loss: 24.16692352294922\n",
      "Epoch: 45, Batch: 11, D Loss: 0.09858921171840049, G Loss: 24.157451629638672\n",
      "Epoch: 45, Batch: 12, D Loss: 0.10424781592373733, G Loss: 24.086885452270508\n",
      "Epoch: 45, Batch: 13, D Loss: 0.09240730109020506, G Loss: 23.639060974121094\n",
      "Epoch: 45, Batch: 14, D Loss: 0.10020659867132187, G Loss: 23.331336975097656\n",
      "Epoch: 45, Batch: 15, D Loss: 0.09971044961523766, G Loss: 23.229684829711914\n",
      "Epoch: 45, Batch: 16, D Loss: 0.09668250385960013, G Loss: 23.260025024414062\n",
      "Epoch: 45, Batch: 17, D Loss: 0.10343864563424654, G Loss: 23.605674743652344\n",
      "Epoch: 45, Batch: 18, D Loss: 0.09483322503713768, G Loss: 23.797412872314453\n",
      "Epoch: 45, Batch: 19, D Loss: 0.09195230903674477, G Loss: 23.699867248535156\n",
      "Epoch: 45, Batch: 20, D Loss: 0.09789869936996437, G Loss: 23.607004165649414\n",
      "Epoch: 45, Batch: 21, D Loss: 0.10455380382729898, G Loss: 23.762754440307617\n",
      "Epoch: 45, Batch: 22, D Loss: 0.10246361794227644, G Loss: 23.974828720092773\n",
      "Epoch: 45, Batch: 23, D Loss: 0.09611330928339418, G Loss: 23.98920249938965\n",
      "Epoch: 45, Batch: 24, D Loss: 0.1002258584097889, G Loss: 23.952045440673828\n",
      "Epoch: 45, Batch: 25, D Loss: 0.09797187896694821, G Loss: 23.829561233520508\n",
      "Epoch: 45, Batch: 26, D Loss: 0.09559229018834253, G Loss: 23.59648895263672\n",
      "Epoch: 45, Batch: 27, D Loss: 0.10258550199696895, G Loss: 23.60663604736328\n",
      "Epoch: 45, Batch: 28, D Loss: 0.09530943634975053, G Loss: 23.57172966003418\n",
      "Epoch: 45, Batch: 29, D Loss: 0.0984871685786539, G Loss: 23.62525177001953\n",
      "Epoch: 45, Batch: 30, D Loss: 0.09526778760297923, G Loss: 23.639148712158203\n",
      "Epoch: 45, Batch: 31, D Loss: 0.10156463834150319, G Loss: 23.800582885742188\n",
      "Epoch: 45, Batch: 32, D Loss: 0.0957089141239209, G Loss: 23.82086753845215\n",
      "Epoch: 45, Batch: 33, D Loss: 0.09768956901935691, G Loss: 23.791763305664062\n",
      "Epoch: 45, Batch: 34, D Loss: 0.09824734183529364, G Loss: 23.760061264038086\n",
      "Epoch: 45, Batch: 35, D Loss: 0.10288412871242439, G Loss: 23.86888313293457\n",
      "Epoch: 45, Batch: 36, D Loss: 0.10062414409772256, G Loss: 23.968460083007812\n",
      "Epoch: 45, Batch: 37, D Loss: 0.09876202048828917, G Loss: 23.959047317504883\n",
      "Epoch: 45, Batch: 38, D Loss: 0.09954769911413104, G Loss: 23.89748764038086\n",
      "Epoch: 45, Batch: 39, D Loss: 0.10225267710371783, G Loss: 23.916772842407227\n",
      "Epoch: 45, Batch: 40, D Loss: 0.09285785260118633, G Loss: 23.697263717651367\n",
      "Epoch: 45, Batch: 41, D Loss: 0.10194610806955802, G Loss: 23.63761329650879\n",
      "Epoch: 45, Batch: 42, D Loss: 0.09823051842816659, G Loss: 23.611356735229492\n",
      "Epoch: 45, Batch: 43, D Loss: 0.0939147323661009, G Loss: 23.527122497558594\n",
      "Epoch: 45, Batch: 44, D Loss: 0.09562525156298365, G Loss: 23.45966339111328\n",
      "Epoch: 45, Batch: 45, D Loss: 0.09918735179383373, G Loss: 23.569299697875977\n",
      "Epoch: 45, Batch: 46, D Loss: 0.09919377418975749, G Loss: 23.776697158813477\n",
      "Epoch: 45, Batch: 47, D Loss: 0.09728686513719555, G Loss: 23.90736198425293\n",
      "Epoch: 45, Batch: 48, D Loss: 0.10245866330368154, G Loss: 24.080705642700195\n",
      "Epoch: 45, Batch: 49, D Loss: 0.1092312112593868, G Loss: 24.450794219970703\n",
      "Epoch: 45, Batch: 50, D Loss: 0.08974506707361238, G Loss: 24.21421241760254\n",
      "Epoch: 45, Batch: 51, D Loss: 0.09684269132117967, G Loss: 23.807458877563477\n",
      "Epoch: 45, Batch: 52, D Loss: 0.10200618209976083, G Loss: 23.623079299926758\n",
      "Epoch: 45, Batch: 53, D Loss: 0.10176716002504271, G Loss: 23.68570327758789\n",
      "Epoch: 45, Batch: 54, D Loss: 0.10300569983587363, G Loss: 23.94830322265625\n",
      "Epoch: 45, Batch: 55, D Loss: 0.10273035617339925, G Loss: 24.294828414916992\n",
      "Epoch: 45, Batch: 56, D Loss: 0.10253399611761554, G Loss: 24.529541015625\n",
      "Epoch: 45, Batch: 57, D Loss: 0.10214437545431593, G Loss: 24.57419204711914\n",
      "Epoch: 45, Batch: 58, D Loss: 0.09888405354034353, G Loss: 24.33811378479004\n",
      "Epoch: 45, Batch: 59, D Loss: 0.10531520844969351, G Loss: 24.17904281616211\n",
      "Epoch: 45, Batch: 60, D Loss: 0.09942942859513207, G Loss: 23.960954666137695\n",
      "Epoch: 45, Batch: 61, D Loss: 0.10366715492825612, G Loss: 23.918033599853516\n",
      "Epoch: 45, Batch: 62, D Loss: 0.09761588277588795, G Loss: 23.8209171295166\n",
      "Epoch: 45, Batch: 63, D Loss: 0.10236410798841761, G Loss: 23.87065887451172\n",
      "Epoch: 45, Batch: 64, D Loss: 0.10129946472242804, G Loss: 24.023435592651367\n",
      "Epoch: 45, Batch: 65, D Loss: 0.10239543022406981, G Loss: 24.1986026763916\n",
      "Epoch: 45, Batch: 66, D Loss: 0.0958021208806265, G Loss: 24.107547760009766\n",
      "Epoch: 45, Batch: 67, D Loss: 0.09352979811072165, G Loss: 23.768354415893555\n",
      "Epoch: 45, Batch: 68, D Loss: 0.09843727949002004, G Loss: 23.513845443725586\n",
      "Epoch: 45, Batch: 69, D Loss: 0.10427388551723275, G Loss: 23.63990020751953\n",
      "Epoch: 45, Batch: 70, D Loss: 0.10383409263927733, G Loss: 24.01183319091797\n",
      "Epoch: 45, Batch: 71, D Loss: 0.10082519055982829, G Loss: 24.33966636657715\n",
      "Epoch: 45, Batch: 72, D Loss: 0.10409635306580944, G Loss: 24.592639923095703\n",
      "Epoch: 45, Batch: 73, D Loss: 0.10056689382658034, G Loss: 24.565462112426758\n",
      "Epoch: 45, Batch: 74, D Loss: 0.0976687744386832, G Loss: 24.24351692199707\n",
      "Epoch: 45, Batch: 75, D Loss: 0.09946461023702455, G Loss: 23.86991310119629\n",
      "Epoch: 45, Batch: 76, D Loss: 0.09823679181473866, G Loss: 23.56732177734375\n",
      "Epoch: 45, Batch: 77, D Loss: 0.09785790744575697, G Loss: 23.427148818969727\n",
      "Epoch: 45, Batch: 78, D Loss: 0.1039616838389775, G Loss: 23.685094833374023\n",
      "Epoch: 45, Batch: 79, D Loss: 0.0961391031971053, G Loss: 23.916419982910156\n",
      "Epoch: 45, Batch: 80, D Loss: 0.09707851709847738, G Loss: 24.050350189208984\n",
      "Epoch: 45, Batch: 81, D Loss: 0.09645135702520126, G Loss: 24.026611328125\n",
      "Epoch: 45, Batch: 82, D Loss: 0.09901535512902812, G Loss: 23.9776554107666\n",
      "Epoch: 45, Batch: 83, D Loss: 0.0981331542335555, G Loss: 23.898141860961914\n",
      "Epoch: 45, Batch: 84, D Loss: 0.09685237707914546, G Loss: 23.79456901550293\n",
      "Epoch: 45, Batch: 85, D Loss: 0.10348358752489331, G Loss: 23.94107437133789\n",
      "Epoch: 45, Batch: 86, D Loss: 0.10027923436789987, G Loss: 24.12569808959961\n",
      "Epoch: 45, Batch: 87, D Loss: 0.10291443021589736, G Loss: 24.343320846557617\n",
      "Epoch: 45, Batch: 88, D Loss: 0.09472200275884403, G Loss: 24.235872268676758\n",
      "Epoch: 45, Batch: 89, D Loss: 0.09671893717562204, G Loss: 23.983379364013672\n",
      "Epoch: 45, Batch: 90, D Loss: 0.09714843334979696, G Loss: 23.713085174560547\n",
      "Epoch: 45, Batch: 91, D Loss: 0.09877926858928678, G Loss: 23.614107131958008\n",
      "Epoch: 45, Batch: 92, D Loss: 0.10877282919751047, G Loss: 24.011926651000977\n",
      "Epoch: 45, Batch: 93, D Loss: 0.10382206739427621, G Loss: 24.513416290283203\n",
      "Epoch: 45, Batch: 94, D Loss: 0.10105171800640815, G Loss: 24.781051635742188\n",
      "Epoch: 45, Batch: 95, D Loss: 0.09987138212621481, G Loss: 24.716262817382812\n",
      "Epoch: 45, Batch: 96, D Loss: 0.10621540994413863, G Loss: 24.636398315429688\n",
      "Epoch: 45, Batch: 97, D Loss: 0.10416325182783771, G Loss: 24.521474838256836\n",
      "Epoch: 45, Batch: 98, D Loss: 0.10635468364905822, G Loss: 24.48224639892578\n",
      "Epoch: 45, Batch: 99, D Loss: 0.10053348542514162, G Loss: 24.3422794342041\n",
      "Epoch: 45, Batch: 100, D Loss: 0.1056423634423623, G Loss: 24.35821533203125\n",
      "Epoch: 45, Batch: 101, D Loss: 0.09288220854139391, G Loss: 24.08191680908203\n",
      "Epoch: 45, Batch: 102, D Loss: 0.10180126132419214, G Loss: 23.976457595825195\n",
      "Epoch: 45, Batch: 103, D Loss: 0.0946575924960095, G Loss: 23.855453491210938\n",
      "Epoch: 45, Batch: 104, D Loss: 0.09893450888131705, G Loss: 23.908967971801758\n",
      "Epoch: 45, Batch: 105, D Loss: 0.09933159502234332, G Loss: 24.095706939697266\n",
      "Epoch: 45, Batch: 106, D Loss: 0.09579706193631943, G Loss: 24.210365295410156\n",
      "Epoch: 45, Batch: 107, D Loss: 0.10246299208563533, G Loss: 24.44318962097168\n",
      "Epoch: 45, Batch: 108, D Loss: 0.09448840470346377, G Loss: 24.42346954345703\n",
      "Epoch: 45, Batch: 109, D Loss: 0.10376467556935995, G Loss: 24.52008056640625\n",
      "Epoch: 45, Batch: 110, D Loss: 0.09965864570060724, G Loss: 24.53731346130371\n",
      "Epoch: 45, Batch: 111, D Loss: 0.09522034974128153, G Loss: 24.342254638671875\n",
      "Epoch: 45, Batch: 112, D Loss: 0.0944973603047534, G Loss: 24.04840087890625\n",
      "Epoch: 45, Batch: 113, D Loss: 0.09308433534819208, G Loss: 23.74948501586914\n",
      "Epoch: 45, Batch: 114, D Loss: 0.09797319772307128, G Loss: 23.73166847229004\n",
      "Epoch: 45, Batch: 115, D Loss: 0.10181038083685963, G Loss: 24.0936279296875\n",
      "Epoch: 45, Batch: 116, D Loss: 0.09083377571495836, G Loss: 24.251953125\n",
      "Epoch: 45, Batch: 117, D Loss: 0.10555315763934821, G Loss: 24.67074966430664\n",
      "Epoch: 45, Batch: 118, D Loss: 0.10573408008387368, G Loss: 25.11014175415039\n",
      "Epoch: 45, Batch: 119, D Loss: 0.09943036735655307, G Loss: 25.18661117553711\n",
      "Epoch: 45, Batch: 120, D Loss: 0.09899397195047387, G Loss: 24.923620223999023\n",
      "Epoch: 45, Batch: 121, D Loss: 0.09788665921451584, G Loss: 24.461116790771484\n",
      "Epoch: 45, Batch: 122, D Loss: 0.10232777894910366, G Loss: 24.19756507873535\n",
      "Epoch: 45, Batch: 123, D Loss: 0.10247661919961533, G Loss: 24.18457794189453\n",
      "Epoch: 45, Batch: 124, D Loss: 0.09222103657010729, G Loss: 24.063751220703125\n",
      "Epoch: 45, Batch: 125, D Loss: 0.10164681823716958, G Loss: 24.192113876342773\n",
      "Epoch: 45, Batch: 126, D Loss: 0.09920461477246166, G Loss: 24.3987979888916\n",
      "Epoch: 45, Batch: 127, D Loss: 0.10017846525853755, G Loss: 24.601848602294922\n",
      "Epoch: 45, Batch: 128, D Loss: 0.09721332789475305, G Loss: 24.650470733642578\n",
      "Epoch: 45, Batch: 129, D Loss: 0.10258556903361334, G Loss: 24.713645935058594\n",
      "Epoch: 45, Batch: 130, D Loss: 0.10323785991372823, G Loss: 24.772964477539062\n",
      "Epoch: 45, Batch: 131, D Loss: 0.10412920267226253, G Loss: 24.850786209106445\n",
      "Epoch: 45, Batch: 132, D Loss: 0.10095131398073584, G Loss: 24.803903579711914\n",
      "Epoch: 45, Batch: 133, D Loss: 0.09870828689096661, G Loss: 24.576799392700195\n",
      "Epoch: 45, Batch: 134, D Loss: 0.10457111151124432, G Loss: 24.510101318359375\n",
      "Epoch: 45, Batch: 135, D Loss: 0.10367028416292322, G Loss: 24.5855655670166\n",
      "Epoch: 45, Batch: 136, D Loss: 0.10586860776887962, G Loss: 24.796672821044922\n",
      "Epoch: 45, Batch: 137, D Loss: 0.09589339793629592, G Loss: 24.68770980834961\n",
      "Epoch: 45, Batch: 138, D Loss: 0.10013080389360382, G Loss: 24.490158081054688\n",
      "Epoch: 45, Batch: 139, D Loss: 0.09887715430369934, G Loss: 24.263792037963867\n",
      "Epoch: 45, Batch: 140, D Loss: 0.10637389124809117, G Loss: 24.3724365234375\n",
      "Epoch: 45, Batch: 141, D Loss: 0.09565773607628454, G Loss: 24.332746505737305\n",
      "Epoch: 45, Batch: 142, D Loss: 0.09510470928244655, G Loss: 24.158695220947266\n",
      "Epoch: 45, Batch: 143, D Loss: 0.09342528881486294, G Loss: 23.901531219482422\n",
      "Epoch: 45, Batch: 144, D Loss: 0.1009190678800183, G Loss: 23.944026947021484\n",
      "Epoch: 45, Batch: 145, D Loss: 0.09255497159575786, G Loss: 23.938518524169922\n",
      "Epoch: 45, Batch: 146, D Loss: 0.10154395552253476, G Loss: 24.184188842773438\n",
      "Epoch: 45, Batch: 147, D Loss: 0.0982429161805143, G Loss: 24.43854331970215\n",
      "Epoch: 45, Batch: 148, D Loss: 0.09348549695048611, G Loss: 24.425613403320312\n",
      "Epoch: 45, Batch: 149, D Loss: 0.09750549496505671, G Loss: 24.346792221069336\n",
      "Epoch: 45, Batch: 150, D Loss: 0.09884145857273724, G Loss: 24.296649932861328\n",
      "Epoch: 45, Batch: 151, D Loss: 0.09917851538858842, G Loss: 24.31059455871582\n",
      "Epoch: 45, Batch: 152, D Loss: 0.0908218920384555, G Loss: 24.111370086669922\n",
      "Epoch: 45, Batch: 153, D Loss: 0.09772075714434103, G Loss: 24.03995132446289\n",
      "Epoch: 45, Batch: 154, D Loss: 0.09786099942275552, G Loss: 24.12186050415039\n",
      "Epoch: 45, Batch: 155, D Loss: 0.10020390154403236, G Loss: 24.363176345825195\n",
      "Epoch: 45, Batch: 156, D Loss: 0.1084493324260414, G Loss: 24.88230323791504\n",
      "Epoch: 45, Batch: 157, D Loss: 0.09745323658692906, G Loss: 25.08134651184082\n",
      "Epoch: 45, Batch: 158, D Loss: 0.10560248792770757, G Loss: 25.2071590423584\n",
      "Epoch: 45, Batch: 159, D Loss: 0.10244126618507535, G Loss: 25.09455680847168\n",
      "Epoch: 45, Batch: 160, D Loss: 0.10796054453302634, G Loss: 25.055315017700195\n",
      "Epoch: 45, Batch: 161, D Loss: 0.0995039120391469, G Loss: 24.804502487182617\n",
      "Epoch: 45, Batch: 162, D Loss: 0.10190109909547088, G Loss: 24.547794342041016\n",
      "Epoch: 45, Batch: 163, D Loss: 0.10266382248359, G Loss: 24.44935417175293\n",
      "Epoch: 45, Batch: 164, D Loss: 0.09431013466303541, G Loss: 24.1960506439209\n",
      "Epoch: 45, Batch: 165, D Loss: 0.0929445028487678, G Loss: 23.886157989501953\n",
      "Epoch: 45, Batch: 166, D Loss: 0.09317455443118602, G Loss: 23.678787231445312\n",
      "Epoch: 45, Batch: 167, D Loss: 0.11294074358453773, G Loss: 24.27889633178711\n",
      "Epoch: 45, Batch: 168, D Loss: 0.10260512680803088, G Loss: 24.977481842041016\n",
      "Epoch: 45, Batch: 169, D Loss: 0.09319101274674536, G Loss: 25.11383819580078\n",
      "Epoch: 45, Batch: 170, D Loss: 0.09850557894186408, G Loss: 24.9603271484375\n",
      "Epoch: 45, Batch: 171, D Loss: 0.09973648191350772, G Loss: 24.64566993713379\n",
      "Epoch: 45, Batch: 172, D Loss: 0.0950967446098484, G Loss: 24.142553329467773\n",
      "Epoch: 45, Batch: 173, D Loss: 0.10346771033378555, G Loss: 24.00409698486328\n",
      "Epoch: 45, Batch: 174, D Loss: 0.09606975318913843, G Loss: 23.971410751342773\n",
      "Epoch: 45, Batch: 175, D Loss: 0.10362921656833066, G Loss: 24.276809692382812\n",
      "Epoch: 45, Batch: 176, D Loss: 0.09329933674489307, G Loss: 24.393455505371094\n",
      "Epoch: 45, Batch: 177, D Loss: 0.10154343397571909, G Loss: 24.592811584472656\n",
      "Epoch: 45, Batch: 178, D Loss: 0.10115451366674706, G Loss: 24.74036979675293\n",
      "Epoch: 45, Batch: 179, D Loss: 0.10094529391215094, G Loss: 24.78357696533203\n",
      "Epoch: 45, Batch: 180, D Loss: 0.09250679613176618, G Loss: 24.469526290893555\n",
      "Epoch: 45, Batch: 181, D Loss: 0.09441588820510051, G Loss: 24.035837173461914\n",
      "Epoch: 45, Batch: 182, D Loss: 0.10401231052321064, G Loss: 24.026893615722656\n",
      "Epoch: 45, Batch: 183, D Loss: 0.09964734317528327, G Loss: 24.225149154663086\n",
      "Epoch: 45, Batch: 184, D Loss: 0.09927071632251822, G Loss: 24.5100040435791\n",
      "Epoch: 45, Batch: 185, D Loss: 0.10476355255556476, G Loss: 24.934310913085938\n",
      "Epoch: 45, Batch: 186, D Loss: 0.09871483594861888, G Loss: 25.09147071838379\n",
      "Epoch: 45, Batch: 187, D Loss: 0.1009403094714115, G Loss: 25.049047470092773\n",
      "Epoch: 45, Batch: 188, D Loss: 0.09626773745609586, G Loss: 24.71504783630371\n",
      "Epoch: 45, Batch: 189, D Loss: 0.11052004993864814, G Loss: 24.757535934448242\n",
      "Epoch: 45, Batch: 190, D Loss: 0.10121429712462797, G Loss: 24.762739181518555\n",
      "Epoch: 45, Batch: 191, D Loss: 0.09958760441274166, G Loss: 24.669532775878906\n",
      "Epoch: 45, Batch: 192, D Loss: 0.09872564674469259, G Loss: 24.519832611083984\n",
      "Epoch: 45, Batch: 193, D Loss: 0.10200747848689172, G Loss: 24.503477096557617\n",
      "Epoch: 45, Batch: 194, D Loss: 0.10338653625126858, G Loss: 24.626956939697266\n",
      "Epoch: 45, Batch: 195, D Loss: 0.0903360843773199, G Loss: 24.381046295166016\n",
      "Epoch: 45, Batch: 196, D Loss: 0.10106640310446457, G Loss: 24.292354583740234\n",
      "Epoch: 45, Batch: 197, D Loss: 0.09414096923199301, G Loss: 24.152103424072266\n",
      "Epoch: 45, Batch: 198, D Loss: 0.10174959899513938, G Loss: 24.27590560913086\n",
      "Epoch: 45, Batch: 199, D Loss: 0.09741500021373785, G Loss: 24.393268585205078\n",
      "Epoch: 45, Batch: 200, D Loss: 0.1011231765265614, G Loss: 24.59422492980957\n",
      "Epoch: 45, Batch: 201, D Loss: 0.1026049777958506, G Loss: 24.808042526245117\n",
      "Epoch: 45, Batch: 202, D Loss: 0.0976202786055072, G Loss: 24.759946823120117\n",
      "Epoch: 45, Batch: 203, D Loss: 0.10126326234073002, G Loss: 24.672367095947266\n",
      "Epoch: 45, Batch: 204, D Loss: 0.10533362627973017, G Loss: 24.712249755859375\n",
      "Epoch: 45, Batch: 205, D Loss: 0.10309376568503573, G Loss: 24.763229370117188\n",
      "Epoch: 45, Batch: 206, D Loss: 0.09889115394090695, G Loss: 24.66016960144043\n",
      "Epoch: 45, Batch: 207, D Loss: 0.09980426729787795, G Loss: 24.497819900512695\n",
      "Epoch: 45, Batch: 208, D Loss: 0.10007090867787351, G Loss: 24.37855339050293\n",
      "Epoch: 45, Batch: 209, D Loss: 0.10121355952125324, G Loss: 24.378202438354492\n",
      "Epoch: 45, Batch: 210, D Loss: 0.09636572749764787, G Loss: 24.3074951171875\n",
      "Epoch: 45, Batch: 211, D Loss: 0.10070364178585416, G Loss: 24.348339080810547\n",
      "Epoch: 45, Batch: 212, D Loss: 0.09770359100229412, G Loss: 24.368770599365234\n",
      "Epoch: 45, Batch: 213, D Loss: 0.0959485918419141, G Loss: 24.29541778564453\n",
      "Epoch: 45, Batch: 214, D Loss: 0.09801292420868979, G Loss: 24.254465103149414\n",
      "Epoch: 45, Batch: 215, D Loss: 0.09717451782508917, G Loss: 24.240306854248047\n",
      "Epoch: 45, Batch: 216, D Loss: 0.1051438003906494, G Loss: 24.520967483520508\n",
      "Epoch: 45, Batch: 217, D Loss: 0.10252195597653109, G Loss: 24.819122314453125\n",
      "Epoch: 45, Batch: 218, D Loss: 0.10448935628669453, G Loss: 25.062057495117188\n",
      "Epoch: 45, Batch: 219, D Loss: 0.09664681554549326, G Loss: 24.90530776977539\n",
      "Epoch: 45, Batch: 220, D Loss: 0.09840166569678932, G Loss: 24.544273376464844\n",
      "Epoch: 45, Batch: 221, D Loss: 0.09696137906501505, G Loss: 24.103727340698242\n",
      "Epoch: 45, Batch: 222, D Loss: 0.09497433902875366, G Loss: 23.756601333618164\n",
      "Epoch: 45, Batch: 223, D Loss: 0.09507718684926042, G Loss: 23.58373260498047\n",
      "Epoch: 45, Batch: 224, D Loss: 0.10169645401304135, G Loss: 23.87986183166504\n",
      "Epoch: 45, Batch: 225, D Loss: 0.10308818520679588, G Loss: 24.466609954833984\n",
      "Epoch: 45, Batch: 226, D Loss: 0.09854106605994824, G Loss: 24.900224685668945\n",
      "Epoch: 45, Batch: 227, D Loss: 0.10033485294086615, G Loss: 25.07921028137207\n",
      "Epoch: 45, Batch: 228, D Loss: 0.09580335766801179, G Loss: 24.848787307739258\n",
      "Epoch: 45, Batch: 229, D Loss: 0.09290132672679893, G Loss: 24.28626823425293\n",
      "Epoch: 45, Batch: 230, D Loss: 0.10022738577636198, G Loss: 23.941570281982422\n",
      "Epoch: 45, Batch: 231, D Loss: 0.09590286763721452, G Loss: 23.762239456176758\n",
      "Epoch: 45, Batch: 232, D Loss: 0.0937620997672972, G Loss: 23.725669860839844\n",
      "Epoch: 45, Batch: 233, D Loss: 0.1037948206262483, G Loss: 24.181346893310547\n",
      "Epoch: 45, Batch: 234, D Loss: 0.10182587058496838, G Loss: 24.78573989868164\n",
      "Epoch: 45, Batch: 235, D Loss: 0.09762789309745036, G Loss: 25.123109817504883\n",
      "Epoch: 45, Batch: 236, D Loss: 0.10043288767926374, G Loss: 25.20344352722168\n",
      "Epoch: 45, Batch: 237, D Loss: 0.09990695119525185, G Loss: 25.02916717529297\n",
      "Epoch: 45, Batch: 238, D Loss: 0.10144036263999656, G Loss: 24.77167320251465\n",
      "Epoch: 45, Batch: 239, D Loss: 0.10655151308467878, G Loss: 24.744617462158203\n",
      "Epoch: 45, Batch: 240, D Loss: 0.10062199831925474, G Loss: 24.70245361328125\n",
      "Epoch: 45, Batch: 241, D Loss: 0.104495048531759, G Loss: 24.815624237060547\n",
      "Epoch: 45, Batch: 242, D Loss: 0.09570863843846775, G Loss: 24.710203170776367\n",
      "Epoch: 45, Batch: 243, D Loss: 0.09670698643770466, G Loss: 24.493574142456055\n",
      "Epoch: 45, Batch: 244, D Loss: 0.1013874113677752, G Loss: 24.44786834716797\n",
      "Epoch: 45, Batch: 245, D Loss: 0.09702135623723654, G Loss: 24.422616958618164\n",
      "Epoch: 45, Batch: 246, D Loss: 0.09730707110204746, G Loss: 24.432926177978516\n",
      "Epoch: 45, Batch: 247, D Loss: 0.09752114118337016, G Loss: 24.484573364257812\n",
      "Epoch: 45, Batch: 248, D Loss: 0.0944835394738375, G Loss: 24.46487045288086\n",
      "Epoch: 45, Batch: 249, D Loss: 0.10263792426459876, G Loss: 24.667490005493164\n",
      "Epoch: 45, Batch: 250, D Loss: 0.09908899665758335, G Loss: 24.850221633911133\n",
      "Epoch: 45, Batch: 251, D Loss: 0.09860974551017546, G Loss: 24.93757438659668\n",
      "Epoch: 45, Batch: 252, D Loss: 0.1016169488500521, G Loss: 25.027446746826172\n",
      "Epoch: 45, Batch: 253, D Loss: 0.09740531445252301, G Loss: 24.952566146850586\n",
      "Epoch: 45, Batch: 254, D Loss: 0.09591165185812678, G Loss: 24.685199737548828\n",
      "Epoch: 45, Batch: 255, D Loss: 0.09985440970504486, G Loss: 24.520626068115234\n",
      "Epoch: 45, Batch: 256, D Loss: 0.10376039148426636, G Loss: 24.646442413330078\n",
      "Epoch: 45, Batch: 257, D Loss: 0.09925606102667785, G Loss: 24.790950775146484\n",
      "Epoch: 45, Batch: 258, D Loss: 0.09652145207788172, G Loss: 24.781953811645508\n",
      "Epoch: 45, Batch: 259, D Loss: 0.09387718142048919, G Loss: 24.561037063598633\n",
      "Epoch: 45, Batch: 260, D Loss: 0.1000971198194763, G Loss: 24.473369598388672\n",
      "Epoch: 45, Batch: 261, D Loss: 0.09351512791038497, G Loss: 24.264545440673828\n",
      "Epoch: 45, Batch: 262, D Loss: 0.09517996759788742, G Loss: 24.116809844970703\n",
      "Epoch: 45, Batch: 263, D Loss: 0.10211600364765999, G Loss: 24.3172607421875\n",
      "Epoch: 45, Batch: 264, D Loss: 0.09673731030257801, G Loss: 24.537109375\n",
      "Epoch: 45, Batch: 265, D Loss: 0.10374113918261986, G Loss: 24.89986228942871\n",
      "Epoch: 45, Batch: 266, D Loss: 0.10531403870024805, G Loss: 25.262601852416992\n",
      "Epoch: 45, Batch: 267, D Loss: 0.09329078347089274, G Loss: 25.0465145111084\n",
      "Epoch: 45, Batch: 268, D Loss: 0.10930927098468275, G Loss: 25.023601531982422\n",
      "Epoch: 45, Batch: 269, D Loss: 0.09718547762225627, G Loss: 24.744548797607422\n",
      "Epoch: 45, Batch: 270, D Loss: 0.09882034362427682, G Loss: 24.41642951965332\n",
      "Epoch: 45, Batch: 271, D Loss: 0.10769791157255372, G Loss: 24.48295783996582\n",
      "Epoch: 45, Batch: 272, D Loss: 0.10440116376720528, G Loss: 24.705425262451172\n",
      "Epoch: 45, Batch: 273, D Loss: 0.10988555104274567, G Loss: 25.159194946289062\n",
      "Epoch: 45, Batch: 274, D Loss: 0.10216618329828978, G Loss: 25.32600212097168\n",
      "Epoch: 45, Batch: 275, D Loss: 0.09444555640848666, G Loss: 24.897798538208008\n",
      "Epoch: 45, Batch: 276, D Loss: 0.10363458842977333, G Loss: 24.519577026367188\n",
      "Epoch: 45, Batch: 277, D Loss: 0.09549111874368114, G Loss: 24.02410316467285\n",
      "Epoch: 45, Batch: 278, D Loss: 0.10847221316698596, G Loss: 24.07790184020996\n",
      "Epoch: 45, Batch: 279, D Loss: 0.0985887646837099, G Loss: 24.220409393310547\n",
      "Epoch: 45, Batch: 280, D Loss: 0.10158126802568082, G Loss: 24.48714828491211\n",
      "Epoch: 45, Batch: 281, D Loss: 0.10482236743938717, G Loss: 24.835166931152344\n",
      "Epoch: 45, Batch: 282, D Loss: 0.09949158132847721, G Loss: 24.94838523864746\n",
      "Epoch: 45, Batch: 283, D Loss: 0.10418389738325037, G Loss: 24.9803466796875\n",
      "Epoch: 45, Batch: 284, D Loss: 0.10666114092571476, G Loss: 25.00702667236328\n",
      "Epoch: 45, Batch: 285, D Loss: 0.0965802818617554, G Loss: 24.70545196533203\n",
      "Epoch: 45, Batch: 286, D Loss: 0.09983760119597025, G Loss: 24.368995666503906\n",
      "Epoch: 45, Batch: 287, D Loss: 0.09618528188825227, G Loss: 24.041563034057617\n",
      "Epoch: 45, Batch: 288, D Loss: 0.10218138994600126, G Loss: 24.0384464263916\n",
      "Epoch: 45, Batch: 289, D Loss: 0.10402680934983034, G Loss: 24.392343521118164\n",
      "Epoch: 45, Batch: 290, D Loss: 0.1033776849607741, G Loss: 24.863544464111328\n",
      "Epoch: 45, Batch: 291, D Loss: 0.09794405103458693, G Loss: 25.030614852905273\n",
      "Epoch: 45, Batch: 292, D Loss: 0.10636685789256507, G Loss: 25.17230796813965\n",
      "Epoch: 45, Batch: 293, D Loss: 0.10053876043000133, G Loss: 25.017562866210938\n",
      "Epoch: 45, Batch: 294, D Loss: 0.09595479072020437, G Loss: 24.53278923034668\n",
      "Epoch: 45, Batch: 295, D Loss: 0.10146634282013807, G Loss: 24.18203353881836\n",
      "Epoch: 45, Batch: 296, D Loss: 0.09664759786735785, G Loss: 23.928709030151367\n",
      "Epoch: 45, Batch: 297, D Loss: 0.09384550156454478, G Loss: 23.734241485595703\n",
      "Epoch: 45, Batch: 298, D Loss: 0.09928821774655233, G Loss: 23.848665237426758\n",
      "Epoch: 45, Batch: 299, D Loss: 0.0959800407487579, G Loss: 24.0539608001709\n",
      "Epoch: 45, Batch: 300, D Loss: 0.09505218269086649, G Loss: 24.21172523498535\n",
      "Epoch: 45, Batch: 301, D Loss: 0.09123694898291171, G Loss: 24.131587982177734\n",
      "Epoch: 45, Batch: 302, D Loss: 0.10290573538876287, G Loss: 24.284809112548828\n",
      "Epoch: 45, Batch: 303, D Loss: 0.10027229787206131, G Loss: 24.47134017944336\n",
      "Epoch: 45, Batch: 304, D Loss: 0.10140611232402039, G Loss: 24.645401000976562\n",
      "Epoch: 45, Batch: 305, D Loss: 0.1012173295116226, G Loss: 24.72028160095215\n",
      "Epoch: 45, Batch: 306, D Loss: 0.1027793437332919, G Loss: 24.75033950805664\n",
      "Epoch: 45, Batch: 307, D Loss: 0.0987354517079748, G Loss: 24.59507179260254\n",
      "Epoch: 45, Batch: 308, D Loss: 0.09874618054632632, G Loss: 24.330556869506836\n",
      "Epoch: 45, Batch: 309, D Loss: 0.10119562597538198, G Loss: 24.196290969848633\n",
      "Epoch: 45, Batch: 310, D Loss: 0.09638360144395368, G Loss: 24.036054611206055\n",
      "Epoch: 45, Batch: 311, D Loss: 0.09424404801933955, G Loss: 23.861854553222656\n",
      "Epoch: 45, Batch: 312, D Loss: 0.10063824059628332, G Loss: 23.968162536621094\n",
      "Epoch: 45, Batch: 313, D Loss: 0.10177523644387511, G Loss: 24.331979751586914\n",
      "Epoch: 45, Batch: 314, D Loss: 0.09924902023017533, G Loss: 24.671361923217773\n",
      "Epoch: 45, Batch: 315, D Loss: 0.0976245775909422, G Loss: 24.790435791015625\n",
      "Epoch: 45, Batch: 316, D Loss: 0.10256548971761822, G Loss: 24.86325454711914\n",
      "Epoch: 45, Batch: 317, D Loss: 0.10141601414299482, G Loss: 24.82792854309082\n",
      "Epoch: 45, Batch: 318, D Loss: 0.0995585396975522, G Loss: 24.66935920715332\n",
      "Epoch: 45, Batch: 319, D Loss: 0.10467512161519026, G Loss: 24.6441707611084\n",
      "Epoch: 45, Batch: 320, D Loss: 0.09706169367925394, G Loss: 24.465421676635742\n",
      "Epoch: 45, Batch: 321, D Loss: 0.1001523658757136, G Loss: 24.380891799926758\n",
      "Epoch: 45, Batch: 322, D Loss: 0.09329974652787901, G Loss: 24.15644073486328\n",
      "Epoch: 45, Batch: 323, D Loss: 0.09544177355127152, G Loss: 24.00876235961914\n",
      "Epoch: 45, Batch: 324, D Loss: 0.09749779106994962, G Loss: 24.073728561401367\n",
      "Epoch: 45, Batch: 325, D Loss: 0.09908860178334625, G Loss: 24.328876495361328\n",
      "Epoch: 45, Batch: 326, D Loss: 0.10201697052629621, G Loss: 24.721712112426758\n",
      "Epoch: 45, Batch: 327, D Loss: 0.09521798045303909, G Loss: 24.842342376708984\n",
      "Epoch: 45, Batch: 328, D Loss: 0.09925304354048632, G Loss: 24.845855712890625\n",
      "Epoch: 45, Batch: 329, D Loss: 0.09632810951162785, G Loss: 24.680862426757812\n",
      "Epoch: 45, Batch: 330, D Loss: 0.09831187130082965, G Loss: 24.479278564453125\n",
      "Epoch: 45, Batch: 331, D Loss: 0.0964682027827205, G Loss: 24.2822208404541\n",
      "Epoch: 45, Batch: 332, D Loss: 0.10535319895822738, G Loss: 24.498085021972656\n",
      "Epoch: 45, Batch: 333, D Loss: 0.10016843677544608, G Loss: 24.80171012878418\n",
      "Epoch: 45, Batch: 334, D Loss: 0.09691521526166588, G Loss: 24.948823928833008\n",
      "Epoch: 45, Batch: 335, D Loss: 0.09665660560886775, G Loss: 24.88529396057129\n",
      "Epoch: 45, Batch: 336, D Loss: 0.09891860187867263, G Loss: 24.802227020263672\n",
      "Epoch: 45, Batch: 337, D Loss: 0.1017008423888983, G Loss: 24.822078704833984\n",
      "Epoch: 45, Batch: 338, D Loss: 0.09682882578037681, G Loss: 24.76076316833496\n",
      "Epoch: 45, Batch: 339, D Loss: 0.10035479069631432, G Loss: 24.77538299560547\n",
      "Epoch: 45, Batch: 340, D Loss: 0.09311866761224197, G Loss: 24.566322326660156\n",
      "Epoch: 45, Batch: 341, D Loss: 0.09257969261471061, G Loss: 24.26494789123535\n",
      "Epoch: 45, Batch: 342, D Loss: 0.09912545235434875, G Loss: 24.236661911010742\n",
      "Epoch: 45, Batch: 343, D Loss: 0.10214003921796345, G Loss: 24.583126068115234\n",
      "Epoch: 45, Batch: 344, D Loss: 0.10192906857355569, G Loss: 25.061559677124023\n",
      "Epoch: 45, Batch: 345, D Loss: 0.1007033437544756, G Loss: 25.41187286376953\n",
      "Epoch: 45, Batch: 346, D Loss: 0.09484209865817686, G Loss: 25.307079315185547\n",
      "Epoch: 45, Batch: 347, D Loss: 0.10622295737783433, G Loss: 25.284528732299805\n",
      "Epoch: 45, Batch: 348, D Loss: 0.09620350599908994, G Loss: 24.959474563598633\n",
      "Epoch: 45, Batch: 349, D Loss: 0.09553217888796123, G Loss: 24.505786895751953\n",
      "Epoch: 45, Batch: 350, D Loss: 0.09466476739851651, G Loss: 24.113588333129883\n",
      "Epoch: 45, Batch: 351, D Loss: 0.0946625396792557, G Loss: 23.953935623168945\n",
      "Epoch: 45, Batch: 352, D Loss: 0.09842936696364418, G Loss: 24.194372177124023\n",
      "Epoch: 45, Batch: 353, D Loss: 0.09922339768421913, G Loss: 24.678211212158203\n",
      "Epoch: 45, Batch: 354, D Loss: 0.10227274895416615, G Loss: 25.268218994140625\n",
      "Epoch: 45, Batch: 355, D Loss: 0.10054686665976797, G Loss: 25.617507934570312\n",
      "Epoch: 45, Batch: 356, D Loss: 0.0901781320617183, G Loss: 25.256181716918945\n",
      "Epoch: 45, Batch: 357, D Loss: 0.10505457968128042, G Loss: 25.021175384521484\n",
      "Epoch: 45, Batch: 358, D Loss: 0.10232843459374084, G Loss: 24.907907485961914\n",
      "Epoch: 45, Batch: 359, D Loss: 0.10066670925211796, G Loss: 24.845813751220703\n",
      "Epoch: 45, Batch: 360, D Loss: 0.10170292855107435, G Loss: 24.873737335205078\n",
      "Epoch: 45, Batch: 361, D Loss: 0.10183958709975581, G Loss: 25.004032135009766\n",
      "Epoch: 45, Batch: 362, D Loss: 0.09907525778479102, G Loss: 25.08623695373535\n",
      "Epoch: 45, Batch: 363, D Loss: 0.1066373139675493, G Loss: 25.342317581176758\n",
      "Epoch: 45, Batch: 364, D Loss: 0.1038615554615618, G Loss: 25.538732528686523\n",
      "Epoch: 45, Batch: 365, D Loss: 0.09362448752398402, G Loss: 25.248334884643555\n",
      "Epoch: 45, Batch: 366, D Loss: 0.09773040563535189, G Loss: 24.852956771850586\n",
      "Epoch: 45, Batch: 367, D Loss: 0.10082599521583194, G Loss: 24.639537811279297\n",
      "Epoch: 45, Batch: 368, D Loss: 0.09959490598252332, G Loss: 24.623403549194336\n",
      "Epoch: 45, Batch: 369, D Loss: 0.09751340002793163, G Loss: 24.70064926147461\n",
      "Epoch: 45, Batch: 370, D Loss: 0.10547558964052937, G Loss: 25.11206817626953\n",
      "Epoch: 45, Batch: 371, D Loss: 0.09618587792474954, G Loss: 25.323959350585938\n",
      "Epoch: 45, Batch: 372, D Loss: 0.09466827661323512, G Loss: 25.24158477783203\n",
      "Epoch: 45, Batch: 373, D Loss: 0.10496398807102374, G Loss: 25.294418334960938\n",
      "Epoch: 45, Batch: 374, D Loss: 0.09655749798383882, G Loss: 25.134002685546875\n",
      "Epoch: 45, Batch: 375, D Loss: 0.1080103814658, G Loss: 25.284706115722656\n",
      "Epoch: 45, Batch: 376, D Loss: 0.10116890073319729, G Loss: 25.378602981567383\n",
      "Epoch: 45, Batch: 377, D Loss: 0.10114896297925619, G Loss: 25.397695541381836\n",
      "Epoch: 45, Batch: 378, D Loss: 0.09177058190682272, G Loss: 25.00016975402832\n",
      "Epoch: 45, Batch: 379, D Loss: 0.10046090186433221, G Loss: 24.752134323120117\n",
      "Epoch: 45, Batch: 380, D Loss: 0.09901391715749491, G Loss: 24.651348114013672\n",
      "Epoch: 45, Batch: 381, D Loss: 0.09990137816409761, G Loss: 24.749954223632812\n",
      "Epoch: 45, Batch: 382, D Loss: 0.09864204377753122, G Loss: 24.915666580200195\n",
      "Epoch: 45, Batch: 383, D Loss: 0.1067048013269951, G Loss: 25.364118576049805\n",
      "Epoch: 45, Batch: 384, D Loss: 0.09734396636931579, G Loss: 25.515453338623047\n",
      "Epoch: 45, Batch: 385, D Loss: 0.09793175012321981, G Loss: 25.365558624267578\n",
      "Epoch: 45, Batch: 386, D Loss: 0.09826657176584773, G Loss: 25.056121826171875\n",
      "Epoch: 45, Batch: 387, D Loss: 0.10264458508008167, G Loss: 24.910526275634766\n",
      "Epoch: 45, Batch: 388, D Loss: 0.1007802337484515, G Loss: 24.89780616760254\n",
      "Epoch: 45, Batch: 389, D Loss: 0.09672188759640926, G Loss: 24.844884872436523\n",
      "Epoch: 45, Batch: 390, D Loss: 0.10489351303106631, G Loss: 25.067277908325195\n",
      "Epoch: 45, Batch: 391, D Loss: 0.10561473668152138, G Loss: 25.452131271362305\n",
      "Epoch: 45, Batch: 392, D Loss: 0.0945384949490826, G Loss: 25.412992477416992\n",
      "Epoch: 45, Batch: 393, D Loss: 0.09839383513254063, G Loss: 25.1834716796875\n",
      "Epoch: 45, Batch: 394, D Loss: 0.10040467978171624, G Loss: 24.966575622558594\n",
      "Epoch: 45, Batch: 395, D Loss: 0.09567794204597821, G Loss: 24.668981552124023\n",
      "Epoch: 45, Batch: 396, D Loss: 0.103059813389596, G Loss: 24.731740951538086\n",
      "Epoch: 45, Batch: 397, D Loss: 0.09215823561897236, G Loss: 24.657773971557617\n",
      "Epoch: 45, Batch: 398, D Loss: 0.09916913510306867, G Loss: 24.73672866821289\n",
      "Epoch: 45, Batch: 399, D Loss: 0.09972240031582234, G Loss: 24.928617477416992\n",
      "Epoch: 45, Batch: 400, D Loss: 0.09702715278372077, G Loss: 25.048234939575195\n",
      "Epoch: 45, Batch: 401, D Loss: 0.10708746314601979, G Loss: 25.38910675048828\n",
      "Epoch: 45, Batch: 402, D Loss: 0.10221329331822343, G Loss: 25.58549690246582\n",
      "Epoch: 45, Batch: 403, D Loss: 0.10079355538284088, G Loss: 25.556049346923828\n",
      "Epoch: 45, Batch: 404, D Loss: 0.1001996249005991, G Loss: 25.302648544311523\n",
      "Epoch: 45, Batch: 405, D Loss: 0.10414480418531882, G Loss: 25.119157791137695\n",
      "Epoch: 45, Batch: 406, D Loss: 0.09800060094126337, G Loss: 24.814441680908203\n",
      "Epoch: 45, Batch: 407, D Loss: 0.09958600998850628, G Loss: 24.62033462524414\n",
      "Epoch: 45, Batch: 408, D Loss: 0.09957288206655772, G Loss: 24.588623046875\n",
      "Epoch: 45, Batch: 409, D Loss: 0.10086514801760361, G Loss: 24.728466033935547\n",
      "Epoch: 45, Batch: 410, D Loss: 0.0999283343636452, G Loss: 24.907442092895508\n",
      "Epoch: 45, Batch: 411, D Loss: 0.10201252997605521, G Loss: 25.111896514892578\n",
      "Epoch: 45, Batch: 412, D Loss: 0.10205240548236787, G Loss: 25.24201774597168\n",
      "Epoch: 45, Batch: 413, D Loss: 0.10286828876080444, G Loss: 25.264528274536133\n",
      "Epoch: 45, Batch: 414, D Loss: 0.09686689079426697, G Loss: 24.98055648803711\n",
      "Epoch: 45, Batch: 415, D Loss: 0.101302772768509, G Loss: 24.720455169677734\n",
      "Epoch: 45, Batch: 416, D Loss: 0.10307584703933856, G Loss: 24.625791549682617\n",
      "Epoch: 45, Batch: 417, D Loss: 0.10270930827635974, G Loss: 24.697790145874023\n",
      "Epoch: 45, Batch: 418, D Loss: 0.0997238904328461, G Loss: 24.764236450195312\n",
      "Epoch: 45, Batch: 419, D Loss: 0.10212692619195059, G Loss: 24.884716033935547\n",
      "Epoch: 45, Batch: 420, D Loss: 0.09936617315596209, G Loss: 24.881200790405273\n",
      "Epoch: 45, Batch: 421, D Loss: 0.10382421315470093, G Loss: 24.951091766357422\n",
      "Epoch: 45, Batch: 422, D Loss: 0.09800611437138834, G Loss: 24.843162536621094\n",
      "Epoch: 45, Batch: 423, D Loss: 0.09868980945061931, G Loss: 24.637088775634766\n",
      "Epoch: 45, Batch: 424, D Loss: 0.10351908207942223, G Loss: 24.628890991210938\n",
      "Epoch: 45, Batch: 425, D Loss: 0.09983015061429355, G Loss: 24.632442474365234\n",
      "Epoch: 45, Batch: 426, D Loss: 0.09843354673209945, G Loss: 24.606924057006836\n",
      "Epoch: 45, Batch: 427, D Loss: 0.09632082284593016, G Loss: 24.486305236816406\n",
      "Epoch: 45, Batch: 428, D Loss: 0.10252895952383569, G Loss: 24.56679916381836\n",
      "Epoch: 45, Batch: 429, D Loss: 0.09619882703898307, G Loss: 24.566864013671875\n",
      "Epoch: 45, Batch: 430, D Loss: 0.09727717937131415, G Loss: 24.52886390686035\n",
      "Epoch: 45, Batch: 431, D Loss: 0.09493134917020916, G Loss: 24.396940231323242\n",
      "Epoch: 45, Batch: 432, D Loss: 0.09861703963383071, G Loss: 24.35800552368164\n",
      "Epoch: 45, Batch: 433, D Loss: 0.10282733292552848, G Loss: 24.594066619873047\n",
      "Epoch: 45, Batch: 434, D Loss: 0.10257257522035008, G Loss: 24.909549713134766\n",
      "Epoch: 45, Batch: 435, D Loss: 0.10199400783259727, G Loss: 25.13625717163086\n",
      "Epoch: 45, Batch: 436, D Loss: 0.09483137727458459, G Loss: 24.931842803955078\n",
      "Epoch: 45, Batch: 437, D Loss: 0.10044150055315852, G Loss: 24.652326583862305\n",
      "Epoch: 45, Batch: 438, D Loss: 0.09577718378313363, G Loss: 24.272930145263672\n",
      "Epoch: 45, Batch: 439, D Loss: 0.10027961434487334, G Loss: 24.124324798583984\n",
      "Epoch: 45, Batch: 440, D Loss: 0.1023995950970356, G Loss: 24.295860290527344\n",
      "Epoch: 45, Batch: 441, D Loss: 0.10513630510504465, G Loss: 24.711421966552734\n",
      "Epoch: 45, Batch: 442, D Loss: 0.0929615721199968, G Loss: 24.69570541381836\n",
      "Epoch: 45, Batch: 443, D Loss: 0.10187388957488666, G Loss: 24.69468879699707\n",
      "Epoch: 45, Batch: 444, D Loss: 0.09391944111510445, G Loss: 24.371322631835938\n",
      "Epoch: 45, Batch: 445, D Loss: 0.10532456637738528, G Loss: 24.360267639160156\n",
      "Epoch: 45, Batch: 446, D Loss: 0.09365971387886209, G Loss: 24.17201042175293\n",
      "Epoch: 45, Batch: 447, D Loss: 0.10138146580836786, G Loss: 24.19379425048828\n",
      "Epoch: 45, Batch: 448, D Loss: 0.100640155389402, G Loss: 24.340038299560547\n",
      "Epoch: 45, Batch: 449, D Loss: 0.10261753202650128, G Loss: 24.609922409057617\n",
      "Epoch: 45, Batch: 450, D Loss: 0.09603849799477387, G Loss: 24.590084075927734\n",
      "Epoch: 45, Batch: 451, D Loss: 0.09277097882112605, G Loss: 24.217849731445312\n",
      "Epoch: 45, Batch: 452, D Loss: 0.10349319876811319, G Loss: 24.152729034423828\n",
      "Epoch: 45, Batch: 453, D Loss: 0.10353222490826716, G Loss: 24.337873458862305\n",
      "Epoch: 45, Batch: 454, D Loss: 0.09822639824227859, G Loss: 24.451871871948242\n",
      "Epoch: 45, Batch: 455, D Loss: 0.10246866942559282, G Loss: 24.606740951538086\n",
      "Epoch: 45, Batch: 456, D Loss: 0.10245701671624316, G Loss: 24.703916549682617\n",
      "Epoch: 45, Batch: 457, D Loss: 0.09819899500422885, G Loss: 24.561073303222656\n",
      "Epoch: 45, Batch: 458, D Loss: 0.09816337378075544, G Loss: 24.289119720458984\n",
      "Epoch: 45, Batch: 459, D Loss: 0.09801895918097908, G Loss: 24.011281967163086\n",
      "Epoch: 45, Batch: 460, D Loss: 0.0945939496379109, G Loss: 23.703845977783203\n",
      "Epoch: 45, Batch: 461, D Loss: 0.10265183451188062, G Loss: 23.81293296813965\n",
      "Epoch: 45, Batch: 462, D Loss: 0.10187625886887204, G Loss: 24.178462982177734\n",
      "Epoch: 45, Batch: 463, D Loss: 0.09682019801322683, G Loss: 24.4412841796875\n",
      "Epoch: 45, Batch: 464, D Loss: 0.09841241688669378, G Loss: 24.572423934936523\n",
      "Epoch: 45, Batch: 465, D Loss: 0.10439807922624518, G Loss: 24.737022399902344\n",
      "Epoch: 45, Batch: 466, D Loss: 0.09508985282008142, G Loss: 24.510452270507812\n",
      "Epoch: 45, Batch: 467, D Loss: 0.09977932275636558, G Loss: 24.256206512451172\n",
      "Epoch: 46, Batch: 0, D Loss: 0.09500882031286063, G Loss: 23.9097843170166\n",
      "Epoch: 46, Batch: 1, D Loss: 0.09116887303772116, G Loss: 23.498300552368164\n",
      "Epoch: 46, Batch: 2, D Loss: 0.10088020566111237, G Loss: 23.58038902282715\n",
      "Epoch: 46, Batch: 3, D Loss: 0.09904810788616197, G Loss: 23.946792602539062\n",
      "Epoch: 46, Batch: 4, D Loss: 0.09760460259136511, G Loss: 24.353979110717773\n",
      "Epoch: 46, Batch: 5, D Loss: 0.10130161048046904, G Loss: 24.76816749572754\n",
      "Epoch: 46, Batch: 6, D Loss: 0.09521098435794455, G Loss: 24.78166961669922\n",
      "Epoch: 46, Batch: 7, D Loss: 0.09745882452510797, G Loss: 24.548419952392578\n",
      "Epoch: 46, Batch: 8, D Loss: 0.10092434288284773, G Loss: 24.345544815063477\n",
      "Epoch: 46, Batch: 9, D Loss: 0.10051287712052916, G Loss: 24.27547836303711\n",
      "Epoch: 46, Batch: 10, D Loss: 0.10911145062438858, G Loss: 24.63728141784668\n",
      "Epoch: 46, Batch: 11, D Loss: 0.10033126921346754, G Loss: 24.865280151367188\n",
      "Epoch: 46, Batch: 12, D Loss: 0.09734012187343366, G Loss: 24.814359664916992\n",
      "Epoch: 46, Batch: 13, D Loss: 0.10587134213069152, G Loss: 24.865921020507812\n",
      "Epoch: 46, Batch: 14, D Loss: 0.10165905953262672, G Loss: 24.830291748046875\n",
      "Epoch: 46, Batch: 15, D Loss: 0.10116155446436123, G Loss: 24.74540138244629\n",
      "Epoch: 46, Batch: 16, D Loss: 0.10024651140936827, G Loss: 24.60924530029297\n",
      "Epoch: 46, Batch: 17, D Loss: 0.09889390320689376, G Loss: 24.471355438232422\n",
      "Epoch: 46, Batch: 18, D Loss: 0.09837906063863336, G Loss: 24.343116760253906\n",
      "Epoch: 46, Batch: 19, D Loss: 0.10231303424926025, G Loss: 24.42490005493164\n",
      "Epoch: 46, Batch: 20, D Loss: 0.0968433320642537, G Loss: 24.474628448486328\n",
      "Epoch: 46, Batch: 21, D Loss: 0.10183277727223328, G Loss: 24.687227249145508\n",
      "Epoch: 46, Batch: 22, D Loss: 0.09303268791240504, G Loss: 24.59716796875\n",
      "Epoch: 46, Batch: 23, D Loss: 0.10463944078453301, G Loss: 24.744112014770508\n",
      "Epoch: 46, Batch: 24, D Loss: 0.09636752308337745, G Loss: 24.690114974975586\n",
      "Epoch: 46, Batch: 25, D Loss: 0.10050351918700867, G Loss: 24.669092178344727\n",
      "Epoch: 46, Batch: 26, D Loss: 0.09823585302635829, G Loss: 24.60831642150879\n",
      "Epoch: 46, Batch: 27, D Loss: 0.09519994260016779, G Loss: 24.416854858398438\n",
      "Epoch: 46, Batch: 28, D Loss: 0.10190856457957372, G Loss: 24.48423957824707\n",
      "Epoch: 46, Batch: 29, D Loss: 0.10139752925492211, G Loss: 24.67857551574707\n",
      "Epoch: 46, Batch: 30, D Loss: 0.09680417180990208, G Loss: 24.736547470092773\n",
      "Epoch: 46, Batch: 31, D Loss: 0.10008031875780538, G Loss: 24.775341033935547\n",
      "Epoch: 46, Batch: 32, D Loss: 0.09870912135536283, G Loss: 24.73296546936035\n",
      "Epoch: 46, Batch: 33, D Loss: 0.09546498210262364, G Loss: 24.501514434814453\n",
      "Epoch: 46, Batch: 34, D Loss: 0.1018190235016595, G Loss: 24.45618438720703\n",
      "Epoch: 46, Batch: 35, D Loss: 0.09797789157641197, G Loss: 24.443326950073242\n",
      "Epoch: 46, Batch: 36, D Loss: 0.10379438103316946, G Loss: 24.676517486572266\n",
      "Epoch: 46, Batch: 37, D Loss: 0.09671726078718033, G Loss: 24.75044059753418\n",
      "Epoch: 46, Batch: 38, D Loss: 0.09639401734832179, G Loss: 24.615278244018555\n",
      "Epoch: 46, Batch: 39, D Loss: 0.10115070642089692, G Loss: 24.562599182128906\n",
      "Epoch: 46, Batch: 40, D Loss: 0.11005792022629522, G Loss: 24.947223663330078\n",
      "Epoch: 46, Batch: 41, D Loss: 0.10317644477513761, G Loss: 25.252798080444336\n",
      "Epoch: 46, Batch: 42, D Loss: 0.09939275682517495, G Loss: 25.23280906677246\n",
      "Epoch: 46, Batch: 43, D Loss: 0.09763957560716721, G Loss: 24.902936935424805\n",
      "Epoch: 46, Batch: 44, D Loss: 0.0928616449343272, G Loss: 24.27487564086914\n",
      "Epoch: 46, Batch: 45, D Loss: 0.10619322957106052, G Loss: 24.19218635559082\n",
      "Epoch: 46, Batch: 46, D Loss: 0.10099786521408118, G Loss: 24.389495849609375\n",
      "Epoch: 46, Batch: 47, D Loss: 0.09139661492210091, G Loss: 24.36845588684082\n",
      "Epoch: 46, Batch: 48, D Loss: 0.10249623657418087, G Loss: 24.617679595947266\n",
      "Epoch: 46, Batch: 49, D Loss: 0.09990295023624662, G Loss: 24.854124069213867\n",
      "Epoch: 46, Batch: 50, D Loss: 0.09861890972437212, G Loss: 24.918733596801758\n",
      "Epoch: 46, Batch: 51, D Loss: 0.0987252295096662, G Loss: 24.817956924438477\n",
      "Epoch: 46, Batch: 52, D Loss: 0.09778921307092046, G Loss: 24.550607681274414\n",
      "Epoch: 46, Batch: 53, D Loss: 0.10034735501984081, G Loss: 24.41061019897461\n",
      "Epoch: 46, Batch: 54, D Loss: 0.0997168421872036, G Loss: 24.387325286865234\n",
      "Epoch: 46, Batch: 55, D Loss: 0.10382786394318615, G Loss: 24.587831497192383\n",
      "Epoch: 46, Batch: 56, D Loss: 0.10332959146213237, G Loss: 24.865978240966797\n",
      "Epoch: 46, Batch: 57, D Loss: 0.10701458156762488, G Loss: 25.235157012939453\n",
      "Epoch: 46, Batch: 58, D Loss: 0.09681556374418568, G Loss: 25.117387771606445\n",
      "Epoch: 46, Batch: 59, D Loss: 0.09814592451627957, G Loss: 24.69533348083496\n",
      "Epoch: 46, Batch: 60, D Loss: 0.10125792772711306, G Loss: 24.342697143554688\n",
      "Epoch: 46, Batch: 61, D Loss: 0.0971762612619431, G Loss: 24.036531448364258\n",
      "Epoch: 46, Batch: 62, D Loss: 0.09907520564279977, G Loss: 23.985280990600586\n",
      "Epoch: 46, Batch: 63, D Loss: 0.10041555763992104, G Loss: 24.210723876953125\n",
      "Epoch: 46, Batch: 64, D Loss: 0.09874542058827977, G Loss: 24.498672485351562\n",
      "Epoch: 46, Batch: 65, D Loss: 0.1023554429506897, G Loss: 24.855195999145508\n",
      "Epoch: 46, Batch: 66, D Loss: 0.09049575031669024, G Loss: 24.71204948425293\n",
      "Epoch: 46, Batch: 67, D Loss: 0.10411387682886857, G Loss: 24.71269416809082\n",
      "Epoch: 46, Batch: 68, D Loss: 0.09874406457905714, G Loss: 24.646347045898438\n",
      "Epoch: 46, Batch: 69, D Loss: 0.09512574971839556, G Loss: 24.414255142211914\n",
      "Epoch: 46, Batch: 70, D Loss: 0.1011829674371468, G Loss: 24.371999740600586\n",
      "Epoch: 46, Batch: 71, D Loss: 0.09474560619767403, G Loss: 24.278488159179688\n",
      "Epoch: 46, Batch: 72, D Loss: 0.09752119333950342, G Loss: 24.319345474243164\n",
      "Epoch: 46, Batch: 73, D Loss: 0.09724877776009047, G Loss: 24.430511474609375\n",
      "Epoch: 46, Batch: 74, D Loss: 0.10049426556702411, G Loss: 24.692914962768555\n",
      "Epoch: 46, Batch: 75, D Loss: 0.09881381691345573, G Loss: 24.906909942626953\n",
      "Epoch: 46, Batch: 76, D Loss: 0.10582943261304753, G Loss: 25.25322914123535\n",
      "Epoch: 46, Batch: 77, D Loss: 0.10508242249950142, G Loss: 25.550514221191406\n",
      "Epoch: 46, Batch: 78, D Loss: 0.10205641389287894, G Loss: 25.577585220336914\n",
      "Epoch: 46, Batch: 79, D Loss: 0.09421724081533893, G Loss: 25.12616539001465\n",
      "Epoch: 46, Batch: 80, D Loss: 0.10088121891774807, G Loss: 24.731632232666016\n",
      "Epoch: 46, Batch: 81, D Loss: 0.0931521281715571, G Loss: 24.27269172668457\n",
      "Epoch: 46, Batch: 82, D Loss: 0.10086308421157433, G Loss: 24.251754760742188\n",
      "Epoch: 46, Batch: 83, D Loss: 0.09510436655463415, G Loss: 24.378833770751953\n",
      "Epoch: 46, Batch: 84, D Loss: 0.09739861638461787, G Loss: 24.671234130859375\n",
      "Epoch: 46, Batch: 85, D Loss: 0.10160625726729744, G Loss: 25.16105842590332\n",
      "Epoch: 46, Batch: 86, D Loss: 0.10330019146656144, G Loss: 25.67157745361328\n",
      "Epoch: 46, Batch: 87, D Loss: 0.09960986674163877, G Loss: 25.797962188720703\n",
      "Epoch: 46, Batch: 88, D Loss: 0.09935949743148449, G Loss: 25.55948829650879\n",
      "Epoch: 46, Batch: 89, D Loss: 0.1029820814774975, G Loss: 25.269392013549805\n",
      "Epoch: 46, Batch: 90, D Loss: 0.09789371491134148, G Loss: 24.866069793701172\n",
      "Epoch: 46, Batch: 91, D Loss: 0.10174678266918033, G Loss: 24.692935943603516\n",
      "Epoch: 46, Batch: 92, D Loss: 0.09788609297060566, G Loss: 24.62738037109375\n",
      "Epoch: 46, Batch: 93, D Loss: 0.10657453537810781, G Loss: 25.010967254638672\n",
      "Epoch: 46, Batch: 94, D Loss: 0.09929051995860474, G Loss: 25.32184410095215\n",
      "Epoch: 46, Batch: 95, D Loss: 0.09864277393112489, G Loss: 25.385692596435547\n",
      "Epoch: 46, Batch: 96, D Loss: 0.09770605713650525, G Loss: 25.196815490722656\n",
      "Epoch: 46, Batch: 97, D Loss: 0.09810738266180019, G Loss: 24.90285873413086\n",
      "Epoch: 46, Batch: 98, D Loss: 0.10358879715993063, G Loss: 24.84515953063965\n",
      "Epoch: 46, Batch: 99, D Loss: 0.10438674689075028, G Loss: 25.029273986816406\n",
      "Epoch: 46, Batch: 100, D Loss: 0.09686297924001191, G Loss: 25.028362274169922\n",
      "Epoch: 46, Batch: 101, D Loss: 0.10390032828476871, G Loss: 25.18145751953125\n",
      "Epoch: 46, Batch: 102, D Loss: 0.09793974459758127, G Loss: 25.156476974487305\n",
      "Epoch: 46, Batch: 103, D Loss: 0.10046011210109648, G Loss: 25.06916046142578\n",
      "Epoch: 46, Batch: 104, D Loss: 0.09875432402604631, G Loss: 24.89780616760254\n",
      "Epoch: 46, Batch: 105, D Loss: 0.09982304275836694, G Loss: 24.820980072021484\n",
      "Epoch: 46, Batch: 106, D Loss: 0.10469490290443798, G Loss: 25.000347137451172\n",
      "Epoch: 46, Batch: 107, D Loss: 0.10348121822491631, G Loss: 25.241750717163086\n",
      "Epoch: 46, Batch: 108, D Loss: 0.0997048467450462, G Loss: 25.30393409729004\n",
      "Epoch: 46, Batch: 109, D Loss: 0.09414522350439734, G Loss: 24.986968994140625\n",
      "Epoch: 46, Batch: 110, D Loss: 0.0960082113830015, G Loss: 24.578624725341797\n",
      "Epoch: 46, Batch: 111, D Loss: 0.10007468612147738, G Loss: 24.427635192871094\n",
      "Epoch: 46, Batch: 112, D Loss: 0.10003188253616871, G Loss: 24.52739143371582\n",
      "Epoch: 46, Batch: 113, D Loss: 0.09973603487988997, G Loss: 24.7818546295166\n",
      "Epoch: 46, Batch: 114, D Loss: 0.09892243892722552, G Loss: 25.004472732543945\n",
      "Epoch: 46, Batch: 115, D Loss: 0.09120530635880468, G Loss: 24.81934928894043\n",
      "Epoch: 46, Batch: 116, D Loss: 0.09175144136989855, G Loss: 24.398326873779297\n",
      "Epoch: 46, Batch: 117, D Loss: 0.0987272337216974, G Loss: 24.237497329711914\n",
      "Epoch: 46, Batch: 118, D Loss: 0.10029423238215796, G Loss: 24.396705627441406\n",
      "Epoch: 46, Batch: 119, D Loss: 0.09802074731488965, G Loss: 24.681381225585938\n",
      "Epoch: 46, Batch: 120, D Loss: 0.09620040656002632, G Loss: 24.86598014831543\n",
      "Epoch: 46, Batch: 121, D Loss: 0.10535648465813294, G Loss: 25.22618293762207\n",
      "Epoch: 46, Batch: 122, D Loss: 0.09874965251015365, G Loss: 25.334012985229492\n",
      "Epoch: 46, Batch: 123, D Loss: 0.1015503257563621, G Loss: 25.301706314086914\n",
      "Epoch: 46, Batch: 124, D Loss: 0.10325257480668623, G Loss: 25.26296043395996\n",
      "Epoch: 46, Batch: 125, D Loss: 0.09660403431086066, G Loss: 24.965505599975586\n",
      "Epoch: 46, Batch: 126, D Loss: 0.10394078493869392, G Loss: 24.88184928894043\n",
      "Epoch: 46, Batch: 127, D Loss: 0.09457328916469848, G Loss: 24.669397354125977\n",
      "Epoch: 46, Batch: 128, D Loss: 0.10245185346350581, G Loss: 24.723634719848633\n",
      "Epoch: 46, Batch: 129, D Loss: 0.096061199912619, G Loss: 24.728557586669922\n",
      "Epoch: 46, Batch: 130, D Loss: 0.09798303247399262, G Loss: 24.749103546142578\n",
      "Epoch: 46, Batch: 131, D Loss: 0.10193340481151607, G Loss: 24.900617599487305\n",
      "Epoch: 46, Batch: 132, D Loss: 0.09877450019856046, G Loss: 24.98179817199707\n",
      "Epoch: 46, Batch: 133, D Loss: 0.09928907454724337, G Loss: 24.972801208496094\n",
      "Epoch: 46, Batch: 134, D Loss: 0.10390079022120996, G Loss: 25.100528717041016\n",
      "Epoch: 46, Batch: 135, D Loss: 0.10275050998326832, G Loss: 25.21018409729004\n",
      "Epoch: 46, Batch: 136, D Loss: 0.09449018538651717, G Loss: 24.925785064697266\n",
      "Epoch: 46, Batch: 137, D Loss: 0.09779039026223971, G Loss: 24.537334442138672\n",
      "Epoch: 46, Batch: 138, D Loss: 0.10326054693417075, G Loss: 24.460031509399414\n",
      "Epoch: 46, Batch: 139, D Loss: 0.09956099094096516, G Loss: 24.55049705505371\n",
      "Epoch: 46, Batch: 140, D Loss: 0.10210373998645815, G Loss: 24.79389762878418\n",
      "Epoch: 46, Batch: 141, D Loss: 0.09423656762506144, G Loss: 24.779373168945312\n",
      "Epoch: 46, Batch: 142, D Loss: 0.10042639077569997, G Loss: 24.79163932800293\n",
      "Epoch: 46, Batch: 143, D Loss: 0.10140979290833459, G Loss: 24.86029815673828\n",
      "Epoch: 46, Batch: 144, D Loss: 0.098593980082084, G Loss: 24.820241928100586\n",
      "Epoch: 46, Batch: 145, D Loss: 0.09596569092015322, G Loss: 24.59896469116211\n",
      "Epoch: 46, Batch: 146, D Loss: 0.1035471260649406, G Loss: 24.634693145751953\n",
      "Epoch: 46, Batch: 147, D Loss: 0.0994427055217483, G Loss: 24.693410873413086\n",
      "Epoch: 46, Batch: 148, D Loss: 0.10425762087956277, G Loss: 24.89261817932129\n",
      "Epoch: 46, Batch: 149, D Loss: 0.09943264723575959, G Loss: 24.945592880249023\n",
      "Epoch: 46, Batch: 150, D Loss: 0.10675093532262032, G Loss: 25.16432762145996\n",
      "Epoch: 46, Batch: 151, D Loss: 0.1031195819432683, G Loss: 25.302507400512695\n",
      "Epoch: 46, Batch: 152, D Loss: 0.09545944631701365, G Loss: 24.999698638916016\n",
      "Epoch: 46, Batch: 153, D Loss: 0.1011054664931773, G Loss: 24.694690704345703\n",
      "Epoch: 46, Batch: 154, D Loss: 0.09414340556847124, G Loss: 24.267797470092773\n",
      "Epoch: 46, Batch: 155, D Loss: 0.10247438402458306, G Loss: 24.228240966796875\n",
      "Epoch: 46, Batch: 156, D Loss: 0.10002502800382698, G Loss: 24.433361053466797\n",
      "Epoch: 46, Batch: 157, D Loss: 0.10180867464346177, G Loss: 24.824438095092773\n",
      "Epoch: 46, Batch: 158, D Loss: 0.09624727816146046, G Loss: 24.995441436767578\n",
      "Epoch: 46, Batch: 159, D Loss: 0.10396660864979017, G Loss: 25.201522827148438\n",
      "Epoch: 46, Batch: 160, D Loss: 0.09289199859565907, G Loss: 24.908985137939453\n",
      "Epoch: 46, Batch: 161, D Loss: 0.09866848588890796, G Loss: 24.586641311645508\n",
      "Epoch: 46, Batch: 162, D Loss: 0.09589032084980997, G Loss: 24.283477783203125\n",
      "Epoch: 46, Batch: 163, D Loss: 0.10002128781335788, G Loss: 24.249055862426758\n",
      "Epoch: 46, Batch: 164, D Loss: 0.0954159945394508, G Loss: 24.277597427368164\n",
      "Epoch: 46, Batch: 165, D Loss: 0.09945407511085033, G Loss: 24.4862117767334\n",
      "Epoch: 46, Batch: 166, D Loss: 0.10131201894052923, G Loss: 24.843242645263672\n",
      "Epoch: 46, Batch: 167, D Loss: 0.09629082680501799, G Loss: 24.986452102661133\n",
      "Epoch: 46, Batch: 168, D Loss: 0.10103349388325673, G Loss: 25.052148818969727\n",
      "Epoch: 46, Batch: 169, D Loss: 0.10007943958725606, G Loss: 24.988502502441406\n",
      "Epoch: 46, Batch: 170, D Loss: 0.10364727676612955, G Loss: 25.000022888183594\n",
      "Epoch: 46, Batch: 171, D Loss: 0.1009679734776698, G Loss: 24.989639282226562\n",
      "Epoch: 46, Batch: 172, D Loss: 0.09909325838838715, G Loss: 24.86359405517578\n",
      "Epoch: 46, Batch: 173, D Loss: 0.09299197793986799, G Loss: 24.467737197875977\n",
      "Epoch: 46, Batch: 174, D Loss: 0.10659219325702723, G Loss: 24.58106231689453\n",
      "Epoch: 46, Batch: 175, D Loss: 0.10416868329910942, G Loss: 24.964126586914062\n",
      "Epoch: 46, Batch: 176, D Loss: 0.10033635795742593, G Loss: 25.22861671447754\n",
      "Epoch: 46, Batch: 177, D Loss: 0.10757336765981856, G Loss: 25.601226806640625\n",
      "Epoch: 46, Batch: 178, D Loss: 0.09992593527221191, G Loss: 25.599456787109375\n",
      "Epoch: 46, Batch: 179, D Loss: 0.10347862542093036, G Loss: 25.427570343017578\n",
      "Epoch: 46, Batch: 180, D Loss: 0.09623879194848126, G Loss: 24.928585052490234\n",
      "Epoch: 46, Batch: 181, D Loss: 0.09878628701918667, G Loss: 24.47382354736328\n",
      "Epoch: 46, Batch: 182, D Loss: 0.0988418012989833, G Loss: 24.247220993041992\n",
      "Epoch: 46, Batch: 183, D Loss: 0.09507545830340443, G Loss: 24.187536239624023\n",
      "Epoch: 46, Batch: 184, D Loss: 0.09566405416993992, G Loss: 24.32050132751465\n",
      "Epoch: 46, Batch: 185, D Loss: 0.09261728824490632, G Loss: 24.411869049072266\n",
      "Epoch: 46, Batch: 186, D Loss: 0.09672307224222627, G Loss: 24.58563995361328\n",
      "Epoch: 46, Batch: 187, D Loss: 0.09921768308592875, G Loss: 24.865188598632812\n",
      "Epoch: 46, Batch: 188, D Loss: 0.10248985887224007, G Loss: 25.245820999145508\n",
      "Epoch: 46, Batch: 189, D Loss: 0.10005459934968775, G Loss: 25.41899299621582\n",
      "Epoch: 46, Batch: 190, D Loss: 0.1030450090810999, G Loss: 25.44517707824707\n",
      "Epoch: 46, Batch: 191, D Loss: 0.09621905535992563, G Loss: 25.101337432861328\n",
      "Epoch: 46, Batch: 192, D Loss: 0.09994652123015742, G Loss: 24.745311737060547\n",
      "Epoch: 46, Batch: 193, D Loss: 0.10232711584322322, G Loss: 24.640918731689453\n",
      "Epoch: 46, Batch: 194, D Loss: 0.09964664281409588, G Loss: 24.63974952697754\n",
      "Epoch: 46, Batch: 195, D Loss: 0.099390022466292, G Loss: 24.699758529663086\n",
      "Epoch: 46, Batch: 196, D Loss: 0.09656876326552054, G Loss: 24.685253143310547\n",
      "Epoch: 46, Batch: 197, D Loss: 0.0988453775739332, G Loss: 24.68720054626465\n",
      "Epoch: 46, Batch: 198, D Loss: 0.10153246671841336, G Loss: 24.831512451171875\n",
      "Epoch: 46, Batch: 199, D Loss: 0.09484310449033975, G Loss: 24.735816955566406\n",
      "Epoch: 46, Batch: 200, D Loss: 0.09839349986084524, G Loss: 24.618663787841797\n",
      "Epoch: 46, Batch: 201, D Loss: 0.09847404063811913, G Loss: 24.532426834106445\n",
      "Epoch: 46, Batch: 202, D Loss: 0.09680014849865509, G Loss: 24.451751708984375\n",
      "Epoch: 46, Batch: 203, D Loss: 0.09473008663728574, G Loss: 24.351783752441406\n",
      "Epoch: 46, Batch: 204, D Loss: 0.09775269777885227, G Loss: 24.388315200805664\n",
      "Epoch: 46, Batch: 205, D Loss: 0.09861484916187245, G Loss: 24.56059455871582\n",
      "Epoch: 46, Batch: 206, D Loss: 0.09875382483971014, G Loss: 24.769174575805664\n",
      "Epoch: 46, Batch: 207, D Loss: 0.10000468791312737, G Loss: 24.98295021057129\n",
      "Epoch: 46, Batch: 208, D Loss: 0.09528454393892914, G Loss: 24.882965087890625\n",
      "Epoch: 46, Batch: 209, D Loss: 0.10312591493898922, G Loss: 24.910987854003906\n",
      "Epoch: 46, Batch: 210, D Loss: 0.10067538172759828, G Loss: 24.92563247680664\n",
      "Epoch: 46, Batch: 211, D Loss: 0.10065082461392669, G Loss: 24.918537139892578\n",
      "Epoch: 46, Batch: 212, D Loss: 0.10122523457569113, G Loss: 24.90879249572754\n",
      "Epoch: 46, Batch: 213, D Loss: 0.10036838800501006, G Loss: 24.846725463867188\n",
      "Epoch: 46, Batch: 214, D Loss: 0.09474988282676337, G Loss: 24.54310417175293\n",
      "Epoch: 46, Batch: 215, D Loss: 0.09420640767962785, G Loss: 24.1585693359375\n",
      "Epoch: 46, Batch: 216, D Loss: 0.0984843969515769, G Loss: 24.048564910888672\n",
      "Epoch: 46, Batch: 217, D Loss: 0.10081876815945981, G Loss: 24.29340171813965\n",
      "Epoch: 46, Batch: 218, D Loss: 0.10050150753196056, G Loss: 24.712806701660156\n",
      "Epoch: 46, Batch: 219, D Loss: 0.09637418390144126, G Loss: 24.933801651000977\n",
      "Epoch: 46, Batch: 220, D Loss: 0.09875111282592526, G Loss: 24.988855361938477\n",
      "Epoch: 46, Batch: 221, D Loss: 0.09723562002945205, G Loss: 24.830419540405273\n",
      "Epoch: 46, Batch: 222, D Loss: 0.09663881362446937, G Loss: 24.532114028930664\n",
      "Epoch: 46, Batch: 223, D Loss: 0.09767141939462749, G Loss: 24.299062728881836\n",
      "Epoch: 46, Batch: 224, D Loss: 0.10393581540678147, G Loss: 24.460426330566406\n",
      "Epoch: 46, Batch: 225, D Loss: 0.09424683452807436, G Loss: 24.519062042236328\n",
      "Epoch: 46, Batch: 226, D Loss: 0.0989002511010427, G Loss: 24.644296646118164\n",
      "Epoch: 46, Batch: 227, D Loss: 0.09807044268608622, G Loss: 24.716266632080078\n",
      "Epoch: 46, Batch: 228, D Loss: 0.09928585589817192, G Loss: 24.79421615600586\n",
      "Epoch: 46, Batch: 229, D Loss: 0.09876054526202084, G Loss: 24.853824615478516\n",
      "Epoch: 46, Batch: 230, D Loss: 0.09446477890898497, G Loss: 24.673038482666016\n",
      "Epoch: 46, Batch: 231, D Loss: 0.09665025771736668, G Loss: 24.468225479125977\n",
      "Epoch: 46, Batch: 232, D Loss: 0.10438396782740626, G Loss: 24.679079055786133\n",
      "Epoch: 46, Batch: 233, D Loss: 0.09675709904123189, G Loss: 24.83231544494629\n",
      "Epoch: 46, Batch: 234, D Loss: 0.09735181928486067, G Loss: 24.86990737915039\n",
      "Epoch: 46, Batch: 235, D Loss: 0.10295146704439403, G Loss: 25.050058364868164\n",
      "Epoch: 46, Batch: 236, D Loss: 0.10267306864860716, G Loss: 25.235383987426758\n",
      "Epoch: 46, Batch: 237, D Loss: 0.10139490664532165, G Loss: 25.31267547607422\n",
      "Epoch: 46, Batch: 238, D Loss: 0.095456019049721, G Loss: 25.060781478881836\n",
      "Epoch: 46, Batch: 239, D Loss: 0.10436694324691358, G Loss: 24.999692916870117\n",
      "Epoch: 46, Batch: 240, D Loss: 0.09238336981183153, G Loss: 24.637378692626953\n",
      "Epoch: 46, Batch: 241, D Loss: 0.1025909334521633, G Loss: 24.624412536621094\n",
      "Epoch: 46, Batch: 242, D Loss: 0.10344627500443479, G Loss: 24.924579620361328\n",
      "Epoch: 46, Batch: 243, D Loss: 0.09026006609996828, G Loss: 24.809803009033203\n",
      "Epoch: 46, Batch: 244, D Loss: 0.09928238392724086, G Loss: 24.791812896728516\n",
      "Epoch: 46, Batch: 245, D Loss: 0.09639520944041133, G Loss: 24.745283126831055\n",
      "Epoch: 46, Batch: 246, D Loss: 0.10128821433427881, G Loss: 24.873458862304688\n",
      "Epoch: 46, Batch: 247, D Loss: 0.0989918261841355, G Loss: 24.969539642333984\n",
      "Epoch: 46, Batch: 248, D Loss: 0.10058851540766955, G Loss: 25.071956634521484\n",
      "Epoch: 46, Batch: 249, D Loss: 0.10453251004792684, G Loss: 25.298131942749023\n",
      "Epoch: 46, Batch: 250, D Loss: 0.09985718876626211, G Loss: 25.345178604125977\n",
      "Epoch: 46, Batch: 251, D Loss: 0.10000187904168281, G Loss: 25.218332290649414\n",
      "Epoch: 46, Batch: 252, D Loss: 0.10073667020209297, G Loss: 25.069482803344727\n",
      "Epoch: 46, Batch: 253, D Loss: 0.10577502102282024, G Loss: 25.14590072631836\n",
      "Epoch: 46, Batch: 254, D Loss: 0.09883057326706242, G Loss: 25.060148239135742\n",
      "Epoch: 46, Batch: 255, D Loss: 0.09706625343117482, G Loss: 24.803295135498047\n",
      "Epoch: 46, Batch: 256, D Loss: 0.10644191504325501, G Loss: 24.90634536743164\n",
      "Epoch: 46, Batch: 257, D Loss: 0.10087369383096086, G Loss: 25.029651641845703\n",
      "Epoch: 46, Batch: 258, D Loss: 0.09656471014723336, G Loss: 24.956649780273438\n",
      "Epoch: 46, Batch: 259, D Loss: 0.10326572508325013, G Loss: 25.009815216064453\n",
      "Epoch: 46, Batch: 260, D Loss: 0.0947537869292104, G Loss: 24.79233741760254\n",
      "Epoch: 46, Batch: 261, D Loss: 0.10225102306281292, G Loss: 24.760719299316406\n",
      "Epoch: 46, Batch: 262, D Loss: 0.09352193773805999, G Loss: 24.49725914001465\n",
      "Epoch: 46, Batch: 263, D Loss: 0.0992683321355736, G Loss: 24.442276000976562\n",
      "Epoch: 46, Batch: 264, D Loss: 0.10546711088206906, G Loss: 24.846845626831055\n",
      "Epoch: 46, Batch: 265, D Loss: 0.09660429508224487, G Loss: 25.041423797607422\n",
      "Epoch: 46, Batch: 266, D Loss: 0.09096422792254352, G Loss: 24.75785255432129\n",
      "Epoch: 46, Batch: 267, D Loss: 0.0957893803823395, G Loss: 24.383726119995117\n",
      "Epoch: 46, Batch: 268, D Loss: 0.10065107048893455, G Loss: 24.31183624267578\n",
      "Epoch: 46, Batch: 269, D Loss: 0.09555622936668327, G Loss: 24.323816299438477\n",
      "Epoch: 46, Batch: 270, D Loss: 0.09596011043910715, G Loss: 24.39418601989746\n",
      "Epoch: 46, Batch: 271, D Loss: 0.10179259629127227, G Loss: 24.723888397216797\n",
      "Epoch: 46, Batch: 272, D Loss: 0.10109244287764929, G Loss: 25.099437713623047\n",
      "Epoch: 46, Batch: 273, D Loss: 0.09910148382766248, G Loss: 25.254600524902344\n",
      "Epoch: 46, Batch: 274, D Loss: 0.10405363143006277, G Loss: 25.335458755493164\n",
      "Epoch: 46, Batch: 275, D Loss: 0.10338977724820107, G Loss: 25.298065185546875\n",
      "Epoch: 46, Batch: 276, D Loss: 0.09248094261374638, G Loss: 24.764785766601562\n",
      "Epoch: 46, Batch: 277, D Loss: 0.0980899110551481, G Loss: 24.251537322998047\n",
      "Epoch: 46, Batch: 278, D Loss: 0.09422421457224686, G Loss: 23.820030212402344\n",
      "Epoch: 46, Batch: 279, D Loss: 0.10121265055854525, G Loss: 23.954408645629883\n",
      "Epoch: 46, Batch: 280, D Loss: 0.09378157557863129, G Loss: 24.1247501373291\n",
      "Epoch: 46, Batch: 281, D Loss: 0.09577113391440979, G Loss: 24.35993766784668\n",
      "Epoch: 46, Batch: 282, D Loss: 0.09852924199048864, G Loss: 24.639556884765625\n",
      "Epoch: 46, Batch: 283, D Loss: 0.10305812210666936, G Loss: 25.002710342407227\n",
      "Epoch: 46, Batch: 284, D Loss: 0.09712601453739159, G Loss: 25.056232452392578\n",
      "Epoch: 46, Batch: 285, D Loss: 0.0950502902345184, G Loss: 24.782024383544922\n",
      "Epoch: 46, Batch: 286, D Loss: 0.10285448283883979, G Loss: 24.64735221862793\n",
      "Epoch: 46, Batch: 287, D Loss: 0.09890823067287101, G Loss: 24.52714729309082\n",
      "Epoch: 46, Batch: 288, D Loss: 0.09912128747651833, G Loss: 24.479867935180664\n",
      "Epoch: 46, Batch: 289, D Loss: 0.10485836864542561, G Loss: 24.72844696044922\n",
      "Epoch: 46, Batch: 290, D Loss: 0.10419310630112778, G Loss: 25.11048126220703\n",
      "Epoch: 46, Batch: 291, D Loss: 0.09371276200485032, G Loss: 24.975900650024414\n",
      "Epoch: 46, Batch: 292, D Loss: 0.1009293198664672, G Loss: 24.77253532409668\n",
      "Epoch: 46, Batch: 293, D Loss: 0.09390261770416215, G Loss: 24.293088912963867\n",
      "Epoch: 46, Batch: 294, D Loss: 0.10020880402728904, G Loss: 24.056703567504883\n",
      "Epoch: 46, Batch: 295, D Loss: 0.10057695956727496, G Loss: 24.159692764282227\n",
      "Epoch: 46, Batch: 296, D Loss: 0.09782391788024723, G Loss: 24.358062744140625\n",
      "Epoch: 46, Batch: 297, D Loss: 0.10058701784543397, G Loss: 24.66119956970215\n",
      "Epoch: 46, Batch: 298, D Loss: 0.0972476527186084, G Loss: 24.786075592041016\n",
      "Epoch: 46, Batch: 299, D Loss: 0.09358609468717159, G Loss: 24.552663803100586\n",
      "Epoch: 46, Batch: 300, D Loss: 0.09274616093812403, G Loss: 24.112215042114258\n",
      "Epoch: 46, Batch: 301, D Loss: 0.09757559003359315, G Loss: 23.872814178466797\n",
      "Epoch: 46, Batch: 302, D Loss: 0.10305801035860095, G Loss: 24.11551284790039\n",
      "Epoch: 46, Batch: 303, D Loss: 0.09359028191905444, G Loss: 24.293703079223633\n",
      "Epoch: 46, Batch: 304, D Loss: 0.1047061681856612, G Loss: 24.775239944458008\n",
      "Epoch: 46, Batch: 305, D Loss: 0.09661796689829659, G Loss: 24.942428588867188\n",
      "Epoch: 46, Batch: 306, D Loss: 0.10502905399273857, G Loss: 25.129356384277344\n",
      "Epoch: 46, Batch: 307, D Loss: 0.09659586847511364, G Loss: 24.91507911682129\n",
      "Epoch: 46, Batch: 308, D Loss: 0.09923999757482278, G Loss: 24.567075729370117\n",
      "Epoch: 46, Batch: 309, D Loss: 0.10066878796832221, G Loss: 24.336721420288086\n",
      "Epoch: 46, Batch: 310, D Loss: 0.09686961771558522, G Loss: 24.132389068603516\n",
      "Epoch: 46, Batch: 311, D Loss: 0.10388516636189751, G Loss: 24.33389663696289\n",
      "Epoch: 46, Batch: 312, D Loss: 0.09392384441004045, G Loss: 24.412128448486328\n",
      "Epoch: 46, Batch: 313, D Loss: 0.10059917719309616, G Loss: 24.591238021850586\n",
      "Epoch: 46, Batch: 314, D Loss: 0.09997084737779229, G Loss: 24.76201629638672\n",
      "Epoch: 46, Batch: 315, D Loss: 0.09946747870089472, G Loss: 24.860898971557617\n",
      "Epoch: 46, Batch: 316, D Loss: 0.10032854975062082, G Loss: 24.874818801879883\n",
      "Epoch: 46, Batch: 317, D Loss: 0.10017207265709228, G Loss: 24.822362899780273\n",
      "Epoch: 46, Batch: 318, D Loss: 0.09876691550914224, G Loss: 24.67161750793457\n",
      "Epoch: 46, Batch: 319, D Loss: 0.09767445177910478, G Loss: 24.472719192504883\n",
      "Epoch: 46, Batch: 320, D Loss: 0.09916537256281568, G Loss: 24.38389778137207\n",
      "Epoch: 46, Batch: 321, D Loss: 0.10268098117082336, G Loss: 24.57732582092285\n",
      "Epoch: 46, Batch: 322, D Loss: 0.09352224321258398, G Loss: 24.53221893310547\n",
      "Epoch: 46, Batch: 323, D Loss: 0.10436051339899698, G Loss: 24.749649047851562\n",
      "Epoch: 46, Batch: 324, D Loss: 0.09677204490577526, G Loss: 24.797903060913086\n",
      "Epoch: 46, Batch: 325, D Loss: 0.09499653429734922, G Loss: 24.602373123168945\n",
      "Epoch: 46, Batch: 326, D Loss: 0.09217409045805591, G Loss: 24.163633346557617\n",
      "Epoch: 46, Batch: 327, D Loss: 0.09778685869565895, G Loss: 23.964637756347656\n",
      "Epoch: 46, Batch: 328, D Loss: 0.09279637040795459, G Loss: 23.840293884277344\n",
      "Epoch: 46, Batch: 329, D Loss: 0.1017346754853385, G Loss: 24.19972801208496\n",
      "Epoch: 46, Batch: 330, D Loss: 0.10065590591419288, G Loss: 24.710886001586914\n",
      "Epoch: 46, Batch: 331, D Loss: 0.10140996427086596, G Loss: 25.131959915161133\n",
      "Epoch: 46, Batch: 332, D Loss: 0.09810422361491136, G Loss: 25.177738189697266\n",
      "Epoch: 46, Batch: 333, D Loss: 0.09714986384597794, G Loss: 24.87152671813965\n",
      "Epoch: 46, Batch: 334, D Loss: 0.09589718283268639, G Loss: 24.33635711669922\n",
      "Epoch: 46, Batch: 335, D Loss: 0.10107989610776902, G Loss: 24.089359283447266\n",
      "Epoch: 46, Batch: 336, D Loss: 0.10566963256881198, G Loss: 24.3869686126709\n",
      "Epoch: 46, Batch: 337, D Loss: 0.09738843144103465, G Loss: 24.648128509521484\n",
      "Epoch: 46, Batch: 338, D Loss: 0.09677650780435454, G Loss: 24.72170639038086\n",
      "Epoch: 46, Batch: 339, D Loss: 0.09697479010594943, G Loss: 24.621932983398438\n",
      "Epoch: 46, Batch: 340, D Loss: 0.09473136813624114, G Loss: 24.339580535888672\n",
      "Epoch: 46, Batch: 341, D Loss: 0.0984031260157387, G Loss: 24.21109390258789\n",
      "Epoch: 46, Batch: 342, D Loss: 0.10125036539045497, G Loss: 24.38014793395996\n",
      "Epoch: 46, Batch: 343, D Loss: 0.11010967195925804, G Loss: 25.081146240234375\n",
      "Epoch: 46, Batch: 344, D Loss: 0.09822294861616383, G Loss: 25.41178321838379\n",
      "Epoch: 46, Batch: 345, D Loss: 0.10203333944529158, G Loss: 25.466777801513672\n",
      "Epoch: 46, Batch: 346, D Loss: 0.10030470788973274, G Loss: 25.226640701293945\n",
      "Epoch: 46, Batch: 347, D Loss: 0.10127957165910587, G Loss: 24.86530113220215\n",
      "Epoch: 46, Batch: 348, D Loss: 0.09985984117728311, G Loss: 24.554285049438477\n",
      "Epoch: 46, Batch: 349, D Loss: 0.09819778056160086, G Loss: 24.349830627441406\n",
      "Epoch: 46, Batch: 350, D Loss: 0.09937371314868904, G Loss: 24.39818572998047\n",
      "Epoch: 46, Batch: 351, D Loss: 0.10072821379778589, G Loss: 24.718677520751953\n",
      "Epoch: 46, Batch: 352, D Loss: 0.10186095536488751, G Loss: 25.14839744567871\n",
      "Epoch: 46, Batch: 353, D Loss: 0.10101480782540029, G Loss: 25.460168838500977\n",
      "Epoch: 46, Batch: 354, D Loss: 0.09461289644728862, G Loss: 25.257793426513672\n",
      "Epoch: 46, Batch: 355, D Loss: 0.09424138069876965, G Loss: 24.68711280822754\n",
      "Epoch: 46, Batch: 356, D Loss: 0.09709911049621531, G Loss: 24.226938247680664\n",
      "Epoch: 46, Batch: 357, D Loss: 0.09932824225788435, G Loss: 24.164243698120117\n",
      "Epoch: 46, Batch: 358, D Loss: 0.09486529232594741, G Loss: 24.259620666503906\n",
      "Epoch: 46, Batch: 359, D Loss: 0.10050400347708352, G Loss: 24.641225814819336\n",
      "Epoch: 46, Batch: 360, D Loss: 0.099448889501907, G Loss: 25.06182289123535\n",
      "Epoch: 46, Batch: 361, D Loss: 0.09529809654381023, G Loss: 25.153493881225586\n",
      "Epoch: 46, Batch: 362, D Loss: 0.09354630113344363, G Loss: 24.856184005737305\n",
      "Epoch: 46, Batch: 363, D Loss: 0.09803241492267131, G Loss: 24.534839630126953\n",
      "Epoch: 46, Batch: 364, D Loss: 0.0986382514357507, G Loss: 24.39272689819336\n",
      "Epoch: 46, Batch: 365, D Loss: 0.1047958135713717, G Loss: 24.69209098815918\n",
      "Epoch: 46, Batch: 366, D Loss: 0.10086335242572672, G Loss: 25.060556411743164\n",
      "Epoch: 46, Batch: 367, D Loss: 0.09827670455576178, G Loss: 25.231855392456055\n",
      "Epoch: 46, Batch: 368, D Loss: 0.10270899534757204, G Loss: 25.29840850830078\n",
      "Epoch: 46, Batch: 369, D Loss: 0.10033314675646839, G Loss: 25.160017013549805\n",
      "Epoch: 46, Batch: 370, D Loss: 0.09756031633129424, G Loss: 24.823999404907227\n",
      "Epoch: 46, Batch: 371, D Loss: 0.09926071763992288, G Loss: 24.55534553527832\n",
      "Epoch: 46, Batch: 372, D Loss: 0.10276538879742815, G Loss: 24.590211868286133\n",
      "Epoch: 46, Batch: 373, D Loss: 0.09317123145968449, G Loss: 24.488847732543945\n",
      "Epoch: 46, Batch: 374, D Loss: 0.08872187138995195, G Loss: 24.138986587524414\n",
      "Epoch: 46, Batch: 375, D Loss: 0.09717819841402675, G Loss: 24.088693618774414\n",
      "Epoch: 46, Batch: 376, D Loss: 0.10429926962997633, G Loss: 24.574403762817383\n",
      "Epoch: 46, Batch: 377, D Loss: 0.09643027187252738, G Loss: 24.97844123840332\n",
      "Epoch: 46, Batch: 378, D Loss: 0.10058262199764308, G Loss: 25.293983459472656\n",
      "Epoch: 46, Batch: 379, D Loss: 0.09665773809484132, G Loss: 25.255949020385742\n",
      "Epoch: 46, Batch: 380, D Loss: 0.10367947817392364, G Loss: 25.23479461669922\n",
      "Epoch: 46, Batch: 381, D Loss: 0.0960398987000034, G Loss: 24.930908203125\n",
      "Epoch: 46, Batch: 382, D Loss: 0.10065641255022711, G Loss: 24.709150314331055\n",
      "Epoch: 46, Batch: 383, D Loss: 0.09434285760999658, G Loss: 24.433168411254883\n",
      "Epoch: 46, Batch: 384, D Loss: 0.10078161211010947, G Loss: 24.487930297851562\n",
      "Epoch: 46, Batch: 385, D Loss: 0.10324975104070641, G Loss: 24.903823852539062\n",
      "Epoch: 46, Batch: 386, D Loss: 0.10117481649538858, G Loss: 25.310977935791016\n",
      "Epoch: 46, Batch: 387, D Loss: 0.10366669297641277, G Loss: 25.66366195678711\n",
      "Epoch: 46, Batch: 388, D Loss: 0.10047097504489877, G Loss: 25.69937515258789\n",
      "Epoch: 46, Batch: 389, D Loss: 0.09542618692366968, G Loss: 25.216405868530273\n",
      "Epoch: 46, Batch: 390, D Loss: 0.10375306010914744, G Loss: 24.87708282470703\n",
      "Epoch: 46, Batch: 391, D Loss: 0.09624220431797698, G Loss: 24.521224975585938\n",
      "Epoch: 46, Batch: 392, D Loss: 0.1022136807550818, G Loss: 24.572370529174805\n",
      "Epoch: 46, Batch: 393, D Loss: 0.10140729696463588, G Loss: 24.8812313079834\n",
      "Epoch: 46, Batch: 394, D Loss: 0.09926086664871663, G Loss: 25.16944694519043\n",
      "Epoch: 46, Batch: 395, D Loss: 0.10129138082788669, G Loss: 25.3875732421875\n",
      "Epoch: 46, Batch: 396, D Loss: 0.09632726759232309, G Loss: 25.224159240722656\n",
      "Epoch: 46, Batch: 397, D Loss: 0.09948812425775888, G Loss: 24.95500946044922\n",
      "Epoch: 46, Batch: 398, D Loss: 0.09813112766393106, G Loss: 24.67288589477539\n",
      "Epoch: 46, Batch: 399, D Loss: 0.09390095622511307, G Loss: 24.31266212463379\n",
      "Epoch: 46, Batch: 400, D Loss: 0.10140383244914354, G Loss: 24.3504638671875\n",
      "Epoch: 46, Batch: 401, D Loss: 0.09317666293520763, G Loss: 24.349512100219727\n",
      "Epoch: 46, Batch: 402, D Loss: 0.09977797420030221, G Loss: 24.550046920776367\n",
      "Epoch: 46, Batch: 403, D Loss: 0.09394891561139763, G Loss: 24.597558975219727\n",
      "Epoch: 46, Batch: 404, D Loss: 0.09915712476768965, G Loss: 24.683942794799805\n",
      "Epoch: 46, Batch: 405, D Loss: 0.09623882920518277, G Loss: 24.652637481689453\n",
      "Epoch: 46, Batch: 406, D Loss: 0.1033428534956187, G Loss: 24.802833557128906\n",
      "Epoch: 46, Batch: 407, D Loss: 0.09670090676226839, G Loss: 24.74291229248047\n",
      "Epoch: 46, Batch: 408, D Loss: 0.097908511767439, G Loss: 24.61824607849121\n",
      "Epoch: 46, Batch: 409, D Loss: 0.09736153484492747, G Loss: 24.466115951538086\n",
      "Epoch: 46, Batch: 410, D Loss: 0.09699504078717934, G Loss: 24.313405990600586\n",
      "Epoch: 46, Batch: 411, D Loss: 0.1008711084856896, G Loss: 24.377138137817383\n",
      "Epoch: 46, Batch: 412, D Loss: 0.10621195287538297, G Loss: 24.818450927734375\n",
      "Epoch: 46, Batch: 413, D Loss: 0.10328470171164941, G Loss: 25.240673065185547\n",
      "Epoch: 46, Batch: 414, D Loss: 0.10152679682278412, G Loss: 25.4056453704834\n",
      "Epoch: 46, Batch: 415, D Loss: 0.1010663360407401, G Loss: 25.254446029663086\n",
      "Epoch: 46, Batch: 416, D Loss: 0.10397045314919956, G Loss: 25.024858474731445\n",
      "Epoch: 46, Batch: 417, D Loss: 0.10052084923605081, G Loss: 24.67391014099121\n",
      "Epoch: 46, Batch: 418, D Loss: 0.10530468822526594, G Loss: 24.59857749938965\n",
      "Epoch: 46, Batch: 419, D Loss: 0.09301659466065405, G Loss: 24.275705337524414\n",
      "Epoch: 46, Batch: 420, D Loss: 0.10252306611761101, G Loss: 24.299062728881836\n",
      "Epoch: 46, Batch: 421, D Loss: 0.09740764649063768, G Loss: 24.379674911499023\n",
      "Epoch: 46, Batch: 422, D Loss: 0.10049898923586671, G Loss: 24.610815048217773\n",
      "Epoch: 46, Batch: 423, D Loss: 0.09631347657249373, G Loss: 24.658538818359375\n",
      "Epoch: 46, Batch: 424, D Loss: 0.10170837492669718, G Loss: 24.77484703063965\n",
      "Epoch: 46, Batch: 425, D Loss: 0.0968557819814049, G Loss: 24.710575103759766\n",
      "Epoch: 46, Batch: 426, D Loss: 0.09948818386560644, G Loss: 24.64586639404297\n",
      "Epoch: 46, Batch: 427, D Loss: 0.09907164425678805, G Loss: 24.586307525634766\n",
      "Epoch: 46, Batch: 428, D Loss: 0.09985268862092388, G Loss: 24.610336303710938\n",
      "Epoch: 46, Batch: 429, D Loss: 0.09809791297740202, G Loss: 24.62071418762207\n",
      "Epoch: 46, Batch: 430, D Loss: 0.09394332767648993, G Loss: 24.439571380615234\n",
      "Epoch: 46, Batch: 431, D Loss: 0.09878937901305901, G Loss: 24.403465270996094\n",
      "Epoch: 46, Batch: 432, D Loss: 0.09810865671662354, G Loss: 24.46650505065918\n",
      "Epoch: 46, Batch: 433, D Loss: 0.09899319709433929, G Loss: 24.629344940185547\n",
      "Epoch: 46, Batch: 434, D Loss: 0.09578493238488656, G Loss: 24.653564453125\n",
      "Epoch: 46, Batch: 435, D Loss: 0.10253527016328705, G Loss: 24.859312057495117\n",
      "Epoch: 46, Batch: 436, D Loss: 0.0972293466409485, G Loss: 24.85978126525879\n",
      "Epoch: 46, Batch: 437, D Loss: 0.10659429431663825, G Loss: 25.10481071472168\n",
      "Epoch: 46, Batch: 438, D Loss: 0.1000634878935141, G Loss: 25.14209747314453\n",
      "Epoch: 46, Batch: 439, D Loss: 0.09782730043628711, G Loss: 24.87213706970215\n",
      "Epoch: 46, Batch: 440, D Loss: 0.09821633995547834, G Loss: 24.482391357421875\n",
      "Epoch: 46, Batch: 441, D Loss: 0.09681104125004207, G Loss: 24.117168426513672\n",
      "Epoch: 46, Batch: 442, D Loss: 0.09689678998632961, G Loss: 23.951663970947266\n",
      "Epoch: 46, Batch: 443, D Loss: 0.1014439612802242, G Loss: 24.184856414794922\n",
      "Epoch: 46, Batch: 444, D Loss: 0.10547181965054406, G Loss: 24.800935745239258\n",
      "Epoch: 46, Batch: 445, D Loss: 0.10219246149709224, G Loss: 25.31902503967285\n",
      "Epoch: 46, Batch: 446, D Loss: 0.09845868498585084, G Loss: 25.343944549560547\n",
      "Epoch: 46, Batch: 447, D Loss: 0.09969511628727037, G Loss: 25.048362731933594\n",
      "Epoch: 46, Batch: 448, D Loss: 0.10569988191854235, G Loss: 24.870574951171875\n",
      "Epoch: 46, Batch: 449, D Loss: 0.09485943616438226, G Loss: 24.419574737548828\n",
      "Epoch: 46, Batch: 450, D Loss: 0.09264719487902252, G Loss: 23.858829498291016\n",
      "Epoch: 46, Batch: 451, D Loss: 0.09966738524354178, G Loss: 23.75044822692871\n",
      "Epoch: 46, Batch: 452, D Loss: 0.10309433939000666, G Loss: 24.184005737304688\n",
      "Epoch: 46, Batch: 453, D Loss: 0.1012504845971005, G Loss: 24.801673889160156\n",
      "Epoch: 46, Batch: 454, D Loss: 0.10423775762929834, G Loss: 25.42891502380371\n",
      "Epoch: 46, Batch: 455, D Loss: 0.0947729051158761, G Loss: 25.41167640686035\n",
      "Epoch: 46, Batch: 456, D Loss: 0.09484884888543245, G Loss: 24.881431579589844\n",
      "Epoch: 46, Batch: 457, D Loss: 0.0922473743680678, G Loss: 24.02173614501953\n",
      "Epoch: 46, Batch: 458, D Loss: 0.09909240158717725, G Loss: 23.60004425048828\n",
      "Epoch: 46, Batch: 459, D Loss: 0.09940674903695103, G Loss: 23.68939971923828\n",
      "Epoch: 46, Batch: 460, D Loss: 0.09364834430080411, G Loss: 23.948558807373047\n",
      "Epoch: 46, Batch: 461, D Loss: 0.10130377860306757, G Loss: 24.573246002197266\n",
      "Epoch: 46, Batch: 462, D Loss: 0.09739603103033216, G Loss: 25.053627014160156\n",
      "Epoch: 46, Batch: 463, D Loss: 0.09977854043824688, G Loss: 25.29828453063965\n",
      "Epoch: 46, Batch: 464, D Loss: 0.10443734378095045, G Loss: 25.463272094726562\n",
      "Epoch: 46, Batch: 465, D Loss: 0.10399876535378226, G Loss: 25.45250701904297\n",
      "Epoch: 46, Batch: 466, D Loss: 0.10598264635061032, G Loss: 25.40931510925293\n",
      "Epoch: 46, Batch: 467, D Loss: 0.09567168355571488, G Loss: 24.96695899963379\n",
      "Epoch: 47, Batch: 0, D Loss: 0.09829603136521807, G Loss: 24.461441040039062\n",
      "Epoch: 47, Batch: 1, D Loss: 0.09848056735017321, G Loss: 24.1397762298584\n",
      "Epoch: 47, Batch: 2, D Loss: 0.10295233877016044, G Loss: 24.307096481323242\n",
      "Epoch: 47, Batch: 3, D Loss: 0.10072417558370483, G Loss: 24.69648551940918\n",
      "Epoch: 47, Batch: 4, D Loss: 0.09913237393696875, G Loss: 25.017051696777344\n",
      "Epoch: 47, Batch: 5, D Loss: 0.0979488790099455, G Loss: 25.13348388671875\n",
      "Epoch: 47, Batch: 6, D Loss: 0.10022455454485549, G Loss: 25.117176055908203\n",
      "Epoch: 47, Batch: 7, D Loss: 0.1032578796209554, G Loss: 25.132888793945312\n",
      "Epoch: 47, Batch: 8, D Loss: 0.09185680747799198, G Loss: 24.69063949584961\n",
      "Epoch: 47, Batch: 9, D Loss: 0.09286995233367541, G Loss: 24.141828536987305\n",
      "Epoch: 47, Batch: 10, D Loss: 0.0993578136141177, G Loss: 24.027841567993164\n",
      "Epoch: 47, Batch: 11, D Loss: 0.09934210778897434, G Loss: 24.271461486816406\n",
      "Epoch: 47, Batch: 12, D Loss: 0.09601832927502049, G Loss: 24.571216583251953\n",
      "Epoch: 47, Batch: 13, D Loss: 0.10360646993732314, G Loss: 25.091453552246094\n",
      "Epoch: 47, Batch: 14, D Loss: 0.09727679938649687, G Loss: 25.288331985473633\n",
      "Epoch: 47, Batch: 15, D Loss: 0.09878368676250511, G Loss: 25.212182998657227\n",
      "Epoch: 47, Batch: 16, D Loss: 0.10101051629206541, G Loss: 25.035202026367188\n",
      "Epoch: 47, Batch: 17, D Loss: 0.10036104173223676, G Loss: 24.80789566040039\n",
      "Epoch: 47, Batch: 18, D Loss: 0.09569459409513897, G Loss: 24.494352340698242\n",
      "Epoch: 47, Batch: 19, D Loss: 0.09587758780839319, G Loss: 24.243690490722656\n",
      "Epoch: 47, Batch: 20, D Loss: 0.10455065966956371, G Loss: 24.48340606689453\n",
      "Epoch: 47, Batch: 21, D Loss: 0.0923143103832952, G Loss: 24.519824981689453\n",
      "Epoch: 47, Batch: 22, D Loss: 0.10267908872145386, G Loss: 24.793895721435547\n",
      "Epoch: 47, Batch: 23, D Loss: 0.09574594349495484, G Loss: 24.854772567749023\n",
      "Epoch: 47, Batch: 24, D Loss: 0.09859982878786702, G Loss: 24.821874618530273\n",
      "Epoch: 47, Batch: 25, D Loss: 0.10187866539572178, G Loss: 24.869775772094727\n",
      "Epoch: 47, Batch: 26, D Loss: 0.10780607909631908, G Loss: 25.1934757232666\n",
      "Epoch: 47, Batch: 27, D Loss: 0.105275653307598, G Loss: 25.477096557617188\n",
      "Epoch: 47, Batch: 28, D Loss: 0.0952688902666604, G Loss: 25.190399169921875\n",
      "Epoch: 47, Batch: 29, D Loss: 0.09382504225606464, G Loss: 24.491596221923828\n",
      "Epoch: 47, Batch: 30, D Loss: 0.09810301663016635, G Loss: 23.961530685424805\n",
      "Epoch: 47, Batch: 31, D Loss: 0.10323666038068768, G Loss: 23.982831954956055\n",
      "Epoch: 47, Batch: 32, D Loss: 0.09697595985453832, G Loss: 24.202882766723633\n",
      "Epoch: 47, Batch: 33, D Loss: 0.09677316249758042, G Loss: 24.466611862182617\n",
      "Epoch: 47, Batch: 34, D Loss: 0.09433253110579082, G Loss: 24.565040588378906\n",
      "Epoch: 47, Batch: 35, D Loss: 0.0997484773499187, G Loss: 24.665706634521484\n",
      "Epoch: 47, Batch: 36, D Loss: 0.0963832885126575, G Loss: 24.61469268798828\n",
      "Epoch: 47, Batch: 37, D Loss: 0.09697626532244129, G Loss: 24.438356399536133\n",
      "Epoch: 47, Batch: 38, D Loss: 0.10157373548770977, G Loss: 24.439485549926758\n",
      "Epoch: 47, Batch: 39, D Loss: 0.10069135577620206, G Loss: 24.573225021362305\n",
      "Epoch: 47, Batch: 40, D Loss: 0.09680928290955058, G Loss: 24.571918487548828\n",
      "Epoch: 47, Batch: 41, D Loss: 0.09179281444596794, G Loss: 24.28431510925293\n",
      "Epoch: 47, Batch: 42, D Loss: 0.09757506848930612, G Loss: 24.11956214904785\n",
      "Epoch: 47, Batch: 43, D Loss: 0.09543387593572727, G Loss: 24.05375099182129\n",
      "Epoch: 47, Batch: 44, D Loss: 0.09909795971329656, G Loss: 24.25969123840332\n",
      "Epoch: 47, Batch: 45, D Loss: 0.09634689988001893, G Loss: 24.4804630279541\n",
      "Epoch: 47, Batch: 46, D Loss: 0.09328733385764405, G Loss: 24.500560760498047\n",
      "Epoch: 47, Batch: 47, D Loss: 0.10056275875449931, G Loss: 24.621545791625977\n",
      "Epoch: 47, Batch: 48, D Loss: 0.10587063432571214, G Loss: 24.998046875\n",
      "Epoch: 47, Batch: 49, D Loss: 0.10009759665177465, G Loss: 25.15155029296875\n",
      "Epoch: 47, Batch: 50, D Loss: 0.0944107920002667, G Loss: 24.81739616394043\n",
      "Epoch: 47, Batch: 51, D Loss: 0.10144847632431628, G Loss: 24.514984130859375\n",
      "Epoch: 47, Batch: 52, D Loss: 0.1070185229289931, G Loss: 24.60285186767578\n",
      "Epoch: 47, Batch: 53, D Loss: 0.09745823592987292, G Loss: 24.590457916259766\n",
      "Epoch: 47, Batch: 54, D Loss: 0.09266015143413431, G Loss: 24.311485290527344\n",
      "Epoch: 47, Batch: 55, D Loss: 0.10082603992436638, G Loss: 24.280668258666992\n",
      "Epoch: 47, Batch: 56, D Loss: 0.09536962212584256, G Loss: 24.245609283447266\n",
      "Epoch: 47, Batch: 57, D Loss: 0.09729555250646545, G Loss: 24.30331802368164\n",
      "Epoch: 47, Batch: 58, D Loss: 0.09827899934151829, G Loss: 24.449514389038086\n",
      "Epoch: 47, Batch: 59, D Loss: 0.09717014433084288, G Loss: 24.56883430480957\n",
      "Epoch: 47, Batch: 60, D Loss: 0.10587146879097258, G Loss: 24.9927978515625\n",
      "Epoch: 47, Batch: 61, D Loss: 0.09421116859413646, G Loss: 25.010690689086914\n",
      "Epoch: 47, Batch: 62, D Loss: 0.09646660090273106, G Loss: 24.768522262573242\n",
      "Epoch: 47, Batch: 63, D Loss: 0.10422982276374895, G Loss: 24.73914909362793\n",
      "Epoch: 47, Batch: 64, D Loss: 0.09441623837761388, G Loss: 24.53095245361328\n",
      "Epoch: 47, Batch: 65, D Loss: 0.09785366059552543, G Loss: 24.3780574798584\n",
      "Epoch: 47, Batch: 66, D Loss: 0.09684646130948686, G Loss: 24.30997085571289\n",
      "Epoch: 47, Batch: 67, D Loss: 0.10360484571447166, G Loss: 24.6096134185791\n",
      "Epoch: 47, Batch: 68, D Loss: 0.09411916137736573, G Loss: 24.668066024780273\n",
      "Epoch: 47, Batch: 69, D Loss: 0.10055436194852557, G Loss: 24.785966873168945\n",
      "Epoch: 47, Batch: 70, D Loss: 0.10357438773687985, G Loss: 24.993270874023438\n",
      "Epoch: 47, Batch: 71, D Loss: 0.10000764579263587, G Loss: 25.038795471191406\n",
      "Epoch: 47, Batch: 72, D Loss: 0.0870070010517577, G Loss: 24.390380859375\n",
      "Epoch: 47, Batch: 73, D Loss: 0.09461000563474833, G Loss: 23.779653549194336\n",
      "Epoch: 47, Batch: 74, D Loss: 0.0922299623785186, G Loss: 23.345035552978516\n",
      "Epoch: 47, Batch: 75, D Loss: 0.09304923567987858, G Loss: 23.26395034790039\n",
      "Epoch: 47, Batch: 76, D Loss: 0.10358124974165996, G Loss: 23.929899215698242\n",
      "Epoch: 47, Batch: 77, D Loss: 0.0930471792968465, G Loss: 24.48185157775879\n",
      "Epoch: 47, Batch: 78, D Loss: 0.10019266606265805, G Loss: 24.998018264770508\n",
      "Epoch: 47, Batch: 79, D Loss: 0.09415349364963597, G Loss: 25.03353500366211\n",
      "Epoch: 47, Batch: 80, D Loss: 0.09661592543910051, G Loss: 24.738426208496094\n",
      "Epoch: 47, Batch: 81, D Loss: 0.10071812571135923, G Loss: 24.46611785888672\n",
      "Epoch: 47, Batch: 82, D Loss: 0.0950774029042931, G Loss: 24.072622299194336\n",
      "Epoch: 47, Batch: 83, D Loss: 0.09667810799709457, G Loss: 23.807371139526367\n",
      "Epoch: 47, Batch: 84, D Loss: 0.09298837187442974, G Loss: 23.611488342285156\n",
      "Epoch: 47, Batch: 85, D Loss: 0.10160899164707306, G Loss: 23.881601333618164\n",
      "Epoch: 47, Batch: 86, D Loss: 0.09900527449161516, G Loss: 24.30554962158203\n",
      "Epoch: 47, Batch: 87, D Loss: 0.10206064582953521, G Loss: 24.780797958374023\n",
      "Epoch: 47, Batch: 88, D Loss: 0.10199879110604357, G Loss: 25.066251754760742\n",
      "Epoch: 47, Batch: 89, D Loss: 0.09666492045660853, G Loss: 24.832551956176758\n",
      "Epoch: 47, Batch: 90, D Loss: 0.09828909487581737, G Loss: 24.36517333984375\n",
      "Epoch: 47, Batch: 91, D Loss: 0.09467711301496035, G Loss: 23.720434188842773\n",
      "Epoch: 47, Batch: 92, D Loss: 0.09732465449050058, G Loss: 23.33649444580078\n",
      "Epoch: 47, Batch: 93, D Loss: 0.10429770502704455, G Loss: 23.572525024414062\n",
      "Epoch: 47, Batch: 94, D Loss: 0.09597022833932245, G Loss: 23.856746673583984\n",
      "Epoch: 47, Batch: 95, D Loss: 0.09815075995428295, G Loss: 24.125822067260742\n",
      "Epoch: 47, Batch: 96, D Loss: 0.10434865952898566, G Loss: 24.508520126342773\n",
      "Epoch: 47, Batch: 97, D Loss: 0.09954945744133742, G Loss: 24.65696907043457\n",
      "Epoch: 47, Batch: 98, D Loss: 0.1006362438303982, G Loss: 24.576679229736328\n",
      "Epoch: 47, Batch: 99, D Loss: 0.0985237807160742, G Loss: 24.259180068969727\n",
      "Epoch: 47, Batch: 100, D Loss: 0.10437135399964122, G Loss: 24.109180450439453\n",
      "Epoch: 47, Batch: 101, D Loss: 0.10460417719308475, G Loss: 24.200159072875977\n",
      "Epoch: 47, Batch: 102, D Loss: 0.09309843184306243, G Loss: 23.971630096435547\n",
      "Epoch: 47, Batch: 103, D Loss: 0.1019170135454643, G Loss: 23.963603973388672\n",
      "Epoch: 47, Batch: 104, D Loss: 0.1034549996431208, G Loss: 24.183216094970703\n",
      "Epoch: 47, Batch: 105, D Loss: 0.1045344323048639, G Loss: 24.561025619506836\n",
      "Epoch: 47, Batch: 106, D Loss: 0.09727700055686692, G Loss: 24.62550926208496\n",
      "Epoch: 47, Batch: 107, D Loss: 0.0949662029862063, G Loss: 24.31532096862793\n",
      "Epoch: 47, Batch: 108, D Loss: 0.09646680952852812, G Loss: 23.87640380859375\n",
      "Epoch: 47, Batch: 109, D Loss: 0.09889248015947956, G Loss: 23.614482879638672\n",
      "Epoch: 47, Batch: 110, D Loss: 0.09823916110259565, G Loss: 23.568557739257812\n",
      "Epoch: 47, Batch: 111, D Loss: 0.10032604637348003, G Loss: 23.78999137878418\n",
      "Epoch: 47, Batch: 112, D Loss: 0.10111842306365754, G Loss: 24.178556442260742\n",
      "Epoch: 47, Batch: 113, D Loss: 0.10416239501247775, G Loss: 24.696046829223633\n",
      "Epoch: 47, Batch: 114, D Loss: 0.09997026623156635, G Loss: 24.866191864013672\n",
      "Epoch: 47, Batch: 115, D Loss: 0.10403776169622832, G Loss: 24.852447509765625\n",
      "Epoch: 47, Batch: 116, D Loss: 0.09669752420000118, G Loss: 24.43099594116211\n",
      "Epoch: 47, Batch: 117, D Loss: 0.10081063957540502, G Loss: 24.02517318725586\n",
      "Epoch: 47, Batch: 118, D Loss: 0.10749769212607625, G Loss: 24.075902938842773\n",
      "Epoch: 47, Batch: 119, D Loss: 0.10337646307070392, G Loss: 24.356449127197266\n",
      "Epoch: 47, Batch: 120, D Loss: 0.09762236477207284, G Loss: 24.4429874420166\n",
      "Epoch: 47, Batch: 121, D Loss: 0.1002176255108239, G Loss: 24.453733444213867\n",
      "Epoch: 47, Batch: 122, D Loss: 0.09988370539005148, G Loss: 24.37883949279785\n",
      "Epoch: 47, Batch: 123, D Loss: 0.09806128592714242, G Loss: 24.2061767578125\n",
      "Epoch: 47, Batch: 124, D Loss: 0.10320962967011788, G Loss: 24.22178077697754\n",
      "Epoch: 47, Batch: 125, D Loss: 0.1068907752760502, G Loss: 24.546987533569336\n",
      "Epoch: 47, Batch: 126, D Loss: 0.09706963599813799, G Loss: 24.558691024780273\n",
      "Epoch: 47, Batch: 127, D Loss: 0.09847630561578971, G Loss: 24.38823890686035\n",
      "Epoch: 47, Batch: 128, D Loss: 0.10616744310898929, G Loss: 24.456384658813477\n",
      "Epoch: 47, Batch: 129, D Loss: 0.10323537887271123, G Loss: 24.566797256469727\n",
      "Epoch: 47, Batch: 130, D Loss: 0.0946404636028261, G Loss: 24.318239212036133\n",
      "Epoch: 47, Batch: 131, D Loss: 0.09974958749227895, G Loss: 24.024316787719727\n",
      "Epoch: 47, Batch: 132, D Loss: 0.09195961060511472, G Loss: 23.543941497802734\n",
      "Epoch: 47, Batch: 133, D Loss: 0.0988781452501146, G Loss: 23.39451789855957\n",
      "Epoch: 47, Batch: 134, D Loss: 0.09448735419408588, G Loss: 23.386465072631836\n",
      "Epoch: 47, Batch: 135, D Loss: 0.09995932134943344, G Loss: 23.71155548095703\n",
      "Epoch: 47, Batch: 136, D Loss: 0.09754026683239433, G Loss: 24.098186492919922\n",
      "Epoch: 47, Batch: 137, D Loss: 0.0934979766771425, G Loss: 24.17717170715332\n",
      "Epoch: 47, Batch: 138, D Loss: 0.09930285812980012, G Loss: 24.207914352416992\n",
      "Epoch: 47, Batch: 139, D Loss: 0.09931305052391595, G Loss: 24.197511672973633\n",
      "Epoch: 47, Batch: 140, D Loss: 0.10227645190066958, G Loss: 24.262826919555664\n",
      "Epoch: 47, Batch: 141, D Loss: 0.1024945974485715, G Loss: 24.389921188354492\n",
      "Epoch: 47, Batch: 142, D Loss: 0.0962377935786041, G Loss: 24.243040084838867\n",
      "Epoch: 47, Batch: 143, D Loss: 0.09693600984105845, G Loss: 24.004369735717773\n",
      "Epoch: 47, Batch: 144, D Loss: 0.09812030198254429, G Loss: 23.82567596435547\n",
      "Epoch: 47, Batch: 145, D Loss: 0.1024716347665316, G Loss: 23.96027946472168\n",
      "Epoch: 47, Batch: 146, D Loss: 0.09646459670751112, G Loss: 24.047103881835938\n",
      "Epoch: 47, Batch: 147, D Loss: 0.09546642752317519, G Loss: 24.03121566772461\n",
      "Epoch: 47, Batch: 148, D Loss: 0.1024110913443431, G Loss: 24.207326889038086\n",
      "Epoch: 47, Batch: 149, D Loss: 0.09501613678104004, G Loss: 24.18045997619629\n",
      "Epoch: 47, Batch: 150, D Loss: 0.10266004504228202, G Loss: 24.332233428955078\n",
      "Epoch: 47, Batch: 151, D Loss: 0.09883257747999966, G Loss: 24.404321670532227\n",
      "Epoch: 47, Batch: 152, D Loss: 0.09821436555476815, G Loss: 24.369226455688477\n",
      "Epoch: 47, Batch: 153, D Loss: 0.10305380077408495, G Loss: 24.468311309814453\n",
      "Epoch: 47, Batch: 154, D Loss: 0.10219943524518492, G Loss: 24.58470344543457\n",
      "Epoch: 47, Batch: 155, D Loss: 0.10014492274392738, G Loss: 24.56645965576172\n",
      "Epoch: 47, Batch: 156, D Loss: 0.09721013904832966, G Loss: 24.326845169067383\n",
      "Epoch: 47, Batch: 157, D Loss: 0.10220712424765624, G Loss: 24.218685150146484\n",
      "Epoch: 47, Batch: 158, D Loss: 0.09410972895010435, G Loss: 23.92254638671875\n",
      "Epoch: 47, Batch: 159, D Loss: 0.10275822134795023, G Loss: 23.989322662353516\n",
      "Epoch: 47, Batch: 160, D Loss: 0.102187037484404, G Loss: 24.27109718322754\n",
      "Epoch: 47, Batch: 161, D Loss: 0.09366915376437501, G Loss: 24.266019821166992\n",
      "Epoch: 47, Batch: 162, D Loss: 0.10389104486840893, G Loss: 24.427030563354492\n",
      "Epoch: 47, Batch: 163, D Loss: 0.09744773061332464, G Loss: 24.400157928466797\n",
      "Epoch: 47, Batch: 164, D Loss: 0.09460095317638649, G Loss: 24.118515014648438\n",
      "Epoch: 47, Batch: 165, D Loss: 0.10802513362492558, G Loss: 24.31057357788086\n",
      "Epoch: 47, Batch: 166, D Loss: 0.10150767864011682, G Loss: 24.557573318481445\n",
      "Epoch: 47, Batch: 167, D Loss: 0.10394821316940474, G Loss: 24.831254959106445\n",
      "Epoch: 47, Batch: 168, D Loss: 0.09622959048454326, G Loss: 24.66405487060547\n",
      "Epoch: 47, Batch: 169, D Loss: 0.09404999018996264, G Loss: 24.138212203979492\n",
      "Epoch: 47, Batch: 170, D Loss: 0.098522394916032, G Loss: 23.72031593322754\n",
      "Epoch: 47, Batch: 171, D Loss: 0.10266771915004742, G Loss: 23.771854400634766\n",
      "Epoch: 47, Batch: 172, D Loss: 0.10088095816021625, G Loss: 24.065067291259766\n",
      "Epoch: 47, Batch: 173, D Loss: 0.10217263550984529, G Loss: 24.48411750793457\n",
      "Epoch: 47, Batch: 174, D Loss: 0.10146943480774297, G Loss: 24.77669906616211\n",
      "Epoch: 47, Batch: 175, D Loss: 0.09849797190150393, G Loss: 24.678104400634766\n",
      "Epoch: 47, Batch: 176, D Loss: 0.10118816794061931, G Loss: 24.420625686645508\n",
      "Epoch: 47, Batch: 177, D Loss: 0.09395252914876309, G Loss: 23.887924194335938\n",
      "Epoch: 47, Batch: 178, D Loss: 0.0988411233083137, G Loss: 23.536283493041992\n",
      "Epoch: 47, Batch: 179, D Loss: 0.10382648560232033, G Loss: 23.663066864013672\n",
      "Epoch: 47, Batch: 180, D Loss: 0.10067488255339611, G Loss: 23.992351531982422\n",
      "Epoch: 47, Batch: 181, D Loss: 0.10165479780777152, G Loss: 24.400917053222656\n",
      "Epoch: 47, Batch: 182, D Loss: 0.09898071737258302, G Loss: 24.56260871887207\n",
      "Epoch: 47, Batch: 183, D Loss: 0.09878317267848072, G Loss: 24.442697525024414\n",
      "Epoch: 47, Batch: 184, D Loss: 0.09967118503038695, G Loss: 24.202674865722656\n",
      "Epoch: 47, Batch: 185, D Loss: 0.0946609005529546, G Loss: 23.730281829833984\n",
      "Epoch: 47, Batch: 186, D Loss: 0.1067918092255547, G Loss: 23.76173973083496\n",
      "Epoch: 47, Batch: 187, D Loss: 0.09112291040721311, G Loss: 23.544837951660156\n",
      "Epoch: 47, Batch: 188, D Loss: 0.10284112396583645, G Loss: 23.710205078125\n",
      "Epoch: 47, Batch: 189, D Loss: 0.08754299583884939, G Loss: 23.48846435546875\n",
      "Epoch: 47, Batch: 190, D Loss: 0.10057979825181437, G Loss: 23.565853118896484\n",
      "Epoch: 47, Batch: 191, D Loss: 0.10337107630915462, G Loss: 23.989219665527344\n",
      "Epoch: 47, Batch: 192, D Loss: 0.09555318953333608, G Loss: 24.178735733032227\n",
      "Epoch: 47, Batch: 193, D Loss: 0.09432794900465072, G Loss: 24.019372940063477\n",
      "Epoch: 47, Batch: 194, D Loss: 0.10490535201389718, G Loss: 24.12903594970703\n",
      "Epoch: 47, Batch: 195, D Loss: 0.09286758305512774, G Loss: 23.90092658996582\n",
      "Epoch: 47, Batch: 196, D Loss: 0.0988137498720418, G Loss: 23.777019500732422\n",
      "Epoch: 47, Batch: 197, D Loss: 0.09361717107540211, G Loss: 23.571533203125\n",
      "Epoch: 47, Batch: 198, D Loss: 0.10176301005192502, G Loss: 23.71253776550293\n",
      "Epoch: 47, Batch: 199, D Loss: 0.10081339629628874, G Loss: 24.033903121948242\n",
      "Epoch: 47, Batch: 200, D Loss: 0.10002833606352457, G Loss: 24.35616683959961\n",
      "Epoch: 47, Batch: 201, D Loss: 0.10372732580816818, G Loss: 24.690532684326172\n",
      "Epoch: 47, Batch: 202, D Loss: 0.09544784576719215, G Loss: 24.55107879638672\n",
      "Epoch: 47, Batch: 203, D Loss: 0.09762044252268134, G Loss: 24.20773696899414\n",
      "Epoch: 47, Batch: 204, D Loss: 0.10091312231378782, G Loss: 23.9615478515625\n",
      "Epoch: 47, Batch: 205, D Loss: 0.10556511582736827, G Loss: 24.132522583007812\n",
      "Epoch: 47, Batch: 206, D Loss: 0.10453786702309763, G Loss: 24.52318000793457\n",
      "Epoch: 47, Batch: 207, D Loss: 0.10125932098408602, G Loss: 24.789331436157227\n",
      "Epoch: 47, Batch: 208, D Loss: 0.09799832106537805, G Loss: 24.694259643554688\n",
      "Epoch: 47, Batch: 209, D Loss: 0.10150769353951887, G Loss: 24.50945281982422\n",
      "Epoch: 47, Batch: 210, D Loss: 0.09695148469388597, G Loss: 24.148500442504883\n",
      "Epoch: 47, Batch: 211, D Loss: 0.10117848219270927, G Loss: 23.97389793395996\n",
      "Epoch: 47, Batch: 212, D Loss: 0.0997217297749014, G Loss: 23.96172523498535\n",
      "Epoch: 47, Batch: 213, D Loss: 0.0995594337766076, G Loss: 24.08824920654297\n",
      "Epoch: 47, Batch: 214, D Loss: 0.10685519130386822, G Loss: 24.55830955505371\n",
      "Epoch: 47, Batch: 215, D Loss: 0.09693019838136983, G Loss: 24.712770462036133\n",
      "Epoch: 47, Batch: 216, D Loss: 0.09416472912917513, G Loss: 24.414539337158203\n",
      "Epoch: 47, Batch: 217, D Loss: 0.09830941261373313, G Loss: 24.04757308959961\n",
      "Epoch: 47, Batch: 218, D Loss: 0.1030888334103389, G Loss: 23.97774314880371\n",
      "Epoch: 47, Batch: 219, D Loss: 0.10013359786891618, G Loss: 24.098054885864258\n",
      "Epoch: 47, Batch: 220, D Loss: 0.10490190984210661, G Loss: 24.489992141723633\n",
      "Epoch: 47, Batch: 221, D Loss: 0.10561221838892988, G Loss: 24.979846954345703\n",
      "Epoch: 47, Batch: 222, D Loss: 0.09501079470644509, G Loss: 24.935386657714844\n",
      "Epoch: 47, Batch: 223, D Loss: 0.09998529405257656, G Loss: 24.6619930267334\n",
      "Epoch: 47, Batch: 224, D Loss: 0.0986874476193247, G Loss: 24.29507064819336\n",
      "Epoch: 47, Batch: 225, D Loss: 0.10393247009787404, G Loss: 24.217592239379883\n",
      "Epoch: 47, Batch: 226, D Loss: 0.09736712278504032, G Loss: 24.156038284301758\n",
      "Epoch: 47, Batch: 227, D Loss: 0.0964650139378641, G Loss: 24.103290557861328\n",
      "Epoch: 47, Batch: 228, D Loss: 0.10490147770877847, G Loss: 24.438661575317383\n",
      "Epoch: 47, Batch: 229, D Loss: 0.09642676265158794, G Loss: 24.61195182800293\n",
      "Epoch: 47, Batch: 230, D Loss: 0.09716030956362846, G Loss: 24.566844940185547\n",
      "Epoch: 47, Batch: 231, D Loss: 0.10399395228451193, G Loss: 24.6612606048584\n",
      "Epoch: 47, Batch: 232, D Loss: 0.09275576473434737, G Loss: 24.342193603515625\n",
      "Epoch: 47, Batch: 233, D Loss: 0.10215575994477895, G Loss: 24.2370548248291\n",
      "Epoch: 47, Batch: 234, D Loss: 0.09273286165542732, G Loss: 23.945619583129883\n",
      "Epoch: 47, Batch: 235, D Loss: 0.10479594768939801, G Loss: 24.091087341308594\n",
      "Epoch: 47, Batch: 236, D Loss: 0.10223765672680163, G Loss: 24.449203491210938\n",
      "Epoch: 47, Batch: 237, D Loss: 0.09543422610705886, G Loss: 24.556726455688477\n",
      "Epoch: 47, Batch: 238, D Loss: 0.10048978031748872, G Loss: 24.582317352294922\n",
      "Epoch: 47, Batch: 239, D Loss: 0.09838949890073898, G Loss: 24.451940536499023\n",
      "Epoch: 47, Batch: 240, D Loss: 0.09427778424312015, G Loss: 24.055532455444336\n",
      "Epoch: 47, Batch: 241, D Loss: 0.09628655018543558, G Loss: 23.728017807006836\n",
      "Epoch: 47, Batch: 242, D Loss: 0.09586963805276283, G Loss: 23.564420700073242\n",
      "Epoch: 47, Batch: 243, D Loss: 0.09057919684282507, G Loss: 23.3829402923584\n",
      "Epoch: 47, Batch: 244, D Loss: 0.09220437709083361, G Loss: 23.346433639526367\n",
      "Epoch: 47, Batch: 245, D Loss: 0.10505454244837836, G Loss: 23.973133087158203\n",
      "Epoch: 47, Batch: 246, D Loss: 0.09842632712315778, G Loss: 24.61532974243164\n",
      "Epoch: 47, Batch: 247, D Loss: 0.09802846611388946, G Loss: 24.9792423248291\n",
      "Epoch: 47, Batch: 248, D Loss: 0.09457768500624532, G Loss: 24.814064025878906\n",
      "Epoch: 47, Batch: 249, D Loss: 0.09215029330227595, G Loss: 24.183998107910156\n",
      "Epoch: 47, Batch: 250, D Loss: 0.10089516641588162, G Loss: 23.84297752380371\n",
      "Epoch: 47, Batch: 251, D Loss: 0.09283506872851964, G Loss: 23.545654296875\n",
      "Epoch: 47, Batch: 252, D Loss: 0.09683075550110122, G Loss: 23.598480224609375\n",
      "Epoch: 47, Batch: 253, D Loss: 0.10893981905668114, G Loss: 24.3712215423584\n",
      "Epoch: 47, Batch: 254, D Loss: 0.0974266380166418, G Loss: 24.980722427368164\n",
      "Epoch: 47, Batch: 255, D Loss: 0.09724612534686429, G Loss: 25.17151641845703\n",
      "Epoch: 47, Batch: 256, D Loss: 0.09752506018334667, G Loss: 24.971805572509766\n",
      "Epoch: 47, Batch: 257, D Loss: 0.09934073687463574, G Loss: 24.61219596862793\n",
      "Epoch: 47, Batch: 258, D Loss: 0.09829429538316763, G Loss: 24.218103408813477\n",
      "Epoch: 47, Batch: 259, D Loss: 0.09728398920858371, G Loss: 23.944154739379883\n",
      "Epoch: 47, Batch: 260, D Loss: 0.10225238652898865, G Loss: 24.07655906677246\n",
      "Epoch: 47, Batch: 261, D Loss: 0.09639915080486744, G Loss: 24.235252380371094\n",
      "Epoch: 47, Batch: 262, D Loss: 0.10449042917453522, G Loss: 24.720596313476562\n",
      "Epoch: 47, Batch: 263, D Loss: 0.09824971110434128, G Loss: 24.969451904296875\n",
      "Epoch: 47, Batch: 264, D Loss: 0.09903039038904106, G Loss: 24.951326370239258\n",
      "Epoch: 47, Batch: 265, D Loss: 0.09871969372860445, G Loss: 24.713001251220703\n",
      "Epoch: 47, Batch: 266, D Loss: 0.10603554547776271, G Loss: 24.67640495300293\n",
      "Epoch: 47, Batch: 267, D Loss: 0.10471980274617546, G Loss: 24.811277389526367\n",
      "Epoch: 47, Batch: 268, D Loss: 0.09868135304103699, G Loss: 24.797340393066406\n",
      "Epoch: 47, Batch: 269, D Loss: 0.09586508573082073, G Loss: 24.5294189453125\n",
      "Epoch: 47, Batch: 270, D Loss: 0.09906028212380531, G Loss: 24.285602569580078\n",
      "Epoch: 47, Batch: 271, D Loss: 0.09689902515829475, G Loss: 24.044750213623047\n",
      "Epoch: 47, Batch: 272, D Loss: 0.09909427167824376, G Loss: 24.009021759033203\n",
      "Epoch: 47, Batch: 273, D Loss: 0.10301791133106075, G Loss: 24.294343948364258\n",
      "Epoch: 47, Batch: 274, D Loss: 0.09967939556847788, G Loss: 24.59109115600586\n",
      "Epoch: 47, Batch: 275, D Loss: 0.09657777101795656, G Loss: 24.686933517456055\n",
      "Epoch: 47, Batch: 276, D Loss: 0.09151083232114039, G Loss: 24.33719825744629\n",
      "Epoch: 47, Batch: 277, D Loss: 0.09951295705190111, G Loss: 24.082229614257812\n",
      "Epoch: 47, Batch: 278, D Loss: 0.10292033107761367, G Loss: 24.155609130859375\n",
      "Epoch: 47, Batch: 279, D Loss: 0.104201003922284, G Loss: 24.543010711669922\n",
      "Epoch: 47, Batch: 280, D Loss: 0.0969460159639739, G Loss: 24.72868537902832\n",
      "Epoch: 47, Batch: 281, D Loss: 0.09834504873480607, G Loss: 24.709444046020508\n",
      "Epoch: 47, Batch: 282, D Loss: 0.10191435367818096, G Loss: 24.66777801513672\n",
      "Epoch: 47, Batch: 283, D Loss: 0.09245485068562065, G Loss: 24.26886558532715\n",
      "Epoch: 47, Batch: 284, D Loss: 0.09914559872630062, G Loss: 23.988435745239258\n",
      "Epoch: 47, Batch: 285, D Loss: 0.10074463488592554, G Loss: 23.976966857910156\n",
      "Epoch: 47, Batch: 286, D Loss: 0.09968303145750543, G Loss: 24.14031219482422\n",
      "Epoch: 47, Batch: 287, D Loss: 0.10047448427906015, G Loss: 24.413103103637695\n",
      "Epoch: 47, Batch: 288, D Loss: 0.10097551346901733, G Loss: 24.697206497192383\n",
      "Epoch: 47, Batch: 289, D Loss: 0.09025356919656659, G Loss: 24.429330825805664\n",
      "Epoch: 47, Batch: 290, D Loss: 0.09882836790317516, G Loss: 24.147733688354492\n",
      "Epoch: 47, Batch: 291, D Loss: 0.09835763277422394, G Loss: 23.958171844482422\n",
      "Epoch: 47, Batch: 292, D Loss: 0.09974101187733184, G Loss: 23.99098777770996\n",
      "Epoch: 47, Batch: 293, D Loss: 0.09800906481152531, G Loss: 24.104875564575195\n",
      "Epoch: 47, Batch: 294, D Loss: 0.09562917055371999, G Loss: 24.1354923248291\n",
      "Epoch: 47, Batch: 295, D Loss: 0.10204070807988701, G Loss: 24.333223342895508\n",
      "Epoch: 47, Batch: 296, D Loss: 0.10359164328539706, G Loss: 24.63190460205078\n",
      "Epoch: 47, Batch: 297, D Loss: 0.1003199145291589, G Loss: 24.76156997680664\n",
      "Epoch: 47, Batch: 298, D Loss: 0.09266815335637062, G Loss: 24.381717681884766\n",
      "Epoch: 47, Batch: 299, D Loss: 0.09726004304122182, G Loss: 23.945663452148438\n",
      "Epoch: 47, Batch: 300, D Loss: 0.10121577980285286, G Loss: 23.800617218017578\n",
      "Epoch: 47, Batch: 301, D Loss: 0.10340198876521159, G Loss: 24.024866104125977\n",
      "Epoch: 47, Batch: 302, D Loss: 0.10121040792809845, G Loss: 24.368083953857422\n",
      "Epoch: 47, Batch: 303, D Loss: 0.09949100018698182, G Loss: 24.61049461364746\n",
      "Epoch: 47, Batch: 304, D Loss: 0.09917294235049325, G Loss: 24.63510513305664\n",
      "Epoch: 47, Batch: 305, D Loss: 0.09903096408722274, G Loss: 24.507490158081055\n",
      "Epoch: 47, Batch: 306, D Loss: 0.10809424520595365, G Loss: 24.647096633911133\n",
      "Epoch: 47, Batch: 307, D Loss: 0.1002765596011221, G Loss: 24.657516479492188\n",
      "Epoch: 47, Batch: 308, D Loss: 0.10638592393115917, G Loss: 24.795053482055664\n",
      "Epoch: 47, Batch: 309, D Loss: 0.0987635701985481, G Loss: 24.67645835876465\n",
      "Epoch: 47, Batch: 310, D Loss: 0.09893155099067823, G Loss: 24.40807342529297\n",
      "Epoch: 47, Batch: 311, D Loss: 0.09591010214437123, G Loss: 24.020254135131836\n",
      "Epoch: 47, Batch: 312, D Loss: 0.09823150934835717, G Loss: 23.82781410217285\n",
      "Epoch: 47, Batch: 313, D Loss: 0.10119960459156652, G Loss: 23.97972869873047\n",
      "Epoch: 47, Batch: 314, D Loss: 0.09409423174316132, G Loss: 24.064496994018555\n",
      "Epoch: 47, Batch: 315, D Loss: 0.09888777883454887, G Loss: 24.26293182373047\n",
      "Epoch: 47, Batch: 316, D Loss: 0.09903676064132405, G Loss: 24.45721435546875\n",
      "Epoch: 47, Batch: 317, D Loss: 0.098155327152583, G Loss: 24.563695907592773\n",
      "Epoch: 47, Batch: 318, D Loss: 0.09219166637705488, G Loss: 24.29306983947754\n",
      "Epoch: 47, Batch: 319, D Loss: 0.10499498994497475, G Loss: 24.388458251953125\n",
      "Epoch: 47, Batch: 320, D Loss: 0.1053416952595368, G Loss: 24.776784896850586\n",
      "Epoch: 47, Batch: 321, D Loss: 0.09830532968851088, G Loss: 24.91582679748535\n",
      "Epoch: 47, Batch: 322, D Loss: 0.09932844341595862, G Loss: 24.819555282592773\n",
      "Epoch: 47, Batch: 323, D Loss: 0.09943284095277227, G Loss: 24.580219268798828\n",
      "Epoch: 47, Batch: 324, D Loss: 0.10223621131101804, G Loss: 24.482820510864258\n",
      "Epoch: 47, Batch: 325, D Loss: 0.09423281998788433, G Loss: 24.20741844177246\n",
      "Epoch: 47, Batch: 326, D Loss: 0.1018337309513579, G Loss: 24.211463928222656\n",
      "Epoch: 47, Batch: 327, D Loss: 0.0999363958975506, G Loss: 24.378713607788086\n",
      "Epoch: 47, Batch: 328, D Loss: 0.09806527198563704, G Loss: 24.515483856201172\n",
      "Epoch: 47, Batch: 329, D Loss: 0.09867254645694432, G Loss: 24.62942123413086\n",
      "Epoch: 47, Batch: 330, D Loss: 0.10201464594353198, G Loss: 24.752681732177734\n",
      "Epoch: 47, Batch: 331, D Loss: 0.09668517113682971, G Loss: 24.624963760375977\n",
      "Epoch: 47, Batch: 332, D Loss: 0.10109952093242326, G Loss: 24.513891220092773\n",
      "Epoch: 47, Batch: 333, D Loss: 0.10071323068097751, G Loss: 24.482460021972656\n",
      "Epoch: 47, Batch: 334, D Loss: 0.0972938165190913, G Loss: 24.390535354614258\n",
      "Epoch: 47, Batch: 335, D Loss: 0.09730850906536932, G Loss: 24.275537490844727\n",
      "Epoch: 47, Batch: 336, D Loss: 0.10622311384727576, G Loss: 24.54750633239746\n",
      "Epoch: 47, Batch: 337, D Loss: 0.10107246042244675, G Loss: 24.819101333618164\n",
      "Epoch: 47, Batch: 338, D Loss: 0.10192950070667524, G Loss: 24.98328399658203\n",
      "Epoch: 47, Batch: 339, D Loss: 0.1026791483232649, G Loss: 25.032215118408203\n",
      "Epoch: 47, Batch: 340, D Loss: 0.09919980169101467, G Loss: 24.802112579345703\n",
      "Epoch: 47, Batch: 341, D Loss: 0.10699646920806163, G Loss: 24.815479278564453\n",
      "Epoch: 47, Batch: 342, D Loss: 0.09864940495225565, G Loss: 24.61777114868164\n",
      "Epoch: 47, Batch: 343, D Loss: 0.10167441518220152, G Loss: 24.461366653442383\n",
      "Epoch: 47, Batch: 344, D Loss: 0.10612005741527429, G Loss: 24.571285247802734\n",
      "Epoch: 47, Batch: 345, D Loss: 0.10775457323482955, G Loss: 24.923749923706055\n",
      "Epoch: 47, Batch: 346, D Loss: 0.09835671634236841, G Loss: 24.910015106201172\n",
      "Epoch: 47, Batch: 347, D Loss: 0.10549928248689322, G Loss: 24.907745361328125\n",
      "Epoch: 47, Batch: 348, D Loss: 0.10138870776534584, G Loss: 24.732656478881836\n",
      "Epoch: 47, Batch: 349, D Loss: 0.10312557221461544, G Loss: 24.542705535888672\n",
      "Epoch: 47, Batch: 350, D Loss: 0.09320867808102545, G Loss: 24.03903579711914\n",
      "Epoch: 47, Batch: 351, D Loss: 0.10223896803456761, G Loss: 23.869382858276367\n",
      "Epoch: 47, Batch: 352, D Loss: 0.10258287938427578, G Loss: 24.02826690673828\n",
      "Epoch: 47, Batch: 353, D Loss: 0.0976163000040156, G Loss: 24.153810501098633\n",
      "Epoch: 47, Batch: 354, D Loss: 0.09717980773844101, G Loss: 24.190841674804688\n",
      "Epoch: 47, Batch: 355, D Loss: 0.10024125130496028, G Loss: 24.25031852722168\n",
      "Epoch: 47, Batch: 356, D Loss: 0.09902884067573117, G Loss: 24.252079010009766\n",
      "Epoch: 47, Batch: 357, D Loss: 0.09644664825605287, G Loss: 24.09144401550293\n",
      "Epoch: 47, Batch: 358, D Loss: 0.10279390217544744, G Loss: 24.14925193786621\n",
      "Epoch: 47, Batch: 359, D Loss: 0.10030169786594093, G Loss: 24.21407699584961\n",
      "Epoch: 47, Batch: 360, D Loss: 0.10076376797226338, G Loss: 24.29850196838379\n",
      "Epoch: 47, Batch: 361, D Loss: 0.10035531224180443, G Loss: 24.35399055480957\n",
      "Epoch: 47, Batch: 362, D Loss: 0.10101471842646025, G Loss: 24.3743839263916\n",
      "Epoch: 47, Batch: 363, D Loss: 0.10012839735890927, G Loss: 24.31882095336914\n",
      "Epoch: 47, Batch: 364, D Loss: 0.09917094559963671, G Loss: 24.16714859008789\n",
      "Epoch: 47, Batch: 365, D Loss: 0.09826991708864503, G Loss: 23.963354110717773\n",
      "Epoch: 47, Batch: 366, D Loss: 0.10608984531736113, G Loss: 24.16172218322754\n",
      "Epoch: 47, Batch: 367, D Loss: 0.10127960146901327, G Loss: 24.384714126586914\n",
      "Epoch: 47, Batch: 368, D Loss: 0.0972758829724209, G Loss: 24.354324340820312\n",
      "Epoch: 47, Batch: 369, D Loss: 0.1055636778597865, G Loss: 24.480091094970703\n",
      "Epoch: 47, Batch: 370, D Loss: 0.09920185060527871, G Loss: 24.399621963500977\n",
      "Epoch: 47, Batch: 371, D Loss: 0.09763056786289197, G Loss: 24.17965316772461\n",
      "Epoch: 47, Batch: 372, D Loss: 0.09485561402561585, G Loss: 23.81618309020996\n",
      "Epoch: 47, Batch: 373, D Loss: 0.09981177749605988, G Loss: 23.743934631347656\n",
      "Epoch: 47, Batch: 374, D Loss: 0.1034958884321972, G Loss: 24.102067947387695\n",
      "Epoch: 47, Batch: 375, D Loss: 0.09928759933910206, G Loss: 24.48623275756836\n",
      "Epoch: 47, Batch: 376, D Loss: 0.10097277165436791, G Loss: 24.813167572021484\n",
      "Epoch: 47, Batch: 377, D Loss: 0.09730369598510774, G Loss: 24.812467575073242\n",
      "Epoch: 47, Batch: 378, D Loss: 0.09763529897674739, G Loss: 24.59602928161621\n",
      "Epoch: 47, Batch: 379, D Loss: 0.10241346062325492, G Loss: 24.497699737548828\n",
      "Epoch: 47, Batch: 380, D Loss: 0.10032261909213175, G Loss: 24.479063034057617\n",
      "Epoch: 47, Batch: 381, D Loss: 0.0977880284310469, G Loss: 24.42488670349121\n",
      "Epoch: 47, Batch: 382, D Loss: 0.0987741053230668, G Loss: 24.38153076171875\n",
      "Epoch: 47, Batch: 383, D Loss: 0.10685821623677426, G Loss: 24.743694305419922\n",
      "Epoch: 47, Batch: 384, D Loss: 0.10079398752034074, G Loss: 25.021297454833984\n",
      "Epoch: 47, Batch: 385, D Loss: 0.09973101318545825, G Loss: 25.06792640686035\n",
      "Epoch: 47, Batch: 386, D Loss: 0.1048295944992292, G Loss: 25.118711471557617\n",
      "Epoch: 47, Batch: 387, D Loss: 0.10052584112364064, G Loss: 24.950984954833984\n",
      "Epoch: 47, Batch: 388, D Loss: 0.09463892878058001, G Loss: 24.438737869262695\n",
      "Epoch: 47, Batch: 389, D Loss: 0.098486728981538, G Loss: 24.003372192382812\n",
      "Epoch: 47, Batch: 390, D Loss: 0.10359080137687175, G Loss: 24.019990921020508\n",
      "Epoch: 47, Batch: 391, D Loss: 0.1027968004497324, G Loss: 24.400333404541016\n",
      "Epoch: 47, Batch: 392, D Loss: 0.0933378636957256, G Loss: 24.49638557434082\n",
      "Epoch: 47, Batch: 393, D Loss: 0.10110032559511085, G Loss: 24.63283920288086\n",
      "Epoch: 47, Batch: 394, D Loss: 0.10044267774579889, G Loss: 24.731660842895508\n",
      "Epoch: 47, Batch: 395, D Loss: 0.09708267451318896, G Loss: 24.574748992919922\n",
      "Epoch: 47, Batch: 396, D Loss: 0.09940614552471685, G Loss: 24.398883819580078\n",
      "Epoch: 47, Batch: 397, D Loss: 0.09681979568233139, G Loss: 24.180782318115234\n",
      "Epoch: 47, Batch: 398, D Loss: 0.09977259488496285, G Loss: 24.172143936157227\n",
      "Epoch: 47, Batch: 399, D Loss: 0.09197379650426979, G Loss: 23.998228073120117\n",
      "Epoch: 47, Batch: 400, D Loss: 0.09586809577512667, G Loss: 23.934965133666992\n",
      "Epoch: 47, Batch: 401, D Loss: 0.10532717408365036, G Loss: 24.354463577270508\n",
      "Epoch: 47, Batch: 402, D Loss: 0.09524498881094502, G Loss: 24.566408157348633\n",
      "Epoch: 47, Batch: 403, D Loss: 0.09913590551425833, G Loss: 24.691280364990234\n",
      "Epoch: 47, Batch: 404, D Loss: 0.10434842855585734, G Loss: 24.89922523498535\n",
      "Epoch: 47, Batch: 405, D Loss: 0.10105868429696216, G Loss: 24.94265365600586\n",
      "Epoch: 47, Batch: 406, D Loss: 0.10104311258384337, G Loss: 24.822053909301758\n",
      "Epoch: 47, Batch: 407, D Loss: 0.09842626751446931, G Loss: 24.510040283203125\n",
      "Epoch: 47, Batch: 408, D Loss: 0.09656760097941071, G Loss: 24.12036895751953\n",
      "Epoch: 47, Batch: 409, D Loss: 0.10006858410260677, G Loss: 23.971805572509766\n",
      "Epoch: 47, Batch: 410, D Loss: 0.10249888898669358, G Loss: 24.19422721862793\n",
      "Epoch: 47, Batch: 411, D Loss: 0.10609002412535498, G Loss: 24.73906135559082\n",
      "Epoch: 47, Batch: 412, D Loss: 0.10423973203391444, G Loss: 25.257095336914062\n",
      "Epoch: 47, Batch: 413, D Loss: 0.10021629185006921, G Loss: 25.309202194213867\n",
      "Epoch: 47, Batch: 414, D Loss: 0.10176550597541965, G Loss: 25.032161712646484\n",
      "Epoch: 47, Batch: 415, D Loss: 0.09619816393612987, G Loss: 24.371152877807617\n",
      "Epoch: 47, Batch: 416, D Loss: 0.10802365840918424, G Loss: 24.183988571166992\n",
      "Epoch: 47, Batch: 417, D Loss: 0.10162261875052349, G Loss: 24.186037063598633\n",
      "Epoch: 47, Batch: 418, D Loss: 0.10950952769540098, G Loss: 24.675445556640625\n",
      "Epoch: 47, Batch: 419, D Loss: 0.09531794489361584, G Loss: 24.73388671875\n",
      "Epoch: 47, Batch: 420, D Loss: 0.09439320118336629, G Loss: 24.364551544189453\n",
      "Epoch: 47, Batch: 421, D Loss: 0.09825457634155409, G Loss: 23.96959114074707\n",
      "Epoch: 47, Batch: 422, D Loss: 0.10004503282031657, G Loss: 23.818212509155273\n",
      "Epoch: 47, Batch: 423, D Loss: 0.09653279187637898, G Loss: 23.753128051757812\n",
      "Epoch: 47, Batch: 424, D Loss: 0.09818612041357769, G Loss: 23.872905731201172\n",
      "Epoch: 47, Batch: 425, D Loss: 0.10126047583245873, G Loss: 24.192176818847656\n",
      "Epoch: 47, Batch: 426, D Loss: 0.09319326283109323, G Loss: 24.18705940246582\n",
      "Epoch: 47, Batch: 427, D Loss: 0.09796327354157121, G Loss: 24.10654640197754\n",
      "Epoch: 47, Batch: 428, D Loss: 0.09892268480629318, G Loss: 24.038230895996094\n",
      "Epoch: 47, Batch: 429, D Loss: 0.10362583400498966, G Loss: 24.186920166015625\n",
      "Epoch: 47, Batch: 430, D Loss: 0.10094768555408438, G Loss: 24.35106658935547\n",
      "Epoch: 47, Batch: 431, D Loss: 0.09399459512535799, G Loss: 24.128005981445312\n",
      "Epoch: 47, Batch: 432, D Loss: 0.09674927594258818, G Loss: 23.792387008666992\n",
      "Epoch: 47, Batch: 433, D Loss: 0.10329676421830769, G Loss: 23.783342361450195\n",
      "Epoch: 47, Batch: 434, D Loss: 0.1051181256970741, G Loss: 24.088157653808594\n",
      "Epoch: 47, Batch: 435, D Loss: 0.09670870007726343, G Loss: 24.18560791015625\n",
      "Epoch: 47, Batch: 436, D Loss: 0.09011945130356282, G Loss: 23.804655075073242\n",
      "Epoch: 47, Batch: 437, D Loss: 0.0976705402405217, G Loss: 23.4998779296875\n",
      "Epoch: 47, Batch: 438, D Loss: 0.10637371244783589, G Loss: 23.743898391723633\n",
      "Epoch: 47, Batch: 439, D Loss: 0.09536398204462011, G Loss: 23.870784759521484\n",
      "Epoch: 47, Batch: 440, D Loss: 0.10094548018683976, G Loss: 24.10637092590332\n",
      "Epoch: 47, Batch: 441, D Loss: 0.09359556438337614, G Loss: 23.995624542236328\n",
      "Epoch: 47, Batch: 442, D Loss: 0.09922890367105369, G Loss: 23.911542892456055\n",
      "Epoch: 47, Batch: 443, D Loss: 0.09496112915192033, G Loss: 23.7052001953125\n",
      "Epoch: 47, Batch: 444, D Loss: 0.09521809223125313, G Loss: 23.50835609436035\n",
      "Epoch: 47, Batch: 445, D Loss: 0.09965182843772202, G Loss: 23.59541130065918\n",
      "Epoch: 47, Batch: 446, D Loss: 0.10147240760257359, G Loss: 23.976177215576172\n",
      "Epoch: 47, Batch: 447, D Loss: 0.10258962960556109, G Loss: 24.45392417907715\n",
      "Epoch: 47, Batch: 448, D Loss: 0.09964124859433418, G Loss: 24.698440551757812\n",
      "Epoch: 47, Batch: 449, D Loss: 0.09516853840223398, G Loss: 24.45968246459961\n",
      "Epoch: 47, Batch: 450, D Loss: 0.09808796645675079, G Loss: 24.070514678955078\n",
      "Epoch: 47, Batch: 451, D Loss: 0.09674723448509812, G Loss: 23.697311401367188\n",
      "Epoch: 47, Batch: 452, D Loss: 0.10178023579274373, G Loss: 23.709978103637695\n",
      "Epoch: 47, Batch: 453, D Loss: 0.09689028563471812, G Loss: 23.839439392089844\n",
      "Epoch: 47, Batch: 454, D Loss: 0.10137429835254476, G Loss: 24.190475463867188\n",
      "Epoch: 47, Batch: 455, D Loss: 0.10284058750910653, G Loss: 24.63930320739746\n",
      "Epoch: 47, Batch: 456, D Loss: 0.10074984283125296, G Loss: 24.89564323425293\n",
      "Epoch: 47, Batch: 457, D Loss: 0.09564005584396988, G Loss: 24.66012954711914\n",
      "Epoch: 47, Batch: 458, D Loss: 0.09633801878764783, G Loss: 24.170141220092773\n",
      "Epoch: 47, Batch: 459, D Loss: 0.09505583347982934, G Loss: 23.65020179748535\n",
      "Epoch: 47, Batch: 460, D Loss: 0.10197363796583896, G Loss: 23.611005783081055\n",
      "Epoch: 47, Batch: 461, D Loss: 0.09926241638689551, G Loss: 23.88315773010254\n",
      "Epoch: 47, Batch: 462, D Loss: 0.09890417756384946, G Loss: 24.265230178833008\n",
      "Epoch: 47, Batch: 463, D Loss: 0.09712746740671319, G Loss: 24.49625587463379\n",
      "Epoch: 47, Batch: 464, D Loss: 0.10098010302634859, G Loss: 24.676959991455078\n",
      "Epoch: 47, Batch: 465, D Loss: 0.09668302537036519, G Loss: 24.549373626708984\n",
      "Epoch: 47, Batch: 466, D Loss: 0.09364494682728557, G Loss: 24.117231369018555\n",
      "Epoch: 47, Batch: 467, D Loss: 0.09902190418978227, G Loss: 23.855215072631836\n",
      "Epoch: 48, Batch: 0, D Loss: 0.10174857082057973, G Loss: 23.95029067993164\n",
      "Epoch: 48, Batch: 1, D Loss: 0.09372948112040812, G Loss: 23.99549674987793\n",
      "Epoch: 48, Batch: 2, D Loss: 0.08983646335305202, G Loss: 23.81263542175293\n",
      "Epoch: 48, Batch: 3, D Loss: 0.09367588164853788, G Loss: 23.68739891052246\n",
      "Epoch: 48, Batch: 4, D Loss: 0.09807355704301306, G Loss: 23.842575073242188\n",
      "Epoch: 48, Batch: 5, D Loss: 0.10293424131163059, G Loss: 24.365983963012695\n",
      "Epoch: 48, Batch: 6, D Loss: 0.09942953289585253, G Loss: 24.822391510009766\n",
      "Epoch: 48, Batch: 7, D Loss: 0.10094930977349517, G Loss: 25.090009689331055\n",
      "Epoch: 48, Batch: 8, D Loss: 0.09722262621619429, G Loss: 24.921274185180664\n",
      "Epoch: 48, Batch: 9, D Loss: 0.0932622701033695, G Loss: 24.303539276123047\n",
      "Epoch: 48, Batch: 10, D Loss: 0.10067555310037393, G Loss: 23.93041229248047\n",
      "Epoch: 48, Batch: 11, D Loss: 0.09838479759474297, G Loss: 23.80175018310547\n",
      "Epoch: 48, Batch: 12, D Loss: 0.10183116795626104, G Loss: 24.07464599609375\n",
      "Epoch: 48, Batch: 13, D Loss: 0.09939371795892742, G Loss: 24.46087074279785\n",
      "Epoch: 48, Batch: 14, D Loss: 0.10092008114830182, G Loss: 24.851715087890625\n",
      "Epoch: 48, Batch: 15, D Loss: 0.0983387231903497, G Loss: 24.944162368774414\n",
      "Epoch: 48, Batch: 16, D Loss: 0.10312116891873124, G Loss: 24.962007522583008\n",
      "Epoch: 48, Batch: 17, D Loss: 0.10399409384255533, G Loss: 24.965049743652344\n",
      "Epoch: 48, Batch: 18, D Loss: 0.1009253561574686, G Loss: 24.811695098876953\n",
      "Epoch: 48, Batch: 19, D Loss: 0.10038702935943827, G Loss: 24.54715919494629\n",
      "Epoch: 48, Batch: 20, D Loss: 0.09914731980632918, G Loss: 24.273483276367188\n",
      "Epoch: 48, Batch: 21, D Loss: 0.10023584218367822, G Loss: 24.147045135498047\n",
      "Epoch: 48, Batch: 22, D Loss: 0.10186571629402766, G Loss: 24.245147705078125\n",
      "Epoch: 48, Batch: 23, D Loss: 0.09910646082332544, G Loss: 24.400846481323242\n",
      "Epoch: 48, Batch: 24, D Loss: 0.09824062140012077, G Loss: 24.474390029907227\n",
      "Epoch: 48, Batch: 25, D Loss: 0.09752164782301595, G Loss: 24.421079635620117\n",
      "Epoch: 48, Batch: 26, D Loss: 0.1043895930165654, G Loss: 24.581615447998047\n",
      "Epoch: 48, Batch: 27, D Loss: 0.1037594527100865, G Loss: 24.786346435546875\n",
      "Epoch: 48, Batch: 28, D Loss: 0.09958009422688488, G Loss: 24.77914047241211\n",
      "Epoch: 48, Batch: 29, D Loss: 0.10437799991029309, G Loss: 24.80983543395996\n",
      "Epoch: 48, Batch: 30, D Loss: 0.09883895517318547, G Loss: 24.6303653717041\n",
      "Epoch: 48, Batch: 31, D Loss: 0.09674373270286091, G Loss: 24.286579132080078\n",
      "Epoch: 48, Batch: 32, D Loss: 0.10007698835519496, G Loss: 24.083391189575195\n",
      "Epoch: 48, Batch: 33, D Loss: 0.09694901110592084, G Loss: 23.962785720825195\n",
      "Epoch: 48, Batch: 34, D Loss: 0.09642488511404583, G Loss: 23.93503189086914\n",
      "Epoch: 48, Batch: 35, D Loss: 0.1013243794617775, G Loss: 24.185409545898438\n",
      "Epoch: 48, Batch: 36, D Loss: 0.09849552811562706, G Loss: 24.443708419799805\n",
      "Epoch: 48, Batch: 37, D Loss: 0.10091127456299313, G Loss: 24.68792724609375\n",
      "Epoch: 48, Batch: 38, D Loss: 0.09791036696182706, G Loss: 24.703937530517578\n",
      "Epoch: 48, Batch: 39, D Loss: 0.10454066843675106, G Loss: 24.814950942993164\n",
      "Epoch: 48, Batch: 40, D Loss: 0.10067944229492057, G Loss: 24.798303604125977\n",
      "Epoch: 48, Batch: 41, D Loss: 0.09930668772190644, G Loss: 24.639129638671875\n",
      "Epoch: 48, Batch: 42, D Loss: 0.09909445048498569, G Loss: 24.416282653808594\n",
      "Epoch: 48, Batch: 43, D Loss: 0.1005706563721464, G Loss: 24.341821670532227\n",
      "Epoch: 48, Batch: 44, D Loss: 0.09259492160459455, G Loss: 24.042430877685547\n",
      "Epoch: 48, Batch: 45, D Loss: 0.10493095220757628, G Loss: 24.249467849731445\n",
      "Epoch: 48, Batch: 46, D Loss: 0.10192289949681119, G Loss: 24.610891342163086\n",
      "Epoch: 48, Batch: 47, D Loss: 0.10359954834812042, G Loss: 25.015796661376953\n",
      "Epoch: 48, Batch: 48, D Loss: 0.09555511922365587, G Loss: 24.913333892822266\n",
      "Epoch: 48, Batch: 49, D Loss: 0.09936775268000764, G Loss: 24.63524627685547\n",
      "Epoch: 48, Batch: 50, D Loss: 0.09796035290970363, G Loss: 24.28097152709961\n",
      "Epoch: 48, Batch: 51, D Loss: 0.10226310791104622, G Loss: 24.15918731689453\n",
      "Epoch: 48, Batch: 52, D Loss: 0.09696480633480818, G Loss: 24.109434127807617\n",
      "Epoch: 48, Batch: 53, D Loss: 0.09713653476725011, G Loss: 24.12419891357422\n",
      "Epoch: 48, Batch: 54, D Loss: 0.1015462875511927, G Loss: 24.38004493713379\n",
      "Epoch: 48, Batch: 55, D Loss: 0.09795539082253901, G Loss: 24.587472915649414\n",
      "Epoch: 48, Batch: 56, D Loss: 0.0984887406330602, G Loss: 24.666419982910156\n",
      "Epoch: 48, Batch: 57, D Loss: 0.09357063473410807, G Loss: 24.35892677307129\n",
      "Epoch: 48, Batch: 58, D Loss: 0.09692041577426556, G Loss: 24.09084701538086\n",
      "Epoch: 48, Batch: 59, D Loss: 0.10115490110465604, G Loss: 24.076013565063477\n",
      "Epoch: 48, Batch: 60, D Loss: 0.10644564033937642, G Loss: 24.525726318359375\n",
      "Epoch: 48, Batch: 61, D Loss: 0.09986808151921006, G Loss: 24.903047561645508\n",
      "Epoch: 48, Batch: 62, D Loss: 0.09858041257394275, G Loss: 24.99722671508789\n",
      "Epoch: 48, Batch: 63, D Loss: 0.10036599636845157, G Loss: 24.812753677368164\n",
      "Epoch: 48, Batch: 64, D Loss: 0.10338128359035037, G Loss: 24.65607261657715\n",
      "Epoch: 48, Batch: 65, D Loss: 0.09962407500660568, G Loss: 24.41983413696289\n",
      "Epoch: 48, Batch: 66, D Loss: 0.098002851023541, G Loss: 24.168386459350586\n",
      "Epoch: 48, Batch: 67, D Loss: 0.10300341250076167, G Loss: 24.205888748168945\n",
      "Epoch: 48, Batch: 68, D Loss: 0.1059427708515173, G Loss: 24.558147430419922\n",
      "Epoch: 48, Batch: 69, D Loss: 0.09919600189723789, G Loss: 24.720640182495117\n",
      "Epoch: 48, Batch: 70, D Loss: 0.10152956844268762, G Loss: 24.774349212646484\n",
      "Epoch: 48, Batch: 71, D Loss: 0.10056701303442593, G Loss: 24.68053436279297\n",
      "Epoch: 48, Batch: 72, D Loss: 0.1070029512140167, G Loss: 24.74478530883789\n",
      "Epoch: 48, Batch: 73, D Loss: 0.09387243540181198, G Loss: 24.37858009338379\n",
      "Epoch: 48, Batch: 74, D Loss: 0.09636956454970164, G Loss: 23.91986656188965\n",
      "Epoch: 48, Batch: 75, D Loss: 0.10283443333803337, G Loss: 23.88324546813965\n",
      "Epoch: 48, Batch: 76, D Loss: 0.10376056285520087, G Loss: 24.18720054626465\n",
      "Epoch: 48, Batch: 77, D Loss: 0.09892429412776856, G Loss: 24.448802947998047\n",
      "Epoch: 48, Batch: 78, D Loss: 0.10002687574531388, G Loss: 24.62466812133789\n",
      "Epoch: 48, Batch: 79, D Loss: 0.10032451153780726, G Loss: 24.68479347229004\n",
      "Epoch: 48, Batch: 80, D Loss: 0.09901915491653801, G Loss: 24.540929794311523\n",
      "Epoch: 48, Batch: 81, D Loss: 0.10012421013123016, G Loss: 24.376148223876953\n",
      "Epoch: 48, Batch: 82, D Loss: 0.09493802489365308, G Loss: 24.080053329467773\n",
      "Epoch: 48, Batch: 83, D Loss: 0.09709881248008255, G Loss: 23.897207260131836\n",
      "Epoch: 48, Batch: 84, D Loss: 0.09939672054847024, G Loss: 23.995248794555664\n",
      "Epoch: 48, Batch: 85, D Loss: 0.09745730461402158, G Loss: 24.189767837524414\n",
      "Epoch: 48, Batch: 86, D Loss: 0.09925522656584508, G Loss: 24.48918914794922\n",
      "Epoch: 48, Batch: 87, D Loss: 0.10115464032671377, G Loss: 24.81380271911621\n",
      "Epoch: 48, Batch: 88, D Loss: 0.09713961929906405, G Loss: 24.843534469604492\n",
      "Epoch: 48, Batch: 89, D Loss: 0.10226371140099665, G Loss: 24.844242095947266\n",
      "Epoch: 48, Batch: 90, D Loss: 0.09902343154856046, G Loss: 24.642032623291016\n",
      "Epoch: 48, Batch: 91, D Loss: 0.09316083790164853, G Loss: 24.144187927246094\n",
      "Epoch: 48, Batch: 92, D Loss: 0.10802268238411658, G Loss: 24.261693954467773\n",
      "Epoch: 48, Batch: 93, D Loss: 0.09739845247453478, G Loss: 24.36510467529297\n",
      "Epoch: 48, Batch: 94, D Loss: 0.10064065457570852, G Loss: 24.562606811523438\n",
      "Epoch: 48, Batch: 95, D Loss: 0.09815585614290483, G Loss: 24.62666893005371\n",
      "Epoch: 48, Batch: 96, D Loss: 0.10372466594898794, G Loss: 24.80556297302246\n",
      "Epoch: 48, Batch: 97, D Loss: 0.09252831340815543, G Loss: 24.521255493164062\n",
      "Epoch: 48, Batch: 98, D Loss: 0.10319408775558286, G Loss: 24.41939353942871\n",
      "Epoch: 48, Batch: 99, D Loss: 0.09911148251391051, G Loss: 24.348648071289062\n",
      "Epoch: 48, Batch: 100, D Loss: 0.0953029468802944, G Loss: 24.157503128051758\n",
      "Epoch: 48, Batch: 101, D Loss: 0.09655106814454521, G Loss: 24.013961791992188\n",
      "Epoch: 48, Batch: 102, D Loss: 0.10387464614363207, G Loss: 24.253501892089844\n",
      "Epoch: 48, Batch: 103, D Loss: 0.09418758751403421, G Loss: 24.28449058532715\n",
      "Epoch: 48, Batch: 104, D Loss: 0.0927070975460284, G Loss: 24.098695755004883\n",
      "Epoch: 48, Batch: 105, D Loss: 0.0931240394911322, G Loss: 23.802797317504883\n",
      "Epoch: 48, Batch: 106, D Loss: 0.09383554014138747, G Loss: 23.601825714111328\n",
      "Epoch: 48, Batch: 107, D Loss: 0.09203214946386971, G Loss: 23.49203109741211\n",
      "Epoch: 48, Batch: 108, D Loss: 0.10066053273907528, G Loss: 23.8383846282959\n",
      "Epoch: 48, Batch: 109, D Loss: 0.09757307173572655, G Loss: 24.288612365722656\n",
      "Epoch: 48, Batch: 110, D Loss: 0.1061697304345927, G Loss: 25.00129508972168\n",
      "Epoch: 48, Batch: 111, D Loss: 0.10629127175122682, G Loss: 25.5976505279541\n",
      "Epoch: 48, Batch: 112, D Loss: 0.0986297950187963, G Loss: 25.539764404296875\n",
      "Epoch: 48, Batch: 113, D Loss: 0.10084705800338624, G Loss: 25.061738967895508\n",
      "Epoch: 48, Batch: 114, D Loss: 0.10054217279863127, G Loss: 24.43824005126953\n",
      "Epoch: 48, Batch: 115, D Loss: 0.09575694801152877, G Loss: 23.773704528808594\n",
      "Epoch: 48, Batch: 116, D Loss: 0.10314039143406137, G Loss: 23.695472717285156\n",
      "Epoch: 48, Batch: 117, D Loss: 0.10521639140412159, G Loss: 24.209983825683594\n",
      "Epoch: 48, Batch: 118, D Loss: 0.1019979715456523, G Loss: 24.849693298339844\n",
      "Epoch: 48, Batch: 119, D Loss: 0.0922640115100679, G Loss: 24.913925170898438\n",
      "Epoch: 48, Batch: 120, D Loss: 0.09774680436511617, G Loss: 24.683950424194336\n",
      "Epoch: 48, Batch: 121, D Loss: 0.09622208030200483, G Loss: 24.29472541809082\n",
      "Epoch: 48, Batch: 122, D Loss: 0.0990224555294578, G Loss: 24.05168342590332\n",
      "Epoch: 48, Batch: 123, D Loss: 0.09899507464791038, G Loss: 24.030441284179688\n",
      "Epoch: 48, Batch: 124, D Loss: 0.10613787175645349, G Loss: 24.515596389770508\n",
      "Epoch: 48, Batch: 125, D Loss: 0.09264358879202356, G Loss: 24.620397567749023\n",
      "Epoch: 48, Batch: 126, D Loss: 0.0986229553918137, G Loss: 24.65951156616211\n",
      "Epoch: 48, Batch: 127, D Loss: 0.10198352486824011, G Loss: 24.75374412536621\n",
      "Epoch: 48, Batch: 128, D Loss: 0.09680302442066419, G Loss: 24.633562088012695\n",
      "Epoch: 48, Batch: 129, D Loss: 0.09716169537232115, G Loss: 24.424110412597656\n",
      "Epoch: 48, Batch: 130, D Loss: 0.09904238582964972, G Loss: 24.315784454345703\n",
      "Epoch: 48, Batch: 131, D Loss: 0.09831265361503586, G Loss: 24.30181884765625\n",
      "Epoch: 48, Batch: 132, D Loss: 0.09497094900857667, G Loss: 24.24064826965332\n",
      "Epoch: 48, Batch: 133, D Loss: 0.09888217599613033, G Loss: 24.333633422851562\n",
      "Epoch: 48, Batch: 134, D Loss: 0.1111012920831293, G Loss: 25.022571563720703\n",
      "Epoch: 48, Batch: 135, D Loss: 0.10023625195569516, G Loss: 25.447086334228516\n",
      "Epoch: 48, Batch: 136, D Loss: 0.10359556973385542, G Loss: 25.62016487121582\n",
      "Epoch: 48, Batch: 137, D Loss: 0.10260991752559637, G Loss: 25.433761596679688\n",
      "Epoch: 48, Batch: 138, D Loss: 0.09362624586295604, G Loss: 24.684249877929688\n",
      "Epoch: 48, Batch: 139, D Loss: 0.09955875576857694, G Loss: 24.07261085510254\n",
      "Epoch: 48, Batch: 140, D Loss: 0.09541486950910769, G Loss: 23.65850830078125\n",
      "Epoch: 48, Batch: 141, D Loss: 0.10545127096020573, G Loss: 23.99156379699707\n",
      "Epoch: 48, Batch: 142, D Loss: 0.09797683359666189, G Loss: 24.481578826904297\n",
      "Epoch: 48, Batch: 143, D Loss: 0.09451968968941502, G Loss: 24.723073959350586\n",
      "Epoch: 48, Batch: 144, D Loss: 0.09870935232300915, G Loss: 24.8568172454834\n",
      "Epoch: 48, Batch: 145, D Loss: 0.09755488485932182, G Loss: 24.78012466430664\n",
      "Epoch: 48, Batch: 146, D Loss: 0.10020357371272307, G Loss: 24.714174270629883\n",
      "Epoch: 48, Batch: 147, D Loss: 0.10459485650917379, G Loss: 24.86234474182129\n",
      "Epoch: 48, Batch: 148, D Loss: 0.09940828383751335, G Loss: 24.897130966186523\n",
      "Epoch: 48, Batch: 149, D Loss: 0.10350249708430627, G Loss: 24.99289321899414\n",
      "Epoch: 48, Batch: 150, D Loss: 0.10153685510846189, G Loss: 25.024948120117188\n",
      "Epoch: 48, Batch: 151, D Loss: 0.10244940221980607, G Loss: 25.042844772338867\n",
      "Epoch: 48, Batch: 152, D Loss: 0.10312813521089512, G Loss: 25.06378173828125\n",
      "Epoch: 48, Batch: 153, D Loss: 0.09802758694414386, G Loss: 24.875465393066406\n",
      "Epoch: 48, Batch: 154, D Loss: 0.09685753286807812, G Loss: 24.571104049682617\n",
      "Epoch: 48, Batch: 155, D Loss: 0.1014023721330796, G Loss: 24.466068267822266\n",
      "Epoch: 48, Batch: 156, D Loss: 0.09819688649180416, G Loss: 24.449201583862305\n",
      "Epoch: 48, Batch: 157, D Loss: 0.09788057209234045, G Loss: 24.499919891357422\n",
      "Epoch: 48, Batch: 158, D Loss: 0.10070856661628752, G Loss: 24.71150016784668\n",
      "Epoch: 48, Batch: 159, D Loss: 0.09913667292252938, G Loss: 24.875186920166016\n",
      "Epoch: 48, Batch: 160, D Loss: 0.10191939026834096, G Loss: 25.05204200744629\n",
      "Epoch: 48, Batch: 161, D Loss: 0.09767638147553044, G Loss: 25.004871368408203\n",
      "Epoch: 48, Batch: 162, D Loss: 0.09856790304947292, G Loss: 24.81562614440918\n",
      "Epoch: 48, Batch: 163, D Loss: 0.10233779997491749, G Loss: 24.763479232788086\n",
      "Epoch: 48, Batch: 164, D Loss: 0.09872803837976675, G Loss: 24.68714141845703\n",
      "Epoch: 48, Batch: 165, D Loss: 0.0961742103204365, G Loss: 24.504114151000977\n",
      "Epoch: 48, Batch: 166, D Loss: 0.09428489954583026, G Loss: 24.24949073791504\n",
      "Epoch: 48, Batch: 167, D Loss: 0.09597349168484481, G Loss: 24.07269859313965\n",
      "Epoch: 48, Batch: 168, D Loss: 0.09812234343753487, G Loss: 24.18390464782715\n",
      "Epoch: 48, Batch: 169, D Loss: 0.10321599991335412, G Loss: 24.68575096130371\n",
      "Epoch: 48, Batch: 170, D Loss: 0.10009124875823072, G Loss: 25.11650848388672\n",
      "Epoch: 48, Batch: 171, D Loss: 0.09256479889811493, G Loss: 25.000072479248047\n",
      "Epoch: 48, Batch: 172, D Loss: 0.10352975875850522, G Loss: 24.954280853271484\n",
      "Epoch: 48, Batch: 173, D Loss: 0.09896160662960113, G Loss: 24.804996490478516\n",
      "Epoch: 48, Batch: 174, D Loss: 0.09821403027506825, G Loss: 24.628456115722656\n",
      "Epoch: 48, Batch: 175, D Loss: 0.10056550801830115, G Loss: 24.585681915283203\n",
      "Epoch: 48, Batch: 176, D Loss: 0.10201485456020348, G Loss: 24.710243225097656\n",
      "Epoch: 48, Batch: 177, D Loss: 0.10075829923985387, G Loss: 24.916187286376953\n",
      "Epoch: 48, Batch: 178, D Loss: 0.09371940792406842, G Loss: 24.806547164916992\n",
      "Epoch: 48, Batch: 179, D Loss: 0.0976568311543913, G Loss: 24.659269332885742\n",
      "Epoch: 48, Batch: 180, D Loss: 0.09974133969337487, G Loss: 24.643953323364258\n",
      "Epoch: 48, Batch: 181, D Loss: 0.09798194468994376, G Loss: 24.679561614990234\n",
      "Epoch: 48, Batch: 182, D Loss: 0.0995105430572817, G Loss: 24.816898345947266\n",
      "Epoch: 48, Batch: 183, D Loss: 0.1001825258210905, G Loss: 25.015628814697266\n",
      "Epoch: 48, Batch: 184, D Loss: 0.10227421671742389, G Loss: 25.290870666503906\n",
      "Epoch: 48, Batch: 185, D Loss: 0.10203638673297064, G Loss: 25.48681640625\n",
      "Epoch: 48, Batch: 186, D Loss: 0.09913146496264802, G Loss: 25.404407501220703\n",
      "Epoch: 48, Batch: 187, D Loss: 0.09919832647384697, G Loss: 25.1209659576416\n",
      "Epoch: 48, Batch: 188, D Loss: 0.09841966629784492, G Loss: 24.726078033447266\n",
      "Epoch: 48, Batch: 189, D Loss: 0.09757506848462119, G Loss: 24.406099319458008\n",
      "Epoch: 48, Batch: 190, D Loss: 0.10215175898116731, G Loss: 24.442537307739258\n",
      "Epoch: 48, Batch: 191, D Loss: 0.10087962449658852, G Loss: 24.694515228271484\n",
      "Epoch: 48, Batch: 192, D Loss: 0.09484182299103759, G Loss: 24.739768981933594\n",
      "Epoch: 48, Batch: 193, D Loss: 0.09825197608180196, G Loss: 24.738399505615234\n",
      "Epoch: 48, Batch: 194, D Loss: 0.09937392176106201, G Loss: 24.72463035583496\n",
      "Epoch: 48, Batch: 195, D Loss: 0.09380652756553393, G Loss: 24.452312469482422\n",
      "Epoch: 48, Batch: 196, D Loss: 0.10045354069535478, G Loss: 24.366579055786133\n",
      "Epoch: 48, Batch: 197, D Loss: 0.0987873524559802, G Loss: 24.344091415405273\n",
      "Epoch: 48, Batch: 198, D Loss: 0.09839639814045396, G Loss: 24.344905853271484\n",
      "Epoch: 48, Batch: 199, D Loss: 0.0983300581705902, G Loss: 24.376924514770508\n",
      "Epoch: 48, Batch: 200, D Loss: 0.10088988394766281, G Loss: 24.48571014404297\n",
      "Epoch: 48, Batch: 201, D Loss: 0.09600950778739333, G Loss: 24.409847259521484\n",
      "Epoch: 48, Batch: 202, D Loss: 0.09267134220905836, G Loss: 24.06836700439453\n",
      "Epoch: 48, Batch: 203, D Loss: 0.10334864260502608, G Loss: 24.09723472595215\n",
      "Epoch: 48, Batch: 204, D Loss: 0.10280654580883017, G Loss: 24.368268966674805\n",
      "Epoch: 48, Batch: 205, D Loss: 0.10700298846760531, G Loss: 24.889158248901367\n",
      "Epoch: 48, Batch: 206, D Loss: 0.09909131378642042, G Loss: 25.066539764404297\n",
      "Epoch: 48, Batch: 207, D Loss: 0.10180215538216936, G Loss: 25.011274337768555\n",
      "Epoch: 48, Batch: 208, D Loss: 0.10866814107385864, G Loss: 25.021160125732422\n",
      "Epoch: 48, Batch: 209, D Loss: 0.10117434711021547, G Loss: 24.81594467163086\n",
      "Epoch: 48, Batch: 210, D Loss: 0.10256249458527907, G Loss: 24.61006736755371\n",
      "Epoch: 48, Batch: 211, D Loss: 0.09384325893061199, G Loss: 24.109888076782227\n",
      "Epoch: 48, Batch: 212, D Loss: 0.09080197664467854, G Loss: 23.479572296142578\n",
      "Epoch: 48, Batch: 213, D Loss: 0.10411719980867304, G Loss: 23.580787658691406\n",
      "Epoch: 48, Batch: 214, D Loss: 0.09672719242556174, G Loss: 23.945554733276367\n",
      "Epoch: 48, Batch: 215, D Loss: 0.09615466000249936, G Loss: 24.36163902282715\n",
      "Epoch: 48, Batch: 216, D Loss: 0.09473272414184485, G Loss: 24.584667205810547\n",
      "Epoch: 48, Batch: 217, D Loss: 0.10479480774062012, G Loss: 24.98488426208496\n",
      "Epoch: 48, Batch: 218, D Loss: 0.10331338644637626, G Loss: 25.259963989257812\n",
      "Epoch: 48, Batch: 219, D Loss: 0.10267814249320786, G Loss: 25.3137264251709\n",
      "Epoch: 48, Batch: 220, D Loss: 0.10226235539266969, G Loss: 25.174758911132812\n",
      "Epoch: 48, Batch: 221, D Loss: 0.1021593213148053, G Loss: 24.919103622436523\n",
      "Epoch: 48, Batch: 222, D Loss: 0.10348665715079847, G Loss: 24.766246795654297\n",
      "Epoch: 48, Batch: 223, D Loss: 0.10406832397854603, G Loss: 24.78095054626465\n",
      "Epoch: 48, Batch: 224, D Loss: 0.0967360437009221, G Loss: 24.6446590423584\n",
      "Epoch: 48, Batch: 225, D Loss: 0.09887614102205809, G Loss: 24.562744140625\n",
      "Epoch: 48, Batch: 226, D Loss: 0.101764254282078, G Loss: 24.682851791381836\n",
      "Epoch: 48, Batch: 227, D Loss: 0.09812624753434551, G Loss: 24.76535987854004\n",
      "Epoch: 48, Batch: 228, D Loss: 0.10184816271857884, G Loss: 24.963138580322266\n",
      "Epoch: 48, Batch: 229, D Loss: 0.09906214476324254, G Loss: 25.038265228271484\n",
      "Epoch: 48, Batch: 230, D Loss: 0.09458543361000823, G Loss: 24.77511215209961\n",
      "Epoch: 48, Batch: 231, D Loss: 0.09396095574999822, G Loss: 24.331937789916992\n",
      "Epoch: 48, Batch: 232, D Loss: 0.09479171784361701, G Loss: 23.97944450378418\n",
      "Epoch: 48, Batch: 233, D Loss: 0.0980562269878564, G Loss: 23.996984481811523\n",
      "Epoch: 48, Batch: 234, D Loss: 0.09733746202437595, G Loss: 24.271080017089844\n",
      "Epoch: 48, Batch: 235, D Loss: 0.10089483113203038, G Loss: 24.77065086364746\n",
      "Epoch: 48, Batch: 236, D Loss: 0.0968051999882424, G Loss: 25.05723762512207\n",
      "Epoch: 48, Batch: 237, D Loss: 0.0960154756971277, G Loss: 24.998687744140625\n",
      "Epoch: 48, Batch: 238, D Loss: 0.10084933043253133, G Loss: 24.914264678955078\n",
      "Epoch: 48, Batch: 239, D Loss: 0.09616009891894832, G Loss: 24.666872024536133\n",
      "Epoch: 48, Batch: 240, D Loss: 0.09758584202434782, G Loss: 24.427520751953125\n",
      "Epoch: 48, Batch: 241, D Loss: 0.09715492279645095, G Loss: 24.312650680541992\n",
      "Epoch: 48, Batch: 242, D Loss: 0.10495361686900567, G Loss: 24.6636905670166\n",
      "Epoch: 48, Batch: 243, D Loss: 0.0987783968531046, G Loss: 24.977197647094727\n",
      "Epoch: 48, Batch: 244, D Loss: 0.0958495438168627, G Loss: 25.012908935546875\n",
      "Epoch: 48, Batch: 245, D Loss: 0.09423530102558139, G Loss: 24.762380599975586\n",
      "Epoch: 48, Batch: 246, D Loss: 0.09944654257057178, G Loss: 24.614778518676758\n",
      "Epoch: 48, Batch: 247, D Loss: 0.09929908813067059, G Loss: 24.61427116394043\n",
      "Epoch: 48, Batch: 248, D Loss: 0.09663495422439394, G Loss: 24.598459243774414\n",
      "Epoch: 48, Batch: 249, D Loss: 0.10095465184198524, G Loss: 24.7850341796875\n",
      "Epoch: 48, Batch: 250, D Loss: 0.09616137296784912, G Loss: 24.86943244934082\n",
      "Epoch: 48, Batch: 251, D Loss: 0.0991479307487999, G Loss: 24.973766326904297\n",
      "Epoch: 48, Batch: 252, D Loss: 0.09766209126218067, G Loss: 25.01034927368164\n",
      "Epoch: 48, Batch: 253, D Loss: 0.1051716655552315, G Loss: 25.283069610595703\n",
      "Epoch: 48, Batch: 254, D Loss: 0.09080435336225784, G Loss: 25.05571174621582\n",
      "Epoch: 48, Batch: 255, D Loss: 0.10123093426923795, G Loss: 24.944799423217773\n",
      "Epoch: 48, Batch: 256, D Loss: 0.10233457387190287, G Loss: 25.043689727783203\n",
      "Epoch: 48, Batch: 257, D Loss: 0.09744836390676591, G Loss: 25.06237030029297\n",
      "Epoch: 48, Batch: 258, D Loss: 0.09582474828455008, G Loss: 24.959787368774414\n",
      "Epoch: 48, Batch: 259, D Loss: 0.10664364696164969, G Loss: 25.263765335083008\n",
      "Epoch: 48, Batch: 260, D Loss: 0.09763272107148227, G Loss: 25.383840560913086\n",
      "Epoch: 48, Batch: 261, D Loss: 0.10052767396434392, G Loss: 25.432106018066406\n",
      "Epoch: 48, Batch: 262, D Loss: 0.10330503434375035, G Loss: 25.511856079101562\n",
      "Epoch: 48, Batch: 263, D Loss: 0.1029626429121263, G Loss: 25.573219299316406\n",
      "Epoch: 48, Batch: 264, D Loss: 0.09832677245568375, G Loss: 25.402616500854492\n",
      "Epoch: 48, Batch: 265, D Loss: 0.09865097702082687, G Loss: 25.139415740966797\n",
      "Epoch: 48, Batch: 266, D Loss: 0.09325595945890884, G Loss: 24.674909591674805\n",
      "Epoch: 48, Batch: 267, D Loss: 0.09672305734066251, G Loss: 24.41695213317871\n",
      "Epoch: 48, Batch: 268, D Loss: 0.09703160078560401, G Loss: 24.44321060180664\n",
      "Epoch: 48, Batch: 269, D Loss: 0.09865148366525023, G Loss: 24.756563186645508\n",
      "Epoch: 48, Batch: 270, D Loss: 0.09536542744201112, G Loss: 25.055740356445312\n",
      "Epoch: 48, Batch: 271, D Loss: 0.09937112033933108, G Loss: 25.33826446533203\n",
      "Epoch: 48, Batch: 272, D Loss: 0.10221508145757086, G Loss: 25.630178451538086\n",
      "Epoch: 48, Batch: 273, D Loss: 0.09880193323261698, G Loss: 25.65616798400879\n",
      "Epoch: 48, Batch: 274, D Loss: 0.09939892590443186, G Loss: 25.47087287902832\n",
      "Epoch: 48, Batch: 275, D Loss: 0.09799955785788819, G Loss: 25.146242141723633\n",
      "Epoch: 48, Batch: 276, D Loss: 0.10094045103260924, G Loss: 24.95146942138672\n",
      "Epoch: 48, Batch: 277, D Loss: 0.10078827292450956, G Loss: 24.96466827392578\n",
      "Epoch: 48, Batch: 278, D Loss: 0.09454731643961363, G Loss: 24.856645584106445\n",
      "Epoch: 48, Batch: 279, D Loss: 0.09746387601718481, G Loss: 24.813730239868164\n",
      "Epoch: 48, Batch: 280, D Loss: 0.09589953721432332, G Loss: 24.75523567199707\n",
      "Epoch: 48, Batch: 281, D Loss: 0.09559508414000618, G Loss: 24.677072525024414\n",
      "Epoch: 48, Batch: 282, D Loss: 0.10034187138963864, G Loss: 24.833494186401367\n",
      "Epoch: 48, Batch: 283, D Loss: 0.0952193886121388, G Loss: 24.88691520690918\n",
      "Epoch: 48, Batch: 284, D Loss: 0.09699317813696254, G Loss: 24.88872718811035\n",
      "Epoch: 48, Batch: 285, D Loss: 0.09928070009515627, G Loss: 24.926382064819336\n",
      "Epoch: 48, Batch: 286, D Loss: 0.1010268926691421, G Loss: 25.02570343017578\n",
      "Epoch: 48, Batch: 287, D Loss: 0.1025503575864073, G Loss: 25.1853084564209\n",
      "Epoch: 48, Batch: 288, D Loss: 0.10068865120968688, G Loss: 25.24953842163086\n",
      "Epoch: 48, Batch: 289, D Loss: 0.09888060391520924, G Loss: 25.144872665405273\n",
      "Epoch: 48, Batch: 290, D Loss: 0.10550391674626107, G Loss: 25.197433471679688\n",
      "Epoch: 48, Batch: 291, D Loss: 0.10615711659703018, G Loss: 25.408727645874023\n",
      "Epoch: 48, Batch: 292, D Loss: 0.09746811539426549, G Loss: 25.287382125854492\n",
      "Epoch: 48, Batch: 293, D Loss: 0.10141481459716878, G Loss: 25.096073150634766\n",
      "Epoch: 48, Batch: 294, D Loss: 0.09922001511573963, G Loss: 24.85662078857422\n",
      "Epoch: 48, Batch: 295, D Loss: 0.09839657694994518, G Loss: 24.65056610107422\n",
      "Epoch: 48, Batch: 296, D Loss: 0.09995456040894636, G Loss: 24.642419815063477\n",
      "Epoch: 48, Batch: 297, D Loss: 0.10170497746157285, G Loss: 24.867828369140625\n",
      "Epoch: 48, Batch: 298, D Loss: 0.09257808328488437, G Loss: 24.81801986694336\n",
      "Epoch: 48, Batch: 299, D Loss: 0.09381050617425236, G Loss: 24.62401008605957\n",
      "Epoch: 48, Batch: 300, D Loss: 0.09476120771085916, G Loss: 24.449871063232422\n",
      "Epoch: 48, Batch: 301, D Loss: 0.10030046106495978, G Loss: 24.601917266845703\n",
      "Epoch: 48, Batch: 302, D Loss: 0.09717898071724111, G Loss: 24.840511322021484\n",
      "Epoch: 48, Batch: 303, D Loss: 0.10380133987105013, G Loss: 25.322166442871094\n",
      "Epoch: 48, Batch: 304, D Loss: 0.0984337776943707, G Loss: 25.561384201049805\n",
      "Epoch: 48, Batch: 305, D Loss: 0.09919355810087603, G Loss: 25.54737091064453\n",
      "Epoch: 48, Batch: 306, D Loss: 0.09911985695813832, G Loss: 25.32424545288086\n",
      "Epoch: 48, Batch: 307, D Loss: 0.0948236584728091, G Loss: 24.841758728027344\n",
      "Epoch: 48, Batch: 308, D Loss: 0.09850279242764036, G Loss: 24.51932144165039\n",
      "Epoch: 48, Batch: 309, D Loss: 0.09634731711157785, G Loss: 24.392152786254883\n",
      "Epoch: 48, Batch: 310, D Loss: 0.10103400797738242, G Loss: 24.696523666381836\n",
      "Epoch: 48, Batch: 311, D Loss: 0.10680831969410128, G Loss: 25.469362258911133\n",
      "Epoch: 48, Batch: 312, D Loss: 0.0991750359569052, G Loss: 25.943788528442383\n",
      "Epoch: 48, Batch: 313, D Loss: 0.10358276963474415, G Loss: 26.1654052734375\n",
      "Epoch: 48, Batch: 314, D Loss: 0.1001373976493526, G Loss: 25.931364059448242\n",
      "Epoch: 48, Batch: 315, D Loss: 0.09921451658366984, G Loss: 25.42903709411621\n",
      "Epoch: 48, Batch: 316, D Loss: 0.10247828066894304, G Loss: 25.07276153564453\n",
      "Epoch: 48, Batch: 317, D Loss: 0.10400038958241825, G Loss: 25.071796417236328\n",
      "Epoch: 48, Batch: 318, D Loss: 0.10496725142540318, G Loss: 25.419275283813477\n",
      "Epoch: 48, Batch: 319, D Loss: 0.1012214794794351, G Loss: 25.701414108276367\n",
      "Epoch: 48, Batch: 320, D Loss: 0.09764970839377955, G Loss: 25.646873474121094\n",
      "Epoch: 48, Batch: 321, D Loss: 0.09729269892401271, G Loss: 25.355348587036133\n",
      "Epoch: 48, Batch: 322, D Loss: 0.09992575645998122, G Loss: 25.118297576904297\n",
      "Epoch: 48, Batch: 323, D Loss: 0.0973131656715183, G Loss: 24.9205379486084\n",
      "Epoch: 48, Batch: 324, D Loss: 0.09729888290945068, G Loss: 24.854990005493164\n",
      "Epoch: 48, Batch: 325, D Loss: 0.10411861539560971, G Loss: 25.18707275390625\n",
      "Epoch: 48, Batch: 326, D Loss: 0.10731545836140023, G Loss: 25.84916114807129\n",
      "Epoch: 48, Batch: 327, D Loss: 0.10013363510621276, G Loss: 26.168813705444336\n",
      "Epoch: 48, Batch: 328, D Loss: 0.09635495394714738, G Loss: 25.916133880615234\n",
      "Epoch: 48, Batch: 329, D Loss: 0.09733601659909193, G Loss: 25.358476638793945\n",
      "Epoch: 48, Batch: 330, D Loss: 0.09756190330443351, G Loss: 24.79244613647461\n",
      "Epoch: 48, Batch: 331, D Loss: 0.09868377448108416, G Loss: 24.531755447387695\n",
      "Epoch: 48, Batch: 332, D Loss: 0.0950379073733576, G Loss: 24.483985900878906\n",
      "Epoch: 48, Batch: 333, D Loss: 0.0975974425774972, G Loss: 24.743314743041992\n",
      "Epoch: 48, Batch: 334, D Loss: 0.09321004153093876, G Loss: 24.971736907958984\n",
      "Epoch: 48, Batch: 335, D Loss: 0.09972859919656445, G Loss: 25.35006332397461\n",
      "Epoch: 48, Batch: 336, D Loss: 0.1056359931862347, G Loss: 25.947595596313477\n",
      "Epoch: 48, Batch: 337, D Loss: 0.09789436310776051, G Loss: 26.116140365600586\n",
      "Epoch: 48, Batch: 338, D Loss: 0.09952544421209125, G Loss: 25.924528121948242\n",
      "Epoch: 48, Batch: 339, D Loss: 0.09966724366289897, G Loss: 25.52366828918457\n",
      "Epoch: 48, Batch: 340, D Loss: 0.09623305500091774, G Loss: 25.01236915588379\n",
      "Epoch: 48, Batch: 341, D Loss: 0.09809861332984163, G Loss: 24.70526695251465\n",
      "Epoch: 48, Batch: 342, D Loss: 0.09826342017397721, G Loss: 24.691499710083008\n",
      "Epoch: 48, Batch: 343, D Loss: 0.09553489834954812, G Loss: 24.81768035888672\n",
      "Epoch: 48, Batch: 344, D Loss: 0.09565151483580656, G Loss: 24.992172241210938\n",
      "Epoch: 48, Batch: 345, D Loss: 0.10247021914088703, G Loss: 25.41443634033203\n",
      "Epoch: 48, Batch: 346, D Loss: 0.0999250635543465, G Loss: 25.736522674560547\n",
      "Epoch: 48, Batch: 347, D Loss: 0.10247628391091725, G Loss: 25.91468620300293\n",
      "Epoch: 48, Batch: 348, D Loss: 0.10428890586170302, G Loss: 25.964902877807617\n",
      "Epoch: 48, Batch: 349, D Loss: 0.1006225198537433, G Loss: 25.718137741088867\n",
      "Epoch: 48, Batch: 350, D Loss: 0.09551183879837483, G Loss: 25.127599716186523\n",
      "Epoch: 48, Batch: 351, D Loss: 0.09685326368435573, G Loss: 24.570831298828125\n",
      "Epoch: 48, Batch: 352, D Loss: 0.10081216694079313, G Loss: 24.41976547241211\n",
      "Epoch: 48, Batch: 353, D Loss: 0.09551363439578009, G Loss: 24.466867446899414\n",
      "Epoch: 48, Batch: 354, D Loss: 0.09761968256081432, G Loss: 24.715181350708008\n",
      "Epoch: 48, Batch: 355, D Loss: 0.10150679946670418, G Loss: 25.174776077270508\n",
      "Epoch: 48, Batch: 356, D Loss: 0.10000558197981747, G Loss: 25.530515670776367\n",
      "Epoch: 48, Batch: 357, D Loss: 0.0951564610046529, G Loss: 25.47312355041504\n",
      "Epoch: 48, Batch: 358, D Loss: 0.10373247415263466, G Loss: 25.45793914794922\n",
      "Epoch: 48, Batch: 359, D Loss: 0.09251675010296971, G Loss: 24.963857650756836\n",
      "Epoch: 48, Batch: 360, D Loss: 0.10067544878369035, G Loss: 24.670854568481445\n",
      "Epoch: 48, Batch: 361, D Loss: 0.10185302794918893, G Loss: 24.722274780273438\n",
      "Epoch: 48, Batch: 362, D Loss: 0.10022778809882782, G Loss: 24.952125549316406\n",
      "Epoch: 48, Batch: 363, D Loss: 0.10240978003154344, G Loss: 25.301151275634766\n",
      "Epoch: 48, Batch: 364, D Loss: 0.090171203023014, G Loss: 25.077651977539062\n",
      "Epoch: 48, Batch: 365, D Loss: 0.1006720215151173, G Loss: 24.942001342773438\n",
      "Epoch: 48, Batch: 366, D Loss: 0.10269911587946856, G Loss: 25.013883590698242\n",
      "Epoch: 48, Batch: 367, D Loss: 0.09837396443561974, G Loss: 25.050378799438477\n",
      "Epoch: 48, Batch: 368, D Loss: 0.09834314883426531, G Loss: 25.019071578979492\n",
      "Epoch: 48, Batch: 369, D Loss: 0.10540880263448815, G Loss: 25.26958465576172\n",
      "Epoch: 48, Batch: 370, D Loss: 0.09469638765413908, G Loss: 25.18082618713379\n",
      "Epoch: 48, Batch: 371, D Loss: 0.10290848464341744, G Loss: 25.21898078918457\n",
      "Epoch: 48, Batch: 372, D Loss: 0.09908010066122988, G Loss: 25.186613082885742\n",
      "Epoch: 48, Batch: 373, D Loss: 0.10350729525630907, G Loss: 25.304094314575195\n",
      "Epoch: 48, Batch: 374, D Loss: 0.10290361941329719, G Loss: 25.472036361694336\n",
      "Epoch: 48, Batch: 375, D Loss: 0.09829775989499681, G Loss: 25.424678802490234\n",
      "Epoch: 48, Batch: 376, D Loss: 0.0982467681220292, G Loss: 25.21216583251953\n",
      "Epoch: 48, Batch: 377, D Loss: 0.09438688308688219, G Loss: 24.82706642150879\n",
      "Epoch: 48, Batch: 378, D Loss: 0.09537623078610466, G Loss: 24.501733779907227\n",
      "Epoch: 48, Batch: 379, D Loss: 0.10060251505272401, G Loss: 24.59252166748047\n",
      "Epoch: 48, Batch: 380, D Loss: 0.10006509722135491, G Loss: 24.968204498291016\n",
      "Epoch: 48, Batch: 381, D Loss: 0.10493352264671743, G Loss: 25.629806518554688\n",
      "Epoch: 48, Batch: 382, D Loss: 0.09380813688390932, G Loss: 25.72865867614746\n",
      "Epoch: 48, Batch: 383, D Loss: 0.09789857268706319, G Loss: 25.52569007873535\n",
      "Epoch: 48, Batch: 384, D Loss: 0.09457327426010251, G Loss: 25.038129806518555\n",
      "Epoch: 48, Batch: 385, D Loss: 0.10080190003669741, G Loss: 24.815349578857422\n",
      "Epoch: 48, Batch: 386, D Loss: 0.09641308338352442, G Loss: 24.668256759643555\n",
      "Epoch: 48, Batch: 387, D Loss: 0.09876158834420859, G Loss: 24.76999855041504\n",
      "Epoch: 48, Batch: 388, D Loss: 0.09986126423622228, G Loss: 25.08559799194336\n",
      "Epoch: 48, Batch: 389, D Loss: 0.09518629313106475, G Loss: 25.228609085083008\n",
      "Epoch: 48, Batch: 390, D Loss: 0.09794593602960397, G Loss: 25.26679801940918\n",
      "Epoch: 48, Batch: 391, D Loss: 0.10900096595708812, G Loss: 25.708786010742188\n",
      "Epoch: 48, Batch: 392, D Loss: 0.10011793673350537, G Loss: 25.882123947143555\n",
      "Epoch: 48, Batch: 393, D Loss: 0.09911032021354918, G Loss: 25.7432861328125\n",
      "Epoch: 48, Batch: 394, D Loss: 0.10595656186685429, G Loss: 25.670082092285156\n",
      "Epoch: 48, Batch: 395, D Loss: 0.10484897345663724, G Loss: 25.649173736572266\n",
      "Epoch: 48, Batch: 396, D Loss: 0.09793950617723188, G Loss: 25.417903900146484\n",
      "Epoch: 48, Batch: 397, D Loss: 0.09737342596597258, G Loss: 25.09013557434082\n",
      "Epoch: 48, Batch: 398, D Loss: 0.0940852761347855, G Loss: 24.66746711730957\n",
      "Epoch: 48, Batch: 399, D Loss: 0.10385917128046135, G Loss: 24.777790069580078\n",
      "Epoch: 48, Batch: 400, D Loss: 0.10045453161713273, G Loss: 25.151979446411133\n",
      "Epoch: 48, Batch: 401, D Loss: 0.0968223512225151, G Loss: 25.396181106567383\n",
      "Epoch: 48, Batch: 402, D Loss: 0.09746024013010039, G Loss: 25.491342544555664\n",
      "Epoch: 48, Batch: 403, D Loss: 0.10155203938891959, G Loss: 25.569263458251953\n",
      "Epoch: 48, Batch: 404, D Loss: 0.1047762408888317, G Loss: 25.7497615814209\n",
      "Epoch: 48, Batch: 405, D Loss: 0.10032925010056921, G Loss: 25.74193572998047\n",
      "Epoch: 48, Batch: 406, D Loss: 0.10210752487524005, G Loss: 25.68129539489746\n",
      "Epoch: 48, Batch: 407, D Loss: 0.09913717210693854, G Loss: 25.430057525634766\n",
      "Epoch: 48, Batch: 408, D Loss: 0.0970377400570659, G Loss: 25.118934631347656\n",
      "Epoch: 48, Batch: 409, D Loss: 0.10247838497774973, G Loss: 25.129541397094727\n",
      "Epoch: 48, Batch: 410, D Loss: 0.0979288220464748, G Loss: 25.187543869018555\n",
      "Epoch: 48, Batch: 411, D Loss: 0.09840118885587504, G Loss: 25.283794403076172\n",
      "Epoch: 48, Batch: 412, D Loss: 0.09486402571740213, G Loss: 25.226293563842773\n",
      "Epoch: 48, Batch: 413, D Loss: 0.1018518507531335, G Loss: 25.393449783325195\n",
      "Epoch: 48, Batch: 414, D Loss: 0.09946811199617589, G Loss: 25.55931282043457\n",
      "Epoch: 48, Batch: 415, D Loss: 0.09963925183198094, G Loss: 25.648643493652344\n",
      "Epoch: 48, Batch: 416, D Loss: 0.10462859273283384, G Loss: 25.84972381591797\n",
      "Epoch: 48, Batch: 417, D Loss: 0.09912821650806766, G Loss: 25.81911849975586\n",
      "Epoch: 48, Batch: 418, D Loss: 0.09470994770906024, G Loss: 25.413089752197266\n",
      "Epoch: 48, Batch: 419, D Loss: 0.09616295248850254, G Loss: 24.96890640258789\n",
      "Epoch: 48, Batch: 420, D Loss: 0.0983304977497489, G Loss: 24.747085571289062\n",
      "Epoch: 48, Batch: 421, D Loss: 0.10525874794270648, G Loss: 25.103565216064453\n",
      "Epoch: 48, Batch: 422, D Loss: 0.09539068490815858, G Loss: 25.352861404418945\n",
      "Epoch: 48, Batch: 423, D Loss: 0.09810668975567347, G Loss: 25.495988845825195\n",
      "Epoch: 48, Batch: 424, D Loss: 0.10508016497260067, G Loss: 25.784616470336914\n",
      "Epoch: 48, Batch: 425, D Loss: 0.09854645282349152, G Loss: 25.771495819091797\n",
      "Epoch: 48, Batch: 426, D Loss: 0.09964618087170972, G Loss: 25.574474334716797\n",
      "Epoch: 48, Batch: 427, D Loss: 0.09970436990706472, G Loss: 25.32651710510254\n",
      "Epoch: 48, Batch: 428, D Loss: 0.09349954128904335, G Loss: 24.863561630249023\n",
      "Epoch: 48, Batch: 429, D Loss: 0.09431931377436234, G Loss: 24.469511032104492\n",
      "Epoch: 48, Batch: 430, D Loss: 0.10317263753280412, G Loss: 24.676576614379883\n",
      "Epoch: 48, Batch: 431, D Loss: 0.09962007404119852, G Loss: 25.154056549072266\n",
      "Epoch: 48, Batch: 432, D Loss: 0.09204395115938348, G Loss: 25.2604923248291\n",
      "Epoch: 48, Batch: 433, D Loss: 0.09201106429695399, G Loss: 25.057788848876953\n",
      "Epoch: 48, Batch: 434, D Loss: 0.09115586430644275, G Loss: 24.655107498168945\n",
      "Epoch: 48, Batch: 435, D Loss: 0.10401877761797491, G Loss: 24.795928955078125\n",
      "Epoch: 48, Batch: 436, D Loss: 0.09925930947780712, G Loss: 25.126956939697266\n",
      "Epoch: 48, Batch: 437, D Loss: 0.09520076215832464, G Loss: 25.276596069335938\n",
      "Epoch: 48, Batch: 438, D Loss: 0.09920522571103028, G Loss: 25.401939392089844\n",
      "Epoch: 48, Batch: 439, D Loss: 0.09385156631986298, G Loss: 25.200183868408203\n",
      "Epoch: 48, Batch: 440, D Loss: 0.09761722386525068, G Loss: 24.969518661499023\n",
      "Epoch: 48, Batch: 441, D Loss: 0.09466648102635905, G Loss: 24.6899471282959\n",
      "Epoch: 48, Batch: 442, D Loss: 0.10194101185512608, G Loss: 24.773555755615234\n",
      "Epoch: 48, Batch: 443, D Loss: 0.09779632837370764, G Loss: 24.957490921020508\n",
      "Epoch: 48, Batch: 444, D Loss: 0.1015778631033146, G Loss: 25.276857376098633\n",
      "Epoch: 48, Batch: 445, D Loss: 0.10296244174683628, G Loss: 25.610916137695312\n",
      "Epoch: 48, Batch: 446, D Loss: 0.09824187308932784, G Loss: 25.581186294555664\n",
      "Epoch: 48, Batch: 447, D Loss: 0.09729074687234958, G Loss: 25.22128677368164\n",
      "Epoch: 48, Batch: 448, D Loss: 0.09304840863532818, G Loss: 24.57434844970703\n",
      "Epoch: 48, Batch: 449, D Loss: 0.09653105588119996, G Loss: 24.11811065673828\n",
      "Epoch: 48, Batch: 450, D Loss: 0.09109625222340917, G Loss: 23.743776321411133\n",
      "Epoch: 48, Batch: 451, D Loss: 0.1071989834493462, G Loss: 24.270164489746094\n",
      "Epoch: 48, Batch: 452, D Loss: 0.09636000544895361, G Loss: 24.847579956054688\n",
      "Epoch: 48, Batch: 453, D Loss: 0.0974073931640577, G Loss: 25.240419387817383\n",
      "Epoch: 48, Batch: 454, D Loss: 0.0933728888687818, G Loss: 25.160322189331055\n",
      "Epoch: 48, Batch: 455, D Loss: 0.09397894144774405, G Loss: 24.796594619750977\n",
      "Epoch: 48, Batch: 456, D Loss: 0.09812003375099751, G Loss: 24.489765167236328\n",
      "Epoch: 48, Batch: 457, D Loss: 0.10194714368497242, G Loss: 24.57219886779785\n",
      "Epoch: 48, Batch: 458, D Loss: 0.10904473812138521, G Loss: 25.236480712890625\n",
      "Epoch: 48, Batch: 459, D Loss: 0.09355096519491751, G Loss: 25.417396545410156\n",
      "Epoch: 48, Batch: 460, D Loss: 0.09628110379476225, G Loss: 25.265106201171875\n",
      "Epoch: 48, Batch: 461, D Loss: 0.10019166768182435, G Loss: 25.086238861083984\n",
      "Epoch: 48, Batch: 462, D Loss: 0.09670585394625994, G Loss: 24.852460861206055\n",
      "Epoch: 48, Batch: 463, D Loss: 0.10379818082609307, G Loss: 24.977508544921875\n",
      "Epoch: 48, Batch: 464, D Loss: 0.09889508784482316, G Loss: 25.102367401123047\n",
      "Epoch: 48, Batch: 465, D Loss: 0.10712312162422641, G Loss: 25.530786514282227\n",
      "Epoch: 48, Batch: 466, D Loss: 0.10144439339992833, G Loss: 25.79662322998047\n",
      "Epoch: 48, Batch: 467, D Loss: 0.10093428939892841, G Loss: 25.803571701049805\n",
      "Epoch: 49, Batch: 0, D Loss: 0.09585837275181171, G Loss: 25.366708755493164\n",
      "Epoch: 49, Batch: 1, D Loss: 0.09809421003489616, G Loss: 24.86989974975586\n",
      "Epoch: 49, Batch: 2, D Loss: 0.09362622351500223, G Loss: 24.337064743041992\n",
      "Epoch: 49, Batch: 3, D Loss: 0.10525448621578502, G Loss: 24.465911865234375\n",
      "Epoch: 49, Batch: 4, D Loss: 0.1032852977601189, G Loss: 25.05291748046875\n",
      "Epoch: 49, Batch: 5, D Loss: 0.09757566452541029, G Loss: 25.52103042602539\n",
      "Epoch: 49, Batch: 6, D Loss: 0.10401090234844751, G Loss: 25.963539123535156\n",
      "Epoch: 49, Batch: 7, D Loss: 0.09654173255246037, G Loss: 25.863183975219727\n",
      "Epoch: 49, Batch: 8, D Loss: 0.10083784908403122, G Loss: 25.54180335998535\n",
      "Epoch: 49, Batch: 9, D Loss: 0.10077342391492566, G Loss: 25.219682693481445\n",
      "Epoch: 49, Batch: 10, D Loss: 0.09993143380305007, G Loss: 25.027481079101562\n",
      "Epoch: 49, Batch: 11, D Loss: 0.09754010290632249, G Loss: 24.89381217956543\n",
      "Epoch: 49, Batch: 12, D Loss: 0.09463971854099201, G Loss: 24.727081298828125\n",
      "Epoch: 49, Batch: 13, D Loss: 0.1063514649942272, G Loss: 25.117820739746094\n",
      "Epoch: 49, Batch: 14, D Loss: 0.09659060836371548, G Loss: 25.3956241607666\n",
      "Epoch: 49, Batch: 15, D Loss: 0.09860624373392318, G Loss: 25.540502548217773\n",
      "Epoch: 49, Batch: 16, D Loss: 0.09877614677359627, G Loss: 25.52736473083496\n",
      "Epoch: 49, Batch: 17, D Loss: 0.10168514401139643, G Loss: 25.484983444213867\n",
      "Epoch: 49, Batch: 18, D Loss: 0.0981343016075434, G Loss: 25.303781509399414\n",
      "Epoch: 49, Batch: 19, D Loss: 0.09530825913561723, G Loss: 24.97467041015625\n",
      "Epoch: 49, Batch: 20, D Loss: 0.10418031365377536, G Loss: 25.012453079223633\n",
      "Epoch: 49, Batch: 21, D Loss: 0.09288079292335032, G Loss: 24.834978103637695\n",
      "Epoch: 49, Batch: 22, D Loss: 0.1033597514107322, G Loss: 25.02750587463379\n",
      "Epoch: 49, Batch: 23, D Loss: 0.09732386470471871, G Loss: 25.157543182373047\n",
      "Epoch: 49, Batch: 24, D Loss: 0.091511614627268, G Loss: 24.95966148376465\n",
      "Epoch: 49, Batch: 25, D Loss: 0.10332400352449667, G Loss: 25.056962966918945\n",
      "Epoch: 49, Batch: 26, D Loss: 0.09649516642756904, G Loss: 25.03595542907715\n",
      "Epoch: 49, Batch: 27, D Loss: 0.10558582842930116, G Loss: 25.30917739868164\n",
      "Epoch: 49, Batch: 28, D Loss: 0.10122878104904384, G Loss: 25.520437240600586\n",
      "Epoch: 49, Batch: 29, D Loss: 0.1041376590766677, G Loss: 25.68143653869629\n",
      "Epoch: 49, Batch: 30, D Loss: 0.10027095675839459, G Loss: 25.57758903503418\n",
      "Epoch: 49, Batch: 31, D Loss: 0.10154999793010226, G Loss: 25.371395111083984\n",
      "Epoch: 49, Batch: 32, D Loss: 0.09758409858341201, G Loss: 24.970760345458984\n",
      "Epoch: 49, Batch: 33, D Loss: 0.10078601539947836, G Loss: 24.72687339782715\n",
      "Epoch: 49, Batch: 34, D Loss: 0.09996867925870645, G Loss: 24.66643714904785\n",
      "Epoch: 49, Batch: 35, D Loss: 0.09767070413604971, G Loss: 24.66677474975586\n",
      "Epoch: 49, Batch: 36, D Loss: 0.09458222986277023, G Loss: 24.58919334411621\n",
      "Epoch: 49, Batch: 37, D Loss: 0.10390505195577385, G Loss: 24.84881019592285\n",
      "Epoch: 49, Batch: 38, D Loss: 0.0965965166763339, G Loss: 24.980289459228516\n",
      "Epoch: 49, Batch: 39, D Loss: 0.09595121444005206, G Loss: 24.91345977783203\n",
      "Epoch: 49, Batch: 40, D Loss: 0.0958054810845626, G Loss: 24.733810424804688\n",
      "Epoch: 49, Batch: 41, D Loss: 0.09810324759238183, G Loss: 24.65018081665039\n",
      "Epoch: 49, Batch: 42, D Loss: 0.10639426113001672, G Loss: 24.983318328857422\n",
      "Epoch: 49, Batch: 43, D Loss: 0.09738122672484627, G Loss: 25.16390037536621\n",
      "Epoch: 49, Batch: 44, D Loss: 0.1021316200549725, G Loss: 25.296842575073242\n",
      "Epoch: 49, Batch: 45, D Loss: 0.10024616122768816, G Loss: 25.271329879760742\n",
      "Epoch: 49, Batch: 46, D Loss: 0.10539370775731244, G Loss: 25.34794807434082\n",
      "Epoch: 49, Batch: 47, D Loss: 0.1007928028753582, G Loss: 25.278982162475586\n",
      "Epoch: 49, Batch: 48, D Loss: 0.09754195809974578, G Loss: 24.994054794311523\n",
      "Epoch: 49, Batch: 49, D Loss: 0.09837444872502611, G Loss: 24.646562576293945\n",
      "Epoch: 49, Batch: 50, D Loss: 0.0989392176381078, G Loss: 24.43351173400879\n",
      "Epoch: 49, Batch: 51, D Loss: 0.09425117821872117, G Loss: 24.218544006347656\n",
      "Epoch: 49, Batch: 52, D Loss: 0.0960703715839375, G Loss: 24.14920425415039\n",
      "Epoch: 49, Batch: 53, D Loss: 0.10422612727990005, G Loss: 24.573341369628906\n",
      "Epoch: 49, Batch: 54, D Loss: 0.10289034248183747, G Loss: 25.149280548095703\n",
      "Epoch: 49, Batch: 55, D Loss: 0.0945547148642581, G Loss: 25.23201560974121\n",
      "Epoch: 49, Batch: 56, D Loss: 0.10132217407801167, G Loss: 25.150955200195312\n",
      "Epoch: 49, Batch: 57, D Loss: 0.09460143745712354, G Loss: 24.674957275390625\n",
      "Epoch: 49, Batch: 58, D Loss: 0.09931326658707952, G Loss: 24.293384552001953\n",
      "Epoch: 49, Batch: 59, D Loss: 0.10630853475459918, G Loss: 24.41582679748535\n",
      "Epoch: 49, Batch: 60, D Loss: 0.09598217160722215, G Loss: 24.466651916503906\n",
      "Epoch: 49, Batch: 61, D Loss: 0.09485998750968974, G Loss: 24.384498596191406\n",
      "Epoch: 49, Batch: 62, D Loss: 0.10373555124965383, G Loss: 24.57994270324707\n",
      "Epoch: 49, Batch: 63, D Loss: 0.10112591088736447, G Loss: 24.846921920776367\n",
      "Epoch: 49, Batch: 64, D Loss: 0.10217706859836385, G Loss: 25.056825637817383\n",
      "Epoch: 49, Batch: 65, D Loss: 0.08921080828544165, G Loss: 24.60666847229004\n",
      "Epoch: 49, Batch: 66, D Loss: 0.10291239620407265, G Loss: 24.3917179107666\n",
      "Epoch: 49, Batch: 67, D Loss: 0.09909395874899023, G Loss: 24.28077507019043\n",
      "Epoch: 49, Batch: 68, D Loss: 0.09823140503431621, G Loss: 24.241085052490234\n",
      "Epoch: 49, Batch: 69, D Loss: 0.09709404410400947, G Loss: 24.259138107299805\n",
      "Epoch: 49, Batch: 70, D Loss: 0.10413507373375774, G Loss: 24.572458267211914\n",
      "Epoch: 49, Batch: 71, D Loss: 0.09604584426713383, G Loss: 24.64385414123535\n",
      "Epoch: 49, Batch: 72, D Loss: 0.09953016788760498, G Loss: 24.640804290771484\n",
      "Epoch: 49, Batch: 73, D Loss: 0.09735109658137062, G Loss: 24.47022819519043\n",
      "Epoch: 49, Batch: 74, D Loss: 0.10313421488987855, G Loss: 24.470001220703125\n",
      "Epoch: 49, Batch: 75, D Loss: 0.10517716408839507, G Loss: 24.66681671142578\n",
      "Epoch: 49, Batch: 76, D Loss: 0.09620125592765648, G Loss: 24.58661651611328\n",
      "Epoch: 49, Batch: 77, D Loss: 0.10163025559081632, G Loss: 24.520959854125977\n",
      "Epoch: 49, Batch: 78, D Loss: 0.09655504674981569, G Loss: 24.295684814453125\n",
      "Epoch: 49, Batch: 79, D Loss: 0.09559080006332812, G Loss: 24.002309799194336\n",
      "Epoch: 49, Batch: 80, D Loss: 0.09839207681040715, G Loss: 23.881000518798828\n",
      "Epoch: 49, Batch: 81, D Loss: 0.10206028075921009, G Loss: 24.099838256835938\n",
      "Epoch: 49, Batch: 82, D Loss: 0.09523804487390825, G Loss: 24.23387336730957\n",
      "Epoch: 49, Batch: 83, D Loss: 0.09923171998441484, G Loss: 24.39673614501953\n",
      "Epoch: 49, Batch: 84, D Loss: 0.10255936534317646, G Loss: 24.66019630432129\n",
      "Epoch: 49, Batch: 85, D Loss: 0.09786941112037591, G Loss: 24.710771560668945\n",
      "Epoch: 49, Batch: 86, D Loss: 0.100302509973089, G Loss: 24.649553298950195\n",
      "Epoch: 49, Batch: 87, D Loss: 0.09642278404186938, G Loss: 24.367937088012695\n",
      "Epoch: 49, Batch: 88, D Loss: 0.09906201066060445, G Loss: 24.1390323638916\n",
      "Epoch: 49, Batch: 89, D Loss: 0.09835578502966504, G Loss: 24.02737808227539\n",
      "Epoch: 49, Batch: 90, D Loss: 0.09929737450463888, G Loss: 24.09592056274414\n",
      "Epoch: 49, Batch: 91, D Loss: 0.09700687231266296, G Loss: 24.189712524414062\n",
      "Epoch: 49, Batch: 92, D Loss: 0.10258524121189244, G Loss: 24.486589431762695\n",
      "Epoch: 49, Batch: 93, D Loss: 0.0997667908773425, G Loss: 24.67804527282715\n",
      "Epoch: 49, Batch: 94, D Loss: 0.10075163097122011, G Loss: 24.729597091674805\n",
      "Epoch: 49, Batch: 95, D Loss: 0.10575390607982496, G Loss: 24.828418731689453\n",
      "Epoch: 49, Batch: 96, D Loss: 0.09871026129459769, G Loss: 24.60072898864746\n",
      "Epoch: 49, Batch: 97, D Loss: 0.09662503750468775, G Loss: 24.114471435546875\n",
      "Epoch: 49, Batch: 98, D Loss: 0.09519129248714978, G Loss: 23.56990623474121\n",
      "Epoch: 49, Batch: 99, D Loss: 0.09596315029737153, G Loss: 23.23882484436035\n",
      "Epoch: 49, Batch: 100, D Loss: 0.09582900260057678, G Loss: 23.19329261779785\n",
      "Epoch: 49, Batch: 101, D Loss: 0.10351845625345908, G Loss: 23.67384147644043\n",
      "Epoch: 49, Batch: 102, D Loss: 0.1011597514342607, G Loss: 24.282896041870117\n",
      "Epoch: 49, Batch: 103, D Loss: 0.10200628639380971, G Loss: 24.74773597717285\n",
      "Epoch: 49, Batch: 104, D Loss: 0.1050002873020775, G Loss: 25.033052444458008\n",
      "Epoch: 49, Batch: 105, D Loss: 0.09593034536447129, G Loss: 24.69923973083496\n",
      "Epoch: 49, Batch: 106, D Loss: 0.0972234308851403, G Loss: 24.05301284790039\n",
      "Epoch: 49, Batch: 107, D Loss: 0.10207174720599835, G Loss: 23.644012451171875\n",
      "Epoch: 49, Batch: 108, D Loss: 0.10002511742609141, G Loss: 23.51875877380371\n",
      "Epoch: 49, Batch: 109, D Loss: 0.10085897895477366, G Loss: 23.708635330200195\n",
      "Epoch: 49, Batch: 110, D Loss: 0.09994081409926894, G Loss: 24.022483825683594\n",
      "Epoch: 49, Batch: 111, D Loss: 0.09807902576195231, G Loss: 24.229598999023438\n",
      "Epoch: 49, Batch: 112, D Loss: 0.10256140680446867, G Loss: 24.464441299438477\n",
      "Epoch: 49, Batch: 113, D Loss: 0.10551665724339741, G Loss: 24.75889015197754\n",
      "Epoch: 49, Batch: 114, D Loss: 0.09212010354856724, G Loss: 24.42539405822754\n",
      "Epoch: 49, Batch: 115, D Loss: 0.09582492710820098, G Loss: 23.864301681518555\n",
      "Epoch: 49, Batch: 116, D Loss: 0.09676480296008376, G Loss: 23.417387008666992\n",
      "Epoch: 49, Batch: 117, D Loss: 0.10508887472819012, G Loss: 23.61237335205078\n",
      "Epoch: 49, Batch: 118, D Loss: 0.10449425878201346, G Loss: 24.18319320678711\n",
      "Epoch: 49, Batch: 119, D Loss: 0.09809512646258091, G Loss: 24.614948272705078\n",
      "Epoch: 49, Batch: 120, D Loss: 0.09563218058171821, G Loss: 24.623075485229492\n",
      "Epoch: 49, Batch: 121, D Loss: 0.09883828462317235, G Loss: 24.385469436645508\n",
      "Epoch: 49, Batch: 122, D Loss: 0.10136006773942514, G Loss: 24.187807083129883\n",
      "Epoch: 49, Batch: 123, D Loss: 0.0951179713196267, G Loss: 23.865192413330078\n",
      "Epoch: 49, Batch: 124, D Loss: 0.09887750449087061, G Loss: 23.753625869750977\n",
      "Epoch: 49, Batch: 125, D Loss: 0.09936933221721939, G Loss: 23.855342864990234\n",
      "Epoch: 49, Batch: 126, D Loss: 0.09571358563575405, G Loss: 23.96453094482422\n",
      "Epoch: 49, Batch: 127, D Loss: 0.09937363864759756, G Loss: 24.15605354309082\n",
      "Epoch: 49, Batch: 128, D Loss: 0.10344704986930388, G Loss: 24.550188064575195\n",
      "Epoch: 49, Batch: 129, D Loss: 0.09124954791048638, G Loss: 24.41075897216797\n",
      "Epoch: 49, Batch: 130, D Loss: 0.10112616421121699, G Loss: 24.296152114868164\n",
      "Epoch: 49, Batch: 131, D Loss: 0.09295319767477636, G Loss: 23.96700668334961\n",
      "Epoch: 49, Batch: 132, D Loss: 0.1038248539162108, G Loss: 24.005725860595703\n",
      "Epoch: 49, Batch: 133, D Loss: 0.10192056001867282, G Loss: 24.270648956298828\n",
      "Epoch: 49, Batch: 134, D Loss: 0.09631393851212738, G Loss: 24.374862670898438\n",
      "Epoch: 49, Batch: 135, D Loss: 0.10057689995815439, G Loss: 24.458171844482422\n",
      "Epoch: 49, Batch: 136, D Loss: 0.09499377013560212, G Loss: 24.285099029541016\n",
      "Epoch: 49, Batch: 137, D Loss: 0.0979559123671171, G Loss: 24.117643356323242\n",
      "Epoch: 49, Batch: 138, D Loss: 0.0963531658236551, G Loss: 23.951309204101562\n",
      "Epoch: 49, Batch: 139, D Loss: 0.10547204317361199, G Loss: 24.245540618896484\n",
      "Epoch: 49, Batch: 140, D Loss: 0.10074602068699233, G Loss: 24.59412956237793\n",
      "Epoch: 49, Batch: 141, D Loss: 0.09588541091509789, G Loss: 24.632238388061523\n",
      "Epoch: 49, Batch: 142, D Loss: 0.10468230397434589, G Loss: 24.78531265258789\n",
      "Epoch: 49, Batch: 143, D Loss: 0.0914266407594096, G Loss: 24.419496536254883\n",
      "Epoch: 49, Batch: 144, D Loss: 0.09331478180146494, G Loss: 23.887165069580078\n",
      "Epoch: 49, Batch: 145, D Loss: 0.09423226865818382, G Loss: 23.44025421142578\n",
      "Epoch: 49, Batch: 146, D Loss: 0.09843718263790943, G Loss: 23.4631290435791\n",
      "Epoch: 49, Batch: 147, D Loss: 0.09672498705736984, G Loss: 23.779125213623047\n",
      "Epoch: 49, Batch: 148, D Loss: 0.09146183731246786, G Loss: 24.019018173217773\n",
      "Epoch: 49, Batch: 149, D Loss: 0.09929185362173618, G Loss: 24.418237686157227\n",
      "Epoch: 49, Batch: 150, D Loss: 0.10100351275012083, G Loss: 24.832897186279297\n",
      "Epoch: 49, Batch: 151, D Loss: 0.10170830786924924, G Loss: 25.143857955932617\n",
      "Epoch: 49, Batch: 152, D Loss: 0.10456836224140788, G Loss: 25.353639602661133\n",
      "Epoch: 49, Batch: 153, D Loss: 0.09618552029702428, G Loss: 25.057849884033203\n",
      "Epoch: 49, Batch: 154, D Loss: 0.10180155188624755, G Loss: 24.727806091308594\n",
      "Epoch: 49, Batch: 155, D Loss: 0.09662635625523136, G Loss: 24.34514617919922\n",
      "Epoch: 49, Batch: 156, D Loss: 0.10169512034849101, G Loss: 24.275455474853516\n",
      "Epoch: 49, Batch: 157, D Loss: 0.09980261327150693, G Loss: 24.43960952758789\n",
      "Epoch: 49, Batch: 158, D Loss: 0.09928626568171267, G Loss: 24.725934982299805\n",
      "Epoch: 49, Batch: 159, D Loss: 0.09854574502307963, G Loss: 24.992956161499023\n",
      "Epoch: 49, Batch: 160, D Loss: 0.09465002269261485, G Loss: 24.967601776123047\n",
      "Epoch: 49, Batch: 161, D Loss: 0.09732626379301418, G Loss: 24.844640731811523\n",
      "Epoch: 49, Batch: 162, D Loss: 0.09553819150642637, G Loss: 24.62557601928711\n",
      "Epoch: 49, Batch: 163, D Loss: 0.104257971057627, G Loss: 24.787668228149414\n",
      "Epoch: 49, Batch: 164, D Loss: 0.10488048196522023, G Loss: 25.22178840637207\n",
      "Epoch: 49, Batch: 165, D Loss: 0.09692103416246899, G Loss: 25.352537155151367\n",
      "Epoch: 49, Batch: 166, D Loss: 0.10128213465703452, G Loss: 25.346410751342773\n",
      "Epoch: 49, Batch: 167, D Loss: 0.09995576739842028, G Loss: 25.19856071472168\n",
      "Epoch: 49, Batch: 168, D Loss: 0.09791505337411366, G Loss: 24.946931838989258\n",
      "Epoch: 49, Batch: 169, D Loss: 0.09881070257038307, G Loss: 24.766326904296875\n",
      "Epoch: 49, Batch: 170, D Loss: 0.10093323142191964, G Loss: 24.813879013061523\n",
      "Epoch: 49, Batch: 171, D Loss: 0.0985028520305484, G Loss: 24.922285079956055\n",
      "Epoch: 49, Batch: 172, D Loss: 0.10033664108016194, G Loss: 25.072368621826172\n",
      "Epoch: 49, Batch: 173, D Loss: 0.10002730787396955, G Loss: 25.22335433959961\n",
      "Epoch: 49, Batch: 174, D Loss: 0.10213022679605459, G Loss: 25.366981506347656\n",
      "Epoch: 49, Batch: 175, D Loss: 0.10098313540694097, G Loss: 25.39590072631836\n",
      "Epoch: 49, Batch: 176, D Loss: 0.09811900556609644, G Loss: 25.18521499633789\n",
      "Epoch: 49, Batch: 177, D Loss: 0.09687873721801467, G Loss: 24.87633514404297\n",
      "Epoch: 49, Batch: 178, D Loss: 0.10195553303582765, G Loss: 24.800338745117188\n",
      "Epoch: 49, Batch: 179, D Loss: 0.09633583576379198, G Loss: 24.703752517700195\n",
      "Epoch: 49, Batch: 180, D Loss: 0.10448633135172822, G Loss: 24.978797912597656\n",
      "Epoch: 49, Batch: 181, D Loss: 0.09577722848140664, G Loss: 25.06181526184082\n",
      "Epoch: 49, Batch: 182, D Loss: 0.09799189121183051, G Loss: 25.064186096191406\n",
      "Epoch: 49, Batch: 183, D Loss: 0.10264322907347578, G Loss: 25.17287826538086\n",
      "Epoch: 49, Batch: 184, D Loss: 0.10506658256554813, G Loss: 25.464895248413086\n",
      "Epoch: 49, Batch: 185, D Loss: 0.10120116174632626, G Loss: 25.575321197509766\n",
      "Epoch: 49, Batch: 186, D Loss: 0.09687297046632398, G Loss: 25.31527328491211\n",
      "Epoch: 49, Batch: 187, D Loss: 0.09764972329776461, G Loss: 24.88034439086914\n",
      "Epoch: 49, Batch: 188, D Loss: 0.09807858617064791, G Loss: 24.509408950805664\n",
      "Epoch: 49, Batch: 189, D Loss: 0.10148334504317438, G Loss: 24.49366569519043\n",
      "Epoch: 49, Batch: 190, D Loss: 0.10312867165575475, G Loss: 24.832733154296875\n",
      "Epoch: 49, Batch: 191, D Loss: 0.09968192876080878, G Loss: 25.147062301635742\n",
      "Epoch: 49, Batch: 192, D Loss: 0.09498911351570963, G Loss: 25.1280460357666\n",
      "Epoch: 49, Batch: 193, D Loss: 0.1017985418499745, G Loss: 25.136165618896484\n",
      "Epoch: 49, Batch: 194, D Loss: 0.09388193488845191, G Loss: 24.797359466552734\n",
      "Epoch: 49, Batch: 195, D Loss: 0.10291968286918216, G Loss: 24.73064422607422\n",
      "Epoch: 49, Batch: 196, D Loss: 0.1006527692166462, G Loss: 24.815887451171875\n",
      "Epoch: 49, Batch: 197, D Loss: 0.10499281436906266, G Loss: 25.146514892578125\n",
      "Epoch: 49, Batch: 198, D Loss: 0.10378196090964951, G Loss: 25.472564697265625\n",
      "Epoch: 49, Batch: 199, D Loss: 0.09884620458316065, G Loss: 25.492313385009766\n",
      "Epoch: 49, Batch: 200, D Loss: 0.09850522876268641, G Loss: 25.24717140197754\n",
      "Epoch: 49, Batch: 201, D Loss: 0.1034156456649282, G Loss: 25.06829071044922\n",
      "Epoch: 49, Batch: 202, D Loss: 0.10122513771752566, G Loss: 24.935617446899414\n",
      "Epoch: 49, Batch: 203, D Loss: 0.08945959062340943, G Loss: 24.44797706604004\n",
      "Epoch: 49, Batch: 204, D Loss: 0.10391932727095263, G Loss: 24.47518539428711\n",
      "Epoch: 49, Batch: 205, D Loss: 0.10031731427721202, G Loss: 24.769119262695312\n",
      "Epoch: 49, Batch: 206, D Loss: 0.10595908761659012, G Loss: 25.377744674682617\n",
      "Epoch: 49, Batch: 207, D Loss: 0.10349199921252758, G Loss: 25.908363342285156\n",
      "Epoch: 49, Batch: 208, D Loss: 0.10427843779574694, G Loss: 26.12942123413086\n",
      "Epoch: 49, Batch: 209, D Loss: 0.09987384081148784, G Loss: 25.83556365966797\n",
      "Epoch: 49, Batch: 210, D Loss: 0.09516963363141669, G Loss: 25.080677032470703\n",
      "Epoch: 49, Batch: 211, D Loss: 0.09986875207129696, G Loss: 24.437902450561523\n",
      "Epoch: 49, Batch: 212, D Loss: 0.1051460951692228, G Loss: 24.38092803955078\n",
      "Epoch: 49, Batch: 213, D Loss: 0.10208896548654216, G Loss: 24.685914993286133\n",
      "Epoch: 49, Batch: 214, D Loss: 0.09356033057867992, G Loss: 24.803539276123047\n",
      "Epoch: 49, Batch: 215, D Loss: 0.09231022746257497, G Loss: 24.712461471557617\n",
      "Epoch: 49, Batch: 216, D Loss: 0.10253621638663432, G Loss: 24.892040252685547\n",
      "Epoch: 49, Batch: 217, D Loss: 0.09944607318146198, G Loss: 25.08553695678711\n",
      "Epoch: 49, Batch: 218, D Loss: 0.09076157212974505, G Loss: 24.861286163330078\n",
      "Epoch: 49, Batch: 219, D Loss: 0.09775686264893732, G Loss: 24.72803497314453\n",
      "Epoch: 49, Batch: 220, D Loss: 0.0965013355112586, G Loss: 24.63178825378418\n",
      "Epoch: 49, Batch: 221, D Loss: 0.10489452631130995, G Loss: 24.948043823242188\n",
      "Epoch: 49, Batch: 222, D Loss: 0.10522305965969661, G Loss: 25.50235366821289\n",
      "Epoch: 49, Batch: 223, D Loss: 0.09708020091439089, G Loss: 25.682479858398438\n",
      "Epoch: 49, Batch: 224, D Loss: 0.09685191512506769, G Loss: 25.439146041870117\n",
      "Epoch: 49, Batch: 225, D Loss: 0.10236204416060159, G Loss: 25.227163314819336\n",
      "Epoch: 49, Batch: 226, D Loss: 0.09590335936020165, G Loss: 24.87409210205078\n",
      "Epoch: 49, Batch: 227, D Loss: 0.10096889735116917, G Loss: 24.731937408447266\n",
      "Epoch: 49, Batch: 228, D Loss: 0.10399407894219999, G Loss: 24.9704647064209\n",
      "Epoch: 49, Batch: 229, D Loss: 0.1000379771056058, G Loss: 25.24551010131836\n",
      "Epoch: 49, Batch: 230, D Loss: 0.09525124729225261, G Loss: 25.237247467041016\n",
      "Epoch: 49, Batch: 231, D Loss: 0.09853109717943913, G Loss: 25.14548110961914\n",
      "Epoch: 49, Batch: 232, D Loss: 0.09718452394665435, G Loss: 24.974502563476562\n",
      "Epoch: 49, Batch: 233, D Loss: 0.09822478146132192, G Loss: 24.823444366455078\n",
      "Epoch: 49, Batch: 234, D Loss: 0.10071248561955885, G Loss: 24.861642837524414\n",
      "Epoch: 49, Batch: 235, D Loss: 0.09938435257232563, G Loss: 24.97464942932129\n",
      "Epoch: 49, Batch: 236, D Loss: 0.10242218524851271, G Loss: 25.19652557373047\n",
      "Epoch: 49, Batch: 237, D Loss: 0.09976644814546688, G Loss: 25.32838249206543\n",
      "Epoch: 49, Batch: 238, D Loss: 0.10350201279389196, G Loss: 25.46940803527832\n",
      "Epoch: 49, Batch: 239, D Loss: 0.09152337164224342, G Loss: 25.0611515045166\n",
      "Epoch: 49, Batch: 240, D Loss: 0.09838978947007318, G Loss: 24.6772403717041\n",
      "Epoch: 49, Batch: 241, D Loss: 0.09678142518832937, G Loss: 24.544326782226562\n",
      "Epoch: 49, Batch: 242, D Loss: 0.10054828227552673, G Loss: 24.74115753173828\n",
      "Epoch: 49, Batch: 243, D Loss: 0.10133787990370391, G Loss: 25.075349807739258\n",
      "Epoch: 49, Batch: 244, D Loss: 0.09582619369642764, G Loss: 25.169811248779297\n",
      "Epoch: 49, Batch: 245, D Loss: 0.09508855641532318, G Loss: 24.989900588989258\n",
      "Epoch: 49, Batch: 246, D Loss: 0.10033367574951207, G Loss: 24.8978271484375\n",
      "Epoch: 49, Batch: 247, D Loss: 0.10116146505630044, G Loss: 24.942996978759766\n",
      "Epoch: 49, Batch: 248, D Loss: 0.09564478696165533, G Loss: 24.847715377807617\n",
      "Epoch: 49, Batch: 249, D Loss: 0.10255137831741384, G Loss: 24.943918228149414\n",
      "Epoch: 49, Batch: 250, D Loss: 0.10076785833308738, G Loss: 25.131759643554688\n",
      "Epoch: 49, Batch: 251, D Loss: 0.09900433570719014, G Loss: 25.24834632873535\n",
      "Epoch: 49, Batch: 252, D Loss: 0.09964624792873278, G Loss: 25.268945693969727\n",
      "Epoch: 49, Batch: 253, D Loss: 0.10585954785825213, G Loss: 25.466535568237305\n",
      "Epoch: 49, Batch: 254, D Loss: 0.09743705392348279, G Loss: 25.344322204589844\n",
      "Epoch: 49, Batch: 255, D Loss: 0.09760606289485618, G Loss: 25.045978546142578\n",
      "Epoch: 49, Batch: 256, D Loss: 0.10305239260888055, G Loss: 24.966861724853516\n",
      "Epoch: 49, Batch: 257, D Loss: 0.09709268064071172, G Loss: 24.84739875793457\n",
      "Epoch: 49, Batch: 258, D Loss: 0.0991838276466473, G Loss: 24.86336898803711\n",
      "Epoch: 49, Batch: 259, D Loss: 0.09761249274794696, G Loss: 24.903905868530273\n",
      "Epoch: 49, Batch: 260, D Loss: 0.09820444882659103, G Loss: 24.957836151123047\n",
      "Epoch: 49, Batch: 261, D Loss: 0.10410974920415897, G Loss: 25.25299644470215\n",
      "Epoch: 49, Batch: 262, D Loss: 0.1023814380214717, G Loss: 25.562776565551758\n",
      "Epoch: 49, Batch: 263, D Loss: 0.096458941702121, G Loss: 25.519479751586914\n",
      "Epoch: 49, Batch: 264, D Loss: 0.1011562794491725, G Loss: 25.365936279296875\n",
      "Epoch: 49, Batch: 265, D Loss: 0.09887231886927657, G Loss: 25.145538330078125\n",
      "Epoch: 49, Batch: 266, D Loss: 0.09250771255072668, G Loss: 24.667755126953125\n",
      "Epoch: 49, Batch: 267, D Loss: 0.1079420968978931, G Loss: 24.8330078125\n",
      "Epoch: 49, Batch: 268, D Loss: 0.09824479372038898, G Loss: 25.056232452392578\n",
      "Epoch: 49, Batch: 269, D Loss: 0.10020718724112442, G Loss: 25.30138397216797\n",
      "Epoch: 49, Batch: 270, D Loss: 0.09209578484857936, G Loss: 25.13350486755371\n",
      "Epoch: 49, Batch: 271, D Loss: 0.10163898766656743, G Loss: 25.107620239257812\n",
      "Epoch: 49, Batch: 272, D Loss: 0.09142601490750879, G Loss: 24.807527542114258\n",
      "Epoch: 49, Batch: 273, D Loss: 0.101692788311097, G Loss: 24.857688903808594\n",
      "Epoch: 49, Batch: 274, D Loss: 0.10297274590195706, G Loss: 25.23234748840332\n",
      "Epoch: 49, Batch: 275, D Loss: 0.10106548667397545, G Loss: 25.642427444458008\n",
      "Epoch: 49, Batch: 276, D Loss: 0.10021610558362168, G Loss: 25.840097427368164\n",
      "Epoch: 49, Batch: 277, D Loss: 0.10014474392241812, G Loss: 25.809871673583984\n",
      "Epoch: 49, Batch: 278, D Loss: 0.09889622032994105, G Loss: 25.563735961914062\n",
      "Epoch: 49, Batch: 279, D Loss: 0.09513941407716012, G Loss: 25.068878173828125\n",
      "Epoch: 49, Batch: 280, D Loss: 0.10259738565184785, G Loss: 24.94037628173828\n",
      "Epoch: 49, Batch: 281, D Loss: 0.09870981425772805, G Loss: 24.969438552856445\n",
      "Epoch: 49, Batch: 282, D Loss: 0.09862740338499269, G Loss: 25.151260375976562\n",
      "Epoch: 49, Batch: 283, D Loss: 0.1011722013404379, G Loss: 25.48427963256836\n",
      "Epoch: 49, Batch: 284, D Loss: 0.09866216034084882, G Loss: 25.671188354492188\n",
      "Epoch: 49, Batch: 285, D Loss: 0.10635499656496435, G Loss: 26.015743255615234\n",
      "Epoch: 49, Batch: 286, D Loss: 0.09711901098741528, G Loss: 26.013439178466797\n",
      "Epoch: 49, Batch: 287, D Loss: 0.10041294247187514, G Loss: 25.844154357910156\n",
      "Epoch: 49, Batch: 288, D Loss: 0.09662547707924986, G Loss: 25.45037078857422\n",
      "Epoch: 49, Batch: 289, D Loss: 0.10531220585560672, G Loss: 25.40680503845215\n",
      "Epoch: 49, Batch: 290, D Loss: 0.10105959326458581, G Loss: 25.545534133911133\n",
      "Epoch: 49, Batch: 291, D Loss: 0.0937590450091052, G Loss: 25.437068939208984\n",
      "Epoch: 49, Batch: 292, D Loss: 0.1048950851004547, G Loss: 25.60978126525879\n",
      "Epoch: 49, Batch: 293, D Loss: 0.09549297392761408, G Loss: 25.53228187561035\n",
      "Epoch: 49, Batch: 294, D Loss: 0.099750310186735, G Loss: 25.49281883239746\n",
      "Epoch: 49, Batch: 295, D Loss: 0.1024758070747166, G Loss: 25.61186981201172\n",
      "Epoch: 49, Batch: 296, D Loss: 0.10137630254381047, G Loss: 25.746734619140625\n",
      "Epoch: 49, Batch: 297, D Loss: 0.10268684476919032, G Loss: 25.89091682434082\n",
      "Epoch: 49, Batch: 298, D Loss: 0.0945507586034841, G Loss: 25.64141845703125\n",
      "Epoch: 49, Batch: 299, D Loss: 0.10121971369193442, G Loss: 25.452787399291992\n",
      "Epoch: 49, Batch: 300, D Loss: 0.10270415246923983, G Loss: 25.471054077148438\n",
      "Epoch: 49, Batch: 301, D Loss: 0.09965188801712811, G Loss: 25.512441635131836\n",
      "Epoch: 49, Batch: 302, D Loss: 0.10019386560131525, G Loss: 25.555171966552734\n",
      "Epoch: 49, Batch: 303, D Loss: 0.09438803792447158, G Loss: 25.335493087768555\n",
      "Epoch: 49, Batch: 304, D Loss: 0.09781534970357877, G Loss: 25.136716842651367\n",
      "Epoch: 49, Batch: 305, D Loss: 0.09975075722348817, G Loss: 25.129135131835938\n",
      "Epoch: 49, Batch: 306, D Loss: 0.09834022820579594, G Loss: 25.213708877563477\n",
      "Epoch: 49, Batch: 307, D Loss: 0.09457702935313908, G Loss: 25.176298141479492\n",
      "Epoch: 49, Batch: 308, D Loss: 0.10566879809395291, G Loss: 25.49306869506836\n",
      "Epoch: 49, Batch: 309, D Loss: 0.10309486836542009, G Loss: 25.874929428100586\n",
      "Epoch: 49, Batch: 310, D Loss: 0.10084929317500632, G Loss: 26.045108795166016\n",
      "Epoch: 49, Batch: 311, D Loss: 0.10053357482214365, G Loss: 25.941383361816406\n",
      "Epoch: 49, Batch: 312, D Loss: 0.10307315737305392, G Loss: 25.770566940307617\n",
      "Epoch: 49, Batch: 313, D Loss: 0.09886572510384774, G Loss: 25.44832992553711\n",
      "Epoch: 49, Batch: 314, D Loss: 0.10156360269088215, G Loss: 25.237686157226562\n",
      "Epoch: 49, Batch: 315, D Loss: 0.10082361102657186, G Loss: 25.21870994567871\n",
      "Epoch: 49, Batch: 316, D Loss: 0.10208074003969253, G Loss: 25.384904861450195\n",
      "Epoch: 49, Batch: 317, D Loss: 0.09817311168167368, G Loss: 25.476154327392578\n",
      "Epoch: 49, Batch: 318, D Loss: 0.09773590416151717, G Loss: 25.457704544067383\n",
      "Epoch: 49, Batch: 319, D Loss: 0.09728910774466168, G Loss: 25.314762115478516\n",
      "Epoch: 49, Batch: 320, D Loss: 0.0968327075298792, G Loss: 25.13226890563965\n",
      "Epoch: 49, Batch: 321, D Loss: 0.09885619581379858, G Loss: 25.05337142944336\n",
      "Epoch: 49, Batch: 322, D Loss: 0.10296321660869744, G Loss: 25.263023376464844\n",
      "Epoch: 49, Batch: 323, D Loss: 0.09923624247792683, G Loss: 25.464014053344727\n",
      "Epoch: 49, Batch: 324, D Loss: 0.10202376544857358, G Loss: 25.718915939331055\n",
      "Epoch: 49, Batch: 325, D Loss: 0.09995242953625402, G Loss: 25.795927047729492\n",
      "Epoch: 49, Batch: 326, D Loss: 0.09767781198376688, G Loss: 25.575223922729492\n",
      "Epoch: 49, Batch: 327, D Loss: 0.09658271074774699, G Loss: 25.184131622314453\n",
      "Epoch: 49, Batch: 328, D Loss: 0.10246188939227337, G Loss: 25.08160972595215\n",
      "Epoch: 49, Batch: 329, D Loss: 0.09688296914756078, G Loss: 25.036285400390625\n",
      "Epoch: 49, Batch: 330, D Loss: 0.09704028815698412, G Loss: 25.042821884155273\n",
      "Epoch: 49, Batch: 331, D Loss: 0.09513920546246349, G Loss: 25.034130096435547\n",
      "Epoch: 49, Batch: 332, D Loss: 0.10038629174837504, G Loss: 25.231027603149414\n",
      "Epoch: 49, Batch: 333, D Loss: 0.09972724318981513, G Loss: 25.504230499267578\n",
      "Epoch: 49, Batch: 334, D Loss: 0.09939131141086224, G Loss: 25.70516014099121\n",
      "Epoch: 49, Batch: 335, D Loss: 0.10154846310933646, G Loss: 25.848604202270508\n",
      "Epoch: 49, Batch: 336, D Loss: 0.0993434786827527, G Loss: 25.771160125732422\n",
      "Epoch: 49, Batch: 337, D Loss: 0.09843178093796756, G Loss: 25.536500930786133\n",
      "Epoch: 49, Batch: 338, D Loss: 0.10163111240108941, G Loss: 25.395971298217773\n",
      "Epoch: 49, Batch: 339, D Loss: 0.09755948186427592, G Loss: 25.241619110107422\n",
      "Epoch: 49, Batch: 340, D Loss: 0.09421719611311132, G Loss: 24.99746322631836\n",
      "Epoch: 49, Batch: 341, D Loss: 0.10620061308745381, G Loss: 25.28020477294922\n",
      "Epoch: 49, Batch: 342, D Loss: 0.09775168449153385, G Loss: 25.501956939697266\n",
      "Epoch: 49, Batch: 343, D Loss: 0.09859707206881073, G Loss: 25.62774658203125\n",
      "Epoch: 49, Batch: 344, D Loss: 0.10044545680642654, G Loss: 25.692995071411133\n",
      "Epoch: 49, Batch: 345, D Loss: 0.10241504758928864, G Loss: 25.775894165039062\n",
      "Epoch: 49, Batch: 346, D Loss: 0.10440838337245756, G Loss: 25.888858795166016\n",
      "Epoch: 49, Batch: 347, D Loss: 0.10639188438911976, G Loss: 26.0809326171875\n",
      "Epoch: 49, Batch: 348, D Loss: 0.0910452753335313, G Loss: 25.629323959350586\n",
      "Epoch: 49, Batch: 349, D Loss: 0.10578021407528578, G Loss: 25.475841522216797\n",
      "Epoch: 49, Batch: 350, D Loss: 0.0953738838484099, G Loss: 25.19974136352539\n",
      "Epoch: 49, Batch: 351, D Loss: 0.0986688882172671, G Loss: 25.092483520507812\n",
      "Epoch: 49, Batch: 352, D Loss: 0.09863679111613186, G Loss: 25.1651611328125\n",
      "Epoch: 49, Batch: 353, D Loss: 0.09899152815872209, G Loss: 25.36370277404785\n",
      "Epoch: 49, Batch: 354, D Loss: 0.10646304488544352, G Loss: 25.90873146057129\n",
      "Epoch: 49, Batch: 355, D Loss: 0.10425525903919328, G Loss: 26.38682746887207\n",
      "Epoch: 49, Batch: 356, D Loss: 0.10395778715765705, G Loss: 26.598939895629883\n",
      "Epoch: 49, Batch: 357, D Loss: 0.09961900860231612, G Loss: 26.344886779785156\n",
      "Epoch: 49, Batch: 358, D Loss: 0.09830334782849406, G Loss: 25.737056732177734\n",
      "Epoch: 49, Batch: 359, D Loss: 0.10059177875959051, G Loss: 25.200641632080078\n",
      "Epoch: 49, Batch: 360, D Loss: 0.09456802905340284, G Loss: 24.71223258972168\n",
      "Epoch: 49, Batch: 361, D Loss: 0.10210673511916935, G Loss: 24.790372848510742\n",
      "Epoch: 49, Batch: 362, D Loss: 0.09142552317015068, G Loss: 24.858375549316406\n",
      "Epoch: 49, Batch: 363, D Loss: 0.09632655978915991, G Loss: 25.07672882080078\n",
      "Epoch: 49, Batch: 364, D Loss: 0.0959908217247515, G Loss: 25.3457088470459\n",
      "Epoch: 49, Batch: 365, D Loss: 0.0949196666524813, G Loss: 25.483652114868164\n",
      "Epoch: 49, Batch: 366, D Loss: 0.09698610008179626, G Loss: 25.534936904907227\n",
      "Epoch: 49, Batch: 367, D Loss: 0.10173617303752124, G Loss: 25.660524368286133\n",
      "Epoch: 49, Batch: 368, D Loss: 0.10032379627569676, G Loss: 25.751916885375977\n",
      "Epoch: 49, Batch: 369, D Loss: 0.09679119289274782, G Loss: 25.60653305053711\n",
      "Epoch: 49, Batch: 370, D Loss: 0.10016003251487315, G Loss: 25.447547912597656\n",
      "Epoch: 49, Batch: 371, D Loss: 0.09917792678350341, G Loss: 25.33467674255371\n",
      "Epoch: 49, Batch: 372, D Loss: 0.09850564599542548, G Loss: 25.302494049072266\n",
      "Epoch: 49, Batch: 373, D Loss: 0.0951351672466163, G Loss: 25.1638126373291\n",
      "Epoch: 49, Batch: 374, D Loss: 0.09701640904556032, G Loss: 25.110363006591797\n",
      "Epoch: 49, Batch: 375, D Loss: 0.10496703535830018, G Loss: 25.480741500854492\n",
      "Epoch: 49, Batch: 376, D Loss: 0.09832929075136909, G Loss: 25.749717712402344\n",
      "Epoch: 49, Batch: 377, D Loss: 0.10166217387011219, G Loss: 25.99302101135254\n",
      "Epoch: 49, Batch: 378, D Loss: 0.10026679188262874, G Loss: 26.048818588256836\n",
      "Epoch: 49, Batch: 379, D Loss: 0.102650403978932, G Loss: 26.003450393676758\n",
      "Epoch: 49, Batch: 380, D Loss: 0.09455920756180486, G Loss: 25.585235595703125\n",
      "Epoch: 49, Batch: 381, D Loss: 0.09455731511629818, G Loss: 25.04472541809082\n",
      "Epoch: 49, Batch: 382, D Loss: 0.0996888578011219, G Loss: 24.861011505126953\n",
      "Epoch: 49, Batch: 383, D Loss: 0.10538396984974838, G Loss: 25.291440963745117\n",
      "Epoch: 49, Batch: 384, D Loss: 0.09757120907720578, G Loss: 25.72016716003418\n",
      "Epoch: 49, Batch: 385, D Loss: 0.099220454695737, G Loss: 26.013259887695312\n",
      "Epoch: 49, Batch: 386, D Loss: 0.09795922041186748, G Loss: 26.04880142211914\n",
      "Epoch: 49, Batch: 387, D Loss: 0.09005768597447253, G Loss: 25.520444869995117\n",
      "Epoch: 49, Batch: 388, D Loss: 0.09736813605342258, G Loss: 25.115354537963867\n",
      "Epoch: 49, Batch: 389, D Loss: 0.09781385958844599, G Loss: 25.022077560424805\n",
      "Epoch: 49, Batch: 390, D Loss: 0.09489384294201507, G Loss: 25.119503021240234\n",
      "Epoch: 49, Batch: 391, D Loss: 0.09752659500170097, G Loss: 25.424142837524414\n",
      "Epoch: 49, Batch: 392, D Loss: 0.10477180779296442, G Loss: 26.112468719482422\n",
      "Epoch: 49, Batch: 393, D Loss: 0.10330182314082806, G Loss: 26.74331283569336\n",
      "Epoch: 49, Batch: 394, D Loss: 0.1025958806286733, G Loss: 27.036226272583008\n",
      "Epoch: 49, Batch: 395, D Loss: 0.10167819261648982, G Loss: 26.88616180419922\n",
      "Epoch: 49, Batch: 396, D Loss: 0.10730150342102443, G Loss: 26.721527099609375\n",
      "Epoch: 49, Batch: 397, D Loss: 0.10002352297460755, G Loss: 26.303255081176758\n",
      "Epoch: 49, Batch: 398, D Loss: 0.09713850915686502, G Loss: 25.732891082763672\n",
      "Epoch: 49, Batch: 399, D Loss: 0.09228464961522889, G Loss: 25.07682991027832\n",
      "Epoch: 49, Batch: 400, D Loss: 0.10259687901202043, G Loss: 25.030750274658203\n",
      "Epoch: 49, Batch: 401, D Loss: 0.10503022373215726, G Loss: 25.62193489074707\n",
      "Epoch: 49, Batch: 402, D Loss: 0.10324782133349741, G Loss: 26.400196075439453\n",
      "Epoch: 49, Batch: 403, D Loss: 0.09872668236633077, G Loss: 26.795942306518555\n",
      "Epoch: 49, Batch: 404, D Loss: 0.10698117315870942, G Loss: 27.032617568969727\n",
      "Epoch: 49, Batch: 405, D Loss: 0.09347944706800887, G Loss: 26.467193603515625\n",
      "Epoch: 49, Batch: 406, D Loss: 0.10107374191510188, G Loss: 25.810731887817383\n",
      "Epoch: 49, Batch: 407, D Loss: 0.09663059562882984, G Loss: 25.143352508544922\n",
      "Epoch: 49, Batch: 408, D Loss: 0.10247275978963316, G Loss: 25.036312103271484\n",
      "Epoch: 49, Batch: 409, D Loss: 0.10023332387786635, G Loss: 25.316755294799805\n",
      "Epoch: 49, Batch: 410, D Loss: 0.10309994966164626, G Loss: 25.895587921142578\n",
      "Epoch: 49, Batch: 411, D Loss: 0.10271620750639125, G Loss: 26.448631286621094\n",
      "Epoch: 49, Batch: 412, D Loss: 0.09673237055698682, G Loss: 26.50191307067871\n",
      "Epoch: 49, Batch: 413, D Loss: 0.10349912941618283, G Loss: 26.40841293334961\n",
      "Epoch: 49, Batch: 414, D Loss: 0.10393460840169447, G Loss: 26.269790649414062\n",
      "Epoch: 49, Batch: 415, D Loss: 0.10144892335159733, G Loss: 26.0263729095459\n",
      "Epoch: 49, Batch: 416, D Loss: 0.09800884127915942, G Loss: 25.676822662353516\n",
      "Epoch: 49, Batch: 417, D Loss: 0.09715045988972344, G Loss: 25.37955093383789\n",
      "Epoch: 49, Batch: 418, D Loss: 0.10094557703011625, G Loss: 25.3989315032959\n",
      "Epoch: 49, Batch: 419, D Loss: 0.10260701179900114, G Loss: 25.70923614501953\n",
      "Epoch: 49, Batch: 420, D Loss: 0.1026785224703273, G Loss: 26.146005630493164\n",
      "Epoch: 49, Batch: 421, D Loss: 0.09582273662301362, G Loss: 26.231300354003906\n",
      "Epoch: 49, Batch: 422, D Loss: 0.09392563998944135, G Loss: 25.870946884155273\n",
      "Epoch: 49, Batch: 423, D Loss: 0.10019893199545525, G Loss: 25.572120666503906\n",
      "Epoch: 49, Batch: 424, D Loss: 0.10403694957879686, G Loss: 25.605966567993164\n",
      "Epoch: 49, Batch: 425, D Loss: 0.10176877677783679, G Loss: 25.79444694519043\n",
      "Epoch: 49, Batch: 426, D Loss: 0.09668763727262204, G Loss: 25.80195426940918\n",
      "Epoch: 49, Batch: 427, D Loss: 0.09489797801133308, G Loss: 25.55836296081543\n",
      "Epoch: 49, Batch: 428, D Loss: 0.09834662080253768, G Loss: 25.352766036987305\n",
      "Epoch: 49, Batch: 429, D Loss: 0.10112159699692905, G Loss: 25.33980941772461\n",
      "Epoch: 49, Batch: 430, D Loss: 0.09087403864234692, G Loss: 25.081607818603516\n",
      "Epoch: 49, Batch: 431, D Loss: 0.09434449673429902, G Loss: 24.82897186279297\n",
      "Epoch: 49, Batch: 432, D Loss: 0.1011714637356657, G Loss: 24.95394515991211\n",
      "Epoch: 49, Batch: 433, D Loss: 0.09629727900708016, G Loss: 25.081823348999023\n",
      "Epoch: 49, Batch: 434, D Loss: 0.10287295282423554, G Loss: 25.416202545166016\n",
      "Epoch: 49, Batch: 435, D Loss: 0.09777927399102436, G Loss: 25.577068328857422\n",
      "Epoch: 49, Batch: 436, D Loss: 0.10467973351829418, G Loss: 25.778003692626953\n",
      "Epoch: 49, Batch: 437, D Loss: 0.09934324026436803, G Loss: 25.718996047973633\n",
      "Epoch: 49, Batch: 438, D Loss: 0.09937952459247408, G Loss: 25.453670501708984\n",
      "Epoch: 49, Batch: 439, D Loss: 0.09898746014172854, G Loss: 25.099271774291992\n",
      "Epoch: 49, Batch: 440, D Loss: 0.10248821974466865, G Loss: 24.989368438720703\n",
      "Epoch: 49, Batch: 441, D Loss: 0.09586334229277178, G Loss: 24.83409881591797\n",
      "Epoch: 49, Batch: 442, D Loss: 0.10492945463180339, G Loss: 25.09351921081543\n",
      "Epoch: 49, Batch: 443, D Loss: 0.10572797805563285, G Loss: 25.568307876586914\n",
      "Epoch: 49, Batch: 444, D Loss: 0.10676679015455535, G Loss: 26.10895538330078\n",
      "Epoch: 49, Batch: 445, D Loss: 0.0989299193047679, G Loss: 26.0977840423584\n",
      "Epoch: 49, Batch: 446, D Loss: 0.09864726662933535, G Loss: 25.620590209960938\n",
      "Epoch: 49, Batch: 447, D Loss: 0.09588524699772233, G Loss: 24.844379425048828\n",
      "Epoch: 49, Batch: 448, D Loss: 0.09820704908271789, G Loss: 24.281991958618164\n",
      "Epoch: 49, Batch: 449, D Loss: 0.09768155218743871, G Loss: 24.092350006103516\n",
      "Epoch: 49, Batch: 450, D Loss: 0.10177979619745142, G Loss: 24.438858032226562\n",
      "Epoch: 49, Batch: 451, D Loss: 0.10286654532788987, G Loss: 25.158565521240234\n",
      "Epoch: 49, Batch: 452, D Loss: 0.10205700993951052, G Loss: 25.842544555664062\n",
      "Epoch: 49, Batch: 453, D Loss: 0.09714757651362924, G Loss: 26.02033805847168\n",
      "Epoch: 49, Batch: 454, D Loss: 0.09645082056820714, G Loss: 25.686386108398438\n",
      "Epoch: 49, Batch: 455, D Loss: 0.10040746629679603, G Loss: 25.241867065429688\n",
      "Epoch: 49, Batch: 456, D Loss: 0.0948215425087706, G Loss: 24.680795669555664\n",
      "Epoch: 49, Batch: 457, D Loss: 0.09771905840555077, G Loss: 24.395252227783203\n",
      "Epoch: 49, Batch: 458, D Loss: 0.09309928120509155, G Loss: 24.314449310302734\n",
      "Epoch: 49, Batch: 459, D Loss: 0.10428006203047686, G Loss: 24.808551788330078\n",
      "Epoch: 49, Batch: 460, D Loss: 0.09407086671083849, G Loss: 25.197513580322266\n",
      "Epoch: 49, Batch: 461, D Loss: 0.09893810004469254, G Loss: 25.550060272216797\n",
      "Epoch: 49, Batch: 462, D Loss: 0.0948173403779414, G Loss: 25.577604293823242\n",
      "Epoch: 49, Batch: 463, D Loss: 0.095065012578633, G Loss: 25.330869674682617\n",
      "Epoch: 49, Batch: 464, D Loss: 0.10503226519126439, G Loss: 25.343612670898438\n",
      "Epoch: 49, Batch: 465, D Loss: 0.10091154277790623, G Loss: 25.448802947998047\n",
      "Epoch: 49, Batch: 466, D Loss: 0.09651063383076869, G Loss: 25.41486358642578\n",
      "Epoch: 49, Batch: 467, D Loss: 0.10897675156974049, G Loss: 25.7683162689209\n",
      "Epoch: 50, Batch: 0, D Loss: 0.10273377597613369, G Loss: 26.024547576904297\n",
      "Epoch: 50, Batch: 1, D Loss: 0.0976186469223676, G Loss: 25.915138244628906\n",
      "Epoch: 50, Batch: 2, D Loss: 0.1040100604325302, G Loss: 25.798200607299805\n",
      "Epoch: 50, Batch: 3, D Loss: 0.10496895015558984, G Loss: 25.757938385009766\n",
      "Epoch: 50, Batch: 4, D Loss: 0.09021502733665641, G Loss: 25.205425262451172\n",
      "Epoch: 50, Batch: 5, D Loss: 0.0978865549039512, G Loss: 24.767032623291016\n",
      "Epoch: 50, Batch: 6, D Loss: 0.10377928615465934, G Loss: 24.82657241821289\n",
      "Epoch: 50, Batch: 7, D Loss: 0.09564477206057974, G Loss: 24.931608200073242\n",
      "Epoch: 50, Batch: 8, D Loss: 0.09467931092501505, G Loss: 25.003162384033203\n",
      "Epoch: 50, Batch: 9, D Loss: 0.09543004632679045, G Loss: 25.028919219970703\n",
      "Epoch: 50, Batch: 10, D Loss: 0.09949547798078907, G Loss: 25.136642456054688\n",
      "Epoch: 50, Batch: 11, D Loss: 0.10217018425989126, G Loss: 25.4100399017334\n",
      "Epoch: 50, Batch: 12, D Loss: 0.10354994237812767, G Loss: 25.727842330932617\n",
      "Epoch: 50, Batch: 13, D Loss: 0.09876455366938822, G Loss: 25.773771286010742\n",
      "Epoch: 50, Batch: 14, D Loss: 0.09710738063226101, G Loss: 25.51255989074707\n",
      "Epoch: 50, Batch: 15, D Loss: 0.08827154338980378, G Loss: 24.750530242919922\n",
      "Epoch: 50, Batch: 16, D Loss: 0.1048476845124248, G Loss: 24.56539535522461\n",
      "Epoch: 50, Batch: 17, D Loss: 0.09231716395584663, G Loss: 24.41575813293457\n",
      "Epoch: 50, Batch: 18, D Loss: 0.10297429562644744, G Loss: 24.779991149902344\n",
      "Epoch: 50, Batch: 19, D Loss: 0.10118058324500556, G Loss: 25.351085662841797\n",
      "Epoch: 50, Batch: 20, D Loss: 0.09679701924738594, G Loss: 25.663888931274414\n",
      "Epoch: 50, Batch: 21, D Loss: 0.09960038215263095, G Loss: 25.753135681152344\n",
      "Epoch: 50, Batch: 22, D Loss: 0.10429148376306313, G Loss: 25.804224014282227\n",
      "Epoch: 50, Batch: 23, D Loss: 0.09807257354612678, G Loss: 25.56089210510254\n",
      "Epoch: 50, Batch: 24, D Loss: 0.10642063618110667, G Loss: 25.522567749023438\n",
      "Epoch: 50, Batch: 25, D Loss: 0.1043230295221455, G Loss: 25.569169998168945\n",
      "Epoch: 50, Batch: 26, D Loss: 0.09994869679618869, G Loss: 25.506053924560547\n",
      "Epoch: 50, Batch: 27, D Loss: 0.09419181943440384, G Loss: 25.165781021118164\n",
      "Epoch: 50, Batch: 28, D Loss: 0.10310801864283824, G Loss: 25.0861759185791\n",
      "Epoch: 50, Batch: 29, D Loss: 0.10166944563988323, G Loss: 25.201658248901367\n",
      "Epoch: 50, Batch: 30, D Loss: 0.09687361121724859, G Loss: 25.271223068237305\n",
      "Epoch: 50, Batch: 31, D Loss: 0.09865909815349835, G Loss: 25.322912216186523\n",
      "Epoch: 50, Batch: 32, D Loss: 0.10375502706019157, G Loss: 25.55422019958496\n",
      "Epoch: 50, Batch: 33, D Loss: 0.10206155479310011, G Loss: 25.772279739379883\n",
      "Epoch: 50, Batch: 34, D Loss: 0.09633237123829332, G Loss: 25.662059783935547\n",
      "Epoch: 50, Batch: 35, D Loss: 0.09583662450746461, G Loss: 25.301563262939453\n",
      "Epoch: 50, Batch: 36, D Loss: 0.09984742105604788, G Loss: 25.013525009155273\n",
      "Epoch: 50, Batch: 37, D Loss: 0.10284058005302041, G Loss: 25.015531539916992\n",
      "Epoch: 50, Batch: 38, D Loss: 0.0976586639946793, G Loss: 25.092411041259766\n",
      "Epoch: 50, Batch: 39, D Loss: 0.09677350521699789, G Loss: 25.156400680541992\n",
      "Epoch: 50, Batch: 40, D Loss: 0.09417651594305325, G Loss: 25.07400894165039\n",
      "Epoch: 50, Batch: 41, D Loss: 0.09337972105263526, G Loss: 24.880056381225586\n",
      "Epoch: 50, Batch: 42, D Loss: 0.09566037357684219, G Loss: 24.76729393005371\n",
      "Epoch: 50, Batch: 43, D Loss: 0.09311050177537195, G Loss: 24.681697845458984\n",
      "Epoch: 50, Batch: 44, D Loss: 0.09918352217331819, G Loss: 24.90303611755371\n",
      "Epoch: 50, Batch: 45, D Loss: 0.10371218622298164, G Loss: 25.470443725585938\n",
      "Epoch: 50, Batch: 46, D Loss: 0.09717434645058423, G Loss: 25.828453063964844\n",
      "Epoch: 50, Batch: 47, D Loss: 0.10046885162867047, G Loss: 26.013355255126953\n",
      "Epoch: 50, Batch: 48, D Loss: 0.0914840400249763, G Loss: 25.632768630981445\n",
      "Epoch: 50, Batch: 49, D Loss: 0.10431288183138217, G Loss: 25.46525001525879\n",
      "Epoch: 50, Batch: 50, D Loss: 0.10463865101752183, G Loss: 25.560487747192383\n",
      "Epoch: 50, Batch: 51, D Loss: 0.09650193900273007, G Loss: 25.52896499633789\n",
      "Epoch: 50, Batch: 52, D Loss: 0.10092560202280022, G Loss: 25.587682723999023\n",
      "Epoch: 50, Batch: 53, D Loss: 0.10411769152026135, G Loss: 25.836257934570312\n",
      "Epoch: 50, Batch: 54, D Loss: 0.0950204283030612, G Loss: 25.744930267333984\n",
      "Epoch: 50, Batch: 55, D Loss: 0.09864380956052385, G Loss: 25.59741973876953\n",
      "Epoch: 50, Batch: 56, D Loss: 0.1004129201213694, G Loss: 25.514524459838867\n",
      "Epoch: 50, Batch: 57, D Loss: 0.09706459939921613, G Loss: 25.396085739135742\n",
      "Epoch: 50, Batch: 58, D Loss: 0.10420864820911001, G Loss: 25.551197052001953\n",
      "Epoch: 50, Batch: 59, D Loss: 0.10151436925291064, G Loss: 25.769634246826172\n",
      "Epoch: 50, Batch: 60, D Loss: 0.10052760690746933, G Loss: 25.925888061523438\n",
      "Epoch: 50, Batch: 61, D Loss: 0.11150886863689678, G Loss: 26.353178024291992\n",
      "Epoch: 50, Batch: 62, D Loss: 0.10615654289879001, G Loss: 26.61223602294922\n",
      "Epoch: 50, Batch: 63, D Loss: 0.09922353923480427, G Loss: 26.34173583984375\n",
      "Epoch: 50, Batch: 64, D Loss: 0.09927956760174056, G Loss: 25.774621963500977\n",
      "Epoch: 50, Batch: 65, D Loss: 0.09743681550475868, G Loss: 25.126073837280273\n",
      "Epoch: 50, Batch: 66, D Loss: 0.09615534544803679, G Loss: 24.58769989013672\n",
      "Epoch: 50, Batch: 67, D Loss: 0.09721635283205804, G Loss: 24.38597297668457\n",
      "Epoch: 50, Batch: 68, D Loss: 0.09789630771862814, G Loss: 24.54596519470215\n",
      "Epoch: 50, Batch: 69, D Loss: 0.10235959292260632, G Loss: 25.134206771850586\n",
      "Epoch: 50, Batch: 70, D Loss: 0.09243421257061625, G Loss: 25.430683135986328\n",
      "Epoch: 50, Batch: 71, D Loss: 0.09788538515979954, G Loss: 25.603374481201172\n",
      "Epoch: 50, Batch: 72, D Loss: 0.1033523604308175, G Loss: 25.792789459228516\n",
      "Epoch: 50, Batch: 73, D Loss: 0.09608209133486982, G Loss: 25.650108337402344\n",
      "Epoch: 50, Batch: 74, D Loss: 0.10645096004368206, G Loss: 25.668617248535156\n",
      "Epoch: 50, Batch: 75, D Loss: 0.1035349965130521, G Loss: 25.69991111755371\n",
      "Epoch: 50, Batch: 76, D Loss: 0.09556311369341439, G Loss: 25.421743392944336\n",
      "Epoch: 50, Batch: 77, D Loss: 0.09893766791152209, G Loss: 25.15595245361328\n",
      "Epoch: 50, Batch: 78, D Loss: 0.09987491369884832, G Loss: 25.0223388671875\n",
      "Epoch: 50, Batch: 79, D Loss: 0.10150156170783016, G Loss: 25.09599494934082\n",
      "Epoch: 50, Batch: 80, D Loss: 0.10206314921946337, G Loss: 25.29781723022461\n",
      "Epoch: 50, Batch: 81, D Loss: 0.10019180924166418, G Loss: 25.489408493041992\n",
      "Epoch: 50, Batch: 82, D Loss: 0.09966471791676283, G Loss: 25.565793991088867\n",
      "Epoch: 50, Batch: 83, D Loss: 0.10169835389051624, G Loss: 25.581079483032227\n",
      "Epoch: 50, Batch: 84, D Loss: 0.09502521902782551, G Loss: 25.260061264038086\n",
      "Epoch: 50, Batch: 85, D Loss: 0.09806920588655398, G Loss: 24.92391014099121\n",
      "Epoch: 50, Batch: 86, D Loss: 0.10203226656492542, G Loss: 24.869964599609375\n",
      "Epoch: 50, Batch: 87, D Loss: 0.102562285966779, G Loss: 25.085914611816406\n",
      "Epoch: 50, Batch: 88, D Loss: 0.1006546244080844, G Loss: 25.344425201416016\n",
      "Epoch: 50, Batch: 89, D Loss: 0.09393025190152436, G Loss: 25.260467529296875\n",
      "Epoch: 50, Batch: 90, D Loss: 0.10099865496709744, G Loss: 25.204574584960938\n",
      "Epoch: 50, Batch: 91, D Loss: 0.09967778623684716, G Loss: 25.155879974365234\n",
      "Epoch: 50, Batch: 92, D Loss: 0.09791539610057456, G Loss: 25.059032440185547\n",
      "Epoch: 50, Batch: 93, D Loss: 0.09908375144685365, G Loss: 24.985149383544922\n",
      "Epoch: 50, Batch: 94, D Loss: 0.10082106292928404, G Loss: 25.051427841186523\n",
      "Epoch: 50, Batch: 95, D Loss: 0.10465051234332089, G Loss: 25.34998321533203\n",
      "Epoch: 50, Batch: 96, D Loss: 0.10667166859302141, G Loss: 25.7779483795166\n",
      "Epoch: 50, Batch: 97, D Loss: 0.09334317595112201, G Loss: 25.62592887878418\n",
      "Epoch: 50, Batch: 98, D Loss: 0.0973063707397399, G Loss: 25.230390548706055\n",
      "Epoch: 50, Batch: 99, D Loss: 0.08982470632409811, G Loss: 24.499366760253906\n",
      "Epoch: 50, Batch: 100, D Loss: 0.09620970489046456, G Loss: 24.04889488220215\n",
      "Epoch: 50, Batch: 101, D Loss: 0.09967682512382679, G Loss: 24.08009910583496\n",
      "Epoch: 50, Batch: 102, D Loss: 0.10229666532412632, G Loss: 24.59810447692871\n",
      "Epoch: 50, Batch: 103, D Loss: 0.09980190546064371, G Loss: 25.229938507080078\n",
      "Epoch: 50, Batch: 104, D Loss: 0.0974046364472467, G Loss: 25.581148147583008\n",
      "Epoch: 50, Batch: 105, D Loss: 0.10586708784435822, G Loss: 25.876840591430664\n",
      "Epoch: 50, Batch: 106, D Loss: 0.1017167121201669, G Loss: 25.82337188720703\n",
      "Epoch: 50, Batch: 107, D Loss: 0.09724944830333514, G Loss: 25.341957092285156\n",
      "Epoch: 50, Batch: 108, D Loss: 0.10216853768257318, G Loss: 24.895050048828125\n",
      "Epoch: 50, Batch: 109, D Loss: 0.10714031011664833, G Loss: 24.82863426208496\n",
      "Epoch: 50, Batch: 110, D Loss: 0.10218847543809442, G Loss: 24.865747451782227\n",
      "Epoch: 50, Batch: 111, D Loss: 0.09756284952987623, G Loss: 24.795848846435547\n",
      "Epoch: 50, Batch: 112, D Loss: 0.10501369834717748, G Loss: 24.98358726501465\n",
      "Epoch: 50, Batch: 113, D Loss: 0.10107932985461283, G Loss: 25.192594528198242\n",
      "Epoch: 50, Batch: 114, D Loss: 0.09877701104265854, G Loss: 25.173425674438477\n",
      "Epoch: 50, Batch: 115, D Loss: 0.10344130546442172, G Loss: 25.161209106445312\n",
      "Epoch: 50, Batch: 116, D Loss: 0.09666977823438577, G Loss: 24.957128524780273\n",
      "Epoch: 50, Batch: 117, D Loss: 0.09984485805829035, G Loss: 24.78282928466797\n",
      "Epoch: 50, Batch: 118, D Loss: 0.10020309687550862, G Loss: 24.723724365234375\n",
      "Epoch: 50, Batch: 119, D Loss: 0.10512041301337609, G Loss: 24.973857879638672\n",
      "Epoch: 50, Batch: 120, D Loss: 0.10451297462565518, G Loss: 25.368576049804688\n",
      "Epoch: 50, Batch: 121, D Loss: 0.10085731745195922, G Loss: 25.58021354675293\n",
      "Epoch: 50, Batch: 122, D Loss: 0.09938573837687073, G Loss: 25.493749618530273\n",
      "Epoch: 50, Batch: 123, D Loss: 0.10121209919927408, G Loss: 25.2779598236084\n",
      "Epoch: 50, Batch: 124, D Loss: 0.10563679785073578, G Loss: 25.237449645996094\n",
      "Epoch: 50, Batch: 125, D Loss: 0.09617871046694164, G Loss: 24.97732162475586\n",
      "Epoch: 50, Batch: 126, D Loss: 0.10308940709368183, G Loss: 24.92296028137207\n",
      "Epoch: 50, Batch: 127, D Loss: 0.10486083478394134, G Loss: 25.169736862182617\n",
      "Epoch: 50, Batch: 128, D Loss: 0.10534298420426771, G Loss: 25.57086181640625\n",
      "Epoch: 50, Batch: 129, D Loss: 0.09355801344329875, G Loss: 25.4779109954834\n",
      "Epoch: 50, Batch: 130, D Loss: 0.10408017039739256, G Loss: 25.43575096130371\n",
      "Epoch: 50, Batch: 131, D Loss: 0.10684775561523975, G Loss: 25.519798278808594\n",
      "Epoch: 50, Batch: 132, D Loss: 0.10219842195928294, G Loss: 25.499164581298828\n",
      "Epoch: 50, Batch: 133, D Loss: 0.10120934248419874, G Loss: 25.37789535522461\n",
      "Epoch: 50, Batch: 134, D Loss: 0.10348409414793346, G Loss: 25.276445388793945\n",
      "Epoch: 50, Batch: 135, D Loss: 0.09762617201215172, G Loss: 25.02178955078125\n",
      "Epoch: 50, Batch: 136, D Loss: 0.10283277929532549, G Loss: 24.956022262573242\n",
      "Epoch: 50, Batch: 137, D Loss: 0.10239411146138214, G Loss: 25.05296516418457\n",
      "Epoch: 50, Batch: 138, D Loss: 0.09793131799156325, G Loss: 25.076303482055664\n",
      "Epoch: 50, Batch: 139, D Loss: 0.10587463528468201, G Loss: 25.37293243408203\n",
      "Epoch: 50, Batch: 140, D Loss: 0.09629382938630607, G Loss: 25.350139617919922\n",
      "Epoch: 50, Batch: 141, D Loss: 0.09681575000842546, G Loss: 25.10544776916504\n",
      "Epoch: 50, Batch: 142, D Loss: 0.10201799870198941, G Loss: 24.996997833251953\n",
      "Epoch: 50, Batch: 143, D Loss: 0.10099089891405394, G Loss: 25.02324676513672\n",
      "Epoch: 50, Batch: 144, D Loss: 0.09588932991744309, G Loss: 24.919593811035156\n",
      "Epoch: 50, Batch: 145, D Loss: 0.10494980216699538, G Loss: 25.13106918334961\n",
      "Epoch: 50, Batch: 146, D Loss: 0.10901524126986269, G Loss: 25.6779727935791\n",
      "Epoch: 50, Batch: 147, D Loss: 0.0973739847574132, G Loss: 25.787555694580078\n",
      "Epoch: 50, Batch: 148, D Loss: 0.10151875764465189, G Loss: 25.68387794494629\n",
      "Epoch: 50, Batch: 149, D Loss: 0.09872804582538235, G Loss: 25.342819213867188\n",
      "Epoch: 50, Batch: 150, D Loss: 0.09618675709417517, G Loss: 24.825511932373047\n",
      "Epoch: 50, Batch: 151, D Loss: 0.09973300249366394, G Loss: 24.500444412231445\n",
      "Epoch: 50, Batch: 152, D Loss: 0.10307347775592177, G Loss: 24.59908103942871\n",
      "Epoch: 50, Batch: 153, D Loss: 0.09231923521603069, G Loss: 24.596981048583984\n",
      "Epoch: 50, Batch: 154, D Loss: 0.09924149514193935, G Loss: 24.768592834472656\n",
      "Epoch: 50, Batch: 155, D Loss: 0.1006214991286243, G Loss: 25.07819938659668\n",
      "Epoch: 50, Batch: 156, D Loss: 0.10212644935195411, G Loss: 25.403072357177734\n",
      "Epoch: 50, Batch: 157, D Loss: 0.1048821285405982, G Loss: 25.734731674194336\n",
      "Epoch: 50, Batch: 158, D Loss: 0.09399152547496861, G Loss: 25.505226135253906\n",
      "Epoch: 50, Batch: 159, D Loss: 0.09881913662474205, G Loss: 25.103750228881836\n",
      "Epoch: 50, Batch: 160, D Loss: 0.09270827473083268, G Loss: 24.472274780273438\n",
      "Epoch: 50, Batch: 161, D Loss: 0.10170083494310354, G Loss: 24.260093688964844\n",
      "Epoch: 50, Batch: 162, D Loss: 0.0978970229766053, G Loss: 24.328948974609375\n",
      "Epoch: 50, Batch: 163, D Loss: 0.09450469912371671, G Loss: 24.452123641967773\n",
      "Epoch: 50, Batch: 164, D Loss: 0.10324600339874984, G Loss: 24.921398162841797\n",
      "Epoch: 50, Batch: 165, D Loss: 0.09822072834397425, G Loss: 25.28285789489746\n",
      "Epoch: 50, Batch: 166, D Loss: 0.09952890128372541, G Loss: 25.465744018554688\n",
      "Epoch: 50, Batch: 167, D Loss: 0.09948628396246072, G Loss: 25.403963088989258\n",
      "Epoch: 50, Batch: 168, D Loss: 0.09538900852770102, G Loss: 25.021947860717773\n",
      "Epoch: 50, Batch: 169, D Loss: 0.09846246243346962, G Loss: 24.65521240234375\n",
      "Epoch: 50, Batch: 170, D Loss: 0.10402233899653834, G Loss: 24.59066390991211\n",
      "Epoch: 50, Batch: 171, D Loss: 0.098697096119691, G Loss: 24.619182586669922\n",
      "Epoch: 50, Batch: 172, D Loss: 0.10318072141100632, G Loss: 24.88433837890625\n",
      "Epoch: 50, Batch: 173, D Loss: 0.10121697933159826, G Loss: 25.14920425415039\n",
      "Epoch: 50, Batch: 174, D Loss: 0.09526536614317098, G Loss: 25.09848976135254\n",
      "Epoch: 50, Batch: 175, D Loss: 0.09630266577719251, G Loss: 24.85862159729004\n",
      "Epoch: 50, Batch: 176, D Loss: 0.1043142527422393, G Loss: 24.84526252746582\n",
      "Epoch: 50, Batch: 177, D Loss: 0.0964950844732089, G Loss: 24.719884872436523\n",
      "Epoch: 50, Batch: 178, D Loss: 0.09963475913731187, G Loss: 24.71387481689453\n",
      "Epoch: 50, Batch: 179, D Loss: 0.09378065914919115, G Loss: 24.558122634887695\n",
      "Epoch: 50, Batch: 180, D Loss: 0.09937602282639293, G Loss: 24.578256607055664\n",
      "Epoch: 50, Batch: 181, D Loss: 0.10349604488317111, G Loss: 24.890850067138672\n",
      "Epoch: 50, Batch: 182, D Loss: 0.09575119615325868, G Loss: 25.017013549804688\n",
      "Epoch: 50, Batch: 183, D Loss: 0.10062312335410667, G Loss: 25.15535545349121\n",
      "Epoch: 50, Batch: 184, D Loss: 0.09784020484066619, G Loss: 25.22592544555664\n",
      "Epoch: 50, Batch: 185, D Loss: 0.0969593450485238, G Loss: 25.132694244384766\n",
      "Epoch: 50, Batch: 186, D Loss: 0.10227763653407473, G Loss: 25.13944435119629\n",
      "Epoch: 50, Batch: 187, D Loss: 0.09608327598028167, G Loss: 25.00442123413086\n",
      "Epoch: 50, Batch: 188, D Loss: 0.09955139458897289, G Loss: 24.933002471923828\n",
      "Epoch: 50, Batch: 189, D Loss: 0.10084955394984821, G Loss: 25.000057220458984\n",
      "Epoch: 50, Batch: 190, D Loss: 0.09804184735492766, G Loss: 25.0638427734375\n",
      "Epoch: 50, Batch: 191, D Loss: 0.10493717343175821, G Loss: 25.348758697509766\n",
      "Epoch: 50, Batch: 192, D Loss: 0.09536944330237081, G Loss: 25.315998077392578\n",
      "Epoch: 50, Batch: 193, D Loss: 0.09761795402118534, G Loss: 25.17458152770996\n",
      "Epoch: 50, Batch: 194, D Loss: 0.09714472294498125, G Loss: 24.984811782836914\n",
      "Epoch: 50, Batch: 195, D Loss: 0.09999663383487332, G Loss: 24.948293685913086\n",
      "Epoch: 50, Batch: 196, D Loss: 0.10020317137925869, G Loss: 25.073827743530273\n",
      "Epoch: 50, Batch: 197, D Loss: 0.09074138850688288, G Loss: 24.87885093688965\n",
      "Epoch: 50, Batch: 198, D Loss: 0.09861400724259026, G Loss: 24.836061477661133\n",
      "Epoch: 50, Batch: 199, D Loss: 0.0939846187914747, G Loss: 24.768386840820312\n",
      "Epoch: 50, Batch: 200, D Loss: 0.0998489931305909, G Loss: 24.936336517333984\n",
      "Epoch: 50, Batch: 201, D Loss: 0.09407435358272155, G Loss: 25.037961959838867\n",
      "Epoch: 50, Batch: 202, D Loss: 0.10479657352493621, G Loss: 25.504138946533203\n",
      "Epoch: 50, Batch: 203, D Loss: 0.10102811456064759, G Loss: 25.913822174072266\n",
      "Epoch: 50, Batch: 204, D Loss: 0.09932997823025103, G Loss: 26.0181827545166\n",
      "Epoch: 50, Batch: 205, D Loss: 0.09906867146761113, G Loss: 25.884614944458008\n",
      "Epoch: 50, Batch: 206, D Loss: 0.09955402464003436, G Loss: 25.62379264831543\n",
      "Epoch: 50, Batch: 207, D Loss: 0.09809278697209778, G Loss: 25.32976722717285\n",
      "Epoch: 50, Batch: 208, D Loss: 0.0924006030025025, G Loss: 24.932392120361328\n",
      "Epoch: 50, Batch: 209, D Loss: 0.09141489864300836, G Loss: 24.560365676879883\n",
      "Epoch: 50, Batch: 210, D Loss: 0.09441168607403409, G Loss: 24.483781814575195\n",
      "Epoch: 50, Batch: 211, D Loss: 0.09368485213398024, G Loss: 24.639598846435547\n",
      "Epoch: 50, Batch: 212, D Loss: 0.09722124040907887, G Loss: 25.102230072021484\n",
      "Epoch: 50, Batch: 213, D Loss: 0.10085872561191263, G Loss: 25.723779678344727\n",
      "Epoch: 50, Batch: 214, D Loss: 0.10240634531027658, G Loss: 26.32814598083496\n",
      "Epoch: 50, Batch: 215, D Loss: 0.10065080970690521, G Loss: 26.53726577758789\n",
      "Epoch: 50, Batch: 216, D Loss: 0.09742050618108973, G Loss: 26.22698974609375\n",
      "Epoch: 50, Batch: 217, D Loss: 0.09808576107295928, G Loss: 25.684982299804688\n",
      "Epoch: 50, Batch: 218, D Loss: 0.10199895501568626, G Loss: 25.285459518432617\n",
      "Epoch: 50, Batch: 219, D Loss: 0.10403046757515161, G Loss: 25.247974395751953\n",
      "Epoch: 50, Batch: 220, D Loss: 0.09991752356810274, G Loss: 25.328325271606445\n",
      "Epoch: 50, Batch: 221, D Loss: 0.09926593304145107, G Loss: 25.467714309692383\n",
      "Epoch: 50, Batch: 222, D Loss: 0.10414953530204298, G Loss: 25.777299880981445\n",
      "Epoch: 50, Batch: 223, D Loss: 0.096059076491224, G Loss: 25.76886749267578\n",
      "Epoch: 50, Batch: 224, D Loss: 0.09724991023903164, G Loss: 25.541988372802734\n",
      "Epoch: 50, Batch: 225, D Loss: 0.10064455867257174, G Loss: 25.36390495300293\n",
      "Epoch: 50, Batch: 226, D Loss: 0.09930657595905859, G Loss: 25.25953483581543\n",
      "Epoch: 50, Batch: 227, D Loss: 0.09757399559580134, G Loss: 25.17804718017578\n",
      "Epoch: 50, Batch: 228, D Loss: 0.09814913571471236, G Loss: 25.148208618164062\n",
      "Epoch: 50, Batch: 229, D Loss: 0.10138384998396913, G Loss: 25.30189323425293\n",
      "Epoch: 50, Batch: 230, D Loss: 0.10063463449941384, G Loss: 25.49738121032715\n",
      "Epoch: 50, Batch: 231, D Loss: 0.10015384108219728, G Loss: 25.640716552734375\n",
      "Epoch: 50, Batch: 232, D Loss: 0.09658567607789717, G Loss: 25.534509658813477\n",
      "Epoch: 50, Batch: 233, D Loss: 0.10386345535917384, G Loss: 25.56389617919922\n",
      "Epoch: 50, Batch: 234, D Loss: 0.09644069523053836, G Loss: 25.382789611816406\n",
      "Epoch: 50, Batch: 235, D Loss: 0.09796367586191959, G Loss: 25.15815544128418\n",
      "Epoch: 50, Batch: 236, D Loss: 0.09820550680807114, G Loss: 24.99311637878418\n",
      "Epoch: 50, Batch: 237, D Loss: 0.09630462528023338, G Loss: 24.864255905151367\n",
      "Epoch: 50, Batch: 238, D Loss: 0.09511537105693085, G Loss: 24.742366790771484\n",
      "Epoch: 50, Batch: 239, D Loss: 0.0991108343088475, G Loss: 24.886213302612305\n",
      "Epoch: 50, Batch: 240, D Loss: 0.10185007751620227, G Loss: 25.280303955078125\n",
      "Epoch: 50, Batch: 241, D Loss: 0.09277544171114135, G Loss: 25.386749267578125\n",
      "Epoch: 50, Batch: 242, D Loss: 0.09263588488633114, G Loss: 25.160917282104492\n",
      "Epoch: 50, Batch: 243, D Loss: 0.10580337793182419, G Loss: 25.306943893432617\n",
      "Epoch: 50, Batch: 244, D Loss: 0.0976781547119352, G Loss: 25.355318069458008\n",
      "Epoch: 50, Batch: 245, D Loss: 0.10128060728768758, G Loss: 25.474185943603516\n",
      "Epoch: 50, Batch: 246, D Loss: 0.08771917224465932, G Loss: 25.06609535217285\n",
      "Epoch: 50, Batch: 247, D Loss: 0.09603777528597164, G Loss: 24.699724197387695\n",
      "Epoch: 50, Batch: 248, D Loss: 0.09351849557032044, G Loss: 24.46161460876465\n",
      "Epoch: 50, Batch: 249, D Loss: 0.10624825210328964, G Loss: 24.89349937438965\n",
      "Epoch: 50, Batch: 250, D Loss: 0.10455295444062544, G Loss: 25.616140365600586\n",
      "Epoch: 50, Batch: 251, D Loss: 0.09614561498477053, G Loss: 25.966629028320312\n",
      "Epoch: 50, Batch: 252, D Loss: 0.10153206438080419, G Loss: 26.038911819458008\n",
      "Epoch: 50, Batch: 253, D Loss: 0.09766969830082989, G Loss: 25.755329132080078\n",
      "Epoch: 50, Batch: 254, D Loss: 0.10275179148091163, G Loss: 25.511856079101562\n",
      "Epoch: 50, Batch: 255, D Loss: 0.09442603588623831, G Loss: 25.089754104614258\n",
      "Epoch: 50, Batch: 256, D Loss: 0.09619345516726377, G Loss: 24.747400283813477\n",
      "Epoch: 50, Batch: 257, D Loss: 0.09867488593777068, G Loss: 24.705455780029297\n",
      "Epoch: 50, Batch: 258, D Loss: 0.09491427243664903, G Loss: 24.753564834594727\n",
      "Epoch: 50, Batch: 259, D Loss: 0.10645991564459623, G Loss: 25.31001853942871\n",
      "Epoch: 50, Batch: 260, D Loss: 0.1000970006028409, G Loss: 25.800283432006836\n",
      "Epoch: 50, Batch: 261, D Loss: 0.10097736120491796, G Loss: 26.089916229248047\n",
      "Epoch: 50, Batch: 262, D Loss: 0.09263855219163665, G Loss: 25.76959991455078\n",
      "Epoch: 50, Batch: 263, D Loss: 0.10115136206539498, G Loss: 25.405736923217773\n",
      "Epoch: 50, Batch: 264, D Loss: 0.09953793883870005, G Loss: 25.090129852294922\n",
      "Epoch: 50, Batch: 265, D Loss: 0.09793173522466082, G Loss: 24.879291534423828\n",
      "Epoch: 50, Batch: 266, D Loss: 0.09826239944296493, G Loss: 24.858386993408203\n",
      "Epoch: 50, Batch: 267, D Loss: 0.10414063931165157, G Loss: 25.241952896118164\n",
      "Epoch: 50, Batch: 268, D Loss: 0.0946639701774435, G Loss: 25.391759872436523\n",
      "Epoch: 50, Batch: 269, D Loss: 0.10216583311981625, G Loss: 25.585315704345703\n",
      "Epoch: 50, Batch: 270, D Loss: 0.10143779218551095, G Loss: 25.75209617614746\n",
      "Epoch: 50, Batch: 271, D Loss: 0.10131932050310602, G Loss: 25.78976821899414\n",
      "Epoch: 50, Batch: 272, D Loss: 0.10517379641839023, G Loss: 25.84556007385254\n",
      "Epoch: 50, Batch: 273, D Loss: 0.10040895641166715, G Loss: 25.7310848236084\n",
      "Epoch: 50, Batch: 274, D Loss: 0.10264170170182188, G Loss: 25.633615493774414\n",
      "Epoch: 50, Batch: 275, D Loss: 0.09701502323568535, G Loss: 25.394338607788086\n",
      "Epoch: 50, Batch: 276, D Loss: 0.10448718816502911, G Loss: 25.423587799072266\n",
      "Epoch: 50, Batch: 277, D Loss: 0.10294794291675735, G Loss: 25.583675384521484\n",
      "Epoch: 50, Batch: 278, D Loss: 0.11003559828101375, G Loss: 26.09024429321289\n",
      "Epoch: 50, Batch: 279, D Loss: 0.09834974259357294, G Loss: 26.2097110748291\n",
      "Epoch: 50, Batch: 280, D Loss: 0.10793364048195077, G Loss: 26.364439010620117\n",
      "Epoch: 50, Batch: 281, D Loss: 0.09959085285861642, G Loss: 26.155561447143555\n",
      "Epoch: 50, Batch: 282, D Loss: 0.09844712168259057, G Loss: 25.680606842041016\n",
      "Epoch: 50, Batch: 283, D Loss: 0.10368600488118425, G Loss: 25.39108657836914\n",
      "Epoch: 50, Batch: 284, D Loss: 0.09597215056974191, G Loss: 25.074010848999023\n",
      "Epoch: 50, Batch: 285, D Loss: 0.10294577479993615, G Loss: 25.114938735961914\n",
      "Epoch: 50, Batch: 286, D Loss: 0.10227259249027398, G Loss: 25.40152359008789\n",
      "Epoch: 50, Batch: 287, D Loss: 0.09825085848983382, G Loss: 25.623441696166992\n",
      "Epoch: 50, Batch: 288, D Loss: 0.09708540887005154, G Loss: 25.6629695892334\n",
      "Epoch: 50, Batch: 289, D Loss: 0.10227306932554396, G Loss: 25.740833282470703\n",
      "Epoch: 50, Batch: 290, D Loss: 0.09502784908186093, G Loss: 25.538227081298828\n",
      "Epoch: 50, Batch: 291, D Loss: 0.09949044138648483, G Loss: 25.31719970703125\n",
      "Epoch: 50, Batch: 292, D Loss: 0.10049127787879089, G Loss: 25.236886978149414\n",
      "Epoch: 50, Batch: 293, D Loss: 0.10579875857107951, G Loss: 25.52821159362793\n",
      "Epoch: 50, Batch: 294, D Loss: 0.10028378665809164, G Loss: 25.762557983398438\n",
      "Epoch: 50, Batch: 295, D Loss: 0.10198292136488456, G Loss: 25.9332332611084\n",
      "Epoch: 50, Batch: 296, D Loss: 0.09876839816857928, G Loss: 25.83453941345215\n",
      "Epoch: 50, Batch: 297, D Loss: 0.09654156864051529, G Loss: 25.48558235168457\n",
      "Epoch: 50, Batch: 298, D Loss: 0.0974652618221702, G Loss: 25.115022659301758\n",
      "Epoch: 50, Batch: 299, D Loss: 0.09416466952114996, G Loss: 24.763031005859375\n",
      "Epoch: 50, Batch: 300, D Loss: 0.10459407419752678, G Loss: 24.97687339782715\n",
      "Epoch: 50, Batch: 301, D Loss: 0.09819473326806412, G Loss: 25.297616958618164\n",
      "Epoch: 50, Batch: 302, D Loss: 0.09530243278019554, G Loss: 25.4744815826416\n",
      "Epoch: 50, Batch: 303, D Loss: 0.10609075427400319, G Loss: 25.902080535888672\n",
      "Epoch: 50, Batch: 304, D Loss: 0.09851232171314112, G Loss: 26.088092803955078\n",
      "Epoch: 50, Batch: 305, D Loss: 0.10129398107762115, G Loss: 26.092021942138672\n",
      "Epoch: 50, Batch: 306, D Loss: 0.1011023223425332, G Loss: 25.941713333129883\n",
      "Epoch: 50, Batch: 307, D Loss: 0.09765703976476209, G Loss: 25.613134384155273\n",
      "Epoch: 50, Batch: 308, D Loss: 0.10090045631350678, G Loss: 25.408647537231445\n",
      "Epoch: 50, Batch: 309, D Loss: 0.10364059359274762, G Loss: 25.501121520996094\n",
      "Epoch: 50, Batch: 310, D Loss: 0.10120747238768842, G Loss: 25.738651275634766\n",
      "Epoch: 50, Batch: 311, D Loss: 0.09176248312349722, G Loss: 25.619220733642578\n",
      "Epoch: 50, Batch: 312, D Loss: 0.1004624590315276, G Loss: 25.608076095581055\n",
      "Epoch: 50, Batch: 313, D Loss: 0.09599064290921411, G Loss: 25.510793685913086\n",
      "Epoch: 50, Batch: 314, D Loss: 0.10792682320221551, G Loss: 25.885555267333984\n",
      "Epoch: 50, Batch: 315, D Loss: 0.10466980189310915, G Loss: 26.336336135864258\n",
      "Epoch: 50, Batch: 316, D Loss: 0.10224763304154856, G Loss: 26.589412689208984\n",
      "Epoch: 50, Batch: 317, D Loss: 0.091016933323736, G Loss: 26.151845932006836\n",
      "Epoch: 50, Batch: 318, D Loss: 0.09539286047529753, G Loss: 25.498193740844727\n",
      "Epoch: 50, Batch: 319, D Loss: 0.09005369991691, G Loss: 24.746047973632812\n",
      "Epoch: 50, Batch: 320, D Loss: 0.09115415812688296, G Loss: 24.270286560058594\n",
      "Epoch: 50, Batch: 321, D Loss: 0.10315852613443632, G Loss: 24.638521194458008\n",
      "Epoch: 50, Batch: 322, D Loss: 0.09584273398644412, G Loss: 25.25473976135254\n",
      "Epoch: 50, Batch: 323, D Loss: 0.10121978074664041, G Loss: 26.061365127563477\n",
      "Epoch: 50, Batch: 324, D Loss: 0.09513996541694343, G Loss: 26.46475601196289\n",
      "Epoch: 50, Batch: 325, D Loss: 0.1032105162753858, G Loss: 26.710140228271484\n",
      "Epoch: 50, Batch: 326, D Loss: 0.1044747531426313, G Loss: 26.752426147460938\n",
      "Epoch: 50, Batch: 327, D Loss: 0.10554284602530696, G Loss: 26.64975929260254\n",
      "Epoch: 50, Batch: 328, D Loss: 0.09925162792372258, G Loss: 26.228496551513672\n",
      "Epoch: 50, Batch: 329, D Loss: 0.09200475365230014, G Loss: 25.447254180908203\n",
      "Epoch: 50, Batch: 330, D Loss: 0.09717234969734302, G Loss: 24.889183044433594\n",
      "Epoch: 50, Batch: 331, D Loss: 0.0952371582477839, G Loss: 24.62934112548828\n",
      "Epoch: 50, Batch: 332, D Loss: 0.10182756186374119, G Loss: 24.968238830566406\n",
      "Epoch: 50, Batch: 333, D Loss: 0.1046160757588654, G Loss: 25.76856803894043\n",
      "Epoch: 50, Batch: 334, D Loss: 0.10632216930585693, G Loss: 26.707744598388672\n",
      "Epoch: 50, Batch: 335, D Loss: 0.10454083979221601, G Loss: 27.30558967590332\n",
      "Epoch: 50, Batch: 336, D Loss: 0.10280891507932514, G Loss: 27.325336456298828\n",
      "Epoch: 50, Batch: 337, D Loss: 0.09941655397506227, G Loss: 26.765132904052734\n",
      "Epoch: 50, Batch: 338, D Loss: 0.09972136467875915, G Loss: 25.96769142150879\n",
      "Epoch: 50, Batch: 339, D Loss: 0.09390840679826358, G Loss: 25.085350036621094\n",
      "Epoch: 50, Batch: 340, D Loss: 0.09598982334969579, G Loss: 24.580720901489258\n",
      "Epoch: 50, Batch: 341, D Loss: 0.09770184011289273, G Loss: 24.643064498901367\n",
      "Epoch: 50, Batch: 342, D Loss: 0.10151657462823753, G Loss: 25.301067352294922\n",
      "Epoch: 50, Batch: 343, D Loss: 0.0983134359155251, G Loss: 26.088407516479492\n",
      "Epoch: 50, Batch: 344, D Loss: 0.09430950880235067, G Loss: 26.539264678955078\n",
      "Epoch: 50, Batch: 345, D Loss: 0.10183609277138721, G Loss: 26.816255569458008\n",
      "Epoch: 50, Batch: 346, D Loss: 0.10379220545398245, G Loss: 26.930484771728516\n",
      "Epoch: 50, Batch: 347, D Loss: 0.0957288891089267, G Loss: 26.562314987182617\n",
      "Epoch: 50, Batch: 348, D Loss: 0.10757571458977135, G Loss: 26.375566482543945\n",
      "Epoch: 50, Batch: 349, D Loss: 0.10184118151858337, G Loss: 26.18364906311035\n",
      "Epoch: 50, Batch: 350, D Loss: 0.1012246906779365, G Loss: 26.109966278076172\n",
      "Epoch: 50, Batch: 351, D Loss: 0.09740071743972242, G Loss: 25.976388931274414\n",
      "Epoch: 50, Batch: 352, D Loss: 0.10344251245510461, G Loss: 26.060577392578125\n",
      "Epoch: 50, Batch: 353, D Loss: 0.10312590003232412, G Loss: 26.239898681640625\n",
      "Epoch: 50, Batch: 354, D Loss: 0.10380697250543265, G Loss: 26.480501174926758\n",
      "Epoch: 50, Batch: 355, D Loss: 0.102664619685678, G Loss: 26.632230758666992\n",
      "Epoch: 50, Batch: 356, D Loss: 0.09768945723921642, G Loss: 26.44761848449707\n",
      "Epoch: 50, Batch: 357, D Loss: 0.10138539225048653, G Loss: 26.203882217407227\n",
      "Epoch: 50, Batch: 358, D Loss: 0.1006944924616031, G Loss: 26.011276245117188\n",
      "Epoch: 50, Batch: 359, D Loss: 0.10110413283373391, G Loss: 25.929258346557617\n",
      "Epoch: 50, Batch: 360, D Loss: 0.1038362681891112, G Loss: 26.073047637939453\n",
      "Epoch: 50, Batch: 361, D Loss: 0.09612108022212557, G Loss: 26.068803787231445\n",
      "Epoch: 50, Batch: 362, D Loss: 0.10206145048368999, G Loss: 26.15817642211914\n",
      "Epoch: 50, Batch: 363, D Loss: 0.10077154636595086, G Loss: 26.211673736572266\n",
      "Epoch: 50, Batch: 364, D Loss: 0.10023310035677589, G Loss: 26.177776336669922\n",
      "Epoch: 50, Batch: 365, D Loss: 0.09949389100298338, G Loss: 26.093271255493164\n",
      "Epoch: 50, Batch: 366, D Loss: 0.0958106294300639, G Loss: 25.85993003845215\n",
      "Epoch: 50, Batch: 367, D Loss: 0.09349980205643879, G Loss: 25.54698944091797\n",
      "Epoch: 50, Batch: 368, D Loss: 0.0984199792188776, G Loss: 25.458755493164062\n",
      "Epoch: 50, Batch: 369, D Loss: 0.10041719675456069, G Loss: 25.67354965209961\n",
      "Epoch: 50, Batch: 370, D Loss: 0.09442716837254846, G Loss: 25.83324432373047\n",
      "Epoch: 50, Batch: 371, D Loss: 0.10246006399644246, G Loss: 26.182403564453125\n",
      "Epoch: 50, Batch: 372, D Loss: 0.0954435467740156, G Loss: 26.289045333862305\n",
      "Epoch: 50, Batch: 373, D Loss: 0.10206890851435697, G Loss: 26.44269561767578\n",
      "Epoch: 50, Batch: 374, D Loss: 0.10094439238465817, G Loss: 26.539167404174805\n",
      "Epoch: 50, Batch: 375, D Loss: 0.09946797043242803, G Loss: 26.431079864501953\n",
      "Epoch: 50, Batch: 376, D Loss: 0.09548553079555645, G Loss: 26.184724807739258\n",
      "Epoch: 50, Batch: 377, D Loss: 0.1019162535689877, G Loss: 26.079177856445312\n",
      "Epoch: 50, Batch: 378, D Loss: 0.09681420773516317, G Loss: 25.980615615844727\n",
      "Epoch: 50, Batch: 379, D Loss: 0.10109187662850931, G Loss: 26.06250762939453\n",
      "Epoch: 50, Batch: 380, D Loss: 0.09439185261969957, G Loss: 26.034210205078125\n",
      "Epoch: 50, Batch: 381, D Loss: 0.10133561492195206, G Loss: 26.17719078063965\n",
      "Epoch: 50, Batch: 382, D Loss: 0.09471039474225869, G Loss: 26.16457176208496\n",
      "Epoch: 50, Batch: 383, D Loss: 0.0994813889286183, G Loss: 26.213109970092773\n",
      "Epoch: 50, Batch: 384, D Loss: 0.1029149144906491, G Loss: 26.414342880249023\n",
      "Epoch: 50, Batch: 385, D Loss: 0.10017651319661346, G Loss: 26.54518699645996\n",
      "Epoch: 50, Batch: 386, D Loss: 0.09789961576616023, G Loss: 26.46803855895996\n",
      "Epoch: 50, Batch: 387, D Loss: 0.09697637707177098, G Loss: 26.221843719482422\n",
      "Epoch: 50, Batch: 388, D Loss: 0.10285699367737701, G Loss: 26.132261276245117\n",
      "Epoch: 50, Batch: 389, D Loss: 0.0997669622325239, G Loss: 26.065275192260742\n",
      "Epoch: 50, Batch: 390, D Loss: 0.10438597202520883, G Loss: 26.226333618164062\n",
      "Epoch: 50, Batch: 391, D Loss: 0.09736400097808637, G Loss: 26.26063346862793\n",
      "Epoch: 50, Batch: 392, D Loss: 0.10752762854270143, G Loss: 26.529354095458984\n",
      "Epoch: 50, Batch: 393, D Loss: 0.0999442338957965, G Loss: 26.601720809936523\n",
      "Epoch: 50, Batch: 394, D Loss: 0.10019180923849019, G Loss: 26.486698150634766\n",
      "Epoch: 50, Batch: 395, D Loss: 0.09758369624800103, G Loss: 26.170761108398438\n",
      "Epoch: 50, Batch: 396, D Loss: 0.09522833675417838, G Loss: 25.72649574279785\n",
      "Epoch: 50, Batch: 397, D Loss: 0.09748762101325198, G Loss: 25.440919876098633\n",
      "Epoch: 50, Batch: 398, D Loss: 0.09402002394690646, G Loss: 25.260547637939453\n",
      "Epoch: 50, Batch: 399, D Loss: 0.09725648910316087, G Loss: 25.356081008911133\n",
      "Epoch: 50, Batch: 400, D Loss: 0.09910386801168779, G Loss: 25.714035034179688\n",
      "Epoch: 50, Batch: 401, D Loss: 0.09547477215824554, G Loss: 25.976903915405273\n",
      "Epoch: 50, Batch: 402, D Loss: 0.10302047431689262, G Loss: 26.301637649536133\n",
      "Epoch: 50, Batch: 403, D Loss: 0.09620884061046005, G Loss: 26.328094482421875\n",
      "Epoch: 50, Batch: 404, D Loss: 0.09970486164286343, G Loss: 26.233903884887695\n",
      "Epoch: 50, Batch: 405, D Loss: 0.09089433402087017, G Loss: 25.726341247558594\n",
      "Epoch: 50, Batch: 406, D Loss: 0.09686286747872926, G Loss: 25.313142776489258\n",
      "Epoch: 50, Batch: 407, D Loss: 0.09946568310784502, G Loss: 25.25411605834961\n",
      "Epoch: 50, Batch: 408, D Loss: 0.09985576570503275, G Loss: 25.515811920166016\n",
      "Epoch: 50, Batch: 409, D Loss: 0.09848970175135692, G Loss: 25.857648849487305\n",
      "Epoch: 50, Batch: 410, D Loss: 0.10467529297099913, G Loss: 26.36881446838379\n",
      "Epoch: 50, Batch: 411, D Loss: 0.09566338360475964, G Loss: 26.482921600341797\n",
      "Epoch: 50, Batch: 412, D Loss: 0.10396977514180775, G Loss: 26.54894256591797\n",
      "Epoch: 50, Batch: 413, D Loss: 0.10484632849839012, G Loss: 26.572608947753906\n",
      "Epoch: 50, Batch: 414, D Loss: 0.09874126315280268, G Loss: 26.333635330200195\n",
      "Epoch: 50, Batch: 415, D Loss: 0.10013963282324356, G Loss: 26.017412185668945\n",
      "Epoch: 50, Batch: 416, D Loss: 0.10531016439457348, G Loss: 25.966217041015625\n",
      "Epoch: 50, Batch: 417, D Loss: 0.09828180820029497, G Loss: 25.858322143554688\n",
      "Epoch: 50, Batch: 418, D Loss: 0.0978631377251553, G Loss: 25.73543930053711\n",
      "Epoch: 50, Batch: 419, D Loss: 0.10268478095848486, G Loss: 25.82781982421875\n",
      "Epoch: 50, Batch: 420, D Loss: 0.09922753274725256, G Loss: 25.95039939880371\n",
      "Epoch: 50, Batch: 421, D Loss: 0.09712050110369802, G Loss: 25.952852249145508\n",
      "Epoch: 50, Batch: 422, D Loss: 0.09728057682791999, G Loss: 25.88302230834961\n",
      "Epoch: 50, Batch: 423, D Loss: 0.0997732654243161, G Loss: 25.847606658935547\n",
      "Epoch: 50, Batch: 424, D Loss: 0.09825976193254095, G Loss: 25.81351661682129\n",
      "Epoch: 50, Batch: 425, D Loss: 0.10203316062978962, G Loss: 25.926008224487305\n",
      "Epoch: 50, Batch: 426, D Loss: 0.10097887367261014, G Loss: 26.10079002380371\n",
      "Epoch: 50, Batch: 427, D Loss: 0.10093943774913244, G Loss: 26.25366973876953\n",
      "Epoch: 50, Batch: 428, D Loss: 0.10237815976327312, G Loss: 26.39068603515625\n",
      "Epoch: 50, Batch: 429, D Loss: 0.10466824472109856, G Loss: 26.545320510864258\n",
      "Epoch: 50, Batch: 430, D Loss: 0.10195973515656341, G Loss: 26.57500648498535\n",
      "Epoch: 50, Batch: 431, D Loss: 0.10240170359763225, G Loss: 26.472442626953125\n",
      "Epoch: 50, Batch: 432, D Loss: 0.10172902792865479, G Loss: 26.311996459960938\n",
      "Epoch: 50, Batch: 433, D Loss: 0.09777676314335511, G Loss: 26.00205421447754\n",
      "Epoch: 50, Batch: 434, D Loss: 0.10027754307083364, G Loss: 25.75594711303711\n",
      "Epoch: 50, Batch: 435, D Loss: 0.0981326475774764, G Loss: 25.60586166381836\n",
      "Epoch: 50, Batch: 436, D Loss: 0.10175517201773916, G Loss: 25.754966735839844\n",
      "Epoch: 50, Batch: 437, D Loss: 0.09930365532928226, G Loss: 25.96913719177246\n",
      "Epoch: 50, Batch: 438, D Loss: 0.09713371843344858, G Loss: 26.105127334594727\n",
      "Epoch: 50, Batch: 439, D Loss: 0.09919244051198756, G Loss: 26.1962890625\n",
      "Epoch: 50, Batch: 440, D Loss: 0.10132296383581686, G Loss: 26.280786514282227\n",
      "Epoch: 50, Batch: 441, D Loss: 0.1043804585951496, G Loss: 26.43253517150879\n",
      "Epoch: 50, Batch: 442, D Loss: 0.09575366974058204, G Loss: 26.26260757446289\n",
      "Epoch: 50, Batch: 443, D Loss: 0.09444269538167532, G Loss: 25.866132736206055\n",
      "Epoch: 50, Batch: 444, D Loss: 0.09191527218007954, G Loss: 25.358152389526367\n",
      "Epoch: 50, Batch: 445, D Loss: 0.10187196732045728, G Loss: 25.385841369628906\n",
      "Epoch: 50, Batch: 446, D Loss: 0.10207690298931588, G Loss: 25.826496124267578\n",
      "Epoch: 50, Batch: 447, D Loss: 0.09685780853273204, G Loss: 26.270910263061523\n",
      "Epoch: 50, Batch: 448, D Loss: 0.09812663495705393, G Loss: 26.589094161987305\n",
      "Epoch: 50, Batch: 449, D Loss: 0.10323302447916244, G Loss: 26.899261474609375\n",
      "Epoch: 50, Batch: 450, D Loss: 0.09703310579170135, G Loss: 26.815340042114258\n",
      "Epoch: 50, Batch: 451, D Loss: 0.09490077197694563, G Loss: 26.370044708251953\n",
      "Epoch: 50, Batch: 452, D Loss: 0.09994858503555001, G Loss: 26.00892448425293\n",
      "Epoch: 50, Batch: 453, D Loss: 0.10412052273999715, G Loss: 26.037471771240234\n",
      "Epoch: 50, Batch: 454, D Loss: 0.10255961120336657, G Loss: 26.35635757446289\n",
      "Epoch: 50, Batch: 455, D Loss: 0.10648057609929243, G Loss: 26.922672271728516\n",
      "Epoch: 50, Batch: 456, D Loss: 0.1018347889193434, G Loss: 27.264070510864258\n",
      "Epoch: 50, Batch: 457, D Loss: 0.09561217576346917, G Loss: 27.03084373474121\n",
      "Epoch: 50, Batch: 458, D Loss: 0.09614101797466935, G Loss: 26.434734344482422\n",
      "Epoch: 50, Batch: 459, D Loss: 0.10272938758335454, G Loss: 26.06747817993164\n",
      "Epoch: 50, Batch: 460, D Loss: 0.09532608092114994, G Loss: 25.737598419189453\n",
      "Epoch: 50, Batch: 461, D Loss: 0.10101927817183906, G Loss: 25.831586837768555\n",
      "Epoch: 50, Batch: 462, D Loss: 0.09611237049377956, G Loss: 26.010009765625\n",
      "Epoch: 50, Batch: 463, D Loss: 0.09810045361741046, G Loss: 26.255996704101562\n",
      "Epoch: 50, Batch: 464, D Loss: 0.09753344208179902, G Loss: 26.45795249938965\n",
      "Epoch: 50, Batch: 465, D Loss: 0.09350512921979517, G Loss: 26.36865997314453\n",
      "Epoch: 50, Batch: 466, D Loss: 0.09620199352696164, G Loss: 26.197410583496094\n",
      "Epoch: 50, Batch: 467, D Loss: 0.10183918476310268, G Loss: 26.235509872436523\n"
     ]
    }
   ],
   "source": [
    "# Call the train function\n",
    "train(epochs=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I09QJRDIlZqo"
   },
   "source": [
    "**Notes:**\n",
    "- Epochs parameter determines how many times the learning algorithm will work through the entire training dataset.\n",
    "- The `batch_size` is the number of samples that will be propagated through the network at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtmQnlKeg9C8"
   },
   "source": [
    "# __Step 7: Generate New Images and Evaluate the Model's Performance__\n",
    "\n",
    "- Generate new images and evaluate the performance of the GAN.\n",
    "- Generate a random noise vector and feed it into the trained generator to create new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oIlF3BEEe45G",
    "outputId": "7d69ba3f-0d68-4aa0-dfed-75515819180f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 100 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Generate random noise as an input to initialize the generator\n",
    "random_noise = np.random.normal(0,1, [100, 100])\n",
    "\n",
    "# Generate the images from the noise\n",
    "generated_images = generator.predict(random_noise)\n",
    "\n",
    "# Visualize the generated images\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(generated_images.shape[0]):\n",
    "    plt.subplot(10, 10, i+1)\n",
    "    plt.imshow(generated_images[i, :, :, 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzI9y3KSlwMp"
   },
   "source": [
    "- The resulting plot shows the images generated by the GAN model.\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "The output effectively demonstrates how model can generate images resembling handwritten digit 8. However, there is room for improving the quality of these images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ic6p2uAFJMDl"
   },
   "source": [
    "# __Conclusion__\n",
    "\n",
    "In this demo, you have successfully implemented a GAN to generate images resembling handwritten digits, focusing on the MNIST dataset. The process involved constructing and training a generator and a discriminator. The results were promising, showcasing the GAN's ability to create images similar to the digit **8**, but also highlighted the need for further improvements in image quality."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
