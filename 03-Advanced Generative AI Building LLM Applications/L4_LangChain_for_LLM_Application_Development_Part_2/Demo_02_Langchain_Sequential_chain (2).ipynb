{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "g0MsvQkSmyEt",
   "metadata": {
    "id": "g0MsvQkSmyEt"
   },
   "source": [
    "# **Demo: Langchain Sequential Chain**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deWmpTym6Hn",
   "metadata": {
    "id": "6deWmpTym6Hn"
   },
   "source": [
    "# **Steps to Perform:**\n",
    "\n",
    "1. Import the Necessary Modules\n",
    "2. Define a Function to Print Responses from Our Chains\n",
    "3. Initialize the Chat Model\n",
    "4. Define the First Chain\n",
    "5. Define the Second Chain\n",
    "6. Define the Sequential Chain\n",
    "7. Run the Sequential Chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mktjBNPmRf96",
   "metadata": {
    "id": "mktjBNPmRf96"
   },
   "source": [
    "# __Description__:\n",
    "In this activity, let's explore how to use LangChain’s Sequential Chain functionality. This tutorial is designed to demonstrate the use of LangChain’s Sequential Chain in the context of a hypothetical TV show called **Banking Chronicles**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YyGPa0RFR1c_",
   "metadata": {
    "id": "YyGPa0RFR1c_"
   },
   "source": [
    "# **Step 1: Import the Necessary Modules**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5154ca7b-42d8-48f4-9d07-9df277613963",
   "metadata": {
    "id": "5154ca7b-42d8-48f4-9d07-9df277613963"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "from getpass import getpass\n",
    "\n",
    "\n",
    "import langchain\n",
    "import openai\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Chroma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HRKgJKoBR8JO",
   "metadata": {
    "id": "HRKgJKoBR8JO"
   },
   "source": [
    "# **Step 2: Define a Function to Print Responses from Our Chains**\n",
    "\n",
    "\n",
    "*   This function is used throughout the tutorial to display the outputs of our chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63ecd79-f70b-466a-b527-64139df3063d",
   "metadata": {
    "id": "d63ecd79-f70b-466a-b527-64139df3063d"
   },
   "outputs": [],
   "source": [
    "def display_response(response: str):\n",
    "    print(\"\\n\".join(textwrap.wrap(response, width=100)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JhChhvhaSF-s",
   "metadata": {
    "id": "JhChhvhaSF-s"
   },
   "source": [
    "# **Step 3: Initialize the Chat Model**\n",
    "\n",
    "\n",
    "*   This model generates the responses for our chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80e73233-300b-4350-8e92-50590c16e9a7",
   "metadata": {
    "id": "80e73233-300b-4350-8e92-50590c16e9a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_138/3679663539.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat_model = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chat_model = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368bfa9c-8949-41c0-8fbc-8532f85fe66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1---->2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WfIEHfihSUve",
   "metadata": {
    "id": "WfIEHfihSUve"
   },
   "source": [
    "# **Step 4: Define the First Chain**\n",
    "\n",
    "\n",
    "*   Define the first chain, which generates a scenario for a new episode based on a given theme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dece129f-4852-4e61-89a0-3aa65dd23728",
   "metadata": {
    "id": "dece129f-4852-4e61-89a0-3aa65dd23728"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_138/2663209342.py:11: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  scenario_chain = LLMChain(llm=chat_model, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "scenario_template = \"\"\"\n",
    "You have to come up with a scenario (along with a 20-50 word description)\n",
    "for a new episode of the TV show \"Banking Chronicles\" based on the theme\n",
    "\n",
    "{theme_input}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"theme_input\"], template=scenario_template)\n",
    "\n",
    "scenario_chain = LLMChain(llm=chat_model, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jqM7Bnm3SdMq",
   "metadata": {
    "id": "jqM7Bnm3SdMq"
   },
   "source": [
    "# **Step 5: Define the Second Chain**\n",
    "\n",
    "\n",
    "*   Define the second chain, which generates a dialogue based on the scenario created by the first chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d4173b6-f525-483b-9818-1dbcc8005c0b",
   "metadata": {
    "id": "9d4173b6-f525-483b-9818-1dbcc8005c0b"
   },
   "outputs": [],
   "source": [
    "\n",
    "dialogue_template = \"\"\"\n",
    "Generate a short dialogue between the bank manager and a customer\n",
    "from the TV show \"Banking Chronicles\" for a new episode based on the scenario\n",
    "\n",
    "{scenario}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"scenario\"], template=dialogue_template)\n",
    "\n",
    "dialogue_chain = LLMChain(llm=chat_model, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KOvT-u20SmlX",
   "metadata": {
    "id": "KOvT-u20SmlX"
   },
   "source": [
    "# **Step 6: Define the Sequential Chain**\n",
    "\n",
    "\n",
    "\n",
    "*   Define the Sequential Chain, which chains the scenario and dialogue together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d85380a-43e3-4fea-8c8c-f7b9ae7eb8e7",
   "metadata": {
    "id": "4d85380a-43e3-4fea-8c8c-f7b9ae7eb8e7"
   },
   "outputs": [],
   "source": [
    "sequential_chain = SimpleSequentialChain(\n",
    "    chains=[scenario_chain, dialogue_chain], verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QJD63eTfSy19",
   "metadata": {
    "id": "QJD63eTfSy19"
   },
   "source": [
    "# **Step 7: Run the Sequential Chain**\n",
    "\n",
    "\n",
    "*   Run the Sequential Chain with the **Investment Strategies** theme and print the resulting conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "387dc95d-c19b-483b-9f94-a0687dd6722a",
   "metadata": {
    "id": "387dc95d-c19b-483b-9f94-a0687dd6722a",
    "outputId": "2cf0e540-75f1-425d-e2da-74abb8aa5871"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank Manager: Good morning, how can I assist you today?\n",
      "\n",
      "Customer: Hi, I'm interested in learning more about different investment options. I want to diversify my portfolio and maximize my returns.\n",
      "\n",
      "Bank Manager: That's great to hear! We have a range of investment options available, from traditional stocks and bonds to alternative choices like real estate and cryptocurrency. Have you considered what type of risk you're comfortable with?\n",
      "\n",
      "Customer: I'm open to exploring different options, but I want to make sure I manage my risk effectively.\n",
      "\n",
      "Bank Manager: That's a smart approach. We can discuss your financial goals and risk tolerance in more detail to tailor a personalized investment strategy for you. Would you like to schedule a meeting with one of our financial experts?\n",
      "\n",
      "Customer: Yes, that would be great. I want to make informed decisions and grow my wealth wisely.\n",
      "\n",
      "Bank Manager: Perfect, let's set up a meeting to discuss your investment goals and create a diversified portfolio that suits your needs. Thank you for choosing our bank for your financial journey.\n"
     ]
    }
   ],
   "source": [
    "response = sequential_chain.run(\"Investment Strategies\")\n",
    "conversation = response\n",
    "print(conversation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knKwd6W9S91I",
   "metadata": {
    "id": "knKwd6W9S91I"
   },
   "source": [
    "# **Conclusion**\n",
    "\n",
    "In this activity, a step-by-step guide on how to use LangChain’s Sequential Chain functionality is provided. You now know how to chain multiple models, with the output of one model serving as the input to the next. This allows you to create complex workflows and generate creative content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9533b098-d486-4c7e-822d-f8cd04aacdc0",
   "metadata": {
    "id": "9533b098-d486-4c7e-822d-f8cd04aacdc0"
   },
   "outputs": [],
   "source": [
    "scenario_template = \"\"\"\n",
    "Summarize\n",
    "\n",
    "{topic}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"topic\"], template=scenario_template)\n",
    "\n",
    "f_chain = LLMChain(llm=chat_model, prompt=prompt, output_key=\"summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a3a9731-b822-4718-8851-5128f1433ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "using this \n",
    "\n",
    "{summary}, write an engaging introduction for an {audience}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "prompt1 = PromptTemplate(input_variables=[\"summary\", \"audience\"], template=template)\n",
    "\n",
    "s_chain = LLMChain(llm=chat_model, prompt=prompt1, output_key=\"blog_intro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5a44b61-1208-47fa-b468-44e6b9808b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "overall_chain = SequentialChain(chains=[f_chain, s_chain],\n",
    "                input_variables=[\"topic\", \"audience\"],#multiple inputs\n",
    "               output_variables=[\"summary\", \"blog_intro\"], #multiple output\n",
    "                                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1b5f5cc-aafa-4a50-b46b-81a6f8e743ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Generative AI refers to artificial intelligence systems that are capable of creating new content, such as images, text, or music, based on patterns and data they have been trained on. These systems can generate realistic and original content that mimics human creativity.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = overall_chain.run({\"topic\":\"Generative AI\",\n",
    "                              \"audience\": \"students\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f5617d-49f4-4535-90fc-9be43add285a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
